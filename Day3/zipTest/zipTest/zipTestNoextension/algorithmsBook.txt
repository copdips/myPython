 www.it-ebooks.info
Algorithms
FOURTH EDITION
PART I
www.it-ebooks.info

This page intentionally left blank
www.it-ebooks.info

Algorithms
FOURTH EDITION
PART I
Robert Sedgewick and
Kevin Wayne
Princeton University
               Upper Saddle River, NJ • Boston • Indianapolis • San Francisco New York • Toronto • Montreal • London • Munich • Paris • Madrid Capetown • Sydney • Tokyo • Singapore • Mexico City
www.it-ebooks.info

Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed with initial capital letters or in all capitals.
The authors and publisher have taken care in the preparation of this book, but make no expressed or im- plied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.
For information about buying this title in bulk quantities, or for special sales opportunities (which may include electronic versions; custom cover designs; and content particular to your business, training goals, marketing focus, or branding interests), please contact our corporate sales department at (800) 382-3419 or corpsales@pearsoned.com.
For government sales inquiries, please contact governmentsales@pearsoned.com.
For questions about sales outside the United States, please contact international@pearsoned.com. Visit us on the Web: informit.com/aw
Copyright © 2014 Pearson Education, Inc.
All rights reserved. Printed in the United States of America. This publication is protected by copyright, and permission must be obtained from the publisher prior to any prohibited reproduction, storage in a retriev- al system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain permission to use material from this work, please submit a written request to Pearson Education, Inc., Permissions Department, One Lake Street, Upper Saddle River, New Jersey 07458, or you may fax your request to (201) 236-3290.
ISBN-13: 978-0-13-379869-2 ISBN-10: 0-13-379869-0
First digital release, February 2014
www.it-ebooks.info

______________________________
To Adam, Andrew, Brett, Robbie and especially Linda ______________________________
     ___________________
To Jackie and Alex ___________________
www.it-ebooks.info

CONTENTS
Note: This is an online edition of Chapters 1 through 3 of Algorithms, Fourth Edition, which con- tains the content covered in our online course Algorithms, Part I.
Preface ix
1. Fundamentals . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.1 Basic Programming Model 8
Primitive data types • Loops and conditionals • Arrays • Static methods • Recursion • APIs • Strings • Input and output • Binary search
1.2 Data Abstraction 64
Objects • Abstract data types • Implementing ADTs • Designing ADTs
1.3 Bags, Queues, and Stacks 120
APIs • Arithmetic expression evaluation • Resizing arrays • Generics • Iterators • Linked lists
1.4 Analysis of Algorithms 172
Running time • Computational experiments • Tilde notation • Order-of- growth classi cations • Amortized analysis • Memory usage
1.5 Case Study: Union-Find 216
Dynamic connectivity • Quick  nd • Quick union • Weighted quick union
www.it-ebooks.info

2. Sorting . . . . . . . . . . . . . . . . . . . . . . . . . . .243
2.1 Elementary Sorts 244
Rules of the game • Selection sort • Insertion sort • Shellsort
2.2 Mergesort 270
Abstract in-place merge • Top-down mergesort • Bottom-up mergesort • N lg N lower bound for sorting
2.3 Quicksort 288
In-place partitioning • Randomized quicksort • 3-way partitioning
2.4 Priority Queues 308
Priority queue API • Elementary implementations • Binary heap • Heapsort
2.5 Applications 336
Comparators • Stability • Median and order statistics
3. Searching . . . . . . . . . . . . . . . . . . . . . . . . . .361
3.1 Symbol Tables 362
Symbol table API • Ordered symbol table API • Dedup • Frequency counter • Sequential search • Binary search
3.2 Binary Search Trees 396
Basic implementation • Order-based methods • Deletion
3.3 Balanced Search Trees 424
2-3 search trees • Red-black BSTs • Deletion
3.4 Hash Tables 458
Hash functions • Separate chaining • Linear probing
3.5 Applications 486
Set data type • Whitelist and blacklist  lters • Dictionary lookup • Inverted index • File indexing • Sparse matrix-vector multiplication
Chapters 4 through 6, which correspond to our online course Algorithms, Part II, are available as Algorithms, Fourth Edition, Part II.
For more information, see http://algs4.cs.princeton.edu.
www.it-ebooks.info

This page intentionally left blank
www.it-ebooks.info

PREFACE
This book is intended to survey the most important computer algorithms in use today, and to teach fundamental techniques to the growing number of people in need of knowing them. It is intended for use as a textbook for a second course in computer science, after students have acquired basic programming skills and familiarity with computer systems. The book also may be useful for self-study or as a reference for people engaged in the development of computer systems or applications programs, since it contains implemen- tations of useful algorithms and detailed information on performance characteristics and clients. The broad perspective taken makes the book an appropriate introduction to the  eld.
the study of algorithms and data structures is fundamental to any computer-science curriculum, but it is not just for programmers and computer-science students. Everyone who uses a computer wants it to run faster or to solve larger problems. The algorithms in this book represent a body of knowledge developed over the last 50 years that has become indispens- able. From N-body simulation problems in physics to genetic-sequencing problems in mo- lecular biology, the basic methods described here have become essential in scienti c research; from architectural modeling systems to aircraft simulation, they have become essential tools in engineering; and from database systems to internet search engines, they have become es- sential parts of modern software systems. And these are but a few examples—as the scope of computer applications continues to grow, so grows the impact of the basic methods covered here.
In Chapter 1, we develop our fundamental approach to studying algorithms, includ- ing coverage of data types for stacks, queues, and other low-level abstractions that we use throughout the book. In Chapters 2 and 3, we survey fundamental algorithms for sorting and searching; and in Chapters 4 and 5, we cover algorithms for processing graphs and strings. Chapter 6 is an overview placing the rest of the material in the book in a larger context.
ix
www.it-ebooks.info

x
Distinctive features The orientation of the book is to study algorithms likely to be of practical use. The book teaches a broad variety of algorithms and data structures and pro- vides suf cient information about them that readers can con dently implement, debug, and put them to work in any computational environment. The approach involves:
Algorithms. Our descriptions of algorithms are based on complete implementations and on a discussion of the operations of these programs on a consistent set of examples. Instead of presenting pseudo-code, we work with real code, so that the programs can quickly be put to practical use. Our programs are written in Java, but in a style such that most of our code can be reused to develop implementations in other modern programming languages.
Data types. We use a modern programming style based on data abstraction, so that algo- rithms and their data structures are encapsulated together.
Applications. Each chapter has a detailed description of applications where the algorithms described play a critical role. These range from applications in physics and molecular biology, to engineering computers and systems, to familiar tasks such as data compression and search- ing on the web.
A scienti c approach We emphasize developing mathematical models for describing the performance of algorithms, using the models to develop hypotheses about performance, and then testing the hypotheses by running the algorithms in realistic contexts.
Breadth of coverage We cover basic abstract data types, sorting algorithms, searching al- gorithms, graph processing, and string processing. We keep the material in algorithmic con- text, describing data structures, algorithm design paradigms, reduction, and problem-solving models. We cover classic methods that have been taught since the 1960s and new methods that have been invented in recent years.
Our primary goal is to introduce the most important algorithms in use today to as wide an audience as possible. These algorithms are generally ingenious creations that, remarkably, can each be expressed in just a dozen or two lines of code. As a group, they represent problem- solving power of amazing scope. They have enabled the construction of computational ar- tifacts, the solution of scienti c problems, and the development of commercial applications that would not have been feasible without them.
www.it-ebooks.info

Booksite An important feature of the book is its relationship to the online booksite algs4.cs.princeton.edu. This site is freely available and contains an extensive amount of material about algorithms and data structures, for teachers, students, and practitioners, in- cluding:
An online synopsis. The text is summarized in the booksite to give it the same overall struc- ture as the book, but linked so as to provide easy navigation through the material.
Full implementations All code in the book is available on the booksite, in a form suitable for program development. Many other implementations are also available, including advanced implementations and improvements described in the book, answers to selected exercises, and client code for various applications. The emphasis is on testing algorithms in the context of meaningful applications.
Exercises and answers The booksite expands on the exercises in the book by adding drill exercises (with answers available with a click), a wide variety of examples illustrating the reach of the material, programming exercises with code solutions, and challenging problems.
Dynamic visualizations Dynamic simulations are impossible in a printed book, but the website is replete with implementations that use a graphics class to present compelling visual demonstrations of algorithm applications.
Course materials A complete set of lecture slides is tied directly to the material in the book and on the booksite. A full selection of programming assignments, with check lists, test data, and preparatory material, is also included.
Online course A full set of lecture videos and self-assessment materials provide opportuni- ties for students to learn or review the material on their own and for instructors to replace or supplement their lectures.
Links to related material Hundreds of links lead students to background information about applications and to resources for studying algorithms.
Our goal in creating this material was to provide a complementary approach to the ideas. Generally, you should read the book when learning speci c algorithms for the  rst time or when trying to get a global picture, and you should use the booksite as a reference when pro- gramming or as a starting point when searching for more detail while online.
xi
www.it-ebooks.info

xii
Use in the curriculum The book is intended as a textbook in a second course in com- puter science. It provides full coverage of core material and is an excellent vehicle for stu- dents to gain experience and maturity in programming, quantitative reasoning, and problem- solving. Typically, one course in computer science will suf ce as a prerequisite—the book is intended for anyone conversant with a modern programming language and with the basic features of modern computer systems.
The algorithms and data structures are expressed in Java, but in a style accessible to people  uent in other modern languages. We embrace modern Java abstractions (including generics) but resist dependence upon esoteric features of the language.
Most of the mathematical material supporting the analytic results is self-contained (or is labeled as beyond the scope of this book), so little speci c preparation in mathematics is required for the bulk of the book, although mathematical maturity is de nitely helpful. Ap- plications are drawn from introductory material in the sciences, again self-contained.
The material covered is a fundamental background for any student intending to major in computer science, electrical engineering, or operations research, and is valuable for any student with interests in science, mathematics, or engineering.
Context The book is intended to follow our introductory text, An Introduction to Pro- gramming in Java: An Interdisciplinary Approach, which is a broad introduction to the  eld. Together, these two books can support a two- or three-semester introduction to computer sci- ence that will give any student the requisite background to successfully address computation in any chosen  eld of study in science, engineering, or the social sciences.
The starting point for much of the material in the book was the Sedgewick series of Al- gorithms books. In spirit, this book is closest to the  rst and second editions of that book, but this text bene ts from decades of experience teaching and learning that material. Sedgewick’s current Algorithms in C/C++/Java, Third Edition is more appropriate as a reference or a text for an advanced course; this book is speci cally designed to be a textbook for a one-semester course for  rst- or second-year college students and as a modern introduction to the basics and a reference for use by working programmers.
www.it-ebooks.info

Acknowledgments This book has been nearly 40 years in the making, so full recogni- tion of all the people who have made it possible is simply not feasible. Earlier editions of this book list dozens of names, including (in alphabetical order) Andrew Appel, Trina Avery, Marc Brown, Lyn Dupré, Philippe Flajolet, Tom Freeman, Dave Hanson, Janet Incerpi, Mike Schid- lowsky, Steve Summit, and Chris Van Wyk. All of these people deserve acknowledgement, even though some of their contributions may have happened decades ago. For this fourth edition, we are grateful to the hundreds of students at Princeton and several other institutions who have suffered through preliminary versions of the work, and to readers around the world for sending in comments and corrections through the booksite.
We are grateful for the support of Princeton University in its unwavering commitment to excellence in teaching and learning, which has provided the basis for the development of this work.
Peter Gordon has provided wise counsel throughout the evolution of this work almost from the beginning, including a gentle introduction of the “back to the basics” idea that is the foundation of this edition. For this fourth edition, we are grateful to Barbara Wood for her careful and professional copyediting, to Julie Nahil for managing the production, and to many others at Pearson for their roles in producing and marketing the book. All were ex- tremely responsive to the demands of a rather tight schedule without the slightest sacri ce to the quality of the result.
Robert Sedgewick Kevin Wayne
Princeton, New Jersey January 2014
www.it-ebooks.info
xiii

 one
Fundamentals
1.1 Basic Programming Model 8
1.2 Data Abstraction 64
1.3 Bags, Queues, and Stacks 120
1.4 Analysis of Algorithms 172
1.5 Case Study: Union-Find 216
     www.it-ebooks.info
 The objective of this book is to study a broad variety of important and useful algorithms—methods for solving problems that are suited for computer imple- mentation. Algorithms go hand in hand with data structures—schemes for or- ganizing data that leave them amenable to ef cient processing by an algorithm. This chapter introduces the basic tools that we need to study algorithms and data structures.
First, we introduce our basic programming model. All of our programs are imple- mented using a small subset of the Java programming language plus a few of our own libraries for input/output and for statistical calculations. Section 1.1 is a summary of language constructs, features, and libraries that we use in this book.
Next, we emphasize data abstraction, where we de ne abstract data types (ADTs) in the service of modular programming. In Section 1.2 we introduce the process of im- plementing an ADT in Java, by specifying an applications programming interface (API) and then using the Java class mechanism to develop an implementation for use in client code.
As important and useful examples, we next consider three fundamental ADTs: the bag, the queue, and the stack. Section 1.3 describes APIs and implementations of bags, queues, and stacks using arrays, resizing arrays, and linked lists that serve as models and starting points for algorithm implementations throughout the book.
Performance is a central consideration in the study of algorithms. Section 1.4 de- scribes our approach to analyzing algorithm performance. The basis of our approach is the scienti c method: we develop hypotheses about performance, create mathematical models, and run experiments to test them, repeating the process as necessary.
We conclude with a case study where we consider solutions to a connectivity problem that uses algorithms and data structures that implement the classic union- nd ADT.
www.it-ebooks.info
3

4 Chapter 1 n Fundamentals
Algorithms When we write a computer program, we are generally implementing a method that has been devised previously to solve some problem. This method is often independent of the particular programming language being used—it is likely to be equally appropriate for many computers and many programming languages. It is the method, rather than the computer program itself, that speci es the steps that we can take to solve the problem. The term algorithm is used in computer science to describe a  nite, deterministic, and effective problem-solving method suitable for implementa- tion as a computer program. Algorithms are the stuff of computer science: they are central objects of study in the  eld.
 We can de ne an algorithm by describing a procedure for solving a problem in a natural language, or by writing a computer program that implements the procedure, as shown at right for Euclid’s algorithm for  nding the greatest common divisor of two numbers, a variant of which was devised
over 2,300 years ago. If you are not familiar
with Euclid’s algorithm, you are encour-
aged to work Exercise 1.1.24 and Exercise
1.1.25, perhaps after reading Section 1.1. In
this book, we use computer programs to de-
scribe algorithms. One important reason for
doing so is that it makes easier the task of
checking whether they are  nite, determin-
istic, and effective, as required. But it is also
important to recognize that a program in a
particular language is just one way to express
an algorithm. The fact that many of the al-
gorithms in this book have been expressed
in multiple programming languages over the
past several decades reinforces the idea that each algorithm is a method suitable for implementation on any computer in any programming language.
Most algorithms of interest involve organizing the data involved in the computa- tion. Such organization leads to data structures, which also are central objects of study in computer science. Algorithms and data structures go hand in hand. In this book we take the view that data structures exist as the byproducts or end products of algorithms and that we must therefore study them in order to understand the algorithms. Simple algorithms can give rise to complicated data structures and, conversely, complicated algorithms can use simple data structures. We shall study the properties of many data structures in this book; indeed, we might well have titled the book Algorithms and Data Structures.
www.it-ebooks.info
English-language description
Java-language description
Compute the greatest common divisor of two nonnegative integers p and q as follows: If q is 0, the answer is p. If not, divide p by q and take the remainder r. The answer is the greatest common divisor of q and r.
public static int gcd(int p, int q)
{
}
if (q == 0) return p;
int r = p % q;
return gcd(q, r);
Euclid’s algorithm

When we use a computer to help us solve a problem, we typically are faced with a number of possible approaches. For small problems, it hardly matters which approach we use, as long as we have one that correctly solves the problem. For huge problems (or applications where we need to solve huge numbers of small problems), however, we quickly become motivated to devise methods that use time and space ef ciently.
The primary reason to learn about algorithms is that this discipline gives us the potential to reap huge savings, even to the point of enabling us to do tasks that would otherwise be impossible. In an application where we are processing millions of objects, it is not unusual to be able to make a program millions of times faster by using a well- designed algorithm. We shall see such examples on numerous occasions throughout the book. By contrast, investing additional money or time to buy and install a new computer holds the potential for speeding up a program by perhaps a factor of only 10 or 100. Careful algorithm design is an extremely effective part of the process of solving a huge problem, whatever the applications area.
When developing a huge or complex computer program, a great deal of effort must go into understanding and de ning the problem to be solved, managing its complex- ity, and decomposing it into smaller subtasks that can be implemented easily. Often, many of the algorithms required after the decomposition are trivial to implement. In most cases, however, there are a few algorithms whose choice is critical because most of the system resources will be spent running those algorithms. These are the types of algorithms on which we concentrate in this book. We study fundamental algorithms that are useful for solving challenging problems in a broad variety of applications areas.
The sharing of programs in computer systems is becoming more widespread, so although we might expect to be using a large fraction of the algorithms in this book, we also might expect to have to implement only a small fraction of them. For example, the Java libraries contain implementations of a host of fundamental algorithms. However, implementing simple versions of basic algorithms helps us to understand them bet- ter and thus to more effectively use and tune advanced versions from a library. More important, the opportunity to reimplement basic algorithms arises frequently. The pri- mary reason to do so is that we are faced, all too often, with completely new computing environments (hardware and software) with new features that old implementations may not use to best advantage. In this book, we concentrate on the simplest reasonable implementations of the best algorithms. We do pay careful attention to coding the criti- cal parts of the algorithms, and take pains to note where low-level optimization effort could be most bene cial.
Choosing the best algorithm for a particular task can be a complicated process, per- haps involving sophisticated mathematical analysis. The branch of computer science that comprises the study of such questions is called analysis of algorithms. Many of the
Chapter 1 n Fundamentals 5
 www.it-ebooks.info

6 Chapter 1 n Fundamentals
algorithms that we study have been shown through analysis to have excellent theoreti- cal performance; others are simply known to work well through experience. Our pri- mary goal is to learn reasonable algorithms for important tasks, yet we shall also pay careful attention to comparative performance of the methods. We should not use an algorithm without having an idea of what resources it might consume, so we strive to be aware of how our algorithms might be expected to perform.
Summary of topics As an overview, we describe the major parts of the book, giv- ing speci c topics covered and an indication of our general orientation toward the material. This set of topics is intended to touch on as many fundamental algorithms as possible. Some of the areas covered are core computer-science areas that we study in depth to learn basic algorithms of wide applicability. Other algorithms that we discuss are from advanced  elds of study within computer science and related  elds. The algo- rithms that we consider are the products of decades of research and development and continue to play an essential role in the ever-expanding applications of computation.
Fundamentals (Chapter 1) in the context of this book are the basic principles and methodology that we use to implement, analyze, and compare algorithms. We consider our Java programming model, data abstraction, basic data structures, abstract data types for collections, methods of analyzing algorithm performance, and a case study.
Sorting algorithms (Chapter 2) for rearranging arrays in order are of fundamental importance. We consider a variety of algorithms in considerable depth, including in- sertion sort, selection sort, shellsort, quicksort, mergesort, and heapsort. We also en- counter algorithms for several related problems, including priority queues, selection, and merging. Many of these algorithms will  nd application as the basis for other algo- rithms later in the book.
Searching algorithms (Chapter 3) for  nding speci c items among large collections of items are also of fundamental importance. We discuss basic and advanced methods for searching, including binary search trees, balanced search trees, and hashing. We note relationships among these methods and compare performance.
Graphs (Chapter 4) are sets of objects and connections, possibly with weights and orientation. Graphs are useful models for a vast number of dif cult and important problems, and the design of algorithms for processing graphs is a major  eld of study. We consider depth- rst search, breadth- rst search, connectivity problems, and sev- eral algorithms and applications, including Kruskal’s and Prim’s algorithms for  nding minimum spanning tree and Dijkstra’s and the Bellman-Ford algorithms for solving shortest-paths problems.
 www.it-ebooks.info

Strings (Chapter 5) are an essential data type in modern computing applications. We consider a range of methods for processing sequences of characters. We begin with faster algorithms for sorting and searching when keys are strings. Then we consider substring search, regular expression pattern matching, and data-compression algo- rithms. Again, an introduction to advanced topics is given through treatment of some elementary problems that are important in their own right.
Context (Chapter6)helpsusrelatethematerialinthebooktoseveralotheradvanced  elds of study, including scienti c computing, operations research, and the theory of computing. We survey event-driven simulation, B-trees, suf x arrays, maximum  ow, and other advanced topics from an introductory viewpoint to develop appreciation for the interesting advanced  elds of study where algorithms play a critical role. Finally, we describe search problems, reduction, and NP-completeness to introduce the theoretical underpinnings of the study of algorithms and relationships to material in this book.
The study of algorithms is interesting and exciting because it is a new  eld (almost all the algorithms that we study are less than 50 years old, and some were just recently discovered) with a rich tradition (a few algorithms have been known for hun- dreds of years). New discoveries are constantly being made, but few algorithms are completely understood. In this book we shall consider intricate, complicated, and dif - cult algorithms as well as elegant, simple, and easy ones. Our challenge is to understand the former and to appreciate the latter in the context of scienti c and commercial ap- plications. In doing so, we shall explore a variety of useful tools and develop a style of algorithmic thinking that will serve us well in computational challenges to come.
Chapter 1 n Fundamentals 7
 www.it-ebooks.info

   8
Our study of algorithms is based upon implementing them as programs written in the Java programming language. We do so for several reasons:
n Our programs are concise, elegant, and complete descriptions of algorithms. n You can run the programs to study properties of the algorithms.
n You can put the algorithms immediately to good use in applications.
These are important and signi cant advantages over the alternatives of working with English-language descriptions of algorithms.
A potential downside to this approach is that we have to work with a speci c pro- gramming language, possibly making it dif cult to separate the idea of the algorithm from the details of its implementation. Our implementations are designed to mitigate this dif culty, by using programming constructs that are both found in many modern languages and needed to adequately describe the algorithms.
We use only a small subset of Java. While we stop short of formally de ning the subset that we use, you will see that we make use of relatively few Java constructs, and that we emphasize those that are found in many modern programming languages. The code that we present is complete, and our expectation is that you will download it and execute it, on our test data or test data of your own choosing.
We refer to the programming constructs, software libraries, and operating system features that we use to implement and describe algorithms as our programming model. In this section and Section 1.2, we fully describe this programming model. The treat- ment is self-contained and primarily intended for documentation and for your refer- ence in understanding any code in the book. The model we describe is the same model introduced in our book An Introduction to Programming in Java: An Interdisciplinary Approach, which provides a slower-paced introduction to the material.
For reference, the  gure on the facing page depicts a complete Java program that illustrates many of the basic features of our programming model. We use this code for examples when discussing language features, but defer considering it in detail to page 46 (it implements a classic algorithm known as binary search and tests it for an applica- tion known as whitelist  ltering). We assume that you have experience programming in some modern language, so that you are likely to recognize many of these features in this code. Page references are included in the annotations to help you  nd answers to any questions that you might have. Since our code is somewhat stylized and we strive to make consistent use of various Java idioms and constructs, it is worthwhile even for experienced Java programmers to read the information in this section.
www.it-ebooks.info
 1.1 BASiC ProgrAMMing MoDel

 import a Java library (see page 27)
public class BinarySearch
{
1.1 n Basic Programming Model 9 code must be in file BinarySearch.java (see page 26)
parameter
variables static method (see page 22)
 import java.util.Arrays;
   while (lo <= hi)
{
 expression (see page 11) int mid = lo + (hi - lo) / 2;
 }
if      (key < a[mid]) hi = mid - 1;
else if (key > a[mid]) lo = mid + 1;
else                   return mid;
 initializing declaration statement (see page 16)
loop statement (see page 15)
{
} }
}
command line (see page 36)
StdOut
(see page 37)
parameter type
public static int rank(int key, int[] a)
  { return type int lo = 0;
       int hi = a.length - 1;
return -1;
return statement system calls main()
public static void main(String[] args)
  }
unit test client (see page 26)
 if (rank(key, whitelist) == -1)
   StdOut.println(key);
      no return value; just side effects (see page 24)
int[] whitelist = In.readInts(args[0]);
Arrays.sort(whitelist); call a method in a Java library (see page 27)
   while (!StdIn.isEmpty())
{
call a method in our standard library; need to download code (see page 27)
  conditional statement (see page 15)
int key = StdIn.readInt();
call a local method (see page 27)
system passes argument value "largeW.txt" tomain()
           file name (args[0])
          % java BinarySearch largeW.txt < largeT.txt
 499569
984875
...
file redirected from StdIn (see page 40)
      Anatomy of a Java program and its invocation from the command line
www.it-ebooks.info

10 Chapter 1 n Fundamentals
Basic structure of a Java program A Java program (class) is either a library of static methods (functions) or a data type de nition. To create libraries of static methods and data-type de nitions, we use the following seven components, the basis of pro- gramming in Java and many other modern languages:
n Primitive data types precisely de ne the meaning of terms like integer, real num- ber, and boolean value within a computer program. Their de nition includes the set of possible values and operations on those values, which can be combined into expressions like mathematical expressions that de ne values.
n Statements allow us to de ne a computation by creating and assigning values to variables, controlling execution  ow, or causing side effects. We use six types of statements: declarations, assignments, conditionals, loops, calls, and returns.
n Arrays allow us to work with multiple values of the same type.
n Static methods allow us to encapsulate and reuse code and to develop programs
as a set of independent modules.
n Strings are sequences of characters. Some operations on them are built into Java. n Input/output sets up communication between programs and the outside world. n Data abstraction extends encapsulation and reuse to allow us to de ne non-
primitive data types, thus supporting object-oriented programming.
In this section, we will consider the  rst  ve of these in turn. Data abstraction is the topic of the next section.
Running a Java program involves interacting with an operating system or a program development environment. For clarity and economy, we describe such actions in terms of a virtual terminal, where we interact with programs by typing commands to the system. See the booksite for details on using a virtual terminal on your system, or for information on using one of the many more advanced program development environ- ments that are available on modern systems.
For example, BinarySearch is two static methods, rank() and main(). The  rst static method, rank(), is four statements: two declarations, a loop (which is itself an as- signment and two conditionals), and a return. The second, main(), is three statements: a declaration, a call, and a loop (which is itself an assignment and a conditional).
To invoke a Java program, we  rst compile it using the javac command, then run it using the java command. For example, to run BinarySearch, we  rst type the com- mand javac BinarySearch.java (which creates a  le BinarySearch.class that contains a lower-level version of the program in Java bytecode). Then we type java BinarySearch (followed by a whitelist  le name) to transfer control to the bytecode version of the program. To develop a basis for understanding the effect of these actions, we next consider in detail primitive data types and expressions, the various kinds of Java statements, arrays, static methods, strings, and input/output.
 www.it-ebooks.info

Primitive data types and expressions A data type is a set of values and a set of operations on those values. We begin by considering the following four primitive data types that are the basis of the Java language:
n Integers, with arithmetic operations (int)
n Real numbers, again with arithmetic operations (double)
n Booleans, the set of values { true, false } with logical operations (boolean) n Characters, the alphanumeric characters and symbols that you type (char)
Next we consider mechanisms for specifying values and operations for these types.
A Java program manipulates variables that are named with identi ers. Each variable is associated with a data type and stores one of the permissible data-type values. In Java code, we use expressions like familiar mathematical expressions to apply the operations associated with each type. For primitive types, we use identi ers to refer to variables, operator symbols such as + - * / to specify operations, literals such as 1 or 3.14 to specifyvalues,andexpressionssuchas(x + 2.236)/2tospecifyoperationsonvalues.
The purpose of an expression is to de ne one of the data-type values.
term examples definition
1.1 n Basic Programming Model 11
  primitive data type
identi er
variable operator
literal
expression
int double boolean char
a set of values and a set of operations on those values (built into the Java language)
a sequence of letters, digits, _, and $, the  rst of which is not a digit
names a data-type value names a data-type operation
source-code representation of a value
a literal, a variable, or a sequence of operations on literals and/or variables that produces a value
a  abc  Ab$  a_b  ab123
[any identi er] + - * /
lo hi
int 1 0 -42 double 2.0 1.0e-15 3.14
boolean
char 'a' '+' '9' '\n'
int lo + (hi - lo)/2 double 1.0e-15 * t
boolean lo <= hi
true false
Basic building blocks for Java programs
 www.it-ebooks.info

12 Chapter 1 n Fundamentals
To de ne a data type, we need only specify the values and the set of operations on those values. This information is summarized in the table below for Java’s int, double, boolean, and char data types. These data types are similar to the basic data types found in many programming languages. For int and double, the operations are familiar arithmetic operations; for boolean, they are familiar logical operations. It is important to note that +, -, *, and / are overloaded—the same symbol speci es operations in mul- tiple different types, depending on context. The key property of these primitive opera- tions is that an operation involving values of a given type has a value of that type. This rule highlights the idea that we are often working with approximate values, since it is often the case that the exact value that would seem to be de ned by the expression is not a value of the type. For example, 5/3 has the value 1 and 5.0/3.0 has a value very close to 1.66666666666667 but neither of these is exactly equal to 5/3. This table is far from complete; we discuss some additional operators and various exceptional situations that we occasionally need to consider in the Q&A at the end of this section.
 type
int
double
boolean
char
set of values
integers between 231 and231 1 (32-bit two’s complement)
double-precision real numbers (64-bit IEEE 754 standard)
true or false
characters (16-bit)
operators
+ (add)
- (subtract) * (multiply) / (divide)
% (remainder)
+ (add)
- (subtract) * (multiply) / (divide)
&& (and) || (or) ! (not) ^ (xor)
typical expressions
[arithmetic operations, rarely used] primitive data types in Java
www.it-ebooks.info
expression
5+ 3 5- 3 5* 3 5/ 3 5% 3
 3.141 - .03
2.0 - 2.0e-7
  100 * .015
6.02e23 / 2.0
true && false
false || true
    !false
 true ^ true
value
8
2 15 1 2
  3.111
1.9999998
   1.5
 3.01e23
  false
   true
   true
  false

Expressions As illustrated in the table at the bottom of the previous page, typical ex- pressions are in x: a literal (or an expression), followed by an operator, followed by another literal (or another expression). When an expression contains more than one operator, the order in which they are applied is often signi cant, so the following pre- cedence conventions are part of the Java language speci cation: The operators * and / (and %) have higher precedence than (are applied before) the + and - operators; among logical operators, ! is the highest precedence, followed by && and then ||. Generally, operators of the same precedence are applied left to right. As in standard arithmetic ex- pressions, you can use parentheses to override these rules. Since precedence rules vary slightly from language to language, we use parentheses and otherwise strive to avoid dependence on precedence rules in our code.
Type conversion Numbers are automatically promoted to a more inclusive type if no information is lost. For example, in the expression 1 + 2.5 , the 1 is promoted to the double value 1.0 and the expression evaluates to the double value 3.5 . A cast is a type name in parentheses within an expression, a directive to convert the following value intoavalueofthattype.Forexample(int) 3.7is3and(double) 3is3.0.Notethat casting to an int is truncation instead of rounding—rules for casting within compli- cated expressions can be intricate, and casts should be used sparingly and with care. A best practice is to use expressions that involve literals or variables of a single type.
Comparisons The following operators compare two values of the same type and produce a boolean value: equal (==), not equal (!=), less than (<), less than or equal (<=), greater than (>), and greater than or equal (>=). These operators are known as mixed-type operators because their value is boolean, not the type of the values being compared. An expression with a boolean value is known as a boolean expression. Such expressions are essential components in conditional and loop statements, as we will see.
Other primitive types Java’s int has 232 different values by design, so it can be repre- sented in a 32-bit machine word (many machines have 64-bit words nowadays, but the 32-bit int persists). Similarly, the double standard speci es a 64-bit representation. These data-type sizes are adequate for typical applications that use integers and real numbers. To provide  exibility, Java has  ve additional primitive data types:
n 64-bit integers, with arithmetic operations (long)
n 16-bit integers, with arithmetic operations (short)
n 16-bit characters, with arithmetic operations (char)
n 8-bit integers, with arithmetic operations (byte)
n 32-bit single-precision real numbers, again with arithmetic operations (float)
We most often use int and double arithmetic operations in this book, so we do not consider the others (which are very similar) in further detail here.
1.1 n Basic Programming Model 13
 www.it-ebooks.info

14 Chapter 1 n Fundamentals
Statements A Java program is composed of statements, which de ne the computa- tion by creating and manipulating variables, assigning data-type values to them, and controlling the  ow of execution of such operations. Statements are often organized in blocks, sequences of statements within curly braces.
n Declarations create variables of a speci ed type and name them with identi ers. n Assignments associate a data-type value (de ned by an expression) with a vari-
able. Java also has several implicit assignment idioms for changing the value of a data-type value relative to its current value, such as incrementing the value of an integer variable.
n Conditionals provide for a simple change in the  ow of execution—execute the statements in one of two blocks, depending on a speci ed condition.
n Loops provide for a more profound change in the  ow of execution—execute the statements in a block as long as a given condition is true.
n Calls and returns relate to static methods (seepage 22), which provide another way to change the  ow of execution and to organize code.
A program is a sequence of statements, with declarations, assignments, conditionals, loops, calls, and returns. Programs typically have a nested structure : a statement among the statements in a block within a conditional or a loop may itself be a conditional or a loop. For example, the while loop in rank() contains an if statement. Next, we con- sider each of these types of statements in turn.
Declarations A declaration statement associates a variable name with a type at com- pile time. Java requires us to use declarations to specify the names and types of vari- ables. By doing so, we are being explicit about any computation that we are specify- ing. Java is said to be a strongly typed language, because the Java compiler checks for consistency (for example, it does not permit us to multiply a boolean and a double). Declarations can appear anywhere before a variable is  rst used—most often, we put them at the point of  rst use. The scope of a variable is the part of the program where it is de ned. Generally the scope of a variable is composed of the statements that follow the declaration in the same block as the declaration.
Assignments An assignment statement associates a data-type value (de ned by an ex- pression) with a variable. When we write c = a + b in Java, we are not expressing mathematical equality, but are instead expressing an action: set the value of the vari- able c to be the value of a plus the value of b. It is true that c is mathematically equal toa + bimmediatelyaftertheassignmentstatementhasbeenexecuted,butthepoint of the statement is to change the value of c (if necessary). The left-hand side of an as- signment statement must be a single variable; the right-hand side can be an arbitrary expression that produces a value of the type.
 www.it-ebooks.info

1.1 n Basic Programming Model 15 Conditionals Most computations require different actions for different inputs. One
way to express these differences in Java is the if statement:
if (<boolean expression>) { <block statements> }
This description introduces a formal notation known as a template that we use occa- sionally to specify the format of Java constructs. We put within angle brackets (< >) a construct that we have already de ned, to indicate that we can use any instance of that construct where speci ed. In this case, <boolean expression> represents an expression that has a boolean value, such as one involving a comparison operation, and <block statements> represents a sequence of Java statements. It is possible to make formal de nitions of <boolean expression> and <block statements>, but we refrain from going into that level of detail. The meaning of an if statement is self- explanatory: the statement(s) in the block are to be executed if and only if the boolean expression is true. The if-else statement:
    if (<boolean expression>) { <block statements> }
    else                      { <block statements> }
allows for choosing between two alternative blocks of statements.
Loops Many computations are inherently repetitive. The basic Java construct for han- dling such computations has the following format:
    while (<boolean expression>) { <block statements> }
The while statement has the same form as the if statement (the only difference being the use of the keyword while instead of if), but the meaning is quite different. It is an instruction to the computer to behave as follows: if the boolean expression is false, do nothing; if the boolean expression is true, execute the sequence of statements in the block (just as with if) but then check the boolean expression again, execute the se- quence of statements in the block again if the boolean expression is true, and continue as long as the boolean expression is true. We refer to the statements in the block in a loop as the body of the loop.
Break and continue Some situations call for slightly more complicated control  ow than provided by the basic if and while statements. Accordingly, Java supports two additional statements for use within while loops:
n The break statement, which immediately exits the loop
n The continue statement, which immediately begins the next iteration of the
loop
We rarely use these statements in the code in this book (and many programmers never use them), but they do considerably simplify code in certain instances.
 www.it-ebooks.info

16 Chapter 1 n Fundamentals
Shortcut notations There are several ways to express a given computation; we seek clear, elegant, and ef cient code. Such code often takes advantage of the following widely used shortcuts (that are found in many languages, not just Java).
Initializing declarations We can combine a declaration with an assignment to ini- tialize a variable at the same time that it is declared (created). For example, the code int i = 1; creates an int variable named i and assigns it the initial value 1. A best practice is to use this mechanism close to  rst use of the variable (to limit scope).
Implicit assignments The following shortcuts are available when our purpose is to modify a variable’s value relative to its current value:
n Increment/decrement operators: ++i is the same as i = i + 1; both have the value i in an expression. Similarly, --i is the same as i = i - 1. The code i++ and i-- are the same except that the expression value is the value before the increment/decrement, not after.
n Other compound operators: Prepending a binary operator to the = in an assign- ment is equivalent to using the variable on the left as the  rst operand. For ex- ample, the code i/=2; is equivalent to the code i = i/2; Note that i += 1; has the same effect as i = i+1; (and i++).
Single-statement blocks If a block of statements in a conditional or a loop has only a single statement, the curly braces may be omitted.
For notation Many loops follow this scheme: initialize an index variable to some val- ue and then use a while loop to test a loop continuation condition involving the index variable, where the last statement in the while loop increments the index variable. You can express such loops compactly with Java’s for notation:
    for (<initialize>; <boolean expression>; <increment>)
    {
       <block statements>
}
This code is, with only a few exceptions, equivalent to
    <initialize>;
    while (<boolean expression>)
    {
       <block statements>
       <increment>;
    }
We use for loops to support this initialize-and-increment programming idiom.
 www.it-ebooks.info

statement
declaration
assignment
initializing declaration
implicit assignment
conditional (if) conditional
(if-else)
loop (while)
while (Math.abs(t - c/t) > 1e-15*t)
1.1 n Basic Programming Model 17 definition
create a variable of a speci ed type, named with a given identi er
assign a data-type value to a variable
declaration that also assigns an initial value
i = i + 1;
execute a statement, depending on boolean expression
execute one or the other statement, depending on boolean expression
execute statement
until boolean expression is false
compact version of while statement
invoke other methods (see page 22) return from a method (see page 24)
loop (for) call
return
   t = (c/t + t) / 2.0;
for (int i = 1; i <= N; i++)
   sum += 1.0/i;
for (int i = 0; i <= N; i++)
   StdOut.println(2*Math.PI*i/N);
int key = StdIn.readInt();
return false;
Java statements
int i = 1;
double c =
3.141592625;
x = -x;
max = x;
max = y;
i++;
i += 1;
if (x <
if (x > else
0) y)
int v = 1;
while (v <= N)
   v = 2*v;
double t = c;
examples
   int i;
double c;
a = b + 3;
discriminant = b*b - 4.0*c;
www.it-ebooks.info

18 Chapter 1 n Fundamentals
Arrays An array stores a sequence of values that are all of the same type. We want not only to store values but also to access each individual value. The method that we use to refer to individual values in an array is numbering and then indexing them. If we have N values, we think of them as being numbered from 0 to N1. Then, we can unambiguously specify one of them in Java code by using the notation a[i] to refer to the ith value for any value of i from 0 to N-1. This Java construct is known as a one- dimensional array.
Creating and initializing an array Making an array in a Java program involves three distinct steps:
n Declare the array name and type. n Create the array.
n Initialize the array values.
To declare the array, you need to specify a name and the type of data it will contain. To create it, you need to specify its length (the number of values). For example, the
“long form” code shown at right makes
an array of N numbers of type double, all
initialized to 0.0. The  rst statement is
the array declaration. It is just like a dec-
laration of a variable of the correspond-
ing primitive type except for the square
brackets following the type name, which
specify that we are declaring an array.
The keyword new in the second state-
ment is a Java directive to create the ar-
ray. The reason that we need to explicitly
create arrays at run time is that the Java
compiler cannot know how much space
to reserve for the array at compile time (as it can for primitive-type values). The for statement initializes the N array values. This code sets all of the array entries to the value 0.0. When you begin to write code that uses an array, you must be sure that your code declares, creates, and initializes it. Omitting one of these steps is a common program- ming mistake.
Default array initialization For economy in code, we often take advantage of Java’s default array initialization convention and combine all three steps into a single state- ment, as in the “short form” code in our example. The code to the left of the equal sign constitutes the declaration; the code to the right constitutes the creation. The for loop is unnecessary in this case because the default initial value of variables of type double
 long form declaration double[] a;
 creation
initializing declaration
     int[] a = { 1, 1, 2, 3, 5, 8 };
Declaring, creating, and initializing an array
 a = new double[N];
for (int i = 0; i < N; i++)
   a[i] = 0.0;
double[] a = new double[N];
 www.it-ebooks.info
short form
initialization

1.1 n Basic Programming Model 19 in a Java array is 0.0, but it would be required if a nonzero value were desired. The de-
fault initial value is zero for numeric types and false for type boolean.
Initializing declaration The third option shown for our example is to specify the initialization values at compile time, by listing literal values between curly braces, sepa- rated by commas.
Using an array Typical array-processing code is shown on page 21. After declaring and creating an array, you can refer to any individual value anywhere you would use a variable name in a program by enclosing an integer index in square brackets after the array name. Once we create an array, its size is  xed. A program can refer to the length of an array a[] with the code a.length. The last element of an array a[] is always a[a.length-1]. Java does automatic bounds checking—if you have created an array of size N and use an index whose value is less than 0 or greater than N-1, your pro- gram will terminate with an ArrayOutOfBoundsException runtime exception.
Aliasing Note carefully that an array name refers to the whole array—if we assign one array name to another, then both refer to the same array, as illustrated in the following code fragment.
    int[] a = new int[N];
    ...
    a[i] = 1234;
    ...
int[] b = a;
    ...
    b[i] = 5678;  // a[i] is now 5678.
This situation is known as aliasing and can lead to subtle bugs. If your intent is to make a copy of an array, then you need to declare, create, and initialize a new array and then copy all of the entries in the original array to the new array, as in the third example on page 21.
Two-dimensional arrays A two-dimensional array in Java is an array of one-dimen- sional arrays. A two-dimensional array may be ragged (its arrays may all be of differing lengths), but we most often work with (for appropriate parameters M and N) M-by-N two-dimensional arrays that are arrays of M rows, each an array of length N (so it also makes sense to refer to the array as having N columns). Extending Java array constructs to handle two-dimensional arrays is straightforward. To refer to the entry in row i and column j of a two-dimensional array a[][], we use the notation a[i][j]; to declare a two-dimensional array, we add another pair of square brackets; and to create the array,
 www.it-ebooks.info

20 Chapter 1 n Fundamentals
we specify the number of rows followed by the number of columns after the type name (both within square brackets), as follows:
    double[][] a = new double[M][N];
We refer to such an array as an M-by-N array. By convention, the  rst dimension is the number of rows and the second is the number of columns. As with one-dimensional arrays, Java initializes all entries in arrays of numeric types to zero and in arrays of boolean values to false. Default initialization of two-dimensional arrays is useful because it masks more code than for one-dimensional arrays. The following code is equivalent to the single-line create-and-initialize idiom that we just considered:
    double[][] a;
    a = new double[M][N];
    for (int i = 0; i < M; i++)
       for (int j = 0; j < N; j++)
          a[i][j] = 0.0;
This code is super uous when initializing to zero, but the nested for loops are needed to initialize to other value(s).
 www.it-ebooks.info

1.1 n Basic Programming Model 21
 task implementation (code fragment)
 nd the maximum of the array values
compute the average of the array values
copy to another array
reverse the elements within an array
double max = a[0];
for (int i = 1; i < a.length; i++)
   if (a[i] > max) max = a[i];
int N = a.length;
double sum = 0.0;
for (int i = 0; i < N; i++)
   sum += a[i];
double average = sum / N;
int N = a.length;
double[] b = new double[N];
for (int i = 0; i < N; i++)
b[i] = a[i];
int N = a.length;
for (int i = 0; i < N/2; i++)
{
   double temp = a[i];
   a[i] = a[N-i-1];
   a[N-i-1] = temp;
}
int N = a.length;
double[][] c = new double[N][N];
for (int i = 0; i < N; i++)
   for (int j = 0; j < N; j++)
   { // Compute dot product of row i and column j.
      for (int k = 0; k < N; k++)
         c[i][j] += a[i][k]*b[k][j];
}
typical array-processing code
matrix-matrix multiplication (square matrices)
 a[][]*b[][] = c[][]
  www.it-ebooks.info

22
Chapter 1 n Fundamentals
Static methods Every Java program in this book is either a data-type de nition (which we describe in detail in Section 1.2) or a library of static methods (which we de- scribe here). Static methods are called functions in many programming languages, since they can behave like mathematical functions, as described next. Each static method is a sequence of statements that are executed, one after the other, when the static method is called, in the manner described below. The modi er static distinguishes these meth- ods from instance methods, which we discuss in Section 1.2. We use the word method without a modi er when describing characteristics shared by both kinds of methods.
De ning a static method A method encapsulates a computation that is de ned as a sequence of statements. A method takes arguments (values of given data types) and computes a return value of some data type that depends upon the arguments (such as a value de ned by a mathematical function) or causes a side effect that depends on the arguments (such as printing a value). The static method rank() in BinarySearch
 signature
local variables
method body
}
return type
method name
argument type
argument variable
is an example of the  rst; main() is an ex- ample of the second. Each static method is composed of a signature (the keywords public static followed by a return type, the method name, and a sequence of ar- guments, each with a declared type) and a body (a statement block: a sequence of statements, enclosed in curly braces). Ex- amples of static methods are shown in the table on the facing page.
Invoking a static method A call on a static method is its name followed by expressions that specify argument values in parenthe-
            public static
{
double
if (c < 0) return Double.NaN;
double err = 1e-15;
         = c;
while (Math.abs(t - c/t) > err * t)
   t = (c/t + t) / 2.0;
sqrt
(
double c
)
      double t
     return t;
     return statement
call on another method
Anatomy of a static method
ses, separated by commas. When the method call is part of an expression, the method computes a value and that value is used in place of the call in the expression. For ex- ample the call on rank() in BinarySearch() returns an int value. A method call followed by a semicolon is a statement that generally causes side effects. For example, the call Arrays.sort() in main() in BinarySearch is a call on the system method Arrays.sort() that has the side effect of putting the entries in the array in sorted order. When a method is called, its argument variables are initialized with the values of the corresponding expressions in the call. A return statement terminates a static method, returning control to the caller. If the static method is to compute a value, that value must be speci ed in a return statement (if such a static method can reach the end of its sequence of statements without a return, the compiler will report the error).
www.it-ebooks.info

task
absolute value of an int value
absolute value of a double value
primality test
square root (Newton’s method)
hypotenuse of a right triangle
Harmonic number (see page 185)
implementation
public static int abs(int x)
{
   if (x < 0) return -x;
   else       return  x;
}
public static double abs(double x)
{
   if (x < 0.0) return -x;
   else         return  x;
}
public static boolean isPrime(int N)
{
   if (N < 2) return false;
   for (int i = 2; i*i <= N; i++)
      if (N % i == 0) return false;
   return true;
}
public static double sqrt(double c)
{
   if (c < 0.0) return Double.NaN;
   double err = 1e-15;
   double t = c;
   while (Math.abs(t - c/t) > err * t)
      t = (c/t + t) / 2.0;
   return t;
}
1.1 n
Basic Programming Model 23
    public static double hypotenuse(double a, double b)
  {  return Math.sqrt(a*a + b*b);  }
  public static double H(int N)
  {
     double sum = 0.0;
     for (int i = 1; i <= N; i++)
        sum += 1.0 / i;
     return sum;
}
typical implementations of static methods
www.it-ebooks.info

24 Chapter 1 n Fundamentals
Properties of methods A complete detailed description of the properties of methods is beyond our scope, but the following points are worth noting:
n Arguments are passed by value. You can use argument variables anywhere in the code in the body of the method in the same way you use local variables. The only difference between an argument variable and a local variable is that the argument variable is initialized with the argument value provided by the call- ing code. The method works with the value of its arguments, not the arguments themselves. One consequence of this approach is that changing the value of an argument variable within a static method has no effect on the calling code. Gen- erally, we do not change argument variables in the code in this book. The pass- by-value convention implies that array arguments are aliased (see page 19)—the method uses the argument variable to refer to the caller’s array and can change the contents of the array (though it cannot change the array itself). For example, Arrays.sort() certainly changes the contents of the array passed as argument: it puts the entries in order.
n Method names can be overloaded. For example, the Java Math library uses
this approach to provide implementations of Math.abs(), Math.min(), and Math.max() for all primitive numeric types. Another common use of overload- ing is to de ne two different versions of a function, one that takes an argument and another that uses a default value of that argument.
n A method has a single return value but may have multiple return statements. A Java method can provide only one return value, of the type declared in the method signature. Control goes back to the calling program as soon as the  rst return statement in a static method is reached. You can put return statements wherever you need them. Even though there may be multiple return statements, any static method returns a single value each time it is invoked: the value follow- ing the  rst return statement encountered.
n A method can have side effects. A method may use the keyword void as its return type, to indicate that it has no return value. An explicit return is not necessary in a void static method: control returns to the caller after the last statement.
A void static method is said to produce side effects (consume input, produce output, change entries in an array, or otherwise change the state of the system). For example, the main() static method in our programs has a void return type because its purpose is to produce output. Technically, void methods do not implement mathematical functions (and neither does Math.random(), which takes no arguments but does produce a return value).
The instance methods that are the subject of Section 2.1 share these properties, though profound differences surround the issue of side effects.
 www.it-ebooks.info

Recursion A method can call itself (if you are not comfortable with this idea, known as recursion, you are encouraged to work Exercises 1.1.16 through 1.1.22). For ex- ample, the code at the bottom of this page gives an alternate implementation of the rank() method in BinarySearch. We often use recursive implementations of methods because they can lead to compact, elegant code that is easier to understand than a cor- responding implementation that does not use recursion. For example, the comment in the implementation below provides a succinct description of what the code is sup- posed to do. We can use this comment to convince ourselves that it operates correctly, by mathematical induction. We will expand on this topic and provide such a proof for binary search in Section 3.1. There are three important rules of thumb in developing recursive programs:
n The recursion has a base case—we always include a conditional statement as the  rst statement in the program that has a return.
n Recursive calls must address subproblems that are smaller in some sense, so that recursive calls converge to the base case. In the code below, the difference between the values of the fourth and the third arguments always decreases.
n Recursive calls should not address subproblems that overlap. In the code below, the portions of the array referenced by the two subproblems are disjoint.
Violating any of these guidelines is likely to lead to incorrect results or a spectacularly inef cient program (see Exercises 1.1.19 and 1.1.27). Adhering to them is likely to lead to a clear and correct program whose performance is easy to understand. Another reason to use recursive methods is that they lead to mathematical models that we can use to understand performance. We address this issue for binary search in Section 3.2 and in several other instances throughout the book.
1.1 n Basic Programming Model 25
    public static int rank(int key, int[] a)
  {  return rank(key, a, 0, a.length - 1);  }
  public static int rank(int key, int[] a, int lo, int hi)
  {  // Index of key in a[], if present, is not smaller than lo
     //                                  and not larger than hi.
     if (lo > hi) return -1;
     int mid = lo + (hi - lo) / 2;
     if      (key < a[mid]) return rank(key, a, lo, mid - 1);
     else if (key > a[mid]) return rank(key, a, mid + 1, hi);
     else                   return mid;
}
recursive implementation of binary search
 www.it-ebooks.info

26 Chapter 1 n Fundamentals
Basic programming model A library of static methods is a set of static methods that arede nedinaJavaclass,bycreatinga lewiththekeywordspublic classfollowed by the class name, followed by the static methods, enclosed in braces, kept in a  le with the same name as the class and a .java extension. A basic model for Java programming is to develop a program that addresses a speci c computational task by creating a li- brary of static methods, one of which is named main(). Typing java followed by a class name followed by a sequence of strings leads to a call on main() in that class, with an array containing those strings as argument. After the last statement in main() executes, the program terminates. In this book, when we talk of a Java program for accomplishing a task, we are talking about code developed along these lines (possibly also including a data-type de nition, as described in Section 1.2). For example, BinarySearch is a Java program composed of two static methods, rank() and main(), that accomplishes the task of printing numbers from an input stream that are not found in a whitelist  le given as command-line argument.
Modular programming Of critical importance in this model is that libraries of stat- ic methods enable modular programming where we build libraries of static methods (modules) and a static method in one library can call static methods de ned in other libraries. This approach has many important advantages. It allows us to
n Work with modules of reasonable size, even in program involving a large amount of code
n Share and reuse code without having to reimplement it
n Easily substitute improved implementations
n Develop appropriate abstract models for addressing programming problems n Localize debugging (see the paragraph below on unit testing)
For example, BinarySearch makes use of three other independently developed librar- ies, our StdIn and In library and Java’s Arrays library. Each of these libraries, in turn, makes use of several other libraries.
Unit testing A best practice in Java programming is to include a main() in every li- brary of static methods that tests the methods in the library (some other programming languages disallow multiple main() methods and thus do not support this approach). Proper unit testing can be a signi cant programming challenge in itself. At a minimum, every module should contain a main() method that exercises the code in the module and provides some assurance that it works. As a module matures, we often re ne the main() method to be a development client that helps us do more detailed tests as we develop the code, or a test client that tests all the code extensively. As a client becomes more complicated, we might put it in an independent module. In this book, we use main() to help illustrate the purpose of each module and leave test clients for exercises.
 www.it-ebooks.info

External libraries We use static methods from four different kinds of libraries, each requiring (slightly) differing procedures for code reuse. Most of these are libraries of static methods, but a few are data-type de nitions that also include some static methods.
n The standard system libraries java.lang.*. These include Math, which contains methods for commonly used mathematical functions; Integer and Double,
which we use for converting between strings of characters and int and double values; String and StringBuilder, which we discuss in detail later in this section and in Chapter 5; and dozens of other libraries that we do not use.
n Imported system libraries such as java.util.Arrays. There are thousands of such libraries in a standard Java release, but we make scant use of them in this book. An import statement at the beginning of the program is needed to use such libraries (and signal that we are doing so).
n Other libraries in this book. For example, another program can use rank() in BinarySearch. To use such a program, down- load the source from the booksite into your working directory.
n The standard libraries Std* that we have developed for use
in this book (and our introductory book An Introduction to Programming in Java: An Interdisciplinary Approach). These libraries are summarized in the following several pages. Source code and instructions for downloading them are available on the booksite.
To invoke a method from another library (one in the same directory or a speci ed directory, a standard system library, or a system library that is named in an import statement before the class de nition), we prepend the library name to the method name for each call. For ex- ample, the main() method in BinarySearch calls the sort() method in the system library java.util.Arrays, the readInts() method in our library In, and the println() method in our library StdOut.
standard system libraries
Math
Integer† Double† String† StringBuilder System
imported system libraries
   java.util.Arrays
our standard libraries
StdIn StdOut StdDraw StdRandom StdStats In†
Out†
† data type definitions that
include some static methods
Libraries with static methods used in this book
Libraries of methods implemented by ourselves and by others in a modular programming environment can vastly expand the scope of our programming model. Beyond all of the libraries available in a standard Java release, thousands more are avail- able on the web for applications of all sorts. To limit the scope of our programming model to a manageable size so that we can concentrate on algorithms, we use just the libraries listed in the table at right on this page, with a subset of their methods listed in APIs, as described next.
www.it-ebooks.info
1.1 n Basic Programming Model 27

28 Chapter 1 n Fundamentals
APIs A critical component of modular programming is documentation that explains the operation of library methods that are intended for use by others. We will consis- tently describe the library methods that we use in this book in application programming interfaces (APIs) that list the library name and the signatures and short descriptions of each of the methods that we use. We use the term client to refer to a program that calls a method in another library and the term implementation to describe the Java code that implements the methods in an API.
Example The following example, the API for commonly used static methods from the standard Math library in java.lang, illustrates our conventions for APIs:
 public class Math
  static double abs(double a)
static double max(double a, double b) static double min(double a, double b)
absolute value of a maximum of a and b minimum of a and b
Note 1: abs(), max(), and min() are de ned also for int, long, and  oat.
static double sin(double theta) static double cos(double theta) static double tan(double theta)
sine function cosine function tangent function
Note 2: Angles are expressed in radians. Use toDegrees() and toRadians() to convert. Note 3: Use asin(), acos(), and atan() for inverse functions.
static double exp(double a)
static double log(double a)
static double pow(double a, double b)
static double random() static double sqrt(double a)
static double E
static double PI
See booksite for other available functions.
exponential (e a)
natural log (loge a, or ln a) raise a to the bth power (ab )
random number in [0, 1) square root of a
value of e (constant) value of  (constant)
apI for Java’s mathematics library (excerpts)
 www.it-ebooks.info

static void sort(int[] a) put the array in increasing order Note : This method is de ned also for other primitive types and Object.
excerpt from Java’s Arrays library (java.util.Arrays)
The Arrays library is not in java.lang, so an import statement is needed to use it, as in BinarySearch. Actually, Chapter 2 of this book is devoted to implementations of sort() for arrays, including the mergesort and quicksort algorithms that are imple- mented in Arrays.sort(). Many of the fundamental algorithms that we consider in this book are implemented in Java and in many other programming environments. For example, Arrays also includes an implementation of binary search. To avoid confusion, we generally use our own implementations, although there is nothing wrong with using a  nely tuned library implementation of an algorithm that you understand.
www.it-ebooks.info
1.1 n Basic Programming Model 29
These methods implement mathematical functions—they use their arguments to com- pute a value of a speci ed type (except random(), which does not implement a math- ematical function because it does not take an argument). Since they all operate on double values and compute a double result, you can consider them as extending the double data type—extensibility of this nature is one of the characteristic features of modern programming languages. Each method is described by a line in the API that speci es the information you need to know in order to use the method. The Math li- brary also de nes the precise constant values PI (for ) and E (for e), so that you can use those names to refer to those constants in your programs. For example, the value of Math.sin(Math.PI/2) is 1.0 and the value of Math.log(Math.E) is 1.0 (because Math.sin() takes its argument in radians and Math.log() implements the natural logarithm function).
Java libraries Extensive online descriptions of thousands of libraries are part of every Java release, but we excerpt just a few methods that we use in the book, in order to clear- ly delineate our programming model. For example, BinarySearch uses the sort() method from Java’s Arrays library, which we document as follows:
 public class Arrays

30 Chapter 1 n Fundamentals
Our standard libraries We have developed a number of libraries that provide useful functionality for introductory Java programming, for scienti c applications, and for the development, study, and application of algorithms. Most of these libraries are for input and output; we also make use of the following two libraries to test and analyze our implementations. The  rst extends Math.random() to allow us to draw random values from various distributions; the second supports statistical calculations:
 public class StdRandom
   static
static
static
static
static
static
static
static
static
static
void setSeed(long seed) double random()
int uniform(int N)
int uniform(int lo, int hi) double uniform(double lo, double hi)
boolean bernoulli(double p)
double gaussian()
double gaussian(double m, double s)
int discrete(double[] a) void shuffle(double[] a)
initialize
real between 0 and 1
integer between 0 and N-1 integer between lo and hi-1 real between lo and hi
true with probability p normal, mean 0, std dev 1 normal, mean m, std dev s
i with probability a[i] randomly shuf e the array a[]
Note: overloaded implementations of shuffle() are included for other primitive types and for Object. apI for our library of static methods for random numbers
public class StdStats
  static double max(double[] a) static double min(double[] a) static double mean(double[] a) static double var(double[] a) static double stddev(double[] a) static double median(double[] a)
largest value
smallest value
average
sample variance
sample standard deviation median
apI for our library of static methods for data analysis
 www.it-ebooks.info

The setSeed() method in StdRandom allows us to seed the random number genera- tor so that we can reproduce experiments involving random numbers. For reference, implementations of many of these methods are given on page 32. Some of these methods are extremely easy to implement; why do we bother including them in a li- brary? Answers to this question are standard for well-designed libraries:
n They implement a level of abstraction that allow us to focus on implement- ing and testing the algorithms in the book, not generating random objects or calculating statistics. Client code that uses such methods is clearer and easier to understand than homegrown code that does the same calculation.
n Library implementations test for exceptional conditions, cover rarely encoun- tered situations, and submit to extensive testing, so that we can count on them to operate as expected. Such implementations might involve a signi cant amount of code. For example, we often want implementations for various types of data. For example, Java’s Arrays library includes multiple overloaded implementa- tions of sort(), one for each type of data that you might need to sort.
These are bedrock considerations for modular programming in Java, but perhaps a bit overstated in this case. While the methods in both of these libraries are essentially self- documenting and many of them are not dif cult to implement, some of them represent interesting algorithmic exercises. Accordingly, you are well-advised to both study the code in StdRandom.java and StdStats.java on the booksite and to take advantage of these tried-and-true implementations. The easiest way to use these libraries (and to examine the code) is to download the source code from the booksite and put them in your working directory; various system-dependent mechanisms for using them with- out making multiple copies are also described on the booksite.
Your own libraries It is worthwhile to consider every program that you write as a li- brary implementation, for possible reuse in the future.
n Write code for the client, a top-level implementation that breaks the computa- tion up into manageable parts.
n Articulate an API for a library (or multiple APIs for multiple libraries) of static methods that can address each part.
n Develop an implementation of the API, with a main() that tests the methods independent of the client.
Not only does this approach provide you with valuable software that you can later reuse, but also taking advantage of modular programming in this way is a key to suc- cessfully addressing a complex programming task.
1.1 n Basic Programming Model 31
 www.it-ebooks.info

32 Chapter 1 n Fundamentals intended result
implementation
  randomdouble value in [a, b)
randomint value in [0..N)
randomint value in [lo..hi)
random int value drawn from discrete distribution (i with probability a[i])
public static double uniform(double a, double b)
{  return a + StdRandom.random() * (b-a);  }
public static int uniform(int N)
{  return (int) (StdRandom.random() * N);  }
public static int uniform(int lo, int hi)
{  return lo + StdRandom.uniform(hi - lo);  }
public static int discrete(double[] a)
{  // Entries in a[] must sum to 1.
     double r = StdRandom.random();
     double sum = 0.0;
     for (int i = 0; i < a.length; i++)
     {
        sum = sum + a[i];
        if (sum >= r) return i;
     }
return -1; }
public static void shuffle(double[] a)
{
   int N = a.length;
   for (int i = 0; i < N; i++)
   {  // Exchange a[i] with random element in a[i..N-1]
      int r = i + StdRandom.uniform(N-i);
      double temp = a[i];
      a[i] = a[r];
      a[r] = temp;
} }
randomly shuf e the elements in an array of double values (See Exercise 1.1.36)
Implementations of static methods in StdRandom library
www.it-ebooks.info

The purpose of an API is to separate the client from the implementation: the client should know nothing about the implementation other than information given in the API, and the implementation should not take properties of any particular client into account. APIs enable us to separately develop code for various purposes, then reuse it widely. No Java library can contain all the methods that we might need for a given computation, so this ability is a crucial step in addressing complex programming ap- plications. Accordingly, programmers normally think of the API as a contract between the client and the implementation that is a clear speci cation of what each method is to do. Our goal when developing an implementation is to honor the terms of the contract. Often, there are many ways to do so, and separating client code from implementation code gives us the freedom to substitute new and improved implementations. In the study of algorithms, this ability is an important ingredient in our ability to understand the impact of algorithmic improvements that we develop.
1.1 n Basic Programming Model 33
 www.it-ebooks.info

34 Chapter 1 n Fundamentals
Strings A String is a sequence of characters (char values). A literal String is a sequence of characters within double quotes, such as "Hello, World". The data type String is a Java data type but it is not a primitive type. We consider String now be- cause it is a fundamental data type that almost every Java program uses.
Concatenation Java has a built-in concatenation operator (+) for String like the built-in operators that it has for primitive types, justifying the addition of the row in the table below to the primitive-type table on page 12. The result of concatenating two String values is a single String value, the  rst string followed by the second.
type set of values typical literals operators
typical expressions
expression value
   character "AB" + String sequences "Hello" (concatenate)
"Hi, " + "Bob" "12" + "34" "1" + "+" + "2"
"Hi, Bob"
  "1234"
  "1+2"
Conversion
"2.5"
Java’s String data type
Two primary uses of strings are to convert values that we can enter on a keyboard into data-type values and to convert data-type values to values that we can read on a display. Java has built-in operations for String to facilitate these operations. In particular, the language includes libraries Integer and Double that contain static methods to convert between String values and int values and between String values and double values, respectively.
public class Integer
static int parseInt(String s) static String toString(int i)
public class Double
static double parseDouble(String s) static String toString(double x)
convert s to an int value convert i to a String value
convert s to a double value convert x to a String value
  apIs for conversion between numbers and String values
www.it-ebooks.info

Automatic conversion We rarely explicitly use the static toString() methods just described because Java has a built-in mechanism that allows us to convert from any data type value to a String value by using concatenation: if one of the arguments of + is a String, Java automatically converts the other argument to a String (if it is not already a String). Beyond usage like "The square root of 2.0 is " + Math.sqrt(2.0) this mechanism enables conversion of any data-type value to a String, by concatenat- ing it with the empty string "".
Command-line arguments One important use of strings in Java programming is to enable a mechanism for passing information from the command line to the program. The mechanism is simple. When you type the java command followed by a library name followed by a sequence of strings, the Java system invokes the main() method in that library with an array of strings as argument: the strings typed after the library name. For example, the main() method in BinarySearch takes one command-line argument, so the system creates an array of size one. The program uses that value, args[0], to name the  le containing the whitelist, for use as the argument to In.readInts(). An- other typical paradigm that we often use in our code is when a command-line argu- ment is intended to represent a number, so we use parseInt() to convert to an int value or parseDouble() to convert to a double value.
Computing with strings is an essential component of modern computing. For the moment, we make use of String just to convert between external representation of numbers as sequences of characters and internal representation of numeric data-type values. In Section 1.2, we will see that Java supports many, many more operations on String values that we use throughout the book; in Section 1.4, we will examine the internal representation of String values; and in Chapter 5, we consider in depth al- gorithms that process String data. These algorithms are among the most interesting, intricate, and impactful methods that we consider in this book.
1.1 n Basic Programming Model 35
 www.it-ebooks.info

36 Chapter 1 n Fundamentals
standard input
file I/O
command-line arguments
standard output
learn and use. We begin by brie y reviewing the model. In our model, a Java program takes input values from command-line arguments or from an abstract stream of characters known as the standard input stream and writes to another abstract stream of characters known as the
standard output stream.
Necessarily, we need to consider the interface between
Java and the operating system, so we need to brie y dis- cuss basic mechanisms that are provided by most modern operating systems and program-development environ- ments. You can  nd more details about your particular system on the booksite. By default, command-line argu- ments, standard input, and standard output are associated
Input and output The primary purpose of our standard libraries for input, out- put, and drawing is to support a simple model for Java programs to interact with the outside world. These libraries are built upon extensive capabilities that are available in Java libraries, but are generally much more complicated and much more dif cult to
                command
 javac
  java
  more
arguments
.java  le name
.class  le name (no extension)
and command-line arguments any text  le name
By convention, both Java and
the operating system process compile Java program the arguments as strings. If
standard drawing
A bird’s-eye view of a Java program
with an application supported by either the operating system or the program develop- ment environment that takes commands. We use the generic term terminal window to refer to the window maintained by this application, where we type and read text. Since early Unix systems in the 1970s this model has proven to be a convenient and direct way for us to interact with our programs and data. We add to the classical model a standard drawing that allows us to create visual representations for data analysis.
Commands and arguments In the terminal window, we see a prompt, where we type commands to the operating system that may take arguments. We use only a few com- mands in this book, shown in the table below. Most often, we use the java command, to run our programs. As mentioned on page 35, Java classes have a main() static method that takes a String array args[] as its argument. That array is the sequence of command-line arguments that we type, provided to Java by the operating system.
typical operating-system commands
purpose
 run Java program print  le contents
we intend for an argument to be a number, we use a method such as Integer.parseInt() to convert it from String to the appropriate type.
www.it-ebooks.info

Standard output Our StdOut library provides sup- port for standard output. By default, the system con- nects standard output to the terminal window. The print() method puts its argument on standard out- put; the println() method adds a newline; and the printf() method supports formatted output, as de- scribed next. Java provides a similar method in its System.out library; we use StdOut to treat standard input and standard output in a uniform manner (and to provide a few technical improvements).
     public class StdOut
static void print(String s)
static void println(String s) static void println()
static void printf(String f, ... )
1.1 n
prompt
Basic Programming Model 37 call the static method
main() in RandomSeq
            Note: overloaded implementations are included for primitive types and for Object. apI for our library of static methods for standard output
To use these methods, download into your working directory StdOut.java from the booksite and use code such as StdOut.println("Hello, World"); to call them. A sample client is shown at right.
Formatted output In its simplest
form, printf() takes two arguments.
The  rst argument is a format string
that describes how the second argu-
ment is to be converted to a string for
output. The simplest type of format
string begins with % and ends with a
one-letter conversion code. The conversion codes that we use most frequently are d (for decimal values from Java’s integer types), f (for  oating-point values), and s (for String values). Between the % and the conversion code is an integer value that speci es the  eld width of the
% java RandomSeq 5 100.0 200.0
 invoke Java runtime
args[0]
     args[1]
           args[2]
Anatomy of a command
 prints
print s, followed by newline print a new line
formatted print
   public class RandomSeq
  {
     public static void main(String[] args)
     {  // Print N random values in (lo, hi).
        int N = Integer.parseInt(args[0]);
        double lo = Double.parseDouble(args[1]);
        double hi = Double.parseDouble(args[2]);
        for (int i = 0; i < N; i++)
        {
           double x = StdRandom.uniform(lo, hi);
           StdOut.printf("%.2f\n", x);
        }
} }
Sample StdOut client
  % java RandomSeq 5 100.0 200.0
123.43
153.13
144.38
155.18
104.02
www.it-ebooks.info

38 Chapter 1 n Fundamentals
converted value (the number of characters in the converted output string). By default, blank spaces are added on the left to make the length of the converted output equal to the  eld width; if we want the spaces on the right, we can insert a minus sign before the  eld width. (If the converted output string is bigger than the  eld width, the  eld width is ignored.) Following the width, we have the option of including a period followed by the number of digits to put after the decimal point (the precision) for a double value or the number of characters to take from the beginning of the string for a String value. The most important thing to remember about using printf() is that the conversion code in the format and the type of the corresponding argument must match. That is, Java must be able to convert from the type of the argument to the type required by the con- version code. The  rst argument of printf() is a String that may contain characters other than a format string. Any part of the argument that is not part of a format string passes through to the output, with the format string replaced by the argument value (converted to a String as speci ed). For example, the statement
    StdOut.printf("PI is approximately %.2f\n", Math.PI);
prints the line
    PI is approximately 3.14
Note that we need to explicitly include the newline character \n in the argument in order to print a new line with printf(). The printf() function can take more than two arguments. In this case, the format string will have a format speci er for each ad- ditional argument, perhaps separated by other characters to pass through to the out- put. You can also use the static method String.format() with arguments exactly as just described for printf() to get a formatted string without printing it. Formatted printing is a convenient mechanism that allows us to develop compact code that can produce tabulated experimental data (our primary use in this book).
 typical literal
                      512
              1595.1680010754388
String s
Format conventions for printf() (see the booksite for many other options)
type code
int d
f e
sample format strings
"%14d"
"%-14d"
"%14.2f"
"%.7f"
"%14.4e"
converted string values for output
" 512" "512 "
"       1595.17"
"1595.1680011"
"    1.5952e+03"
 double
"Hello, World"
"%14s"
"%-14s"
"%-14.5s"
"  Hello, World"
"Hello, World  "
"Hello         "
www.it-ebooks.info

1.1 n Basic Programming Model 39
Standard input Our StdIn library
takes data from the standard input
stream that may be empty or may
contain a sequence of values sepa-
rated by whitespace (spaces, tabs,
newline characters, and the like). By
default, the system connects stan-
dard output to the terminal win-
dow—what you type is the input
stream (terminated by <ctrl-d> or
<ctrl-z>, depending on your termi-
nal window application). Each value
is a String or a value from one of
Java’s primitive types. One of the key
features of the standard input stream
is that your program consumes values when it reads them. Once your program has read a value, it cannot back up and read it again. This assumption is restrictive, but it re ects physical characteristics of some input devices and simpli es implementing the abstrac- tion. Within the input stream model, the static methods in this li- brary are largely self-documenting (described by their signatures).
 public class StdIn
 static
static
static
static
static
static
static
static
static
static
static
static
boolean
    int
 double
  float
   long
boolean
   char
   byte
 String
boolean
 String
 String
isEmpty()
readInt()
readDouble()
readFloat()
readLong()
readBoolean()
readChar()
readByte()
readString()
hasNextLine()
readLine()
readAll()
true if no more values, false otherwise read a value of type int
read a value of type double
read a value of type  oat
read a value of type long
read a value of type boolean
read a value of type char
read a value of type byte
read a value of type String
is there another line in the input stream? read the rest of the line
read the rest of the input stream
apI for our library of static methods for standard input
   public class Average
  {
     public static void main(String[] args)
     {  // Average the numbers on StdIn.
        double sum = 0.0;
        int cnt = 0;
        while (!StdIn.isEmpty())
        {  // Read a number and cumulate the sum.
           sum += StdIn.readDouble();
cnt++; }
        double avg = sum / cnt;
        StdOut.printf("Average is %.5f\n", avg);
     }
}
Sample StdIn client
 % java Average
1.23456
2.34567
3.45678
4.56789
<ctrl-d>
Average is 2.90123
 www.it-ebooks.info

40 Chapter 1 n Fundamentals
Redirection and piping Standard input and output enable us to take advantage of command-line extensions supported by many operating-systems. By adding a simple directive to the command that invokes a program, we can redirect its standard output to a  le, either for permanent storage or for input to another program at a later time:
    % java RandomSeq 1000 100.0 200.0 > data.txt
This command speci es that the standard output stream is not to be printed in the ter- minal window, but instead is to be written to a text  le named data.txt. Each call to StdOut.print() or StdOut.println() appends text at the end of that  le. In this example, the end result is a  le that contains 1,000 random values. No out- put appears in the terminal window: it goes directly into the  le named after the > symbol. Thus, we can save away information for later retrieval. Note that we do not have to change RandomSeq in any way—it is using the standard out- put abstraction and is unaffected by our use of a different implementation of that abstraction. Similarly, we can redi- rect standard input so that StdIn reads data from a  le instead of the terminal
 redirecting from a  le to standard input
 % java Average < data.txt
   data.txt
redirecting standard output to a  le
 % java RandomSeq 1000 100.0 200.0 > data.txt
data.txt
piping the output of one program to the input of another
 % java RandomSeq 1000 100.0 200.0 | java Average
Redirection and piping from the command line
application:
% java Average < data.txt
This command reads a sequence of numbers from the  le data.txt and computes their average value. Speci - cally, the < symbol is a directive that tells the operating system to implement the standard input stream by reading from the text  le data.txt instead of waiting for the user to type something into the
  standard input
       Average
 RandomSeq
   standard output
     RandomSeq
   standard output
standard input
        Average
terminal window. When the program calls StdIn.readDouble(), the operating system reads the value from the  le. Combining these to redirect the output of one program to the input of another is known as piping:
    % java RandomSeq 1000 100.0 200.0 | java Average
www.it-ebooks.info

This command speci es that standard output for RandomSeq and standard input for Average are the same stream. The effect is as if RandomSeq were typing the numbers it generates into the terminal window while Average is running. This difference is pro- found, because it removes the limitation on the size of the input and output streams that we can process. For example, we could replace 1000 in our example with 1000000000, even though we might not have the space to save a billion numbers on our computer (we do need the time to process them). When RandomSeq calls StdOut.printf(), a string is added to the end of the stream; when Average calls StdIn.readDouble(), a string is removed from the beginning of the stream. The timing of precisely what happens is up to the operating system: it might run RandomSeq until it produces some numbers, and then run Average to consume those numbers, or it might run Average until it needs to consume a number, and then run RandomSeq until it produces the needed number. The end result is the same, but our programs are freed from worry- ing about such details because they work solely with the standard input and standard output abstractions.
Input and output from a  le Our In and Out libraries provide static methods that implement the abstraction of reading from and writing to a  le the contents of an ar- ray of values of a primitive type (or String). We use readInts(), readDoubles(), and readStrings() in the In library and writeInts(), writeDoubles(), and writeStrings() in the Out library. The named argument can be a  le or a web page. For example, this ability allows us to use a  le and standard input for two different pur- poses in the same program, as in BinarySearch. The In and Out libraries also imple- ment data types with instance methods that allow us the more general ability to treat multiple  les as input and output streams, and web pages as input streams, so we will revisit them in Section 1.2.
public class In
static int[] readInts(String name) static double[] readDoubles(String name) static String[] readStrings(String name)
public class Out
static void write(int[] a, String name) static void write(double[] a, String name) static void write(String[] a, String name)
Note 1: Other primitive types are supported.
Note 2: StdIn and StdOut are supported (omit name argument).
read int values read double values read String values
write int values write double values write String values
1.1 n Basic Programming Model 41
       apIs for our static methods for reading and writing arrays
www.it-ebooks.info

42 Chapter 1 n Fundamentals
Standarddrawing(basicmethods) Uptothispoint, our input/output abstractions have focused exclusively on text strings. Now we introduce an abstraction for producing drawings as output. This library is easy to use and allows us to take advantage of a visual medi- um to cope with far more information than is possible with just text. As with standard input/output, our stan- dard drawing abstraction is implemented in a library StdDraw that you can access by downloading the  le StdDraw.java from the booksite into your working directory. Standard draw is very simple: we imagine an abstract drawing device capable of drawing lines and points on a two-dimensional canvas. The device is ca- pable of responding to the commands to draw basic geometric shapes that our programs issue in the form of calls to static methods in StdDraw, including meth- ods for drawing lines, points, text strings, circles, rect- angles, and polygons. Like the methods for standard input and standard output, these methods are nearly self-documenting: StdDraw.line() draws a straight line segment connecting the point (x0 , y0) with the point (x1 , y1) whose coordinates are given as arguments. StdDraw.point() draws a spot centered on the point (x, y) whose coordinates are given as arguments, and so forth, as illustrated in the diagrams at right. Geometric shapes can be  lled (in black, by default). The default scale is the unit square (all coordinates are between 0 and 1). The standard implementation displays the can- vas in a window on your computer’s screen, with black lines and points on a white background.
StdDraw.point(x0, y0);
StdDraw.line(x1, y1, x2, y2);
StdDraw.circle(x, y, r);
StdDraw.square(x, y, r);
    (x1, y1)
(0, 0)
(1, 1) (x0, y0)
(x2, y2)
          r
(x, y)
     (x, y)
double[] x = {x0, x1, x2, x3};
double[] y = {y0, y1, y2, y3};
StdDraw.polygon(x, y);
StdDraw examples
 (x0, y0)
(x1, y1)
(x3, y3)
r
r
      (x2, y2)
www.it-ebooks.info

public class StdDraw
   static void line(double x0, double y0, double x1, double y1) static void point(double x, double y)
static void text(double x, double y, String s)
static void circle(double x, double y, double r)
static void filledCircle(double x, double y, double r)
static void ellipse(double x, double y, double rw, double rh)
static void filledEllipse(double x, double y, double rw, double rh) static void square(double x, double y, double r)
static void filledSquare(double x, double y, double r)
static void rectangle(double x, double y, double rw, double rh) static void filledRectangle(double x, double y, double rw, double rh) static void polygon(double[] x, double[] y)
static void filledPolygon(double[] x, double[] y)
apI for our library of static methods for standard drawing (drawing methods)
Standard drawing (control methods) The library also includes methods to change the scale and size of the canvas, the color and width of the lines, the text font, and the timing of drawing (for use in animation). As arguments for setPenColor() you can use one of the prede ned colors BLACK, BLUE, CYAN, DARK_GRAY, GRAY, GREEN, LIGHT_GRAY, MAGENTA, ORANGE, PINK, RED, BOOK_RED, WHITE, and YELLOW that are de-  ned as constants in StdDraw (so we refer to one of them with code like StdDraw.RED). The window also includes a menu option to save your drawing to a  le, in a format suitable for publishing on the web.
 public class StdDraw
1.1 n Basic Programming Model 43
    static void setXscale(double x0, double x1) static void setYscale(double y0, double y1) static void setPenRadius(double r)
static void setPenColor(Color c)
static void setFont(Font f)
static void setCanvasSize(int w, int h) static void clear(Color c)
static void show(int dt)
reset x range to (x0 , x1) reset y range to (y0 , y1) set pen radius to r
set pen color to c
set text font to f
set canvas to w-by-h window clear the canvas; color it c show all; pause dt milliseconds
apI for our library of static methods for standard drawing (control methods)
www.it-ebooks.info

44 Chapter 1 n Fundamentals
In this book, we use StdDraw for data analysis and for creating visual representations of algorithms in operation. The table on the opposite page indicates some possiblities; we will consider many more examples in the text and the exercises throughout the book. The library also supports animation—of course, this topic is treated primarily on the booksite.
 www.it-ebooks.info

data
function values
plot implementation (code fragment)
int N = 100;
StdDraw.setXscale(0, N);
StdDraw.setYscale(0, N*N);
StdDraw.setPenRadius(.01);
for (int i = 1; i <= N; i++)
{
1.1 n
Basic Programming Model 45 result
      StdDraw.point(i, i);
   StdDraw.point(i, i*i);
   StdDraw.point(i, i*Math.log(i));
}
int N = 50;
double[] a = new double[N];
for (int i = 0; i < N; i++)
   a[i] = StdRandom.random();
for (int i = 0; i < N; i++)
{
   double x = 1.0*i/N;
   double y = a[i]/2.0;
   double rw = 0.5/N;
   double rh = a[i]/2.0;
   StdDraw.filledRectangle(x, y, rw, rh);
 array of random values
}
          int N = 50;
          double[] a = new double[N];
          for (int i = 0; i < N; i++)
             a[i] = StdRandom.random();
          Arrays.sort(a);
          for (int i = 0; i < N; i++)
          {
  sorted array of random values
}
double x = 1.0*i/N;
double y = a[i]/2.0;
double rw = 0.5/N;
double rh = a[i]/2.0;
StdDraw.filledRectangle(x, y, rw, rh);
StdDraw plotting examples
www.it-ebooks.info

46 Chapter 1 n Fundamentals
Binary search The sample Java program that we started with, shown on the facing page, is based on the famous, effective, and widely used binary search algorithm. This example is a prototype of the way in which we will examine new algorithms throughout the book. As with all of the programs we consider, it is both a precise de nition of the method and a complete Java implementation that you can download from the booksite.
Binary search We will study the binary search algorithm in detail in Section 3.2, but a brief description is appropriate here. The algorithm is implemented in the static
 successful search for 23
lo mid
10 11 12 16 18 23 29 33 48 lo mid hi
hi
method rank(), which takes an integer key and a sorted array of int values as arguments and re- turns the index of the key if it is present in the array, -1 otherwise. It accomplishes this task by maintaining variables lo and hi such that the key is in a[lo..hi] if it is in the array, then entering into a loop that tests the middle entry in the in- terval (at index mid). If the key is equal to a[mid], the return value is mid; otherwise the method cuts the interval size about in half, looking at the left half if the key is less than a[mid] and at the right half if the key is greater than a[mid]. The process terminates when the key is found or the interval is empty. Binary search is effective because it needs to examine just a few ar-
                              54 57 68 77 84 98
10 11 12 16 18 23 29 33 48 54 57 68 77 84 98
   lo mid hi
10 11 12 16 18 23 29 33 48 54 57 68 77 84 98 unsuccessful search for 50
   lo
10 11 12 16 18 23 29
10 11 12 16 18 23 29
10 11 12 16 18 23 29 33 48 54 57 68 77 84 98 lo mid hi
10 11 12 16 18 23 29 33 48 54 57 68 77 84 98 hi lo
mid
33 48 lo
hi
54 57 68 77 84 98
mid hi
54 57 68 77 84 98
      33 48
lo mid hi
      ray entries (relative to the size of the array) to  nd the key (or determine that it is not there).
tinyW.txt tinyT.txt
  10 11 12 16 18 23 29
33 48 54
57 68 77 84 98
84 23 48 50 68 10 10 99 18 18 98 23 12 98 23 84 54 11 57 10 48 48 33 77 16 13 77 54 11 98 29 77
77 68
Small test  les for BinarySearch test client
 Binary search in an ordered array
Development client For every algorithm implementation, we include a development client main() that you can use with sample input  les provided in the book and on the booksite to learn about the algorithm and to test its performance. In this example, the client reads integers from the  le named on the command line, then prints any integers to standard output that do not appear in the  le. We use small test  les such as those shown at right to demonstrate this behavior, and as the basis for traces and examples such as those at left above. We use large test  les to model real-world applications and to test performance (see page 48).
not in
tinyW.txt
 www.it-ebooks.info

 Binary Search
  import java.util.Arrays;
  public class BinarySearch
  {
     public static int rank(int key, int[] a)
     {  // Array must be sorted.
        int lo = 0;
        int hi = a.length - 1;
        while (lo <= hi)
        {  // Key is in a[lo..hi] or not present.
           int mid = lo + (hi - lo) / 2;
           if      (key < a[mid]) hi = mid - 1;
           else if (key > a[mid]) lo = mid + 1;
           else                   return mid;
}
return -1; }
     public static void main(String[] args)
     {
        int[] whitelist = In.readInts(args[0]);
        Arrays.sort(whitelist);
        while (!StdIn.isEmpty())
        {  // Read key, print if not in whitelist.
           int key = StdIn.readInt();
           if (rank(key, whitelist) == -1)
              StdOut.println(key);
        }
} }
This program takes the name of a whitelist  le (a sequence of integers) as argument and  lters any entry that is on the whitelist from standard input, leaving only integers that are not on the whitelist on standard output. It uses the binary search algorithm, implemented in the static method rank(), to accomplish the task ef ciently. See Sec-
tion 3.1 for a full discussion of the binary search algorithm, its correctness, its per- formance analysis, and its applications.
1.1 n Basic Programming Model 47
    www.it-ebooks.info
% java BinarySearch tinyW.txt < tinyT.txt
50
99
13
48 Chapter 1 n Fundamentals
Whitelisting When possible, our development clients are intended to mirror practical situations and demonstrate the need for the algorithm at hand. In this case, the process is known as whitelisting. Speci cally, imagine a credit card company that needs to check whether customer transactions are for a valid account. To do so, it can
n Keep customers account numbers in a  le, which we refer to as a whitelist.
n Produce the account number associated with each transaction in the standard
input stream.
n Use the test client to put onto standard output the numbers that are not associat-
ed with any customer. Presumably the company would refuse such transactions. It would not be unusual for a big company with millions of customers to have to pro- cess millions of transactions or more. To model this situation, we provide on the book- site the  les largeW.txt (1 million integers) and largeT.txt (10 million integers).
Performance A working program is often not suf cient. For example, a much simpler implementation of rank(), which does not even require the array to be sorted, is to check every entry, as follows:
    public static int rank(int key, int[] a)
    {
       for (int i = 0; i < a.length; i++)
          if (a[i] == key) return i;
return -1; }
Given this simple and easy-to-understand solution, why do we use mergesort and bi- nary search? If you work Exercise 1.1.38, you will see that your computer is too slow to run this brute-force implementation of rank() for large numbers of inputs (say, 1 million whitelist entries and 10 million transactions). Solving the whitelist problem for a large number of inputs is not feasible without ef cient algorithms such as binary search and mergesort. Good performance is often of critical importance, so we lay the ground- work for studying performance in Section 1.4 and analyze the performance character- istics of all of our algorithms (including binary search, in Section 3.1 and mergesort, in Section 2.2).
In the present context, our goal in thoroughly outlining our programming model is to ensure that you can run code like BinarySearch on your computer, use it on test data like ours, and modify it to adapt to various situations (such as those described in the exercises at the end of this section), in order to best understand its applicability. The programming model that we have sketched is designed to facilitate such activities, which are crucial to our approach to studying algorithms.
 www.it-ebooks.info

largeW.txt
 489910
  18940
 774392
 490636
 125544
 407391
 115771
 992663
 923282
 176914
 217904
 571222
 519039
 395667
...
1,000,000
int values
largeT.txt
  944443
  293674
  572153
  600579
  499569
  984875
  763178
  295754
44696
207807
  138910
  903531
  140925
  699418
  759984
  199694
  774549
  635871
  161828
  805380
...
10,000,000
int values
not in
largeW.txt
1.1 n
Basic Programming Model 49
       % java BinarySearch largeW.txt < largeT.txt
499569
984875
295754
207807
140925
161828
...
    367,966
int values
Large  les for BinarySearch test client
www.it-ebooks.info

50 Chapter 1 n Fundamentals
Perspective In this section, we have described a  ne and complete programming model that served (and still serves) many programmers for many decades. Modern programming, however, goes one step further. This next level is called data abstraction, sometimes known as object-oriented programming, and is the subject of the next sec- tion. Simply put, the idea behind data abstraction is to allow a program to de ne data types (sets of values and sets of operations on those values), not just static methods that operate on prede ned data types.
Object-oriented programming has come into widespread use in recent decades, and data abstraction is central to modern program development. We embrace data abstrac- tion in this book for three primary reasons:
n It enables us to expand our ability to reuse code through modular programming. For example, our sorts in Chapter 2 and binary search and other algorithms in Chapter 3 allow clients to make use of the same code for any type of data (not just integers), including one de ned by the client.
n It provides a convenient mechanism for building so-called linked data structures that provide more  exibility than arrays and are the basis of ef cient algorithms in many settings.
n It enables us to precisely de ne the algorithmic challenges that we face. For ex- ample, our union- nd algorithms in Section 1.5, our priority-queue algorithms in Section 2.4, and our symbol-table algorithms in Chapter 3 are all oriented toward de ning data structures that enable ef cient implementations of a set of operations. This challenge aligns perfectly with data abstraction.
Despite all of these considerations, our focus remains on the study of algorithms. In this context, we proceed to consider next the essential features of object-oriented pro- gramming that are relevant to our mission.
 www.it-ebooks.info

Q. What is Java bytecode?
A. Alow-levelversionofyourprogramthatrunsontheJavavirtualmachine.Thislevel of abstraction makes it easier for the developers of Java to ensure that our programs run on a broad variety of devices.
Q. ItseemswrongthatJavashouldjustletintsover owandgivebadvalues.Shouldn’t Java automatically check for over ow?
A. This issue is a contentious one among programmers. The short answer is that the lack of such checking is one reason such types are called primitive data types. A little knowledge can go a long way in avoiding such problems. We use the int type for small numbers (less than ten decimal digits), and the long type when values run into the bil- lions or more.
Q. What is the value of Math.abs(-2147483648)?
A. -2147483648. This strange (but true) result is a typical example of the effects of
integer over ow.
Q. How can I initialize a double variable to in nity?
A. Javahasbuilt-inconstantsavailableforthispurpose:Double.POSITIVE_INFINITY and Double.NEGATIVE_INFINITY.
Q. Can you compare a double to an int?
A. Not without doing a type conversion, but remember that Java usually does the req- uisite type conversion automatically. For example, if x is an int with the value 3, then theexpression(x < 3.1)istrue—Javaconvertsxtodouble(because3.1isadouble literal) before performing the comparison.
Q. What happens if I use a variable before initializing it to a value?
A. Java will report a compile-time error if there is any path through your code that
would lead to use of an uninitialized variable.
Q. What are the values of 1/0 and 1.0/0.0 as Java expressions?
A. The rstgeneratesaruntimeexceptionfordivisionbyzero(whichstopsyourpro- gram because the value is unde ned); the second has the value Infinity.
www.it-ebooks.info
1.1 n Basic Programming Model 51
 Q&A

52 Chapter 1 n Fundamentals
 Q. Can you use < and > to compare String variables?
A. No. Those operators are de ned only for primitive types. See page 80. Q. What is the result of division and remainder for negative integers?
A. The quotient a/b rounds toward 0; the remainder a % b is de ned such that (a / b) * b + a % b is always equal to a. For example, -14/3 and 14/-3 are both -4, but -14 % 3is-2and14 % -3is2.
Q. Why do we say (a && b) and not (a & b)?
A. Theoperators&,|,and^arebitwiselogicaloperationsforintegertypesthatdoand, or, and exclusive or (respectively) on each bit position. Thus the value of 10 & 6 is 2, the value of 10 | 6 is 14, and the value of 10 ^ 6 is 12. We use these operators rarely (but occasionally) in this book. The operators && and || are valid only in boolean expres- sions; they differ from the operators & and | because of short-circuiting: an expression is evaluated left-to-right and the evaluation stops when the value is known.
Q. Is ambiguity in nested if statements a problem? A. Yes. In Java, when you write
if <expr1> if <expr2> <stmntA> else <stmntB> it is equivalent to
if <expr1> { if <expr2> <stmntA> else <stmntB> } even if you might have been thinking
if <expr1> { if <expr2> <stmntA> } else <stmntB>
Using explicit braces is a good way to avoid this dangling else pitfall.
Q. What is the difference between a for loop and its while formulation?
A. The code in the for loop header is considered to be in the same block as the for loop body. In a typical for loop, the incrementing variable is not available for use in later statements; in the corresponding while loop, it is. This distinction is often a rea- son to use a while instead of a for loop.
Q. Some Java programmers use int a[] instead of int[] a to declare arrays. What’s the difference?
www.it-ebooks.info
 Q&A (continued)

1.1 n Basic Programming Model 53
  A. In Java, both are legal and equivalent. The former is how arrays are declared in C. The latter is the preferred style in Java since the type of the variable int[] more clearly indicates that it is an array of integers.
Q. Why do array indices start at 0 instead of 1?
A. This convention originated with machine-language programming, where the ad- dress of an array element would be computed by adding the index to the address of the beginning of an array. Starting indices at 1 would entail either a waste of space at the beginning of the array or a waste of time to subtract the 1.
Q. If a[] is an array, why does StdOut.println(a) print out a hexadecimal integer, such as @f62373 , instead of the elements of the array?
A. Goodquestion.Typically,itprintsthememoryaddressofthearray,which,unfor- tunately, is rarely what you want. Instead, you can  rst call Arrays.toString(a).
Q. Why are we not using the standard Java libraries for input and graphics?
A. We are using them, but we prefer to work with simpler abstract models. The Java libraries behind StdIn and StdDraw are built for production programming, and the libraries and their APIs are a bit unwieldy. To get an idea of what they are like, look at the code in StdIn.java and StdDraw.java.
Q. Can my program reread data from standard input?
A. No. You only get one shot at it, in the same way that you cannot undo println().
Q. What happens if my program attempts to read after standard input is exhausted?
A. Youwillgetanerror.StdIn.isEmpty()allowsyoutoavoidsuchanerrorbycheck- ing whether there is more input available.
Q. What does this error message mean?
Exception in thread "main" java.lang.NoClassDefFoundError: StdIn A. You probably forgot to put StdIn.java in your working directory.
Q. Can a static method take another static method as an argument in Java?
A. No. Good question, since many other languages do support this capability.
www.it-ebooks.info

54 Chapter 1 n Fundamentals
   1.1.1 Give the value of each of the following expressions:
a. ( 0 + 15 ) / 2
b. 2.0e-6 * 100000000.1
c. true && false || true && true
1.1.2 Give the type and value of each of the following expressions:
a. (1 + 2.236)/2
b. 1 + 2 + 3 + 4.0 c. 4.1 >= 4
d. 1 + 2 + "3"
1.1.3 Write a program that takes three integer command-line arguments and prints equal if all three are equal, and not equal otherwise.
1.1.4 What (if anything) is wrong with each of the following statements?
a. if (a > b) then c = 0;
b. if a > b { c = 0; }
c. if (a > b) c = 0;
d. if (a > b) c = 0 else b = 0;
1.1.5 Write a code fragment that prints true if the double variables x and y are both strictly between 0 and 1 and false otherwise.
1.1.6 What does the following program print?
    int f = 0;
    int g = 1;
    for (int i = 0; i <= 15; i++)
    {
       StdOut.println(f);
       f = f + g;
       g = f - g;
}
www.it-ebooks.info
 ExErcisEs
  1.1.7 Give the value printed by each of the following code fragments:
a. double t = 9.0;
while (Math.abs(t - 9.0/t) > .001)
           t = (9.0/t + t) / 2.0;
        StdOut.printf("%.5f\n", t);
b. int sum = 0;
for (int i = 1; i < 1000; i++)
           for (int j = 0; j < i; j++)
              sum++;
        StdOut.println(sum);
c. int sum = 0;
for (int i = 1; i < 1000; i *= 2)
           for (int j = 0; j < 1000; j++)
              sum++;
        StdOut.println(sum);
1.1.8 What do each of the following print?
a. System.out.println('b');
b. System.out.println('b' + 'c');
c. System.out.println((char) ('a' + 4));
Explain each outcome.
1.1.9 Write a code fragment that puts the binary representation of a positive integer N
into a String s.
Solution: Java has a built-in method Integer.toBinaryString(N) for this job, but the point of the exercise is to see how such a method might be implemented. Here is a particularly concise solution:
    String s = "";
    for (int n = N; n > 0; n /= 2)
s = (n % 2) + s;
 1.1 n Basic Programming Model 55
 www.it-ebooks.info
56 Chapter 1 n Fundamentals
   www.it-ebooks.info
 ExErcisEs (continued)
1.1.10 What is wrong with the following code fragment?
    int[] a;
    for (int i = 0; i < 10; i++)
a[i] = i * i;
Solution: It does not allocate memory for a[] with new. This code results in a
variable a might not have been initialized compile-time error.
1.1.11 Write a code fragment that prints the contents of a two-dimensional boolean array, using * to represent true and a space to represent false. Include row and column numbers.
1.1.12 What does the following code fragment print?
    int[] a = new int[10];
    for (int i = 0; i < 10; i++)
       a[i] = 9 - i;
    for (int i = 0; i < 10; i++)
       a[i] = a[a[i]];
    for (int i = 0; i < 10; i++)
       System.out.println(a[i]);
1.1.13 Write a code fragment to print the transposition (rows and columns changed) of a two-dimensional array with M rows and N columns.
1.1.14 Write a static method lg() that takes an int value N as argument and returns the largest int not larger than the base-2 logarithm of N. Do not use Math.
1.1.15 Write a static method histogram() that takes an array a[] of int values and an integer M as arguments and returns an array of length M whose ith entry is the num- ber of times the integer i appeared in the argument array. If the values in a[] are all between 0 and M–1, the sum of the values in the returned array should be equal to a.length.
1.1.16 Give the value of exR1(6):
    public static String exR1(int n)
    {
       if (n <= 0) return "";
       return exR1(n-3) + n + exR1(n-2) + n;
    }
  1.1.17 Criticize the following recursive function:
    public static String exR2(int n)
    {
       String s = exR2(n-3) + n + exR2(n-2) + n;
       if (n <= 0) return "";
       return s;
}
Answer : The base case will never be reached. A call to exR2(3) will result in calls to
exR2(0), exR2(-3), exR3(-6), and so forth until a StackOverflowError occurs. 1.1.18 Consider the following recursive function:
    public static int mystery(int a, int b)
    {
       if (b == 0)     return 0;
       if (b % 2 == 0) return mystery(a+a, b/2);
       return mystery(a+a, b/2) + a;
}
What are the values of mystery(2, 25) and mystery(3, 11)? Given positive integers aandb,describewhatvaluemystery(a, b)computes.Answerthesamequestion,but replace the three + operators with * and replace return 0 with return 1.
1.1.19 Run the following program on your computer:
    public class Fibonacci
    {
       public static long F(int N)
       {
          if (N == 0) return 0;
          if (N == 1) return 1;
          return F(N-1) + F(N-2);
}
       public static void main(String[] args)
       {
          for (int N = 0; N < 100; N++)
             StdOut.println(N + " " + F(N));
} }
 1.1 n Basic Programming Model 57
 www.it-ebooks.info
58 Chapter 1 n Fundamentals
 ExErcisEs (continued)
What is the largest value of N for which this program takes less than 1 hour to compute the value of F(N)? Develop a better implementation of F(N) that saves computed values in an array.
1.1.20 Write a recursive static method that computes the value of ln (N !).
1.1.21 Writeaprogramthatreadsinlinesfromstandardinputwitheachlinecontain- ing a name and two integers and then uses printf() to print a table with a column of the names, the integers, and the result of dividing the  rst by the second, accurate to three decimal places. You could use a program like this to tabulate batting averages for baseball players or grades for students.
1.1.22 WriteaversionofBinarySearchthatusestherecursiverank()givenonpage 25 and traces the method calls. Each time the recursive method is called, print the argu- ment values lo and hi, indented by the depth of the recursion. Hint: Add an argument to the recursive method that keeps track of the depth.
1.1.23 Add to the BinarySearch test client the ability to respond to a second argu- ment: + to print numbers from standard input that are not in the whitelist, - to print numbers that are in the whitelist.
1.1.24 Give the sequence of values of p and q that are computed when Euclid’s algo- rithm is used to compute the greatest common divisor of 105 and 24. Extend the code given on page 4 to develop a program Euclid that takes two integers from the command line and computes their greatest common divisor, printing out the two arguments for each call on the recursive method. Use your program to compute the greatest common divisor of 1111111 and 1234567.
1.1.25 Use mathematical induction to prove that Euclid’s algorithm computes the greatest common divisor of any pair of nonnegative integers p and q.
 www.it-ebooks.info

1.1.26 Sorting three numbers. Suppose that the variables a, b, c, and t are all of the same numeric primitive type. Show that the following code puts a, b, and c in ascending order:
    if (a > b) { t = a; a = b; b = t; }
    if (a > c) { t = a; a = c; c = t; }
    if (b > c) { t = b; b = c; c = t; }
1.1.27 Binomial distribution. Estimate the number of recursive calls that would be used by the code
    public static double binomial(int N, int k, double p)
    {
       if ((N == 0) && (k == 0)) return 1.0;
       if ((N  < 0) || (k  < 0)) return 0.0;
       return (1 - p)*binomial(N-1, k, p) + p*binomial(N-1, k-1, p);
}
tocomputebinomial(100, 50, 0.25).Developabetterimplementationthatisbased
on saving computed values in an array.
1.1.28 Remove duplicates. Modify the test client in BinarySearch to remove any du- plicate keys in the whitelist after the sort.
1.1.29 Equal keys. Add to BinarySearch a static method rank() that takes a key and a sorted array of int values (some of which may be equal) as arguments and returns the number of elements that are smaller than the key and a similar method count() that returns the number of elements equal to the key. Note : If i and j are the values returned byrank(key, a)andcount(key, a)respectively,thena[i..i+j-1]arethevaluesin the array that are equal to key.
1.1.30 Array exercise. Write a code fragment that creates an N-by-N boolean array a[][] such that a[i][j] is true if i and j are relatively prime (have no common fac- tors), and false otherwise.
1.1.31 Random connections. Write a program that takes as command-line arguments an integer N and a double value p (between 0 and 1), plots N equally spaced dots of size .05 on the circumference of a circle, and then, with probability p for each pair of points, draws a gray line connecting them.
www.it-ebooks.info
1.1 n Basic Programming Model 59
 crEAtivE problEms

60 Chapter 1 n Fundamentals
 crEAtivE problEms (continued)
1.1.32 Histogram. Suppose that the standard input stream is a sequence of double values. Write a program that takes an integer N and two double values l and r from the command line and uses StdDraw to plot a histogram of the count of the numbers in the standard input stream that fall in each of the N intervals de ned by dividing (l , r) into N equal-sized intervals.
1.1.33 Matrix library. Write a library Matrix that implements the following API: public class Matrix
   static
static
static
static
static
double dot(double[] x, double[] y) double[][] mult(double[][] a, double[][] b) double[][] transpose(double[][] a)
double[] mult(double[][] a, double[] x) double[] mult(double[] y, double[][] a)
vector dot product matrix-matrix product transpose matrix-vector product vector-matrix product
Develop a test client that reads values from standard input and tests all the methods.
1.1.34 Filtering. Which of the following require saving all the values from standard input (in an array, say), and which could be implemented as a  lter using only a  xed number of variables and arrays of  xed size (not dependent on N)? For each, the input comes from standard input and consists of N real numbers between 0 and 1.
n Print the maximum and minimum numbers.
n Print the median of the numbers.
n Print the k th smallest value, for k less than 100.
n Print the sum of the squares of the numbers.
n Print the average of the N numbers.
n Print the percentage of numbers greater than the average. n Print the N numbers in increasing order.
n Print the N numbers in random order.
 www.it-ebooks.info

 ExpErimENts
  1.1.35 Dice simulation. The following code computes the exact probability distribu- tion for the sum of two dice:
    int SIDES = 6;
    double[] dist = new double[2*SIDES+1];
    for (int i = 1; i <= SIDES; i++)
       for (int j = 1; j <= SIDES; j++)
          dist[i+j] += 1.0;
    for (int k = 2; k <= 2*SIDES; k++)
       dist[k] /= 36.0;
The value dist[k] is the probability that the dice sum to k. Run experiments to vali- date this calculation simulating N dice throws, keeping track of the frequencies of oc- currence of each value when you compute the sum of two random integers between 1 and 6. How large does N have to be before your empirical results match the exact results to three decimal places?
1.1.36 Empirical shuf e check. Run computational experiments to check that our shuf ing code on page 32 works as advertised. Write a program ShuffleTest that takes command-line arguments M and N, does N shuf es of an array of size M that is initializedwitha[i] = ibeforeeachshuf e,andprintsanM-by-Mtablesuchthatrow i gives the number of times i wound up in position j for all j. All entries in the table should be close to N/M.
1.1.37 Bad shuf ing. Suppose that you choose a random integer between 0 and N-1 in our shuf ing code instead of one between i and N-1. Show that the resulting order is not equally likely to be one of the N ! possibilities. Run the test of the previous exercise for this version.
1.1.38 Binary search versus brute-force search. Write a program BruteForceSearch that uses the brute-force search method given onpage 48 and compare its running time on your computer with that of BinarySearch for largeW.txt and largeT.txt.
www.it-ebooks.info
1.1 n Basic Programming Model 61

62 Chapter 1 n Fundamentals ExpErimENts (continued)
1.1.39 Random matches. Write a BinarySearch client that takes an int value T as command-line argument and runs T trials of the following experiment for N = 103, 104, 105, and 106: generate two arrays of N randomly generated positive six-digit int values, and  nd the number of values that appear in both arrays. Print a table giving the average value of this quantity over the T trials for each value of N.
  www.it-ebooks.info

This page intentionally left blank
www.it-ebooks.info

   64
A data type is a set of values and a set of operations on those values. So far, we have discussed in detail Java’s primitive data types: for example, the values of the primitive data type int are integers between 231 and 231  1; the operations of int include +, *, -, /, %, <, and >. In principle, we could write all of our programs using only the built-in primitive types, but it is much more convenient to write programs at a higher level of abstraction. In this section, we focus on the process of de ning and using data types, which is known as data abstraction (and supplements the function abstraction style that is the basis of SECTION 1.1).
Programming in Java is largely based on building data types known as reference types with the familiar Java class. This style of programming is known as object-oriented programming, as it revolves around the concept of an object, an entity that holds a data type value. With Java’s primitive types we are largely con ned to programs that operate on numbers, but with reference types we can write programs that operate on strings, pictures, sounds, any of hundreds of other abstractions that are available in Java’s stan- dard libraries or on our booksite. Even more signi cant than libraries of prede ned data types is that the range of data types available in Java programming is open-ended, because you can de ne your own data types to implement any abstraction whatsoever.
An abstract data type (ADT) is a data type whose representation is hidden from the client. Implementing an ADT as a Java class is not very different from implementing a function library as a set of static methods. The primary difference is that we associate data with the function implementations and we hide the representation of the data from the client. When using an ADT, we focus on the operations speci ed in the API and pay no attention to the data representation; when implementing an ADT, we focus on the data, then implement operations on that data.
Abstract data types are important because they support encapsulation in program design. In this book, we use them as a means to
n Precisely specify problems in the form of APIs for use by diverse clients
n Describe algorithms and data structures as API implementations
Our primary reason for studying different algorithms for the same task is that perfor- mance characteristics differ. Abstract data types are an appropriate framework for the study of algorithms because they allow us to put knowledge of algorithm performance to immediate use: we can substitute one algorithm for another to improve performance for all clients without changing any client code.
www.it-ebooks.info
 1.2 DAtA ABStrACtion

 Using abstract data types You do not need to know how a data type is imple- mented in order to be able to use it, so we begin by describing how to write programs that use a simple data type named Counter whose values are a name and a nonnega- tive integer and whose operations are create and initialize to zero, increment by one, and examine the current value. This abstraction is useful in many contexts. For example, it would be reasonable to use such a data type in electronic voting software, to ensure that the only thing that a voter can do is increment a chosen candidate’s tally by one. Or, we might use a Counter to keep track of fundamental operations when analyzing the performance of algorithms. To use a Counter, you need to learn our mechanism for specifying the operations de ned in the data type and the Java language mechanisms for creating and manipulating data-type values. Such mechanisms are critically im- portant in modern programming, and we use them throughout this book, so this  rst example is worthy of careful attention.
API for an abstract data type To specify the behavior of an abstract data type, we use an application programming interface (API), which is a list of constructors and instance methods (operations), with an informal description of the effect of each, as in this API for Counter:
int tally()
String toString()
an apI for a counter
Even though the basis of a data-type de nition is a set of values, the role of the values is not visible from the API, only the operations on those values. Accordingly, an ADT de nition has many similarities with a library of static methods (see page 24):
n Both are implemented as a Java class.
n Instance methods may take zero or more arguments of a speci ed type, sepa-
rated by commas and enclosed in parentheses.
n They may provide a return value of a speci ed type or no return value (signi ed
by void).
And there are three signi cant differences:
n Some entries in the API have the same name as the class and lack a return type. Such entries are known as constructors and play a special role. In this case, Counter has a constructor that takes a String argument.
www.it-ebooks.info
1.2 n Data Abstraction 65
 public class Counter
Counter(String id) void increment()
create a counter named id increment the counter by one number of increments since creation string representation

66 Chapter 1 n Fundamentals
n Instance methods lack the static modi er. They are not static methods—their purpose is to operate on data type values.
n Some instance methods are present so as to adhere to Java conventions—we refer to such methods as inherited methods and shade them gray in the API.
As with APIs for libraries of static methods, an API for an abstract data type is a con- tract with all clients and, therefore, the starting point both for developing any client code and for developing any data-type implementation. In this case, the API tells us that to use Counter, we have available the Counter() constructor, the increment() and tally() instance methods, and the inherited toString() method.
Inherited methods Various Java conventions enable a data type to take advantage of built-in language mechanisms by including speci c methods in the API. For example, all Java data types inherit a toString() method that typically returns a String repre- sentation of the data-type values. Java calls this method when any data-type value is to be concatenated with a String value with the + operator. The default implementation is not particularly useful (it gives a string representation of the memory address of the data-type value), so we often provide an implementation that overrides the default, and include toString() in the API whenever we do so. Other examples of such methods include equals(), compareTo(), and hashCode() (see page 101).
Client code As with modular programming based on static methods, the API allows us to write client code without knowing details of the implementation (and to write implementation code without knowing details of any particular client). The mecha- nisms introduced on page 28 for organizing programs as independent modules are use- ful for all Java classes, and thus are effective for modular programming with ADTs as well as for libraries of static methods. Accordingly, we can use an ADT in any program provided that the source code is in a .java  le in the same directory, or in the standard Java library, or accessible through an import statement, or through one of the classpath mechanisms described on the booksite. All of the bene ts of modular programming follow. By encapsulating all the code that implements a data type within a single Java class, we enable the development of client code at a higher level of abstraction. To de- velop client code, you need to be able to declare variables, create objects to hold data- type values, and provide access to the values for instance methods to operate on them. These processes are different from the corresponding processes for primitive types, though you will notice many similarities.
 www.it-ebooks.info

1.2 n Data Abstraction Objects Naturally, you can declare that a variable heads is to be associated with data
of type Counter with the code Counter heads;
but how can you assign values or specify operations? The answer to this question in- volves a fundamental concept in data abstraction: an object is an entity that can take on a data-type value. Objects are characterized by three essential prop-
erties: state, identity, and behavior. The state of an object is a value
67
 from its data type. The identity of an object distinguishes one object from another. It is useful to think of an object’s identity as the place where its value is stored in memory. The behavior of an object is the effect of data-type operations. The implementation has the sole re- sponsibility for maintaining an object’s identity, so that client code can use a data type without regard to the representation of its state by conforming to an API that describes an object’s behavior. An ob- ject’s state might be used to provide information to a client or cause a side effect or be changed by one of its data type’s operations, but the details of the representation of the data-type value are not rel- evant to client code. A reference is a mechanism for accessing an ob- ject. Java nomenclature makes clear the distinction from primitive types (where variables are associated with values) by using the term reference types for nonprimitive types. The details of implementing references vary in Java implementations, but it is useful to think of a reference as a memory address, as shown at right (for brevity, we use three-digit memory addresses in the diagram).
Creating objects Each data-type value is stored in an object. To create (or instantiate) an individual object, we invoke a constructor by using the keyword new, followed by the class name, followed by () (or a list of argument values enclosed in parentheses, if the con- structor takes arguments). A constructor has no return type because it always returns a reference to an object of its data type. Each time that a client uses new(), the system
n Allocates memory space for the object
n Invokes the constructor to initialize its value n Returns a reference to the object
one Counter object
heads
460
two Counter objects
heads tails
460
612
reference
identity details hidden)
   460
 (
             460
 612
identity of heads
identity of tails
            In client code we typically create objects in an initializing declaration that associates a variable with the object, as we often do with variables of primitive types. Unlike primi- tive types, variables are associated with references to objects, not the data-type values
www.it-ebooks.info
Object representation

68 Chapter 1 n Fundamentals themselves. We can create any num-
ber of objects from the same class— each object has its own identity and may or may not store the same value as another object of the same type. For example, the code
             Counter heads = new Counter("heads");
             Counter tails = new Counter("tails");
invoke constructor to create an object
=);
Creating an object
 declaration to associate variable with object reference
    object name
invoke an instance method that accesses the object’s value
creates two different Counter objects. In an abstract data type, details of the representa- tion of the value are hidden from client code. You might assume that the value associ- ated with each Counter object is a String name and an int tally, but you cannot write code that depends on any speci c representation (or even know whether that assumption is true—perhaps the tally is a long value).
Invoking instance methods The purpose of an instance method is to operate on data- type values, so the Java language includes a special mechanism to invoke instance meth- ods that emphasizes a connection to an object. Speci cally, we invoke an instance meth-
   Counter heads;
with new (constructor) heads =
declaration
od by writing a variable name that refers to an object, followed by a period, followed by an instance method name, followed by 0 or more arguments, enclosed in parentheses and separated by commas. An instance method might change the data-type value or just exam- ine the data-type value. Instance methods have all of the properties of static methods that we considered on page 24—arguments are passed by value, method names can be overloaded, they may have a return value, and they may cause side effects—but they have an addi- tional property that characterizes them: each invoca- tion is associated with an object. For example, the code
heads.increment();
invokes the instance method increment() to operate
on the Counter object heads (in this case the opera- tion involves incrementing the tally), and the code
    heads.tally() - tails.tally();
invokes the instance method tally() twice,  rst to operate on the Counter object heads and then to op- erate on the Counter object tails (in this case the
new Counter ("heads");
 invoke a constructor (create an object) as a statement (void return value)
heads.increment();
  object name
as an expression
invoke an instance method that changes the object’s value
 heads
.tally() - tails.tally()
  via automatic type conversion (toString()) StdOut.println( );
invoke heads.toString() Invoking instance methods
Counter heads
new Counter("heads"
   heads
  www.it-ebooks.info

operation involves returning the tally as an int value). As these examples illustrate, you can use calls on instance methods in client code in the same way as you use calls on stat- ic methods—as statements (void methods) or values in expressions (methods that re- turn a value). The primary purpose of stat-
ic methods is to implement functions; the primary purpose of non-static (instance) methods is to implement data-type opera- tions. Either type of method may appear in client code, but you can easily distinguish between them, because a static method call starts with a class name (uppercase, by convention) and a non-static method call always starts with an object name (lower- case, by convention). These differences are summarized in the table at right.
sample call invoked with
parameters
primary purpose
instance method
heads.increment()
object name
reference to object and argument(s)
examine or change object value
static method
Math.sqrt(2.0)
class name
argument(s)
compute return value
Using objects Declarations give us variable names for objects that we can use in code not just to create objects and invoke instance methods, but also in the same way as we use variable names for integers,  oating-point numbers, and other primitive types. To develop client code for a given data type, we:
n Declare variables of the type, for use in referring to objects
n Use the keyword new to invoke a constructor that creates objects of the type
n Use the object name to invoke instance methods, either as statements or within
expressions
For example, the class Flips shown at the top of the next page is a Counter client that takes a command-line argument T and simulates T coin  ips (it is also a StdRandom cli- ent). Beyond these direct uses, we can use variables associated with objects in the same way as we use variables associated with primitive-type values:
n In assignment statements
n To pass or return objects from methods n To create and use arrays of object.
Understanding the behavior of each of these types of uses requires thinking in terms of references, not values, as you will see when we consider them, in turn.
Assignment statements An assignment statement with a reference type creates a copy of the reference. The assignment statement does not create a new object, just another reference to an existing object. This situation is known as aliasing: both variables refer to the same object. The effect of aliasing is a bit unexpected, because it is different for variables holding values of a primitive type. Be sure that you understand the difference.
www.it-ebooks.info
1.2 n Data Abstraction 69
 Instance methods versus static methods

70 Chapter 1 n Fundamentals
   public class Flips
  {
     public static void main(String[] args)
     {
        int T = Integer.parseInt(args[0]);
        Counter heads = new Counter("heads");
        Counter tails = new Counter("tails");
        for (int t = 0; t < T; t++)
           if (StdRandom.bernoulli(0.5))
                heads.increment();
           else tails.increment();
        StdOut.println(heads);
        StdOut.println(tails);
        int d = heads.tally() - tails.tally();
        StdOut.println("delta: " + Math.abs(d));
} }
Counter client that simulates t coin flips
 % java Flips 10
5 heads
5 tails
delta: 0
% java Flips 10
8 heads
2 tails
delta: 6
% java Flips 1000000
499710 heads
500290 tails
delta: 580
 If x and y are variables of a primitive type, then the as- signment x = y copies the value of y to x. For reference types, the reference is copied (not the value). Aliasing is a common source of bugs in Java programs, as illustrated by the following example:
Counter c1;
c1 = new Counter("ones");
c1.increment();
Counter c2 = c1;
c2.increment();
   Counter c1 = new Counter("ones");
c1.increment();
Counter c2 = c1;
c2.increment();
StdOut.println(c1);
c1 c2
811
references to same object
reference to
"ones"
Aliasing
 811
     811
   With a typical toString() implementation this code would print the string "2 ones" which may or may not be what was intended and is counterintuitive at  rst. Such bugs are common in programs written by people without much experience in using objects (that may be you, so pay attention here!). Changing the state of an object impacts all code involving aliased variables referencing that ob- ject. We are used to thinking of two different variables of primitive types as being independent, but that intuition does not carry over to variables of reference types.
       2
  www.it-ebooks.info

Objects as arguments You can pass objects as arguments to methods. This ability typi- cally simpli es client code. For example, when we use a Counter as an argument, we are essentially passing both a name and a tally, but need only specify one variable. When we call a method with arguments, the effect in Java is as if each argument value were to appear on the right-hand side of an assignment statement with the corresponding argument name on the left. That is, Java passes a copy of the argument value from the calling program to the method. This arrangement is known as pass by value (see page 24). One important consequence is that the method cannot change the value of a caller’s variable. For primitive types, this policy is what we expect (the two variables are inde- pendent), but each time that we use a reference type as a method argument we create an alias, so we must be cautious. In other words, the convention is to pass the reference by value (make a copy of it) but to pass the object by reference. For example, if we pass a reference to an object of type Counter, the method cannot change the original refer- ence (make it point to a different Counter), but it can change the value of the object, for example by using the reference to call increment().
Objects as return values Naturally, you can also use an object as a return value from a method. The method might return an object passed to it as an argument, as in the example below, or it might create an object and return a reference to it. This capa- bility is important because
Java methods allow only one return value—using objects enables us to write code that, in effect, returns multiple values.
1.2 n Data Abstraction 71
    public class FlipsMax
  {
     public static Counter max(Counter x, Counter y)
     {
        if (x.tally() > y.tally()) return x;
        else                       return y;
     }
     public static void main(String[] args)
     {
        int T = Integer.parseInt(args[0]);
        Counter heads = new Counter("heads");
        Counter tails = new Counter("tails");
        for (int t = 0; t < T; t++)
           if (StdRandom.bernoulli(0.5))
                heads.increment();
           else tails.increment();
        if (heads.tally() == tails.tally())
             StdOut.println("Tie");
        else StdOut.println(max(heads, tails) + " wins");
     }
}
example of a static method with object arguments and return values
 % java FlipsMax 1000000
500281 tails wins
 www.it-ebooks.info

72 Chapter 1 n Fundamentals
Arrays are objects In Java, every value of any nonprimitive type is an object. In par- ticular, arrays are objects. As with strings, there is special language support for certain operations on arrays: declarations, initialization, and indexing. As with any other ob- ject, when we pass an array to a method or use an array variable on the right hand side of an assignment statement, we are making a copy of the array reference, not a copy of the array. This convention is appropriate for the typical case where we expect the method to be able to modify the array, by rearranging its entries, as, for example, in java.util.Arrays.sort() or the shuffle() method that we considered on page 32.
Arrays of objects Array entries can be of any type, as we have already seen: args[] in our main() implementations is an array of String objects. When we create an array of objects, we do so in two steps:
n Create the array, using the bracket syntax for array constructors.
n Create each object in the array, using a standard constructor for each.
For example, the code below simulates rolling a die, using an array of Counter objects to keep track of the number of occurrences of each possible value. An array of objects in Java is an array of references to objects, not the objects themselves. If the objects are large, then we may gain ef ciency by not having to move them around, just their refer- ences. If they are small, we may lose ef ciency by having to follow a reference each time we need to get to some information.
    public class Rolls
  {
     public static void main(String[] args)
     {
        int T = Integer.parseInt(args[0]);
        int SIDES = 6;
        Counter[] rolls = new Counter[SIDES+1];
        for (int i = 1; i <= SIDES; i++)
           rolls[i] = new Counter(i + "'s");
        for (int t = 0; t < T; t++)
        {
           int result = StdRandom.uniform(1, SIDES+1);
           rolls[result].increment();
        }
        for (int i = 1; i <= SIDES; i++)
           StdOut.println(rolls[i]);
} }
Counter client that simulates T rolls of a die
 % java Rolls 1000000
167308 1's
166540 2's
166087 3's
167051 4's
166422 5's
166592 6's
 www.it-ebooks.info

www.it-ebooks.info
1.2 n Data Abstraction 73
With this focus on objects, writing code that embraces data abstraction (de ning and using data types, with data-type values held in objects) is widely referred to as object-oriented programming. The basic concepts that we have just covered are the start- ing point for object-oriented programming, so it is worthwhile to brie y summarize them. A data type is a set of values and a set of operations de ned on those values. We implement data types in independent Java class modules and write client programs that use them. An object is an entity that can take on a data-type value or an instance of a data type. Objects are characterized by three essential properties: state, identity, and behavior. A data-type implementation supports clients of the data type as follows:
n Client code can create objects (establish identity) by using the new construct to invoke a constructor that creates an object, initializes its instance variables, and returns a reference to that object.
n Client code can manipulate data-type values (control an object’s behavior, pos- sibly changing its state) by using a variable associated with an object to invoke an instance method that operates on that object’s instance variables.
n Client code can manipulate objects by creating arrays of objects and passing them and returning them to methods, in the same way as for primitive-type values, except that variables refer to references to values, not the values themselves.
These capabilities are the foundation of a  exible, modern, and widely useful program- ming style that we will use as the basis for studying algorithms in this book.

74 Chapter 1 n Fundamentals
Examples of abstract data types The Java language has thousands of built-in ADTs, and we have de ned many other ADTs to facilitate the study of algorithms. In- deed, every Java program that we write is a data-type implementation (or a library of static methods). To control complexity, we will speci cally cite APIs for any ADT that we use in this book (not many, actually).
In this section, we introduce as examples several data types, with some examples of client code. In some cases, we present excerpts of APIs that may contain dozens of instance methods or more. We articulate these APIs to present real-world examples, to specify the instance methods that we will use in the book, and to emphasize that you do not need to know the details of an ADT implementation in order to be able to use it.
For reference, the data types that we use and develop in this book are shown on the facing page. These fall into several different categories:
n Standard system ADTs in java.lang.*, which can be used in any Java program. n Java ADTs in libraries such as java.awt, java.net, and java.io, which can also
be used in any Java program, but need an import statement.
n Our I/O ADTs that allow us to work with multiple input/output streams similar
to StdIn and StdOut.
n Data-oriented ADTs whose primary purpose is to facilitate organizing and pro-
cessing data by encapsulating the representation. We describe several examples for applications in computational geometry and information processing later in this section and use them as examples in client code later on.
n Collection ADTs whose primary purpose is to facilitate manipulating collections of data of the same type. We describe the basic Bag, Stack, and Queue types in Section 1.3, PQ types in Chapter 2, and the ST and SET types in Chapters 3 and 5.
n Operations-oriented ADTs that we use to analyze algorithms, as described in Section 1.4 and Section 1.5.
n ADTs for graph algorithms, including both data-oriented ADTs that focus on encapsulating representations of various kinds of graphs and operations-orient- ed ADTs that focus on providing speci cations for graph-processing algorithms.
This list does not include the dozens of types that we consider in exercises, which may be found in the index. Also, as described opnage 90, we often distinguish multiple imple- mentations of various ADTs with a descriptive pre x. As a group, the ADTs that we use demonstrate that organizing and understanding the data types that you use is an important factor in modern programming.
A typical application might use only  ve to ten of these ADTs. A prime goal in the development and organization of the ADTs in this book is to enable programmers to easily take advantage of a relatively small set of them in developing client code.
 www.it-ebooks.info

standard Java system types in java.lang
collection types
  Stack
  Queue
  Bag
  MinPQ MaxPQ
  IndexMinPQ IndexMaxPQ
  ST
SET
StringST
data-oriented graph types
  Graph
  Digraph
  Edge
  EdgeWeightedGraph
  DirectedEdge
  EdgeWeightedDigraph
operations-oriented graph types
  UF
  DepthFirstPaths
  CC
  BreadthFirstPaths
  DirectedDFS
  DirectedBFS
  TransitiveClosure
  Topological
  DepthFirstOrder
  DirectedCycle
  SCC
  MST
  SP
  Integer
  Double
  String
  StringBuilder
other Java types
  java.awt.Color
  java.awt.Font
  java.net.URL
  java.io.File
our standard I/o types
In Out Draw
data-oriented types
  Point2D
  Interval1D
  Interval2D
  Date
  Transaction
types for the analysis of algorithms
Counter
Accumulator
VisualAccumulator
Stopwatch
counter accumulator visual version stopwatch
int wrapper double wrapper indexed chars builder for strings
colors fonts URLs  les
input stream output stream drawing
for client examples
point in the plane 1D interval
2D interval
date
transaction
pushdown stack
FIFO queue
bag
priority queue
priority queue (indexed ) symbol table
set
symbol table (string keys )
graph
directed graph
edge (weighted )
graph (weighted )
edge (directed, weighted ) graph (directed, weighted )
dynamic connectivity DFS path search connected components BFS path search
DFS digraph path search BFS digraph path search all paths
topological order
DFS order
cycle search
strong components minimum spanning tree shortest paths
Selected aDts used in this book
www.it-ebooks.info
1.2
n
Data Abstraction 75

 76 Chapter 1 n Fundamentals
Geometric objects A natural example of object-oriented programming is designing data types for geometric objects. For example, the APIs on the facing page de ne ab- stract data types for three familiar geometric objects: Point2D (points in the plane), Interval1D (intervals on the line), and Interval2D (two- dimensional intervals in the plane, or axis-aligned rectangles). As usual, the APIs are essentially self-docu- menting and lead immediately to easily understood client code such as the example at left, which reads the boundaries of an Interval2D and an integer T from the command line, generates T random points in the unit square, and counts the number of points that fall in the interval (an estimate of the area of the rectangle). For dramatic effect, the client also draws the interval and the points that fall outside the interval. This compu- tation is a model for a method that reduces the problem of computing the area and volume of geometric shapes to the problem of determin- ing whether a point falls within the shape or not (a less dif-  cult but not trivial problem). Of course, we can de ne APIs for other geometric objects such as line segments, triangles, polygons, circles, and so forth, though implementing opera- tions on them can be challenging. Several examples are ad-
public static void main(String[] args)
{
double xlo = Double.parseDouble(args[0]);
double xhi = Double.parseDouble(args[1]);
double ylo = Double.parseDouble(args[2]);
double yhi = Double.parseDouble(args[3]);
int T = Integer.parseInt(args[4]);
Interval1D xint = new Interval1D(xlo, xhi);
Interval1D yint = new Interval1D(ylo, yhi);
Interval2D box  = new Interval2D(xint, yint);
box.draw();
Counter c = new Counter("hits");
for (int t = 0; t < T; t++)
{
}
double x = StdRandom.random();
double y = StdRandom.random();
Point2D p = new Point2D(x, y);
if (box.contains(p)) c.increment();
else                 p.draw();
StdOut.println(c);
StdOut.printf("area = %.2f\n", box.area());
}
Interval2D test client
% java Interval2D .2 .5 .5 .6 10000
297 hits
area = .03
dressed in the exercises at the end of this section.
Programs that process geometric objects have wide application in computing with models of the natural world, in scienti c computing, video games, movies, and many other applications. The development and study of such pro- grams and applications has blossomed into a far-reaching  eld of study known as computational geometry, which is a
www.it-ebooks.info
public class Point2D
double
double
double
double
double
create a point
x coordinate
y coordinate
radius (polar coordinates)
angle (polar coordinates)
Euclidean distance from this point to that draw the point on StdDraw
an apI for points in the plane
 double
 double
 double
boolean
boolean
Interval1D(double left, double right)
left()
right()
length()
contains(double x)
intersects(Interval1D that)
create an interval
left endpoint
right endpoint
length of the interval
does the interval contain x?
does the interval intersect that?
distanceTo(Point2D that) void draw()
public class Interval1D
public class Interval2D
Interval2D(Interval1D x, Interval1D y) double area()
boolean contains(Point2D p)
boolean intersects(Interval2D that)
create a 2D interval
area of the 2D interval
does the 2D interval contain p?
does the 2D interval intersect that?
an apI for intervals on the line
1.2 n
Data Abstraction 77
 Point2D(double x, double y)
x()
y()
r()
theta()
  void draw() draw the 2D interval on StdDraw an apI for two dimensional intervals in the plane
fertile area of examples for the application of the algorithms that we address in this book, as you will see in examples throughout the book. In the present context, our interest is to suggest that abstract data types that directly represent geometric abstrac- tions are not dif cult to de ne and can lead to simple and clear client code. This idea is reinforced in several exercises at the end of this section and on the booksite.
 www.it-ebooks.info

78 Chapter 1 n Fundamentals
Information processing Whether it be a bank processing millions of credit card trans- actions or a web analytics company processing billions of touchpad taps or a scien- ti c research group processing millions of experimental observations, a great many applications are centered around processing and organizing information. Abstract data types provide a natural mechanism for organizing the information. Without getting into details, the two APIs on the facing page suggest a typical approach for a commer- cial application. The idea is to de ne data types that allow us to keep information in objects that correspond to things in the real world. A date is a day, a month, and a year and a transaction is a customer, a date, and an amount. These two are just examples: we might also de ne data types that can hold detailed information for customers, times, locations, goods and services, or whatever. Each data type consists of constructors that create objects containing the data and methods for use by client code to access it. To simplify client code, we provide two constructors for each type, one that presents the data in its appropriate type and another that parses a string to get the data (see Exer- cise 1.2.19 for details). As usual, there is no reason for client code to know the rep- resentation of the data. Most often, the reason to organize the data in this way is to treat the data associated with an object as a single entity: we can maintain arrays of Transaction values, use Date values as a argument or a return value for a method, and so forth. The focus of such data types is on encapsulating the data, while at the same time enabling the development of client code that does not depend on the representa- tion of the data. We do not dwell on organizing information in this way, except to take note that doing so and including the inherited methods toString(), compareTo(), equals(), and hashCode() allows us to take advantage of algorithm implementations that can process any type of data. We will discuss inherited methods in more detail on page 100. For example, we have already noted Java’s convention that enables clients to print a string representation of every value if we include toString() implemen- tation in a data type. We consider conventions corresponding to the other inherited methods in Section 1.3, Section 2.5, Section 3.4, and Section 3.5, using Date and Transaction as examples. Section 1.3 gives classic examples of data types and a Java language mechanism known as parameterized types, or generics, that takes advantage of these conventions, and Chapter 2 and Chapter 3 are also devoted to taking advantage of generic types and inherited methods to develop implementations of sorting and searching algorithms that are effective for any type of data.
Whenever you have data of different types that logically belong together, it is worthwhile to contemplate de ning an ADT as in these examples. The ability to do so helps to organize the data, can greatly simplify client code in typical applications, and is an important step on the road to data abstraction.
 www.it-ebooks.info

public class Date implements Comparable<Date>
             Date(int month, int day, int year)
Date(String date) int month()
int day()
int year()
String toString()
boolean equals(Object that)
int compareTo(Date that) int hashCode()
create a date
create a date (parse constructor) month
day
year
string representation
is this the same date as that? compare this date to that
hash code
 String
   Date
 double
 String
boolean
    int
    int
Transaction(String transaction)
who()
when()
amount()
toString()
equals(Object that)
compareTo(Transaction that)
hashCode()
create a transaction (parse constructor) customer name
date
amount
string representation
is this the same transaction as that? compare this transaction to that hash code
Transaction(String who, Date when, double amount)
Sample apIs for commercial applications (dates and transactions)
www.it-ebooks.info
1.2 n Data Abstraction 79
 public class Transaction implements Comparable<Transaction>

80 Chapter 1 n
Fundamentals
Strings Java’s String is an important and useful ADT. A String is an indexed se- quence of char values. String has dozens of instance methods, including the following:
 public class String
    String() int length()
char charAt(int i)
int indexOf(String p)
int indexOf(String p, int i)
String concat(String t)
String substring(int i, int j) String[] split(String delim)
int compareTo(String t)
boolean equals(String t) int hashCode()
create an empty string
length of the string
ith character
 rst occurrence of p (-1 if none)
 rst occurrence of p a er i (-1 if none) this string with t appended
substring of this string (ith to j-1st chars) strings between occurrences of delim string comparison
is this string’s value the same as t’s ?
hash code
Java String apI (partial list of methods)
String values are similar to arrays of characters, but the two are not the same. Ar- rays have built-in Java language syntax for accessing a character; String has instance methods for indexed access, length, and many other operations. On the other hand, String has special language support for initialization and concatenation: instead of creating and initializing a string with a constructor, we can use a string literal; instead of invoking the method concat() we can use the + operator. We do not need to con- sider the details of the implementation, though
understanding performance characteristics of someofthemethodsisimportantwhendevelop- ing string-processing algorithms, as you will see in Chapter 5. Why not just use arrays of charac- ters instead of String values? The answer to this question is the same as for any ADT: to simplify and clarify client code. With String, we can write clear and simple client code that uses numerous convenient instance methods without regard to the way in which strings are represented (see fac- ing page). Even this short list contains powerful operations that require advanced algorithms such
String a = "now is ";
String b = "the time ";
String c = "to"
 www.it-ebooks.info
call
       a.length()
      a.charAt(4)
      a.concat(c)
  a.indexOf("is")
a.substring(2, 5)
  a.split(" ")[0]
  a.split(" ")[1]
      b.equals(c)
value
7
i
"now is to"
4
"w i"
"now"
"is"
false
Examples of string operations

task
is the string a palindrome?
extract  le name and extension from a command-line argument
print all lines in standard input that contain a string
speci ed on the command line
create an array
of the strings on StdIn delimited by whitespace
check whether an array of strings is in alphabetical order
implementation
public static boolean isPalindrome(String s)
{
   int N = s.length();
   for (int i = 0; i < N/2; i++)
      if (s.charAt(i) != s.charAt(N-1-i))
         return false;
   return true;
}
String s = args[0];
int dot = s.indexOf(".");
String base      = s.substring(0, dot);
String extension = s.substring(dot + 1, s.length());
String query = args[0];
while (!StdIn.isEmpty())
{
   String s = StdIn.readLine();
   if (s.contains(query)) StdOut.println(s);
}
String input = StdIn.readAll();
String[] words = input.split("\\s+");
public boolean isSorted(String[] a)
{
   for (int i = 1; i < a.length; i++)
   {
      if (a[i-1].compareTo(a[i]) > 0)
         return false;
}
   return true;
}
typical string-processing code
www.it-ebooks.info
1.2 n Data Abstraction 81

82 Chapter 1 n Fundamentals
as those considered in Chapter 5. For example, the argument of split() can be a regular expression (see Section 5.4)—the split() example on page 81 uses the argu- ment "\\s+", which means “one or more tabs, spaces, newlines, or returns.”
Input and output revisited A disadvantage of the StdIn, StdOut, and StdDraw stan- dard libraries of Section 1.1 is that they restrict us to working with just one input  le, one output  le, and one drawing for any given program. With object-oriented pro- gramming, we can de ne similar mechanisms that allow us to work with multiple input streams, output streams, and drawings within one program. Speci cally, our standard libary includes the data types In, Out, and Draw with the APIs shown on the facing page. When invoked with a constructor having a String argument, In and Out will  rst try to  nd a  le in the current directory of your computer that has that name. If it cannot
do so, it will assume the argu- ment to be a website name and will try to connect to that web- site (if no such website exists, it will issue a runtime exception). In either case, the speci ed  le or website becomes the source/ target of the input/output for the stream object thus created, and the read*() and print*() methods will refer to that  le or website. (If you use the no-argu- ment constructor, then you ob- tain the standard streams.) This arrangement makes it possible for a single program to process
multiple  les and drawings. You also can assign such objects to variables, pass them as arguments or re- turn values from methods, create arrays of them, and manipulate them just as you manipulate objects of any type. The program Cat shown at left is a sample client of In and Out that uses multiple input streams to concatenate several input  les into a single out- put  le. The In and Out classes also contain static methods for reading  les containing values that are all int, double, or String types into an array (see page 126 and Exercise 1.2.15).
    public class Cat
  {
     public static void main(String[] args)
     {  // Copy input files to out (last argument).
        Out out = new Out(args[args.length-1]);
        for (int i = 0; i < args.length - 1; i++)
        {  // Copy input file named on ith arg to out.
           In in = new In(args[i]);
           String s = in.readAll();
           out.println(s);
           in.close();
}
        out.close();
     }
}
a sample In and Out client
  % more in1.txt
This is
% more in2.txt
a tiny
test.
% java Cat in1.txt in2.txt out.txt
% more out.txt
This is
a tiny
test.
www.it-ebooks.info

public class In
In()
In(String name) boolean isEmpty()
int readInt() double readDouble()
... void close()
create an input stream from standard input create an input stream from a  le or website true if no more input, false otherwise read a value of type int
read a value of type double close the input stream
1.2 n Data Abstraction 83
 Note: all operations supported by StdIn are also supported for In objects. apI for our data type for input streams
public class Out
Out()
Out(String name) void print(String s)
void println(String s) void println()
void printf(String f, ...) void close()
create an output stream to standard output create an output stream to a  le
append s to the output stream
append s and a newline to the output stream append a newline to the output stream formatted print to the output steam
close the output stream
 Note: all operations supported by StdOut are also supported for Out objects. apI for our data type for output streams
  public class Draw
Draw()
void line(double x0, double y0, double x1, double y1) void point(double x, double y)
...
Note: all operations supported by StdDraw are also supported for Draw objects.
apI for our data type for drawings
 www.it-ebooks.info

84 Chapter 1 n Fundamentals
Implementing abstract data types As with libraries of static methods, we im- plement ADTs with a Java class, putting the code in a  le with the same name as the class, followed by the .java extension. The  rst statements in the  le declare instance variables that de ne the data-type values. Following the instance variables are the con- structor and the instance methods that implement operations on data-type values. In- stance methods may be public (speci ed in the API) or private (used to organize the computation and not available to clients). A data-type de nition may have multiple constructors and may also include de nitions of static methods. In particular, a unit- test client main() is normally useful for testing and debugging. As a  rst example, we consider an implementation of the Counter ADT that we de ned on page 65. A full annotated implementation is shown on the facing page, for reference as we discuss its constituent parts. Every ADT implementation that you will develop has the same basic ingredients as this simple example.
                                                 public class Counter
                                                 {
 Instance variables To de ne data-type
values (the state of each object), we de-
clare instance variables in much the same
way as we declare local variables. There is a
critical distinction between instance vari-
ables and the local variables within a static
method or a block that you are accustomed to: there is just one value corresponding to each local variable at a given time, but there are numerous values corresponding to each instance variable (one for each object that is an instance of the data type). There is no ambiguity with this arrangement, because each time that we access an instance variable, we do so with an object name—that object is the one whose value we are accessing. Also, each declaration is quali ed by a visibility modi er. In ADT implementations, we use private, using a Java language mechanism to enforce the idea that the representa- tion of an ADT is to be hidden from the client, and also final, if the value is not to be changed once it is initialized. Counter has two instance variables: a String value name and an int value count. If we were to use public instance variables (allowed in Java) the data type would, by de nition, not be abstract, so we do not do so.
Constructors Every Java class has at least one constructor that establishes an object’s identity. A constructor is like a static method, but it can refer directly to instance vari- ables and has no return value. Generally, the purpose of a constructor is to initialize the instance variables. Every constructor creates an object and provides to the client a reference to that object. Constructors always share the same name as the class. We can overload the name and have multiple constructors with different signatures, just as with methods. If no other constructor is de ned, a default no-argument constructor is
instance
variable declarations ...
}
Instance variables in ADTs are private
private final String name;
private int count;
  www.it-ebooks.info

public class Counter
{
1.2 n
Data Abstraction 85
   instance variables
constructor
instance methods
test client
create and initialize objects
class private final String name; name
private int count;
     public Counter(String id)
{ name = id; }
  public void increment()
{ count++; }
   public int tally()
{ return count; }
   public String toString()
{ return count + " " + name; }
     public static void main(String[] args)
{
   Counter heads = new Counter("heads");
   Counter tails = new
        heads.increment();
heads.increment();
tails.increment();
invoke constructor
automatically invoke
toString()
 }
invoke method
Counter("tails");
object name
 StdOut.println(heads + " " + tails);
StdOut.println(heads.tally() - tails.tally() );
     www.it-ebooks.info
instance variable name
    }
Anatomy of a class that de nes a data type

86 Chapter 1 n Fundamentals
implicit, has no arguments, and initializes instance values to default values. The default values of instance variables are 0 for primitive numeric types, false for boolean, and null for reference types. These defaults
may be changed by using initializing
 declarations for instance variables. Java automatically invokes a constructor when a client program uses the keyword new. Overloaded constructors are typi- cally used to initialize instance variables to client-supplied values other than the defaults. For example, Counter has a one-argument constructor that initial- izes the name instance variable to the value given as argument (leaving the count instance variable to be initialized to the default value 0).
public class Counter
{
visibility modifier
NO return type
constructor name (same as class name)
parameter variable
signature
private final String name;
private int count;
...
                  public
Counter
(
String id
)
    of a sequence of statements, including a
return statement that provides a value of
the return type back to the client). When
a client invokes a method, the parameter
values (if any) are initialized with client
values, the statements are executed un-
til a return value is computed, and the
value is returned to the client, with the
same effect as if the method invocation
in the client were replaced with that value. All of this action is the same as for static methods, but there is one critical distinction for instance methods: they can access and perform operations on instance variables. How do we specify which object’s instance variables we want to use? If you think about this question for a moment, you will see the logical answer: a reference to a variable in an instance method refers to the value for the object that was used to invoke the method. When we say heads.increment() the code in increment() is referring to the instance variables for heads. In other words,
{}
name = id;
 code to initialize instance variables (count initialized to 0 by default)
... }
Anatomy of a constructor
Instance methods To implement data-type operations (the behavior of each object), we implement instance methods with code that is precisely like the code that you learned in Section 1.1 to implement static methods (functions). Each instance method has a return type, a signature (which speci es its name and the types and names of its param- eter variables), and a body (which consists
visibility return method modifier type name
{ count++; }
instance variable name
Anatomy of an instance method
signature
      public
  void
  increment()
   www.it-ebooks.info

object-oriented programming adds one critically important additional way to use vari- ables in a Java program:
n to invoke an instance method that operates on the object’s values.
The difference from working solely with static methods is semantic (see the Q&A), but has reoriented the way that modern programmers think about developing code in many situations. As you will see, it also dovetails well with the study of algorithms and data structures.
Scope In summary, the Java code that we write to implement instance methods uses three kinds of variables:
n Parameter variables n Local variables
n Instance variables
The  rst two of these are the same as for static methods: parameter variables are spec- i ed in the method signature and initialized with client values when the method is called, and local variables are declared and initialized within the method body. The scope of parameter variables is the entire method; the scope of local variables is the following statements in the block where they are de ned. Instance variables are com- pletely different: they hold data-type values for objects in a class, and their scope is the entire class (whenever there is an ambiguity, you can use the this pre x to identify in- stance variables). Understanding the distinctions among these three kinds of variables in instance methods is a key to success in object-oriented programming.
instance public class Example variable
                {
                   private int var;
                   ...
int var;
1.2 n Data Abstraction 87
  private void method1()
{
 local variable
}
          private void method2()
          {
... var ...
refers to local variable, NOT instance variable
 ...  var       ...
...  this.var  ...
  refers to instance variable
  }
... }
refers to instance variable
Scope of instance and local variables in an instance method
www.it-ebooks.info

88 Chapter 1 n Fundamentals
API, clients, and implementations These are the basic components that you need to understand to be able to build and use abstract data types in Java. Every ADT im- plementation that we will consider will be a Java class with private instance variables, constructors, instance methods, and a client. To fully understand a data type, we need the API, typical client code, and an implementation, summarized for Counter on the facing page. To emphasize the separation of client and implementation, we normally present each client as a separate class containing a static method main() and reserve test client’s main() in the data-type de nition for minimal unit testing and develop- ment (calling each instance method at least once). In each data type that we develop, we go through the same steps. Rather than thinking about what action we need to take next to accomplish a computational goal (as we did when  rst learning to program), we think about the needs of a client, then accommodate them in an ADT, following these three steps:
n Specify an API. The purpose of the API is to separate clients from implementa- tions, to enable modular programming. We have two goals when specifying an API. First, we want to enable clear and correct client code. Indeed, it is a good idea to write some client code before  nalizing the API to gain con dence that the speci ed data-type operations are the ones that clients need. Second, we want to be able to implement the operations. There is no point specifying opera- tions that we have no idea how to implement.
n Implement a Java class that meets the API speci cations. First we choose the instance variables, then we write constructors and the instance methods.
n Develop multiple test clients, to validate the design decisions made in the  rst two steps.
What operations do clients need to perform, and what data-type values can best sup- port those operations? These basic decisions are at the heart of every implementation that we develop.
 www.it-ebooks.info

typical client
apI public class Counter
Counter(String id) create a counter named id
  void
   int
String
increment()
tally()
toString()
increment the counter
number of increments since creation string representation
1.2 n Data Abstraction 89
   public class Flips
{
   public static void main(String[] args)
   {
      int T = Integer.parseInt(args[0]);
      Counter heads = new Counter("heads");
      Counter tails = new Counter("tails");
      for (int t = 0; t < T; t++)
         if (StdRandom.bernoulli(0.5))
              heads.increment();
         else tails.increment();
      StdOut.println(heads);
      StdOut.println(tails);
      int d = heads.tally() - tails.tally();
      StdOut.println("delta: " + Math.abs(d));
} }
 application
implementation
  public class Counter
{
   private final String name;
   private int count;
   public Counter(String id)
   { name = id; }
   public void increment()
   { count++; }
   public int tally()
   { return count; }
   public String toString()
   { return count + " " + name; }
}
  an abstract data type for a simple counter
% java Flips 1000000
500172 heads
499828 tails
delta: 344
 www.it-ebooks.info

90 Chapter 1 n Fundamentals
More implementations of abstract data types As with any programming concept, the best way to understand the power and utility of ADTs is to consider care- fully more examples and more implementations. There will be ample opportunity for you to do so, as much of this book is devoted to ADT implementations, but a few more simple examples will help us lay the groundwork for addressing them.
Date Shown on the facing page are two implementations of the Date ADT that we con- sidered onpage 79. To reduce clutter, we omit the parsing constructor (which is described inExercise1.2.19)andtheinheritedmethodsequals()(seepage103),compareTo()(see page 247), and hashCode() (see Exercise 3.4.22). The straightforward implementation on the left maintains the day, month, and year as instance variables, so that the instance methods can just return the appropriate value; the more space-ef cient implementa- tion on the right uses only a single int value to represent a date, using a mixed-radix number that represents the date with day d, month m, and year y as 512y + 32m + d. One way that a client might notice the difference between these implementations is by violating implicit assumptions: the second implementation depends for its correctness on the day being between 0 and 31, the month being between 0 and 15, and the year be- ing positive (in practice, both implementations should check that months are between 1 and 12, days are between 1 and 31, and that dates such as June 31 and February 29, 2009, are illegal, though that requires a bit more work). This example highlights the idea that we rarely fully specify implementation requirements in an API (we normally do the best we can, and could do better here). Another way that a client might notice the difference between the two implementations is performance: the implementation on the right uses less space to hold data-type values at the cost of more time to provide them to the client in the agreed form (one or two arithmetic operations are needed). Such trad- eoffs are common: one client may prefer one of the implementations and another client might prefer the other, so we need to accommodate both. Indeed, one of the recurring themes of this book is that we need to understand the space and time requirements of various implementations and their suitability for use by various clients. One of the key advantages of using data abstraction in our implementations is that we can normally change from one implementation to another without changing any client code.
Maintaining multiple implementations Multiple implementations of the same API can present maintainence and nomenclature issues. In some cases, we simply want to replace an old implementation with an improved one. In others, we may need to main- tain two implementations, one suitable for some clients, the other suitable for others. Indeed, a prime goal of this book is to consider in depth several implementations of each of a number of fundamental ADTs, generally with different performance charac- teristics. In this book, we often compare the performance of a single client using two
 www.it-ebooks.info

an abstract data type to encapsulate dates, with two implementations
application
1.2 n Data Abstraction 91
 apI
public class Date
   Date(int month, int day, int year) int month()
int day()
int year() String toString()
create a date month
day
year
string representation
test client
    public static void main(String[] args)
{
   int m = Integer.parseInt(args[0]);
   int d = Integer.parseInt(args[1]);
   int y = Integer.parseInt(args[2]);
   Date date = new Date(m, d, y);
   StdOut.println(date);
}
% java Date 12 31 1999
12/31/1999
implementation
  public class Date
{
   private final int month;
   private final int day;
   private final int year;
   public Date(int m, int d, int y)
   {  month = m; day = d; year = y; }
   public int month()
   {  return month;  }
   public int day()
   {  return day;  }
   public int year()
   {  return day;  }
   public String toString()
   {  return month() + "/" + day()
}
+ "/" + year();  }
alternate implementation
  public class Date
{
   private final int value;
   public Date(int m, int d, int y)
   { value = y*512 + m*32 + d; }
   public int month()
   { return (value / 32) % 16; }
   public int day()
   { return value % 32; }
   public int year()
   { return value / 512; }
   public String toString()
   {  return month() + "/" + day()
}
+ "/" + year();  }
 www.it-ebooks.info

92 Chapter 1 n Fundamentals
different implementations of the same API. For this reason, we generally adopt an in- formal naming convention where we:
n Identify different implementations of the same API by prepending a descrip- tive modi er. For example, we might name our Date implementations on the previous page BasicDate and SmallDate, and we might wish to develop a SmartDate implementation that can validate that dates are legal.
n Maintain a reference implementation with no pre x that makes a choice that should be suitable for most clients. That is, most clients should just use Date.
In a large system, this solution is not ideal, as it might involve changing client code. For example, if we were to develop a new implementation ExtraSmallDate, then our only options are to change client code or to make it the reference implementation for use by all clients. Java has various advanced language mechanisms for maintaining multiple implementations without needing to change client code, but we use them sparingly because their use is challenging (and even controversial) even for experts, especially in conjuction with other advanced language features that we do value (generics and itera- tors). These issues are important (for example, ignoring them led to the celebrated Y2K problem at the turn of the millennium, because many programs used their own imple- mentations of the date abstraction that did not take into account the  rst two digits of the year), but detailed consideration of these issues would take us rather far a eld from the study of algorithms.
Accumulator The accumulator API shown on the facing page de nes an abstract data type that provides to clients the ability to maintain a running average of data values. For example, we use this data type frequently in this book to process experimental results (see Section 1.4). The implementation is straightforward: it maintains an int instance variable N that counts the number of data values seen so far and a double instance variable total that keeps track of the sum of the values seen so far; to compute the average it divides the sum by the count. Note that the implementation does not save the data values—it could be used for a huge number of them (even on a device that is not capable of holding that many), or a huge number of accumulators could be used on a big system. This performance characteristic is subtle and might be speci ed in the API, because an implementation that does save the values might cause an application to run out of memory.
 www.it-ebooks.info

1.2 n Data Abstraction 93
public class Accumulator
 Accumulator()
void addDataValue(double val)
double mean()
String toString()
create an accumulator add a new data value mean of all data values string representation
 apI
  public class TestAccumulator
{
   public static void main(String[] args)
   {
      int T = Integer.parseInt(args[0]);
      Accumulator a = new Accumulator();
      for (int t = 0; t < T; t++)
         a.addDataValue(StdRandom.random());
      StdOut.println(a);
} }
typical client
  application
implementation
 % java TestAccumulator 1000
Mean (1000 values): 0.51829
% java TestAccumulator 1000000
Mean (1000000 values): 0.49948
% java TestAccumulator 1000000
Mean (1000000 values): 0.50014
 public class Accumulator
{
   private double total;
   private int N;
   public void addDataValue(double val)
   {
N++;
       total += val;
   }
   public double mean()
   {  return total/N;  }
   public String toString()
   { return "Mean (" + N + " values): "
}
+ String.format("%7.5f", mean()); }
 an abstract data type for accumulating data values
 www.it-ebooks.info

 94 Chapter 1 n Fundamentals
Visual accumulator The visual accumulator implementation shown on the facing page extends Accumulator to present a useful side effect: it draws on StdDraw all the
data (in gray) and the running average (in red).
The easiest way to do so is to add a constructor
that provides the number of points to be plotted
and the maximum value, for rescaling the plot.
VisualAccumulator is not technically an imple-
mentation of the Accumulator API (its construc-
tor has a different signature and it causes a differ-
ent prescribed side effect). Generally, we are
careful to fully specify APIs and are loath to make
any changes in an API once articulated, as it might
involve changing an unknown amount of client (and implementation) code, but add- ing a constructor to gain functionality can sometimes be defended because it involves changing the same line in client code that we change when changing a class name. In this example, if we have developed a client that uses an Accumulator and perhaps has many calls to addDataValue() and mean(), we can enjoy the bene ts of VisualAccumulator by just changing one line of client code.
application
% java TestVisualAccumulator 2000
Mean (2000 values): 0.509789
www.it-ebooks.info
height of Nth red dot from the left is the average of the heights
of the leftmost N gray dots
height of gray dot
is the data point value
Visual accumulator plot
1.2 n Data Abstraction 95
 apI
public class VisualAccumulator
  VisualAccumulator(int trials, double max)
void addDataValue(double val) double mean()
String toString()
add a new data value mean of all data values string representation
 public class TestVisualAccumulator
{
   public static void main(String[] args)
   {
      int T = Integer.parseInt(args[0]);
      VisualAccumulator a = new VisualAccumulator(T, 1.0);
      for (int t = 0; t < T; t++)
         a.addDataValue(StdRandom.random());
      StdOut.println(a);
} }
typical client
  public class VisualAccumulator
{
   private double total;
   private int N;
   public VisualAccumulator(int trials, double max)
   {
      StdDraw.setXscale(0, trials);
      StdDraw.setYscale(0, max);
      StdDraw.setPenRadius(.005);
}
   public void addDataValue(double val)
   {
      N++;
      total += val;
      StdDraw.setPenColor(StdDraw.DARK_GRAY);
      StdDraw.point(N, val);
      StdDraw.setPenColor(StdDraw.RED);
      StdDraw.point(N, mean());
}
   public double mean()
   public String toString()
   // Same as Accumulator.
}
implementation
 an abstract data type for accumulating data values (visual version)
 www.it-ebooks.info

96 Chapter 1 n Fundamentals
Designing abstract data types An abstract data type is a data type whose repre- sentation is hidden from the client. This idea has had a powerful effect on modern pro- gramming. The various examples that we have considered give us the vocabulary to ad- dress advanced characteristics of ADTs and their implementation as Java classes. Many of these topics are, on the surface, tangential to the study of algorithms, so it is safe for you to skim this section and refer to it later in the context of speci c implementation problems. Our goal is to put important information related to designing data types in one place for reference and to set the stage for implementations throughout this book.
Encapsulation A hallmark of object-oriented programming is that it enables us to encapsulate data types within their implementations, to facilitate separate development of clients and data type implementations. Encapsulation enables modular program- ming, allowing us to
n Independently develop client and implementation code
n Substitute improved implementations without affecting clients
n Support programs not yet written (the API is a guide for any future client)
Encapsulation also isolates data-type operations, which leads to the possibility of n Limiting the potential for error
n Adding consistency checks and other debugging tools in implementations n Clarifying client code
An encapsulated data type can be used by any client, so it extends the Java language. The programming style that we are advocating is predicated on the idea of breaking large programs into small modules that can be developed and debugged independently. This approach improves the resiliency of our software by limiting and localizing the ef- fects of making changes, and it promotes code reuse by making it possible to substitute new implementations of a data type to improve performance, accuracy, or memory footprint. The same idea works in many settings. We often reap the bene ts of encap- sulation when we use system libraries. New versions of the Java system often include new implementations of various data types or static method libraries, but the APIs do not change. In the context of the study of algorithms and data structures, there is strong and constant motivation to develop better algorithms because we can improve perfor- mance for all clients by substituting an improved ADT implementation without chang- ing the code of any client. The key to success in modular programming is to maintain independence among modules. We do so by insisting on the API being the only point of dependence between client and implementation. You do not need to know how a data type is implemented in order to use it and you can assume that a client knows nothing but the API when implementing a data type. Encapsulation is the key to attaining both of these advantages.
 www.it-ebooks.info

www.it-ebooks.info
1.2 n Data Abstraction 97
Designing APIs One of the most important and most challenging steps in building modern software is designing APIs. This task takes practice, careful deliberation, and many iterations, but any time spent designing a good API is certain to be repaid in time saved debugging or code reuse. Articulating an API might seem to be overkill when writing a small program, but you should consider writing every program as though you will need to reuse the code someday. Ideally, an API would clearly articulate behavior for all possible inputs, including side effects, and then we would have software to check that implementations meet the speci cation. Unfortunately, a fundamental result from theoretical computer science known as the speci cation problem implies that this goal is actually impossible to achieve. Brie y, such a speci cation would have to be written in a formal language like a programming language, and the problem of determining whether two programs perform the same computation is known, mathematically, to be undecidable. Therefore, our APIs are brief English-language descriptions of the set of values in the associated abstract data type along with a list of constructors and instance methods, again with brief English-language descriptions of their purpose, including side effects. To validate the design, we always include examples of client code in the text surrounding our APIs. Within this broad outline, there are numerous pitfalls that every API design is susceptible to:
n An API may be too hard to implement, implying implementations that are dif-  cult or impossible to develop.
n An API may be too hard to use, leading to client code that is more complicated than it would be without the API.
n An API may be too narrow, omitting methods that clients need.
n An API may be too wide, including a large number of methods not needed
by any client. This pitfall is perhaps the most common, and one of the most dif cult to avoid. The size of an API tends to grow over time because it is not dif cult to add methods to an existing API, but it is dif cult to remove methods without breaking existing clients.
n An API may be too general, providing no useful abstractions.
n An API may be too speci c, providing abstractions so detailed or so diffuse as to
be useless.
n An API may be too dependent on a particular representation, therefore not serv-
ing the purpose of freeing client code from the details of using that representa- tion. This pitfall is also dif cult to avoid, because the representation is certainly central to the development of the implementation.
These considerations are sometimes summarized in yet another motto: provide to cli- ents the methods they need and no others.

98 Chapter 1 n Fundamentals
Algorithms and abstract data types Data abstraction is naturally suited to the study of algorithms, because it helps us provide a framework within which we can precisely specify both what an algorithm needs to accomplish and how a client can make use of an algorithm. Typically, in this book, an algorithm is an implementation of an instance method in an abstract data type. For example, our whitelisting example at the begin- ning of the chapter is naturally cast as an ADT client, based on the following operations:
n Construct a SET from an array of given values.
n Determine whether a given value is in the set.
These operations are encapsulated in the StaticSETofInts ADT, shown on the facing page along with Whitelist, a typical client. StaticSETofInts is a special case of the more general and more useful symbol table ADT that is the focus of Chapter 3. Binary search is one of several algorithms that we study that is suitable for implementing these ADTs. By comparison with the BinarySearch implementation on page 47, this imple- mentation leads to clearer and more useful client code. For example, StaticSETofInts enforces the idea that the array must be sorted before rank() is called. With the abstract data type, we separate the client from the implementation making it easier for any client to bene t from the ingenuity of the binary search algorithm, just by following the API (clients of rank() in BinarySearch have to know to sort the array  rst). Whitelisting is one of many clients that can take advantage of binary search.
 Every Java program is a set of static methods and/or a data type implementation. In this book, we focus primarily on abstract data type implementations such as StaticSETofInts, where the focus is on operations and the representa- tion of the data is hidden from the client. As this example illustrates, data abstraction enables us to
application
  n Precisely specify what algorithms can provide for clients
n Separate algorithm implementations from the client code
n Develop layers of abstraction, where we make use of well-understood algorithms
to develop other algorithms
These are desirable properties of any approach to describing algorithms, whether it be an English-language description or pseudo-code. By embracing the Java class mecha- nism in support of data abstraction, we have little to lose and much to gain: working code that we can test and use to compare performance for diverse clients.
% java Whitelist largeW.txt < largeT.txt
499569
984875
295754
207807
140925
161828
...
www.it-ebooks.info

apI
typical client
public class StaticSETofInts
StaticSETofInts(int[] a) boolean contains(int key)
create a set from the values in a[] is key in the set?
1.2 n Data Abstraction 99
   public class Whitelist
{
   public static void main(String[] args)
   {
      int[] w = In.readInts(args[0]);
      StaticSETofInts set = new StaticSETofInts(w);
      while (!StdIn.isEmpty())
      {  // Read key, print if not in whitelist.
         int key = StdIn.readInt();
         if (!set.contains(key))
            StdOut.println(key);
} }
}
  import java.util.Arrays;
public class StaticSETofInts
{
   private int[] a;
   public StaticSETofInts(int[] keys)
   {
      a = new int[keys.length];
      for (int i = 0; i < keys.length; i++)
         a[i] = keys[i]; // defensive copy
      Arrays.sort(a);
}
   public boolean contains(int key)
   {  return rank(key) != -1;  }
   private int rank(int key)
   {  // Binary search.
      int lo  = 0;
      int hi = a.length - 1;
      while (lo <= hi)
      {  // Key is in a[lo..hi] or not present.
         int mid = lo + (hi - lo) / 2;
         if      (key < a[mid]) hi = mid - 1;
         else if (key > a[mid]) lo = mid + 1;
         else                   return mid;
}
return -1; }
}
implementation
 Binary search recast as an object-oriented program (an aDt for search in a set of integers)
 www.it-ebooks.info

100 Chapter 1 n Fundamentals
Interface inheritance Java provides language support for de ning relationships among objects, known as inheritance. These mechanisms are widely used by software developers, so you will study them in detail if you take a course in software engineer- ing. The  rst inheritance mechanism that we consider is known as subtyping, which allows us to specify a relationship between otherwise unrelated classes by specifying in an interface a set of common methods that each implementing class must contain. An interface is nothing more than a list of instance methods. For example, instead of using our informal API, we might have articulated an interface for Date:
    public interface Datable
    {
       int month();
       int day();
       int year();
}
and then referred to the interface in our implementation code
    public class Date implements Datable
    {
       // implementation code (same as before)
}
so that the Java compiler will check that it matches the interface. Adding the code implements Datable to any class that implements month(), day(), and year() pro- vides a guarantee to any client that an object of that class can invoke those methods. This arrangement is known as interface inheritance—an implementing class inherits the interface. Interface inheritance allows us to write client programs that can manipulate
interface
java.lang.Comparable
java.util.Comparator
methods
section
objects of any type that implements the interface (even a type to be creat- ed in the future), by invoking meth- ods in the interface. We might have used interface inheritance in place of our more informal APIs, but chose not to do so to avoid dependence on speci c high-level language mecha- nisms that are not critical to the understanding of algorithms and to avoid the extra baggage of inter- face  les. But there are a few situa- tions where Java conventions make
 comparison
iteration
compareTo() 2.1 compare() 2.5
java.lang.Iterable iterator() 1.3
java.util.Iterator
hasNext()
next() 1.3
remove()
Java interfaces used in this book
www.it-ebooks.info

it worthwhile for us to take advantage of interfaces: we use them for comparison and for iteration, as detailed in the table at the bottom of the previous page, and will consider them in more detail when we cover those concepts.
Implementation inheritance Java also supports another inheritence mechanism known as subclassing, which is a powerful technique that enables a programmer to change behavior and add functionality without rewriting an entire class from scratch. The idea is to de ne a new class (subclass, or derived class) that inherits instance meth- ods and instance variables from another class (superclass, or base class). The subclass contains more methods than the superclass. Moreover, the subclass can rede ne or override methods in the superclass. Subclassing is widely used by systems programmers to build so-called extensible libraries—one programmer (even you) can add methods to a library built by another programmer (or, perhaps, a team of systems programmers), effectively reusing the code in a potentially huge library. For example, this approach is widely used in the development of graphical user interfaces, so that the large amount of code required to provide all the facilities that users expect (drop-down menus, cut-and- paste, access to  les, and so forth) can be reused. The use of subclassing is controversial among systems and applications programmers (its advantages over interface inheri- tance are debatable), and we avoid it in this book because it generally works against encapsulation. Certain vestiges of the approach are built into Java and therefore un- avoidable: speci cally, every class is a subtype of Java’s Object class. This structure enables the “convention” that every class includes an implementation of getClass(), toString(), equals(), hashCode(), and several other methods that we do not use in this book. Actually, every class inherits these methods from Object through subclassing, so any client can use them for any object. We usually override toString(), equals(), hashCode() in new classes because the default Object implementation generally does not lead to the desired behavior. We now will consider toString() and equals(); we discuss hashCode() in Section 3.4.
method
getClass()
toString()
equals(Object that) is this object equal to that? 1.2 hashCode() hash code for this object 3.4
Inherited methods from Object used in this book
purpose
section
1.2 n Data Abstraction 101
   Class
 String
boolean
    int
what class is this object? 1.2 string representation of this object 1.1
www.it-ebooks.info

102 Chapter 1 n Fundamentals
String conversion By convention, every Java type inherits toString() from Object, so any client can invoke toString() for any object. This convention is the basis for Ja- va’s automatic conversion of one operand of the concatenation operator + to a String whenever the other operand is a String. If an object’s data type does not include an implementation of toString(), then the default implementation in Object is invoked, which is normally not helpful, since it typically returns a string representation of the memory address of the object. Accordingly, we generally include implementations of toString() that override the default in every class that we develop, as highlighted for Date on the facing page. As illustrated in this code, toString() implementations are often quite simple, implicitly (through +) using toString() for each instance variable.
Wrapper types Java supplies built-in reference types known as wrapper types, one for each of the primitive types: Boolean, Byte, Character, Double, Float, Integer, Long, and Short correspond to boolean, byte, char, double, float, int, long, and short, respectively. These classes consist primarily of static methods such as parseInt() but they also include the inherited instance methods toString(), compareTo(), equals(), and hashCode(). Java automatically converts from primitive types to wrapper types when warranted, as described on page 122. For example, when an int value is concat- enated with a String, it is converted to an Integer that can invoke toString().
Equality What does it mean for two objects to be equal? If we test equality with (a == b)whereaandbarereferencevariablesofthesametype,wearetestingwhether they have the same identity: whether the references are equal. Typical clients would rather be able to test whether the data-type values (object state) are the same, or to implement some type-speci c rule. Java gives us a head start by providing implementa- tions both for standard types such as Integer, Double, and String and for more com- plicated types such as File and URL. When using these types of data, you can just use the built-in implementation. For example, if x and y are String values, then x.equals(y) is true if and only if x and y have the same length and are identical in each character position. When we de ne our own data types, such as Date or Transaction, we need to override equals(). Java’s convention is that equals() must be an equivalence rela- tion. It must be
n Re exive : x.equals(x) is true.
n Symmetric : x.equals(y) is true if and only if y.equals(x) is true.
n Transitive : if x.equals(y) and y.equals(z) are true, then so is x.equals(z).
In addition, it must take an Object as argument and satisfy the following properties. n Consistent : multiple invocations of x.equals(y) consistently return the same
value, provided neither object is modi ed. n Not null : x.equals(null) returns false.
 www.it-ebooks.info

1.2 n Data Abstraction 103
These are natural de nitions, but ensuring that these properties hold, adhering to Java conventions, and avoiding unnecessary work in an implementation can be tricky, as il- lustrated for Date below. It takes the following step-by-step approach:
n If the reference to this object is the same as the reference to the argument object, return true. This test saves the work of doing all the other checks in this case.
n If the argument is null, return false, to adhere to the convention (and to avoid following a null reference in code to follow).
n If the objects are not from the same class, return false. To determine an object’s class, we use getClass(). Note that we can use == to tell us whether two objects of type Class are equal because getClass() is guaranteed to return the same reference for all objects in any given class.
n Cast the argument from Object to Date (this cast must succeed because of the previous test).
n Return false if any instance variables do not match. For other classes, some other de nition of equality might be appropriate. For example, we might regard two Counter objects as equal if their count instance variables are equal.
This implementation is a model that you can use to implement equals() for any type that you implement. Once you have implemented one equals(), you will not  nd it dif cult to implement another.
    public class Date
  {
     private final int month;
     private final int day;
     private final int year;
     public Date(int m, int d, int y)
     {  month = m; day = d; year = y; }
     public int month()
     {  return month;  }
     public int day()
     {  return day;  }
     public int year()
     {  return year;  }
     public String toString()
     {  return month() + "/" + day() + "/" + year();  }
     public boolean equals(Object x)
     {
        if (this == x) return true;
        if (x == null) return false;
        if (this.getClass() != x.getClass()) return false;
        Date that = (Date) x;
        if (this.day != that.day)
        if (this.month != that.month)
        if (this.year != that.year)
        return true;
}
}
overriding toString() and equals() in a data-type definition
return false;
return false;
return false;
 www.it-ebooks.info

104 Chapter 1 n Fundamentals
Memory management The ability to assign a new value to a reference variable cre- ates the possibility that a program may have created an object that can no longer be referenced. For example, consider the three assignment statements in the  gure at left. After the third assignment statement, not only do a and b refer to the same Date object (12/31/1999), but also there is no longer a reference to the Date object that was created
 and used to initialize b. The only reference to that object was in the variable b, and this reference was overwritten by the assignment, so there is no way to refer to the object again. Such an object is said to be orphaned. Objects are also orphaned when they go out of scope. Java programs tend to create huge numbers of objects (and variables that hold primitive data-type values), but only have a need for a small number of them at any given point in time. Accord- ingly, programming languages and systems need mecha- nisms to allocate memory for data-type values during the time they are needed and to free the memory when they are no longer needed (for an object, sometime after it is orphaned). Memory management turns out to be easier for primitive types because all of the information needed for memory allocation is known at compile time. Java (and most other systems) takes care of reserving space for vari- ables when they are declared and freeing that space when they go out of scope. Memory management for objects is more complicated: the system can allocate memory for an object when it is created, but cannot know precisely when to free the memory associated with each object because the dynamics of a program in execution determines when objects are orphaned. In many languages (such as C and C++) the programmer is responsible for both allocating and freeing memory. Doing so is tedious and notoriously
error-prone. One
age memory. The
memory by keeping track of orphaned objects and returning the memory they use to a pool of free memory. Reclaiming memory in this way is known as garbage collection. One of Java’s characteristic features is its policy that references cannot be modi ed. This policy enables Java to do ef cient automatic garbage collection. Programmers still debate whether the overhead of automatic garbage collection justi es the convenience of not having to worry about memory management.
Date a = new Date(12, 31, 1999);
Date b = new Date( 1,  1, 2011);
b = a;
   655
 655
  12
 31
 1999
  1
 1
 2011
 a b
655 656 657
811 812 813
references to same object
New Year’s Eve 1999
orphaned object
New Year’s Day 2011
An orphaned object
        of Java’s most signi cant features is its ability to automatically man- idea is to free the programmers from the responsibility of managing
www.it-ebooks.info

Immutability An immutable data type, such as Date, has the property that the value of an object never changes once constructed. By contrast, a mutable data type, such as Counter or Accumulator, manipulates object values that are intended to change. Java’s language support for helping to enforce immutability is the final modi er. When you declare a variable to be final, you are promising to assign it a value only once, either in an initializer or in the constructor. Code that could modify the value of a final variable leads to a compile-time error. In our code, we use the modi er final with instance variables whose values never change. This policy serves as documentation that the value does not change, prevents accidental changes, and makes programs easier to debug. For example, you do not have to include a final value in a trace, since you know that its value never changes. A data type such as Date whose instance variables are all primitive and final is immutable (in code that does not use implementation inheritence, our convention). Whether to make a data type immutable is an important design decision and depends on the application at hand. For data
types such as Date, the purpose of the abstraction is to encap-
sulate values that do not change so that we can use them in as-
signment statements and as arguments and return values from
functions in the same way as we use primitive types (without hav-
ing to worry about their values changing). A programmer imple-
menting a Date client might reasonably expect to write the code
d = d0 fortwoDatevariables,inthesamewayasfordoubleor
int values. But if Date were mutable and the value of d were to
change after the assignment d = d0, then the value of d0 would also change (they are both references to the same object)! On the other hand, for data types such as Counter and Accumulator, the very purpose of the abstraction is to encapsulate values as they change. You have already encountered this distinction as a client programmer, when using Java arrays (mutable) and Java’s String data type (immutable). When you pass a String to a method, you do not worry about that method changing the sequence of characters in the String, but when you pass an array to a method, the method is free to change the contents of the array. String objects are immutable because we generally do not want String values to change, and Java arrays are mutable because we generally do want array values to change. There are also situations where we want to have mutable strings (that is the purpose of Java’s StringBuilder class) and where we want to have immutable arrays (that is the purpose of the Vector class that we consider later in this section). Generally, immutable types are easier to use and harder to misuse than muta- ble types because the scope of code that can change their values is far smaller. It is easier to debug code that uses immutable types because it is easier to guarantee that variables in client code that uses them remain in a consistent state. When using mutable types,
1.2 n Data Abstraction 105
 mutable
Counter
Java arrays
immutable
Date
String
 www.it-ebooks.info
Mutable/immutable examples

106 Chapter 1 n Fundamentals
you must always be concerned about where and when their values change. The down- side of immutability is that a new object must be created for every value. This expense is normally manageable because Java garbage collectors are typically optimized for such situations. Another downside of immutability stems from the fact that, unfortunately, final guarantees immutability only when instance variables are primitive types, not reference types. If an instance variable of a reference type has the final modi er, the value of that instance variable (the reference to an object) will never change—it will always refer to the same object—but the value of the object itself can change. For ex- ample, this code does not implement an immutable type:
    public class Vector
    {
       private final double[] coords;
       public Vector(double[] a)
       {  coords = a; }
       ...
}
A client program could create a Vector by specifying the entries in an array, and then
(bypassing the API) change the elements of the Vector after construction:
    double[] a = { 3.0, 4.0 };
    Vector vector = new Vector(a);
    a[0] = 0.0;  // Bypasses the public API.
The instance variable coords[] is private and final, but Vector is mutable because the client holds a reference to the data. Immutability needs to be taken into account in any data-type design, and whether a data type is immutable should be speci ed in the API, so that clients know that object values will not change. In this book, our primary interest in immutability is for use in certifying the correctness of our algorithms. For example, if the type of data used for a binary search algorithm were mutable, then cli- ents could invalidate our assumption that the array is sorted for binary search.
 www.it-ebooks.info

Design by contract To conclude, we brie y discuss Java language mechanisms that enables you to verify assumptions about your program as it is running. We use two Java language mechanisms for this purpose:
n Exceptions and errors, which generally handle unforeseen errors outside our control
n Assertions, which verify assumptions that we make within code we develop Liberal use of both exceptions and assertions is good programming practice. We use them sparingly in the book for economy, but you will  nd them throughout the code on the booksite. This code aligns with a substantial amount of the surrounding com- mentary about each algorithm in the text that has to do with exceptional conditions and with asserted invariants.
Exceptions and errors Exceptions and errors are disruptive events that occur while a program is running, often to signal an error. The action taken is known as throwing an exception or throwing an error. We have already encountered exceptions thrown by Java system methods in the course of learning basic features of Java: StackOverflowError, ArithmeticException, ArrayIndexOutOfBoundsException, OutOfMemoryError, and NullPointerException are typical examples. You can also create your own ex- ceptions. The simplest kind is a RuntimeException that terminates execution of the program and prints an error message
    throw new RuntimeException("Error message here.");
A general practice known as fail fast programming suggests that an error is more easily pinpointed if an exception is thrown as soon as an error is discovered (as opposed to ignoring the error and deferring the exception to sometime in the future).
Assertions An assertion is a boolean expression that you are af rming is true at that point in the program. If the expression is false, the program will terminate and re- port an error message. We use assertions both to gain con dence in the correctness of programs and to document intent. For example, suppose that you have a computed value that you might use to index into an array. If this value were negative, it would cause an ArrayIndexOutOfBoundsException sometime later. But if you write the code assert index >= 0; you can pinpoint the place where the error occurred. You can also add an optional detail message such as
     assert index >= 0 : "Negative index in method X";
to help you locate the bug. By default, assertions are disabled. You can enable them from the command line by using the -enableassertions  ag (-ea for short). Assertions are for debugging: your program should not rely on assertions for normal operation since they may be disabled. When you take a course in systems programming, you will learn
1.2 n Data Abstraction 107
 www.it-ebooks.info

108 Chapter 1 n Fundamentals
to use assertions to ensure that your code never terminates in a system error or goes into an in nite loop. One model, known as the design-by-contract model of programming expresses the idea. The designer of a data type expresses a precondition (the condition that the client promises to satisfy when calling a method), a postcondition (the condi- tion that the implementation promises to achieve when returning from a method), and side effects (any other change in state that the method could cause). During develop- ment, these conditions can be tested with assertions.
Summary The language mechanisms discussed throughout this section illustrate that effective data-type design leads to nontrivial issues that are not easy to resolve. Ex- perts are still debating the best ways to support some of the design ideas that we are discussing. Why does Java not allow functions as arguments? Why does Matlab copy arrays passed as arguments to functions? As mentioned early in Chapter 1, it is a slip- pery slope from complaining about features in a programming language to becoming a programming-language designer. If you do not plan to do so, your best strategy is to use widely available languages. Most systems have extensive libraries that you cer- tainly should use when appropriate, but you often can simplify your client code and protect yourself by building abstractions that can easily transport to other languages. Your main goal is to develop data types so that most of your work is done at a level of abstraction that is appropriate to the problem at hand.
The table on the facing page summarizes the various kinds of Java classes that we have considered.
 www.it-ebooks.info

kind of class
static methods
immutable abstract data type
mutable abstract data type
abstract data type with I/O side e ects
examples
 Math StdIn StdOut
 Date Transaction
   String Integer
Counter Accumulator
 VisualAccumulator
    In Out Draw
1.2 n Data Abstraction 109 characteristics
no instance variables instance variables all private
instance variables all final defensive copy for reference types Note: these are necessary but not suf cient.
instance variables all private not all instance variables final
instance variables all private instance methods do I/O
 Java classes (data-type implementations)
www.it-ebooks.info

110 Chapter 1 n Fundamentals
   Q. Why bother with data abstraction?
A. Ithelpsusproducereliableandcorrectcode.Forexample,inthe2000presidential election, Al Gore received –16,022 votes on an electronic voting machine in Volusia County, Florida—the tally was clearly not properly encapsulated in the voting machine software!
Q. Whythedistinctionbetweenprimitiveandreferencetypes?Whynotjusthaverefer- ence types?
A. Performance.JavaprovidesthereferencetypesInteger,Double,andsoforththat correspond to primitive types that can be used by programmers who prefer to ignore the distinction. Primitive types are closer to the types of data that are supported by computer hardware, so programs that use them usually run faster than programs that use corresponding reference types.
Q. Do data types have to be abstract?
A. No. Java also allows public and protected to allow some clients to refer directly to instance variables. As described in the text, the advantages of allowing client code to directly refer to data are greatly outweighed by the disadvantages of dependence on a particular representation, so all instance variables are private in our code. We also oc- casionally use private instance methods to share code among public methods.
Q. What happens if I forget to use new when creating an object?
A. ToJava,itlooksasthoughyouwanttocallastaticmethodwithareturnvalueofthe object type. Since you have not de ned such a method, the error message is the same as anytime you refer to an unde ned symbol. If you compile the code
    Counter c = Counter("test");
you get this error message:
    cannot find symbol
    symbol  : method Counter(String)
You get the same kind of error message if you provide the wrong number of arguments to a constructor.
www.it-ebooks.info
 Q&A
  Q. What happens if I forget to use new when creating an array of objects?
A. Youneedtousenewforeachobjectthatyoucreate,sowhenyoucreateanarrayof N objects, you need to use new N+1 times: once for the array and once for each of the objects. If you forget to create the array:
    Counter[] a;
    a[0] = new Counter("test");
you get the same error message that you would get when trying to assign a value to any uninitialized variable:
    variable a might not have been initialized
          a[0] = new Counter("test");
          ^
but if you forget to use new when creating an object within the array and then try to use it to invoke a method:
    Counter[] a = new Counter[2];
    a[0].increment();
you get a NullPointerException.
Q. Why not write StdOut.println(x.toString()) to print objects?
A. That code works  ne, but Java saves us the trouble of writing it by automatically invoking the toString() method for any object, since println() has a method that takes an Object as argument.
Q. What is a pointer ?
A. Goodquestion.PerhapsthatshouldbeNullReferenceException.LikeaJavaref- erence, you can think of a pointer as a machine address. In many programming lan- guages, the pointer is a primitive data type that programmers can manipulate in many ways. But programming with pointers is notoriously error-prone, so operations pro- vided for pointers need to be carefully designed to help programmers avoid errors. Java takes this point of view to an extreme (that is favored by many modern program- ming-language designers). In Java, there is only one way to create a reference (new) and only one way to change a reference (with an assignment statement). That is, the only things that a programmer can do with references are to create them and copy them. In
www.it-ebooks.info
1.2 n Data Abstraction 111

112 Chapter 1 n Fundamentals
   www.it-ebooks.info
 Q & A (continued)
programming-language jargon, Java references are known as safe pointers, because Java can guarantee that each reference points to an object of the speci ed type (and it can determine which objects are not in use, for garbage collection). Programmers used to writing code that directly manipulates pointers think of Java as having no pointers at all, but people still debate whether it is really desirable to have unsafe pointers.
Q. WherecanI ndmoredetailsonhowJavaimplementsreferencesanddoesgarbage collection?
A. One Java system might differ completely from another. For example, one natural scheme is to use a pointer (machine address); another is to use a handle (a pointer to a pointer). The former gives faster access to data; the latter provides for better garbage collection.
Q. What exactly does it mean to import a name?
A. Notmuch:itjustsavessometyping.Youcouldtypejava.util.Arraysinsteadof
Arrays everywhere in your code instead of using the import statement.
Q. What is the problem with implementation inheritance?
A. Subtyping makes modular programming more dif cult for two reasons. First, any change in the superclass affects all subclasses. The subclass cannot be developed inde- pendently of the superclass; indeed, it is completely dependent on the superclass. This problem is known as the fragile base class problem. Second, the subclass code, hav- ing access to instance variables, can subvert the intention of the superclass code. For example, the designer of a class like Counter for a voting system may take great care to make it so that Counter can only increment the tally by one (remember Al Gore’s problem). But a subclass, with full access to the instance variable, can change it to any value whatever.
Q. How do I make a class immutable?
A. To ensure immutability of a data type that includes an instance variable of a mu- table type, we need to make a local copy, known as a defensive copy. And that may not be enough. Making the copy is one challenge; ensuring that none of the instance methods change values is another.
Q. What is null?
  A. It is a literal value that refers to no object. Invoking a method using the null ref- erence is meaningless and results in a NullPointerException. If you get this error message, check to make sure that your constructor properly initializes all of its instance variables.
Q. Can I have a static method in a class that implements a data type?
A. Ofcourse.Forexample,allofourclasseshavemain().Also,itisnaturaltoconsider adding static methods for operations that involve multiple objects where none of them naturally suggests itself as the one that should invoke the method. For example, we might de ne a static method like the following within Point:
    public static double distance(Point a, Point b)
    {
       return a.distTo(b);
    }
Often, including such methods can serve to clarify client code.
Q. Are there other kinds of variables besides parameter, local, and instance variables?
A. If you include the keyword static in a class declaration (outside of any type) it creates a completely different type of variable, known as a static variable. Like instance variables, static variables are accessible to every method in the class; however, they are not associated with any object. In older programming languages, such variables are known as global variables, because of their global scope. In modern programming, we focus on limiting scope and therefore rarely use such variables. When we do, we will call attention to them.
Q. What is a deprecated method?
A. Amethodthatisnolongerfullysupported,butkeptinanAPItomaintaincompat- ibility. For example, Java once included a method Character.isSpace(), and pro- grammers wrote programs that relied on using that method’s behavior. When the de- signers of Java later wanted to support additional Unicode whitespace characters, they could not change the behavior of isSpace() without breaking client programs, so, instead, they added a new method, Character.isWhiteSpace(), and deprecated the old method. As time wears on, this practice certainly complicates APIs. Sometimes, en- tire classes are deprecated. For example, Java deprecated its java.util.Date in order to better support internationalization.
www.it-ebooks.info
1.2 n Data Abstraction 113

114 Chapter 1 n Fundamentals
  1.2.1 Write a Point2D client that takes an integer value N from the command line, generates N random points in the unit square, and computes the distance separating the closest pair of points.
1.2.2 Write an Interval1D client that takes an int value N as command-line argu- ment, reads N intervals (each de ned by a pair of double values) from standard input, and prints all pairs that intersect.
1.2.3 WriteanInterval2Dclientthattakescommand-lineargumentsN,min,andmax and generates N random 2D intervals whose width and height are uniformly distributed between min and max in the unit square. Draw them on StdDraw and print the number of pairs of intervals that intersect and the number of intervals that are contained in one another.
1.2.4 What does the following code fragment print?
    String string1 = "hello";
    String string2 = string1;
    string1 = "world";
    StdOut.println(string1);
    StdOut.println(string2);
1.2.5 What does the following code fragment print?
    String s = "Hello World";
    s.toUpperCase();
    s.substring(6, 11);
    StdOut.println(s);
Answer: "Hello World". String objects are immutable—string methods return a new String object with the appropriate value (but they do not change the value of the object that was used to invoke them). This code ignores the objects returned and just prints the original string. To print "WORLD", use s = s.toUpperCase() and s = s.substring(6, 11).
1.2.6 A string s is a circular rotation of a string t if it matches when the characters are circularly shifted by any number of positions; e.g., ACTGACG is a circular shift of TGACGAC, and vice versa. Detecting this condition is important in the study of genomic sequences. Write a program that checks whether two given strings s and t are circular
www.it-ebooks.info
 ExErcisEs
  shifts of one another. Hint : The solution is a one-liner with indexOf(), length(), and string concatenation.
1.2.7 What does the following recursive function return?
    public static String mystery(String s)
    {
       int N = s.length();
       if (N <= 1) return s;
       String a = s.substring(0, N/2);
       String b = s.substring(N/2, N);
       return mystery(b) + mystery(a);
}
1.2.8 Suppose that a[] and b[] are each integer arrays consisting of millions of inte-
gers. What does the follow code do? Is it reasonably ef cient?
    int[] t = a; a = b; b = t;
Answer. It swaps them. It could hardly be more ef cient because it does so by copying references, so that it is not necessary to copy millions of elements.
1.2.9 InstrumentBinarySearch(page47)touseaCountertocountthetotalnumber of keys examined during all searches and then print the total after all searches are com- plete. Hint : Create a Counter in main() and pass it as an argument to rank().
1.2.10 Develop a class VisualCounter that allows both increment and decrement operations. Take two arguments N and max in the constructor, where N speci es the maximum number of operations and max speci es the maximum absolute value for the counter. As a side effect, create a plot showing the value of the counter each time its tally changes.
1.2.11 Develop an implementation SmartDate of our Date API that raises an excep- tion if the date is not legal.
1.2.12 Add a method dayOfTheWeek() to SmartDate that returns a String value Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, or Sunday, giving the ap- propriate day of the week for the date. You may assume that the date is in the 21st century.
 1.2 n Data Abstraction 115
 www.it-ebooks.info
116 Chapter 1 n Fundamentals
 ExErcisEs (continued)
1.2.13 Using our implementation of Date as a model p( age 91), develop an implementa- tion of Transaction.
1.2.14 Usingourimplementationofequals()inDateasamodel(page103),developan implementation of equals() for Transaction.
 www.it-ebooks.info

 crEAtivE problEms
  1.2.15 File input. Develop a possible implementation of the static readInts() meth- od from In (which we use for various test clients, such as binary search onpage 47) that is based on the split() method in String.
Solution:
    public static int[] readInts(String name)
    {
       In in = new In(name);
       String input = in.readAll();
        String[] words = input.split("\\s+");
       int[] ints = new int[words.length];
       for int i = 0; i < word.length; i++)
          ints[i] = Integer.parseInt(words[i]);
       return ints;
}
We will consider a different implementation in Section 1.3 (see page 126).
1.2.16 Rational numbers. Implement an immutable data type Rational for rational
numbers that supports addition, subtraction, multiplication, and division.
    public class Rational
Rational
Rational
Rational
Rational
 boolean
  String
plus(Rational b)
minus(Rational b)
times(Rational b)
dividedBy(Rational b)
equals(Object that)
toString()
sum of this number and b difference of this number and b product of this number and b quotient of this number and b is this number equal to that ? string representation
Rational(int numerator, int denominator)
You do not have to worry about testing for over ow (see Exercise 1.2.17), but use as instance variables two long values that represent the numerator and denominator to limit the possibility of over ow. Use Euclid’s algorithm (see page 4) to ensure that the numerator and denominator never have any common factors. Include a test client that exercises all of your methods.
www.it-ebooks.info
1.2 n Data Abstraction 117

118 Chapter 1 n Fundamentals
   www.it-ebooks.info
 crEAtivE problEms (continued)
1.2.17 Robust implementation of rational numbers. Use assertions to develop an im- plementation of Rational (see Exercise 1.2.16) that is immune to over ow.
1.2.18 Variance for accumulator. Validate that the following code, which adds the methods var() and stddev() to Accumulator, computes both the sample mean, sam- ple variance, and sample standard deviation of the numbers presented as arguments to addDataValue():
    public class Accumulator
    {
       private double m;
       private double s;
       private int N;
       public void addDataValue(double x)
       {
          N++;
          s = s + 1.0 * (N-1) / N * (x - m) * (x - m);
          m = m + (x - m) / N;
}
       public double mean()
       {  return m;  }
       public double var()
       {  return s/(N - 1);  }
       public double stddev()
       {  return Math.sqrt(this.var());  }
}
This implementation is less susceptible to roundoff error than the straightforward im- plementation based on saving the sum of the squares of the numbers.
  1.2.19 Parsing. Develop the parse constructors for your Date and Transaction im- plementations of Exercise 1.2.13 that take a single String argument to specify the initialization values, using the formats given in the table below.
Partial solution:
    public Date(String date)
    {
       String[] fields = date.split("/");
       month = Integer.parseInt(fields[0]);
       day   = Integer.parseInt(fields[1]);
       year  = Integer.parseInt(fields[2]);
}
type format
Date integers separated by slashes Transaction customer, date, and amount,
separated by whitespace
Formats for parsing
example
      5/22/1939
Turing 5/22/1939 11.99
   1.2 n Data Abstraction 119
 www.it-ebooks.info
   120
Several fundamental data types involve collections of objects. Speci cally, the set of values is a collection of objects, and the operations revolve around adding, remov- ing, or examining objects in the collection. In this section, we consider three such data types, known as the bag, the queue, and the stack. They differ in the speci cation of which object is to be removed or examined next.
Bags, queues, and stacks are fundamental and broadly useful. We use them in imple- mentations throughout the book. Beyond this direct applicability, the client and imple- mentation code in this section serves as an introduction to our general approach to the development of data structures and algorithms.
One goal of this section is to emphasize the idea that the way in which we represent the objects in the collection directly impacts the ef ciency of the various operations. For collections, we design data structures for representing the collection of objects that can support ef cient implementation of the requisite operations.
A second goal of this section is to introduce generics and iteration, basic Java con- structs that substantially simplify client code. These are advanced programming-lan- guage mechanisms that are not necessarily essential to the understanding of algorithms, but their use allows us to develop client code (and implementations of algorithms) that is more clear, compact, and elegant than would otherwise be possible.
A third goal of this section is to introduce and show the importance of linked data structures. In particular, a classic data structure known as the linked list enables im- plementation of bags, queues, and stacks that achieve ef ciencies not otherwise pos- sible. Understanding linked lists is a key  rst step to the study of algorithms and data structures.
For each of the three types, we consider APIs and sample client programs, then look at possible representations of the data type values and implementations of the data-type operations. This scenario repeats (with more complicated data structures) throughout this book. The implementations here are models of implementations later in the book and worthy of careful study.
www.it-ebooks.info
 1.3 BAgS, QUeUeS, AnD StACkS

 APIs As usual, we begin our discussion of abstract data types for collections by de-  ning their APIs, shown below. Each contains a no-argument constructor, a method to add an item to the collection, a method to test whether the collection is empty, and a method that returns the size of the collection. Stack and Queue each have a method to remove a particular item from the collection. Beyond these basics, these APIs re ect two Java features that we will describe on the next few pages: generics and iterable collections.
Bag
1.3 n Bags, Queues, and Stacks 121
 public class Bag<Item> implements Iterable<Item>
 FIFo queue
Bag()
void add(Item item)
boolean isEmpty() int size()
create an empty bag
add an item
is the bag empty?
number of items in the bag
public class Queue<Item> implements Iterable<Item>
 Queue()
void enqueue(Item item) Item dequeue()
boolean isEmpty() int size()
pushdown (LIFo) stack
create an empty queue
add an item
remove the least recently added item is the queue empty?
number of items in the queue
public class Stack<Item> implements Iterable<Item>
 Stack()
void push(Item item)
Item pop() boolean isEmpty()
int size()
create an empty stack
add an item
remove the most recently added item is the stack empty?
number of items in the stack
apIs for fundamental generic iterable collections
www.it-ebooks.info

122 Chapter 1 n Fundamentals
Generics An essential characteristic of collection ADTs is that we should be able to use them for any type of data. A speci c Java mechanism known as generics, also known as parameterized types, enables this capability. The impact of generics on the program- ming language is suf ciently deep that they are not found in many languages (including early versions of Java), but our use of them in the present context involves just a small bit of extra Java syntax and is easy to understand. The notation <Item> after the class name in each of our APIs de nes the name Item as a type parameter, a symbolic place- holder for some concrete type to be used by the client. You can read Stack<Item> as “stack of items.” When implementing Stack, we do not know the concrete type of Item, but a client can use our stack for any type of data, including one de ned long after we develop our implementation. The client code provides a concrete type when the stack is created: we can replace Item with the name of any reference data type (consistently, everywhere it appears). This provides exactly the capability that we need. For example, you can write code such as
    Stack<String> stack = new Stack<String>();
    stack.push("Test");
    ...
    String next = stack.pop();
to use a stack for String objects and code such as
    Queue<Date> queue = new Queue<Date>();
    queue.enqueue(new Date(12, 31, 1999));
    ...
    Date next = queue.dequeue();
to use a queue for Date objects. If you try to add a Date (or data of any other type than String) to stack or a String (or data of any other type than Date) to queue, you will get a compile-time error. Without generics, we would have to de ne (and implement) different APIs for each type of data we might need to collect; with generics, we can use one API (and one implementation) for all types of data, even types that are imple- mented in the future. As you will soon see, generic types lead to clear client code that is easy to understand and debug, so we use them throughout this book.
Autoboxing Type parameters have to be instantiated as reference types, so Java has special mechanisms to allow generic code to be used with primitive types. Recall that Java’s wrapper types are reference types that correspond to primitive types: Boolean, Byte, Character, Double, Float, Integer, Long, and Short correspond to boolean, byte, char, double, float, int, long, and short, respectively. Java automatically con- verts between these reference types and the corresponding primitive types—in assign- ments, method arguments, and arithmetic/logic expressions. In the present context,
 www.it-ebooks.info

1.3 n Bags, Queues, and Stacks 123 this conversion is helpful because it enables us to use generics with primitive types, as
in the following code:
    Stack<Integer> stack = new Stack<Integer>();
    stack.push(17);      // auto-boxing (int -> Integer)
    int i = stack.pop(); // auto-unboxing (Integer -> int)
Automatically casting a primitive type to a wrapper type is known as autoboxing, and automatically casting a wrapper type to a primitive type is known as auto-unboxing. In this example, Java automatically casts (autoboxes) the primitive value 17 to be of type Integer when we pass it to the push() method. The pop() method returns an Integer, which Java casts (auto-unboxes) to an int before assigning it to the variable i.
Iterable collections For many applications, the client’s requirement is just to process each of the items in some way, or to iterate through the items in the collection. This paradigm is so important that it has achieved  rst-class status in Java and many other modern languages (the programming language itself has speci c mechanisms to sup- port it, not just the libraries). With it, we can write clear and compact code that is free from dependence on the details of a collection’s implementation. For example, suppose that a client maintains a collection of transactions in a Queue, as follows:
    Queue<Transaction> collection = new Queue<Transaction>();
If the collection is iterable, the client can print a transaction list with a single statement:
    for (Transaction t : collection)
    {  StdOut.println(t);  }
This construct is known as the foreach statement: you can read the for statement as for each transaction t in the collection, execute the following block of code. This client code does not need to know anything about the representation or the implementation of the collection; it just wants to process each of the items in the collection. The same for loop would work with a Bag of transactions or any other iterable collection. We could hardly imagine client code that is more clear and compact. As you will see, supporting this capability requires extra effort in the implementation, but this effort is well worthwhile.
It is interesting to note that the only differences between the APIs for Stack and Queue are their names and the names of the methods. This observation highlights the idea that we cannot easily specify all of the characteristics of a data type in a list of method signatures. In this case, the true speci cation has to do with the English-lan- guage descriptions that specify the rules by which an item is chosen to be removed (or to be processed next in the foreach statement). Differences in these rules are profound, part of the API, and certainly of critical importance in developing client code.
 www.it-ebooks.info

124 Chapter 1 n Fundamentals
Bags A bag is a collection where removing items is not supported—its purpose is to provide clients with the ability to collect items and then to iterate through the collected items (the client can also test if a bag is empty and  nd its number of items). The order of iteration is unspeci ed and should be immaterial to the client. To appreciate the con- cept, consider the idea of an avid marble collector, who might put marbles in a bag, one at a time, and periodically process all the marbles to look
 for one having some particular characteristic. With our Bag API, a client can add items to a bag and process them all with a foreach statement whenever needed. Such a cli- ent could use a stack or a queue, but one way to emphasize that the order in which items are processed is immaterial is to use a Bag. The class Stats at right illustrates a typi- cal Bag client. The task is simply to compute the average and the sample standard deviation of the double values on standard input. If there are N numbers on standard in- put, their average is computed by adding the numbers and dividing by N; their sample standard deviation is comput- ed by adding the squares of the difference between each number and the average, dividing by N–1, and taking the square root. The order in which the numbers are consid- ered is not relevant for either of these calculations, so we save them in a Bag and use the foreach construct to com- pute each sum. Note : It is possible to compute the stan- dard deviation without saving all the numbers (as we did for the average in Accumulator—see Exercise 1.2.18). Keeping the numbers in a Bag is required for more com- plicated statistics.
a bag of marbles
add( )
add( )
   for (Marble m : bag)
process each marble m (in any order)
Operations on a bag
                              www.it-ebooks.info

typical Bag client
1.3 n Bags, Queues, and Stacks 125
 public class Stats
{
   public static void main(String[] args)
   {
      Bag<Double> numbers = new Bag<Double>();
      while (!StdIn.isEmpty())
         numbers.add(StdIn.readDouble());
      int N = numbers.size();
      double sum = 0.0;
      for (double x : numbers)
         sum += x;
      double mean = sum/N;
      sum = 0.0;
      for (double x : numbers)
         sum += (x - mean)*(x - mean);
      double std = Math.sqrt(sum/(N-1));
      StdOut.printf("Mean: %.2f\n", mean);
      StdOut.printf("Std dev: %.2f\n", std);
} }
  application
 % java Stats
100
99
101
120
98
107
109
81
101
90
Mean: 100.60
Std dev: 10.51
www.it-ebooks.info

126 Chapter 1 n Fundamentals
FIFO queues A FIFO queue (or just a queue) is a collection that is based on the  rst- in- rst-out (FIFO) policy. The policy of doing tasks in the same order that they arrive
 server
queue of customers
012
is one that we encounter frequently in everyday life: from people waiting in line at a theater, to cars wait- ing in line at a toll booth, to tasks waiting to be ser- viced by an application on your computer. One bed- rock principle of any service policy is the perception of fairness. The  rst idea that comes to mind when most people think about fairness is that whoever has been waiting the longest should be served  rst. That is precisely the FIFO discipline. Queues are a natu- ral model for many everyday phenomena, and they play a central role in numerous applications. When a client iterates through the items in a queue with the foreach construct, the items are processed in the order they were added to the queue. A typical reason to use a queue in an application is to save items in a collection while at the same time preserving their relative order: they come out in the same order in which they were put in. For example, the client be- low is a possible implementation of the readInts() static method from our In class. The problem that this method solves for the client is that the client can get numbers from a  le into an array without know-
      new arrival at the end
 enqueue
      3 0123
  enqueue
4
dequeue
new arrival at the end
01234
      first in line leaves queue
        001234
next in line leaves queue
dequeue
         11234
A typical FIFO queue
ing the  le size ahead of time. We enqueue the numbers from the  le, use the size() method from Queue to  nd the size needed for the array, create the array, and then dequeue the numbers to move
them to the array. A queue is
appropriate because it puts the numbers into the array in the order in which they appear in the  le (we might use a Bag if that order is immaterial). This code uses autoboxing and auto-unboxing to convert be- tween the client’s int primitive type and the queue’s Integer wrapper type.
   public static int[] readInts(String name)
  {
     In in = new In(name);
     Queue<Integer> q = new Queue<Integer>();
     while (!in.isEmpty())
         q.enqueue(in.readInt());
     int N = q.size();
     int[] a = new int[N];
     for (int i = 0; i < N; i++)
        a[i] = q.dequeue();
     return a;
}
Sample Queue client
 www.it-ebooks.info

Pushdown stacks A pushdown stack (or just a stack) is a collection that is based on the last-in- rst-out (LIFO) policy. When you keep your mail in a pile on your desk, you are using a stack. You pile pieces of new mail on the top when they arrive and take each piece of mail from the top when you are ready to read it. People do not process as many papers as they did in the past, but the same organizing principle underlies several of the ap- plications that you use regularly on your computer. For example, many people organize their email as a stack— they push messages on the top when they are received and pop them from the top when they read them, with most recently received  rst (last in,  rst out). The ad- vantage of this strategy is that we see interesting email as soon as possible; the disadvantage is that some old email might never get read if we never empty the stack. You have likely encountered another common example of a stack when sur ng the web. When you click a hyperlink, your browser displays the new page (and pushes onto a stack). You can keep clicking on hyperlinks to visit new pages, but you can always revisit the previous page by clicking the back button (popping it from the stack). The LIFO policy offered by a stack provides just the be- havior that you expect. When a client iterates through the items in a stack with the foreach construct, the items are processed in the reverse of the order in
which they were added. A typical reason to use a stack iterator in an application is to save items in a collection while at the same time reversing their relative order. For example, the client Reverse at right reverses the or- der of the integers on standard input, again without having to know ahead of time how many there are. The importance of stacks in computing is fundamental and profound, as indicated in the detailed example that we consider next.
1.3 n Bags, Queues, and Stacks a stack of
documents
push( )
127
new (gray) one goes on top
new (black) one goes on top
remove the black one from the top
remove the gray one from the top
      push(
)
    = pop()
= pop()
     Operations on a pushdown stack
   public class Reverse
  {
     public static void main(String[] args)
     {
        Stack<Integer> stack;
        stack = new Stack<Integer>();
        while (!StdIn.isEmpty())
           stack.push(StdIn.readInt());
        for (int i : stack)
           StdOut.println(i);
} }
Sample Stack client
 www.it-ebooks.info

128 Chapter 1 n Fundamentals
Arithmetic expression evaluation As another example of a stack client, we consider a classic example that also demonstrates the utility of generics. Some of the  rst pro- grams that we considered in Section 1.1 involved computing the value of arithmetic expressions like this one:
( 1+((2+3)*(4*5)))
If you multiply 4 by 5, add 3 to 2, multiply the result, and then add 1, you get the value 101. But how does the Java system do this calculation? Without going into the details of how the Java system is built, we can address the essential ideas by writing a Java program that can take a string as input (the expression) and produce the number represented by the expression as output. For simplicity, we begin with the following explicit recursive de nition: an arithmetic expression is either a number, or a left parenthesis followed by an arithmetic expression followed by an operator followed by another arithmetic ex- pression followed by a right parenthesis. For simplicity, this de nition is for fully paren- thesized arithmetic expressions, which specify precisely which operators apply to which operands—you are a bit more familiar with expressions such as 1 + 2 * 3, where we often rely on precedence rules instead of parentheses. The same basic mechanisms that we consider can handle precedence rules, but we avoid that complication. For speci-  city, we support the familiar binary operators *, +, -, and /, as well as a square-root operator sqrt that takes just one argument. We could easily allow more operators and more kinds of operators to embrace a large class of familiar mathematical expressions, involving trigonometric, exponential, and logarithmic functions. Our focus is on un- derstanding how to interpret the string of parentheses, operators, and numbers to en- able performing in the proper order the low-level arithmetic operations that are avail- able on any computer. Precisely how can we convert an arithmetic expression—a string of characters—to the value that it represents? A remarkably simple algorithm that was developed by E. W. Dijkstra in the 1960s uses two stacks (one for operands and one for operators) to do this job. An expression consists of parentheses, operators, and oper- ands (numbers). Proceeding from left to right and taking these entities one at a time, we manipulate the stacks according to four possible cases, as follows:
n Push operands onto the operand stack.
n Push operators onto the operator stack.
n Ignore left parentheses.
n On encountering a right parenthesis, pop an operator, pop the requisite number
of operands, and push onto the operand stack the result of applying that opera-
tor to those operands.
After the  nal right parenthesis has been processed, there is one value on the stack, which is the value of the expression. This method may seem mysterious at  rst, but it
 www.it-ebooks.info

  Dijkstra’s two-Stack Algorithm for expression evaluation
  public class Evaluate
  {
     public static void main(String[] args)
     {
        Stack<String> ops  = new Stack<String>();
        Stack<Double> vals = new Stack<Double>();
        while (!StdIn.isEmpty())
        {  // Read token, push if operator.
 String s = StdIn.readString();
if      (s.equals("("))
                                      ;
                           ops.push(s);
                           ops.push(s);
                           ops.push(s);
                           ops.push(s);
else if (s.equals("sqrt")) ops.push(s);
else if (s.equals("+"))
else if (s.equals("-"))
else if (s.equals("*"))
else if (s.equals("/"))
else if (s.equals(")"))
{  // Pop, evaluate, and push result if token is ")".
              String op = ops.pop();
              double v = vals.pop();
              if      (op.equals("+"))
              else if (op.equals("-"))
              else if (op.equals("*"))
              else if (op.equals("/"))
              else if (op.equals("sqrt")) v = Math.sqrt(v);
              vals.push(v);
           }  // Token not operator or paren: push double value.
           else vals.push(Double.parseDouble(s));
        }
        StdOut.println(vals.pop());
     }
}
This Stack client uses two stacks to evaluate arithmetic expressions, illustrating an essential compu- tational process: interpreting a string as a program and executing that program to compute the de- sired result. With generics, we can use the code in a single Stack implementation to implement one stack of String values and another stack of Double
values. For simplicity, this code assumes that the expres- sion is fully parenthesized, with numbers and characters separated by whitespace.
www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 129
v = vals.pop() + v;
v = vals.pop() - v;
v = vals.pop() * v;
v = vals.pop() / v;
  % java Evaluate
( 1+((2+3)*(4*5))) 101.0
% java Evaluate
( ( 1 + sqrt ( 5.0 ) ) / 2.0 )
1.618033988749895
130 Chapter 1 n Fundamentals
is easy to convince yourself that it computes the proper value: any time the algorithm encounters a subexpression consisting of two operands separated by an operator, all surrounded by parentheses, it leaves the result of performing that operation on those operands on the operand stack. The result is the same as if that value had appeared in the input instead of the subexpression, so we can think of replacing the subexpression by the value to get an expression that would yield the same result. We can apply this argument again and again until we get a single value. For example, the algorithm com- putes the same value for all of these expressions:
( 1+((2+3)*(4*5))) ( 1+(5*(4*5)))
( 1 + ( 5 * 20 ) )
( 1 + 100 )
101
Evaluate on the previous page is an implementation of this algorithm. This code is a simple example of an interpreter: a program that interprets the computation speci ed by a given string and performs the computation to arrive at the result.
 www.it-ebooks.info

www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 131
    1
  1
+
  1 +
  1 +
  12 +
  12 ++
  1 23 ++
  15 +
  15 +*
  15 +*
  1 54 +*
  15 4 + **
  1 5 45 +* *
  1 5 20 +*
  1 100 +
  101
 operand stack
operator stack
left parenthesis: ignore
(1+((2+3)*(4*5)))
operand: push onto operand stack
1+((2+3)*(4*5)))
operator: push onto operator stack
+((2+3)*(4*5))) ((2+3)*(4*5))) (2+3)*(4*5))) 2+3)*(4*5))) +3)*(4*5)))
3)*(4*5)))
right parenthesis: pop operator and operands and push result
)*(4*5))) *(4*5))) (4*5))) 4*5))) *5)))
5))) ))) ))
)
     Trace of Dijkstra’s two-stack arithmetic expression-evaluation algorithm

132 Chapter 1 n Fundamentals
StdIn StdOut
(push) (pop)
to be or not to
- to be
- be
not
a[]
N 0 1 2 3 4
0
1to 2tobe
3 to be or
operations, as illustrated at left for the test client, which reads strings from standard input and push- es each string onto a stack, unless it is "-", when it pops the stack and prints the result. The primary performance characteristic of this implementation is that the push and pop operations take time inde- pendent of the stack size. For many applications, it is the method of choice because of its simplicity. But it has several drawbacks that limit its potential applicability as a general-purpose tool, which we now address. With a moderate amount of effort (and some help from Java language mechanisms), we can develop an implementation that is broadly useful. This effort is worthwhile because the im- plementations that we develop serve as a model for implementations of other, more powerful, abstract data types throughout the book.
- that -
4 to be 5 to be 4 to be 5 to be 4 to be 3 to be 4 to be 3 to be 2 to be 1 to be 2 to is
or not
or not to or not to or not be or not be or not be or that be or that be or that be or that be or not to
that - or - be
is
Implementing collections To address the issue of implementing Bag, Stack and Queue, we begin with a simple classic implementation, then address improvements that lead us to implementations of the APIs articulated on page 121.
Fixed-capacity stack As a strawman, we consider an abstract data type for a  xed- capacity stack of strings, shown on the opposite page. The API differs from our Stack API: it works only for String values, it requires the client to specify a capacity, and it does not support iteration. The primary choice in developing an API implementation is to choose a representation for the data. For FixedCapacityStackOfStrings, an obvious choice is to use an array of String values. Pursuing this choice leads to the implemen- tation shown at the bottom on the opposite page, which could hardly be simpler (each method is a one-liner). The instance variables are an array a[] that holds the items in the stack and an integer N that counts the number of items in the stack. To remove an item, we decrement N and then return a[N]; to insert a new item, we set a[N] equal to the new item and then increment N. These operations preserve the following properties:
n The items in the array are in their insertion order.
n The stack is empty when N is 0.
n The top of the stack (if it is nonempty) is at a[N-1].
As usual, thinking in terms of invariants of this sort is the easiest way to verify that an implementation operates as intended. Be sure that you fully understand this implemen- tation. The best way to do so is to examine a trace of the stack contents for a sequence of
   trace of FixedCapacityStackOfStrings test client
www.it-ebooks.info

apI public class FixedCapacityStackOfStrings
FixedCapacityStackOfStrings(int void push(String item)
String pop() boolean isEmpty()
cap)
create an empty stack of capacity cap add a string
remove the most recently added string is the stack empty?
number of strings on the stack
test client
int size()
1.3
n
Bags, Queues, and Stacks 133
   public static void main(String[] args)
{
   FixedCapacityStackOfStrings s;
   s = new FixedCapacityStackOfStrings(100);
   while (!StdIn.isEmpty())
   {
      String item = StdIn.readString();
      if (!item.equals("-"))
           s.push(item);
      else if (!s.isEmpty()) StdOut.print(s.pop() + " ");
}
   StdOut.println("(" + s.size() + " left on stack)");
}
  application
implementation
 % more tobe.txt
to be or not to - be - - that - - - is
% java FixedCapacityStackOfStrings < tobe.txt
to be not that or be (2 left on stack)
 public class FixedCapacityStackOfStrings
{
   private String[] a; // stack entries
   private int N;      // size
   public FixedCapacityStackOfStrings(int cap)
   {  a = new String[cap];  }
   public boolean isEmpty() {  return N == 0; }
   public int size()        {  return N; }
   public void push(String item)
   {  a[N++] = item; }
   public String pop()
   {  return a[--N]; }
}
 an abstract data type for a fixed-capacity stack of strings
 www.it-ebooks.info

134 Chapter 1 n Fundamentals
Generics The  rst drawback of FixedCapacityStackOfStrings is that it works only for String objects. If we want a stack of double values, we would need to develop another class with similar code, essentially replacing String with double everywhere. This is easy enough but becomes burdensome when we consider building a stack of Transaction values or a queue of Date values, and so forth. As discussed on page 122, Java’s parameterized types (generics) are speci cally designed to address this situation, and we saw several examples of client code (on pages 125, 126, 127, and 129). But how do we implement a generic stack? The code on the facing page shows the details. It imple- ments a class FixedCapacityStack that differs from FixedCapacityStackOfStrings only in the code highlighted in red—we replace every occurrence of String with Item (with one exception, discussed below) and declare the class with the following  rst line of code:
    public class FixedCapacityStack<Item>
The name Item is a type parameter, a symbolic placeholder for some concrete type to be used by the client. You can read FixedCapacityStack<Item> as stack of items, which is precisely what we want. When implementing FixedCapacityStack, we do not know the actual type of Item, but a client can use our stack for any type of data by providing a concrete type when the stack is created. Concrete types must be reference types, but cli- ents can depend on autoboxing to convert primitive types to their corresponding wrap- per types. Java uses the type parameter Item to check for type mismatch errors—even though no concrete type is yet known, variables of type Item must be assigned values of type Item, and so forth. But there is one signi cant hitch in this story: We would like to implement the constructor in FixedCapacityStack with the code
    a = new Item[cap];
which calls for creation of a generic array. For historical and technical reasons beyond our scope, generic array creation is disallowed in Java. Instead, we need to use a cast:
    a = (Item[]) new Object[cap];
This code produces the desired effect (though the Java compiler gives a warning, which we can safely ignore), and we use this idiom throughout the book (the Java system li- brary implementations of similar abstract data types use the same idiom).
 www.it-ebooks.info

apI public class FixedCapacityStack<Item>
FixedCapacityStack(int cap)
create an empty stack of capacity cap add an item
remove the most recently added item is the stack empty?
number of items on the stack
void push(Item
Item pop() boolean isEmpty()
int size()
item)
1.3
n
Bags, Queues, and Stacks 135
   public static void main(String[] args)
{
   FixedCapacityStack<String> s;
   s = new FixedCapacityStack<String>(100);
   while (!StdIn.isEmpty())
   {
      String item = StdIn.readString();
      if (!item.equals("-"))
           s.push(item);
      else if (!s.isEmpty()) StdOut.print(s.pop() + " ");
}
   StdOut.println("(" + s.size() + " left on stack)");
}
test client
  application
implementation
% more tobe.txt
to be or not to - be - - that - - - is
% java FixedCapacityStack < tobe.txt
to be not that or be (2 left on stack)
  public class FixedCapacityStack<Item>
{
   private Item[] a;   // stack entries
   private int N;      // size
   public FixedCapacityStack(int cap)
   {  a = (Item[]) new Object[cap];  }
   public boolean isEmpty() {  return N == 0; }
   public int size()        {  return N; }
   public void push(Item item)
   {  a[N++] = item; }
   public Item pop()
   {  return a[--N]; }
}
 an abstract data type for a fixed-capacity generic stack
 www.it-ebooks.info

136 Chapter 1 n Fundamentals
Array resizing Choosing an array to represent the stack contents implies that clients must estimate the maximum size of the stack ahead of time. In Java, we cannot change the size of an array once created, so the stack always uses space proportional to that maximum. A client that chooses a large capacity risks wasting a large amount of mem- ory at times when the collection is empty or nearly empty. For example, a transaction system might involve billions of items and thousands of collections of them. Such a client would have to allow for the possibility that each of those collections could hold all of those items, even though a typical constraint in such systems is that each item can appear in only one collection. Moreover, every client risks over ow if the collection grows larger than the array. For this reason, push() needs code to test for a full stack, and we should have an isFull() method in the API to allow clients to test for that condition. We omit that code, because our desire is to relieve the client from having to deal with the concept of a full stack, as articulated in our original Stack API. Instead, we modify the array implementation to dynamically adjust the size of the array a[] so that it is both suf ciently large to hold all of the items and not so large as to waste an excessive amount of space. Achieving these goals turns out to be remarkably easy. First, we implement a method that moves a stack into an array of a different size:
    private void resize(int max)
    {  // Move stack of size N <= max to a new array of size max.
       Item[] temp = (Item[]) new Object[max];
       for (int i = 0; i < N; i++)
          temp[i] = a[i];
       a = temp;
}
Now, in push(), we check whether the array is too small. In particular, we check wheth- er there is room for the new item in the array by checking whether the stack size N is equal to the array size a.length. If there is no room, we double the size of the array. Then we simply insert the new item with the code a[N++] = item, as before:
    public void push(Item item)
    {  // Add item to top of stack.
       if (N == a.length) resize(2*a.length);
       a[N++] = item;
    }
Similarly, in pop(), we begin by deleting the item, then we halve the array size if it is too large. If you think a bit about the situation, you will see that the appropriate test is whether the stack size is less than one-fourth the array size. After the array is halved, it will be about half full and can accommodate a substantial number of push() and pop() operations before having to change the size of the array again.
 www.it-ebooks.info

www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 137
    public Item pop()
    {  // Remove item from top of stack.
       String item = a[--N];
       a[N] = null;  // Avoid loitering (see text).
       if (N > 0 && N == a.length/4) resize(a.length/2);
       return item;
}
With this implementation, the stack never over ows and never becomes less than one- quarter full (unless the stack is empty, when the array size is 2). We will address the performance analysis of this approach in more detail in Section 1.4.
Loitering Java’s garbage collection policy is to reclaim the memory associated with any objects that can no longer be accessed. In our pop() implementations, the reference to the popped item remains in the array. The item is effectively an orphan—it will never be accessed again—but the Java garbage collector has no way to know this until it is overwritten. Even when the client is done with the item, the reference in the array may keep it alive. This condition (holding a reference to an item that is no longer needed) is known as loitering. In this case, loitering is easy to avoid, by setting the array entry corresponding to the popped item to null, thus overwriting the unused reference and making it possible for the system to reclaim the memory associated with the popped item when the client is  nished with it.
 push() pop()
to be or not to
-to be
-be
- not that
- that -or - be
N a.length
a[]
01234567
                     is
0 1 null 1 1 to
2 2 3 4 4 4 5 8 4 8 5 8 4 8 3 8 4 8 3 8 2 4 1 2 2 2
to be to be to be to be to be to be to be to be to be to be to be to null to is
or null
trace of array resizing during a sequence of push() and pop() operations
or or
or or or or or or null
not
to null null null be null null null null null null null null null null
null
not
null null
null null null null null null null null null null null null
not
not not null that

138 Chapter 1 n Fundamentals
Iteration As mentioned earlier in this section, one of the fundamental operations on collections is to process each item by iterating through the collection using Java’s foreach statement. This paradigm leads to clear and compact code that is free from dependence on the details of a collection’s implementation. To consider the task of implementing iteration, we start with a snippet of client code that prints all of the items in a collection of strings, one per line:
    Stack<String> collection = new Stack<String>();
    ...
    for (String s : collection)
       StdOut.println(s);
    ...
Now, this foreach statement is shorthand for a while construct (just like the for state- ment itself). It is essentially equivalent to the following while statement:
    Iterator<String> i = collection.iterator();
    while (i.hasNext())
    {
       String s = i.next();
       StdOut.println(s);
    }
This code exposes the ingredients that we need to implement in any iterable collection: n The collection must implement an iterator() method that returns an
Iterator object.
n The Iterator class must include two methods: hasNext() (which returns a
boolean value) and next() (which returns a generic item from the collection). In Java, we use the interface mechanism to express the idea that a class implements a speci c method (seepage 100). For iterable collections, the necessary interfaces are al- ready de ned for us in Java. To make a class iterable, the  rst step is to add the phrase implements Iterable<Item> to its declaration, matching the interface
    public interface Iterable<Item>
    {
       Iterator<Item> iterator();
    }
(which is in java.lang.Iterable), and to add a method iterator() to the class that returns an Iterator<Item>. Iterators are generic, so we can use our parameterized type Item to allow clients to iterate through objects of whatever type is provided by our client. For the array representation that we have been using, we need to iterate through
 www.it-ebooks.info

1.3 n Bags, Queues, and Stacks 139 an array in reverse order, so we name the iterator ReverseArrayIterator and add this
method:
    public Iterator<Item> iterator()
    {  return new ReverseArrayIterator();  }
What is an iterator? An object from a class that implements the methods hasNext() and next(), as de ned in the following interface (which is in java.util.Iterator):
    public interface Iterator<Item>
    {
        boolean hasNext();
        Item next();
        void remove();
}
Although the interface speci es a remove() method, we always use an empty method for remove() in this book, because interleaving iteration with operations that modify the data structure is best avoided. For ReverseArrayIterator, these methods are all one-liners, implemented in a nested class within our stack class:
    private class ReverseArrayIterator implements Iterator<Item>
    {
       private int i = N;
       public boolean hasNext() {  return i > 0;   }
       public Item next()       {  return a[--i];  }
       public void remove()     {                  }
}
Note that this nested class can access the instance variables of the enclosing class, in this case a[] and N (this ability is the main reason we use nested classes for iterators). Technically, to conform to the Iterator speci cation, we should throw exceptions in two cases: an UnsupportedOperationException if a client calls remove() and a NoSuchElementException if a client calls next() when i is 0. Since we only use itera- tors in the foreach construction where these conditions do not arise, we omit this code. One crucial detail remains: we have to include
    import java.util.Iterator;
at the beginning of the program because (for historical reasons) Iterator is not part of java.lang (even though Iterable is part of java.lang). Now a client using the foreach statement for this class will get behavior equivalent to the common for loop for arrays, but does not need to be aware of the array representation (an implementation
 www.it-ebooks.info

140 Chapter 1 n Fundamentals
detail). This arrangement is of critical importance for implementations of fundamen- tal data types like the collections that we consider in this book and those included in Java libraries. For example, it frees us to switch to a totally different representation without having to change any client code. More important, taking the client’s point of view, it allows clients to use iteration without having to know any details of the class implementation.
Algorithm 1.1 is an implementation of our Stack API that resizes the array, allows clients to make stacks for any type of data, and supports client use of foreach to iterate through the stack items in LIFO order. This implementation is based on Java language nuances involving Iterator and Iterable, but there is no need to study those nuances in detail, as the code itself is not complicated and can be used as a template for other collection implementations.
For example, we can implement the Queue API by maintaining two indices as in- stance variables, a variable head for the beginning of the queue and a variable tail for the end of the queue. To remove an item, use head to access it and then increment head; to insert an item, use tail to store it, and then increment tail. If incrementing an index brings it past the end of the array, reset it to 0. Developing the details of checking when the queue is empty and when the array is full and needs resizing is an interesting and worthwhile programming exercise (see Exercise 1.3.14).
 StdIn StdOut
a[]
01234567
tobeornotto tobeornotto tobeornotto be tobeornotto be tobeornotto be
N
5
be 5 -be 4 -or 3
head tail
0 5 1 5 1 6 2 6 3 6
 (enqueue) (dequeue) -to 4
trace of ResizingArrayQueue test client
In the context of the study of algorithms, Algorithm 1.1 is signi cant because it almost (but not quite) achieves optimum performance goals for any collection implementation:
n Each operation should require time independent of the collection size.
n The space used should always be within a constant factor of the collection size. The  aw in ResizingArrayStack is that some push and pop operations require resiz- ing: this takes time proportional to the size of the stack. Next, we consider a way to cor- rect this  aw, using a fundamentally different way to structure data.
www.it-ebooks.info

  aLgorIthM 1.1 Pushdown (liFo) stack (resizing array implementation)
  import java.util.Iterator;
  public class ResizingArrayStack<Item> implements Iterable<Item>
  {
     private Item[] a = (Item[]) new Object[1];  // stack items
     private int N = 0;                          // number of items
     public boolean isEmpty()  {  return N == 0; }
     public int size()         {  return N;      }
     private void resize(int max)
     {  // Move stack to a new array of size max.
        Item[] temp = (Item[]) new Object[max];
        for (int i = 0; i < N; i++)
           temp[i] = a[i];
        a = temp;
}
     public void push(Item item)
     {  // Add item to top of stack.
        if (N == a.length) resize(2*a.length);
        a[N++] = item;
     }
     public Item pop()
     {  // Remove item from top of stack.
        Item item = a[--N];
        a[N] = null;  // Avoid loitering (see text).
        if (N > 0 && N == a.length/4) resize(a.length/2);
        return item;
}
     public Iterator<Item> iterator()
     {  return new ReverseArrayIterator();  }
     private class ReverseArrayIterator implements Iterator<Item>
     {  // Support LIFO iteration.
        private int i = N;
        public boolean hasNext() {  return i > 0;   }
        public    Item next()    {  return a[--i];  }
        public    void remove()  {                  }
} }
This generic, iterable implementation of our Stack API is a model for collection ADTs that keep items in an array. It resizes the array to keep the array size within a constant factor of the stack size.
  www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 141
142 Chapter 1 n Fundamentals
Linked lists Now we consider the use of a fundamental data structure that is an ap- propriate choice for representing the data in a collection ADT implementation. This is our  rst example of building a data structure that is not directly supported by the Java language. Our implementation serves as a model for the code that we use for building more complex data structures throughout the book, so you should read this section carefully, even if you have experience working with linked lists.
 Definition. Alinkedlistisarecursivedatastructurethatiseitherempty(null)ora reference to a node having a generic item and a reference to a linked list.
The node in this de nition is an abstract entity that might hold any kind of data, in ad- dition to the node reference that characterizes its role in building linked lists. As with a recursive program, the concept of a recursive data structure can be a bit mindbending at  rst, but is of great value because of its simplicity.
Node record With object-oriented programming, implementing linked lists is not dif-  cult. We start with a nested class that de nes the node abstraction:
    private class Node
    {
Item item;
Node next; }
A Node has two instance variables: an Item (a parameterized type) and a Node. We de ne Node within the class where we want to use it, and make it private because it is not for use by clients. As with any data type, we create an object of type Node by in- voking the (no-argument) constructor with new Node(). The result is a reference to a Node object whose instance variables are both initialized to the value null. The Item is a placeholder for any data that we might want to structure with a linked list (we will use Java’s generic mechanism so that it can represent any reference type); the instance vari- able of type Node characterizes the linked nature of the data structure. To emphasize that we are just using the Node class to structure the data, we de ne no methods and we refer directly to the instance variables in code: if first is a variable associated with an object of type Node, we can refer to the instance variables with the code first.item and first.next. Classes of this kind are sometimes called records. They do not imple- ment abstract data types because we refer directly to instance variables. However, Node and its client code are in the same class in all of our implementations and not accessible by clients of that class, so we still enjoy the bene ts of data abstraction.
 www.it-ebooks.info

Building a linked list Now, from the recursive de nition, we can represent a linked list with a variable of type Node simply by ensuring that its value is either null or a ref- erence to a Node whose next  eld is a reference to a linked list. For example, to build a linked list that contains the items to, be, and or, we create a Node for each item:
    Node first  = new Node();
    Node second = new Node();
    Node third  = new Node();
and set the item  eld in each of the nodes to the desired value (for simplicity, these examples assume that Item is String):
    first.item  = "to";
    second.item = "be";
    third.item  = "or";
and set the next  elds to build the linked list: first.next = second;
    second.next = third;
(Note that third.next remains null, the value it was initialized to at the time of creation.) As a re- sult, third is a linked list (it is a reference to a node that has a reference to null, which is the null refer- ence to an empty linked list), and second is a linked list (it is a reference to a node that has a reference to third, which is a linked list), and first is a linked list (it is a reference to a node that has a reference to second, which is a linked list). The code that we will examine does these assignment statements in a dif- ferent order, depicted in the diagram on this page.
A linked list represents a sequence of items. In the example just considered, first representsthesequenceto be or.Wecanalsouseanarraytorepresentasequenceof items. For example, we could use
    String[] s = { "to", "be", "or" };
to represent the same sequence of strings. The difference is that it is easier to insert items into the sequence and to remove items from the sequence with linked lists. Next, we consider code to accomplish these tasks.
1.3 n Bags, Queues, and Stacks 143
 Node first  = new Node();
first.item  = "to";
first
Node second = new Node();
second.item = "be";
first.next  = second;
   to
 null
 first
second
    to
   be
  null
  Node third  = new Node();
third.item  = "or";
second.next = third;
first
second
  third
  to
      be
      or
 Linking together a list
null
  www.it-ebooks.info

144 Chapter 1 n Fundamentals
When tracing code that uses linked lists and other linked structures, we use a visual representation where
n We draw a rectangle to represent each object
n We put the values of instance variables within the rectangle
n We use arrows that point to the referenced objects to depict references
This visual representation captures the essential characteristic of linked lists. For econ- omy, we use the term links to refer to node references. For simplicity, when item values are strings (as in our examples), we put the string within the object rectangle rather than the more accurate rendition depicting the string object and the character array that we discussed in Section 1.2. This visual representation allows us to focus on the links.
Insert at the beginning First, suppose that you want to insert a new node into a linked list. The easiest place to do so is at the beginning of the list. For example, to insert the string not at the beginning of a given linked list whose  rst node is first, we save first in oldfirst, assign to first a new Node, and assign its item  eld to not and its next  eld to oldfirst. This code for inserting a node at the beginning of a linked list involves just a few assignment statements, so the amount of time that it takes is inde- pendent of the length of the list.
 save a link to the list
Node oldfirst = first; oldfirst
first
create a new node for the beginning
first = new Node(); oldfirst
first
set the instance variables in the new node
   first.item = "not";
   first.next = oldfirst;
first
Inserting a new node at the beginning of a linked list
    to
   be
  or
null
         to
 be
  or
null
   not
   to
   be
  or
null
   www.it-ebooks.info

Remove from the beginning Next, suppose that you
want to remove the  rst node from a list. This op-
eration is even easier: simply assign to first the value
first.next. Normally, you would retrieve the value of
the item (by assigning it to some variable of type Item)
before doing this assignment, because once you change
the value of first, you may not have any access to the
node to which it was referring. Typically, the node ob-
ject becomes an orphan, and the Java memory manage-
ment system eventually reclaims the memory it occupies.
Again, this operation just involves one assignment statement, so its running time is independent of the length of the list.
Insertattheend Howdoweaddanodetotheendofalinkedlist?Todoso,weneed a link to the last node in the list, because that node’s link has to be changed to refer- ence a new node containing the item to be inserted. Maintaining an extra link is not something that should be taken lightly in linked-list code, because every method that modi es the list needs code to check whether that variable needs to be modi ed (and to make the necessary modi cations). For
example, the code that we just examined for removing the  rst node in the list might in- volve changing the reference to the last node in the list, since when there is only one node in the list, it is both the  rst one and the last one! Also, this code does not work (it follows a null link) in the case that the list is empty. Details like these make linked-list code noto- riously dif cult to debug.
Insert/remove at other positions In sum- mary, we have shown that we can implement the following operations on linked lists with just a few instructions, provided that we have access to both a link first to the  rst ele- ment in the list and a link last to the last element in the list:
n Insert at the beginning.
n Remove from the beginning. n Insert at the end.
save a link to the last node
Node oldlast = last; oldlast
1.3 n
Bags, Queues, and Stacks 145
first = first.next; first
first
Removing the  rst node in a linked list
    to
   be
        to
     first
create a new node for the end
   last = new Node();
   last.item = "not";
first
last
oldlast
oldlast
last
last
     be
be
or
null
      or
null
or
null
      to
     be
   or
null
  link the new node to the end of the list
oldlast.next = last; first
not
null
   to
     be
    or
 not
null
 www.it-ebooks.info
to
Inserting a new node at the end of a linked list

146 Chapter 1 n Fundamentals
Other operations, such as the following, are not so easily handled: n Remove a given node.
n Insert a new node before a given node.
For example, how can we remove the last node from a list? The link last is no help, because we need to set the link in the previous node in the list (the one with the same value as last) to null. In the absence of any other information, the only solution is to traverse the entire list looking for the node that links to last (see below and Exercise 1.3.19). Such a solution is undesirable because it takes time proportional to the length of the list. The standard solution to enable arbitrary insertions and deletions is to use a doubly-linked list, where each node has two links, one in each direction. We leave the code for these operations as an exercise (see Exercise 1.3.31). We do not need doubly linked lists for any of our implementations.
Traversal To examine every item in an array, we use familiar code like the following loop for processing the items in an array a[]:
    for (int i = 0; i < N; i++)
    {
       // Process a[i].
}
There is a corresponding idiom for examining the items in a linked list: We initialize a loop index variable x to reference the  rst Node of the linked list. Then we  nd the item associated with x by accessing x.item, and then update x to refer to the next Node in the linked list, assigning to it the value of x.next and repeating this process until x is null (which indicates that we have reached the end of the linked list). This process is known as traversing the list and is succinctly expressed in code like the following loop for pro- cessing the items in a linked list whose  rst item is associated with the variable first:
    for (Node x = first; x != null; x = x.next)
    {
       // Process x.item.
}
This idiom is as natural as the standard idiom for iterating through the items in an ar- ray. In our implementations, we use it as the basis for iterators for providing client code the capability of iterating through the items, without having to know the details of the linked-list implementation.
 www.it-ebooks.info

Stack implementation Given these preliminaries, developing an implementation for our Stack API is straightforward, as shown in Algorithm 1.2 on page 149. It maintains the stack as a linked list, with the top of the stack at the beginning, referenced by an instance variable first. Thus, to push() an item, we add it to the beginning of the list, using the code discussed on page 144 and to pop() an item, we remove it from the beginning of the list, using the code discussed opnage 145. To implement size(), we keep track of the number of items in an instance variable N, incrementing N when we push and decrementing N when we pop. To implement isEmpty() we check whether first is null (alternatively, we could check whether N is 0). The implementation uses the generic type Item—you can think of the code <Item> after the class name as meaning that any occurrence of Item in the implementation will be replaced by a client-supplied data-type name (seepage 134). For now, we omit the code to support iteration, which we consider on page 155. A trace for the test client that we have been using is shown on the next page. This use of linked lists achieves our optimum design goals:
n It can be used for any type of data.
n The space required is always proportional to the size of the collection.
n The time per operation is always independent of the size of the collection.
This implementation is a prototype for many algorithm implementations that we con- sider. It de nes the linked-list data structure and implements the client methods push() and pop() that achieve the speci ed effect with just a few lines of code. The algorithms and data structure go hand in hand. In this case, the code for the algorithm implemen- tations is quite simple, but the properties of the data structure are not at all elemen- tary, requiring explanations on the past several pages. This interaction between data structure de nition and algorithm implementation is typical and is our focus in ADT implementations throughout this book.
1.3 n Bags, Queues, and Stacks 147
   public static void main(String[] args)
  {  // Create a stack and push/pop strings as directed on StdIn.
     Stack<String> s = new Stack<String>();
     while (!StdIn.isEmpty())
     {
        String item = StdIn.readString();
        if (!item.equals("-"))
             s.push(item);
        else if (!s.isEmpty()) StdOut.print(s.pop() + " ");
}
     StdOut.println("(" + s.size() + " left on stack)");
  }
test client for Stack
 www.it-ebooks.info

148 Chapter 1
n Fundamentals
StdIn to
be
or not to
StdOut
 to
null
 be
 not
to
null
   or
 be
     or
to
null
     be
   to
null
   to
 not
   or
   be
     - to be
- be
- not that
- that - or - be
is
not
or
to
null
     be
   to
null
   be
 not
    or
  be
   to
null
   not
 or
   be
   to
null
   or
   be
 to
null
   that
 or
       or
be
 to
null
  be
   to
null
   be
   to
to
  is
 to
  Trace of Stack development client
www.it-ebooks.info

 aLgorIthM 1.2 Pushdown stack (linked-list implementation)
  public class Stack<Item> implements Iterable<Item>
  {
     private Node first; // top of stack (most recently added node)
     private int N;      // number of items
     private class Node
     {  // nested class to define nodes
Item item;
Node next; }
     public boolean isEmpty() {  return first == null; }
     public int size()        {  return N; }
     public void push(Item item)
     {  // Add item to top of stack.
        Node oldfirst = first;
        first = new Node();
        first.item = item;
        first.next = oldfirst;
        N++;
}
     public Item pop()
     {  // Remove item from top of stack.
        Item item = first.item;
        first = first.next;
        N--;
        return item;
}
     // See page 155 for iterator() implementation.
     // See page 147 for test client main().
}
This generic Stack implementation is based on a linked-list data structure. It can be used to create stacks containing any type of data. To support
iteration, add the highlighted code described
for Bag on page 155.
1.3 n Bags, Queues, and Stacks 149
    www.it-ebooks.info
% more tobe.txt
to be or not to - be - - that - - - is
% java Stack < tobe.txt
to be not that or be (2 left on stack)
150 Chapter 1 n Fundamentals
Queue implementation An implementation of our Queue API based on the linked- list data structure is also straightforward, as shown in Algorithm 1.3 on the facing page. It maintains the queue as a linked list in order from least recently to most recently added items, with the beginning of the queue referenced by an instance variable first and the end of the queue referenced by an instance variable last. Thus, to enqueue() an item, we add it to the end of the list (using the code discussed opnage 145, augmented to set both first and last to refer to the new node when the list is empty) and to dequeue() an item, we remove it from the beginning of the list (using the same code as for pop() in Stack, augmented to update last when the list becomes empty). The implementations of size() and isEmpty() are the same as for Stack. As with Stack the implementation uses the generic type parameter Item, and we omit the code to support iteration, which we consider in our Bag implementation onpage 155. A develop- ment client similar to the one we used for Stack is shown below, and the trace for this client is shown on the following page. This implementation uses the same data struc- ture as does Stack—a linked list—but it implements different algorithms for adding and removing items, which make the difference between LIFO and FIFO for the client. Again, the use of linked lists achieves our optimum design goals: it can be used for any type of data, the space required is proportional to the number of items in the collection, and the time required per operation is always independent of the size of the collection.
    public static void main(String[] args)
  {  // Create a queue and enqueue/dequeue strings.
     Queue<String> q = new Queue<String>();
     while (!StdIn.isEmpty())
     {
        String item = StdIn.readString();
        if (!item.equals("-"))
             q.enqueue(item);
        else if (!q.isEmpty()) StdOut.print(q.dequeue() + " ");
}
     StdOut.println("(" + q.size() + " left on queue)");
  }
test client for Queue
  % more tobe.txt
to be or not to - be - - that - - - is
% java Queue < tobe.txt
to be or not to be (2 left on queue)
www.it-ebooks.info

  aLgorIthM 1.3 FiFo queue
  public class Queue<Item> implements Iterable<Item>
  {
     private Node first; // link to least recently added node
     private Node last;  // link to most recently added node
     private int N;      // number of items on the queue
     private class Node
     {  // nested class to define nodes
Item item;
Node next; }
     public boolean isEmpty() {  return first == null;  }
     public int size()        {  return N;  }
     public void enqueue(Item item)
     {  // Add item to the end of the list.
        Node oldlast = last;
        last = new Node();
        last.item = item;
        last.next = null;
        if (isEmpty()) first = last;
        else           oldlast.next = last;
        N++;
}
     public Item dequeue()
     {  // Remove item from the beginning of the list.
        Item item = first.item;
        first = first.next;
        N--;
        if (isEmpty()) last = null;
        return item;
}
     // See page 155 for iterator() implementation.
     // See page 150 for test client main().
}
This generic Queue implementation is based on a linked-list data structure. It can be used to create queues containing any type of data. To support iteration, add the highlighted code described for Bag on page 155.
  www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 151
152 Chapter 1
n Fundamentals
StdIn to
be
or not to
StdOut
 to
null
 to
 to
be
null
   to
 be
     be
or
null
     or
   not
null
   to
 be
   or
   not
     - to be
- be
- or that
- not - to - be
is
be
or
to
null
     not
   to
null
   be
 or
    not
  to
   be
null
   or
 not
   to
   be
null
   not
 to
   be
null
   not
 to
       to
be
 that
null
  be
   that
null
   be
   that
null
that
null
  that
 is
null
  Trace of Queue development client
www.it-ebooks.info

Linked lists are a fundamental alternative to arrays for structuring a collection of data. From a historical perspective, this alternative has been available to program- mers for many decades. Indeed, a landmark in the history of programming languages was the development of LISP by John McCarthy in the 1950s, where linked lists are the primary structure for programs and data. Programming with linked lists presents all sorts of challenges and is notoriously dif cult to debug, as you can see in the exercises. In modern code, the use of safe pointers, automatic garbage collection (speaege111),and ADTs allows us to encapsulate list-processing code in just a few classes such as the ones presented here.
1.3 n Bags, Queues, and Stacks 153
 www.it-ebooks.info

154 Chapter 1 n Fundamentals
Bag implementation Implementing our Bag API using a linked-list data structure is simply a matter of changing the name of push() in Stack to add() and removing the implementation of pop(), as shown in Algorithm 1.4 on the facing page (doing the same for Queue would also be effective but requires a bit more code). This implemen- tation also highlights the code needed to make Stack, Queue, and Bag all iterable, by traversing the list. For Stack the list is in LIFO order; for Queue it is in FIFO order; and for Bag it happens to be in LIFO order, but the order is not relevant. As detailed in the highlighted code in Algorithm 1.4, to implement iteration in a collection, the  rst step is to include
import java.util.Iterator;
so that our code can refer to Java’s Iterator interface. The second step is to add
    implements Iterable<Item>
to the class declaration, a promise to provide an iterator() method. The iterator() method itself simply returns an object from a class that implements the Iterator interface:
    public Iterator<Item> iterator()
    {  return new ListIterator();  }
This code is a promise to implement a class that implements the hasNext(), next(), and remove() methods that are called when a client uses the foreach construct. To implement these methods, the nested class ListIterator in Algorithm 1.4 maintains an instance variable current that keeps track of the current node on the list. Then the hasNext() method tests if current is null, and the next() method saves a reference to the current item, updates current to refer to the next node on the list, and returns the saved reference.
 www.it-ebooks.info

  aLgorIthM 1.4 Bag
import java.util.Iterator;
  public class Bag<Item> implements Iterable<Item>
  {
     private Node first;  // first node in list
     private class Node
     {
Item item;
Node next; }
     public void add(Item item)
     {  // same as push() in Stack
        Node oldfirst = first;
        first = new Node();
        first.item = item;
        first.next = oldfirst;
}
     public Iterator<Item> iterator()
     {  return new ListIterator();  }
     private class ListIterator implements Iterator<Item>
     {
         private Node current = first;
         public boolean hasNext()
         {  return current != null;  }
         public void remove() { }
         public Item next()
         {
             Item item = current.item;
             current = current.next;
             return item;
} }
}
This Bag implementation maintains a linked list of the items provided in calls to add(). Code for isEmpty() and size() is the same as in Stack and is omitted. The iterator traverses the list, main- taining the current node in current. We can make Stack and Queue iterable by adding the code highlighted in red to Algorithms 1.2 and Algorithm 1.3, because they use the same underlying data structure and Stack and Queue maintain the list in LIFO and FIFO order, respectively.
  www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 155
156 Chapter 1 n Fundamentals
data structure
array linked list
advantage
index provides immediate access to any item
uses space proportional to size
disadvantage
need to know size on initialization
need reference to access an item
combine and extend these basic structures in numerous ways. One important exten- sion is to data structures with multiple links. For example, our focus in Sections 3.2 and 3.3 is on data structures known as binary trees that are built from nodes that each have two links. Another important extension is to compose data structures: we can have a bag of stacks, a queue of ar- rays, and so forth. For example, our focus in Chapter 4 is on graphs, which we rep-
Overview The implementations of bags, queues, and stacks that support generics and iteration that we have considered in this section provide a level of abstraction that allows us to write compact client programs that manipulate collections of objects. De- tailed understanding of these ADTs is important as an introduction to the study of al- gorithms and data structures for three reasons. First, we use these data types as building blocks in higher-level data structures throughout this book. Second, they illustrate the interplay between data structures and algorithms and the challenge of simultaneously achieving natural performance goals that may con ict. Third, the focus of several of our implementations is on ADTs that support more powerful operations on collections of objects, and we use the implementations here as starting points.
Data structures We now have two ways to represent collections of objects, arrays and linked lists. Arrays are built into Java; linked lists are easy to build with standard Java records. These two alternatives, often referred to as sequential allocation and linked al- location, are fundamental. Later in the book, we develop ADT implementations that
 Fundamental data structures
resent as arrays of bags. It is very easy to de ne data structures of arbitrary complexity in this way: one important reason for our focus on abstract data types is an attempt to control such complexity.
www.it-ebooks.info

www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 157
Our treatment of BAGS, queues, and STACKS in this section is a prototypical ex- ample of the approach that we use throughout this book to describe data structures and algorithms. In approaching a new applications domain, we identify computational challenges and use data abstraction to address them, proceeding as follows:
n Specify an API.
n Develop client code with reference to speci c applications.
n Describe a data structure (representation of the set of values) that can serve as
the basis for the instance variables in a class that will implement an ADT that
meets the speci cation in the API.
n Describe algorithms (approaches to implementing the set of operations) that
can serve as the basis for implementing the instance methods in the class. n Analyze the performance characteristics of the algorithms.
In the next section, we consider this last step in detail, as it often dictates which algo- rithms and implementations can be most useful in addressing real-world applications.
 data structure
parent-link tree
binary search tree
string
binary heap hash table
(separate chaining) hash table
(linear probing) graph adjacency lists
trie ternary search trie
section
1.5 3.2, 3.3 5.1 2.4 3.4
3.4
4.1, 4.2
5.2 5.3
aDt
      UnionFind
         BST
        String
          PQ
SeparateChainingHashST
  LinearProbingHashST
Graph
TrieST TST
representation
array of integers
two links per node array, o set, and length array of objects
arrays of linked lists
two arrays of objects
array of Bag objects node with array of links
three links per node
 examples of data structures developed in this book

158 Chapter 1 n Fundamentals
   Q. Notallprogramminglanguageshavegenerics,evenearlyversionsofJava.Whatare the alternatives?
A. One alternative is to maintain a different implementation for each type of data, as mentioned in the text. Another is to build a stack of Object values, then cast to the desired type in client code for pop(). The problem with this approach is that type mis- match errors cannot be detected until run time. But with generics, if you write code to push an object of the wrong type on the stack, like this:
    Stack<Apple> stack = new Stack<Apple>();
    Apple  a = new Apple();
    ...
    Orange b = new Orange();
    ...
    stack.push(a);
    ...
    stack.push(b);     // compile-time error
you will get a compile-time error:
    push(Apple) in Stack<Apple> cannot be applied to (Orange)
This ability to discover such errors at compile time is reason enough to use generics. Q. Why does Java disallow generic arrays?
A. Expertsstilldebatethispoint.Youmightneedtobecomeonetounderstandit!For starters, learn about covariant arrays and type erasure.
Q. How do I create an array of stacks of strings? A. Use a cast, such as the following:
    Stack<String>[] a = (Stack<String>[]) new Stack[N];
Warning : This cast, in client code, is different from the one described onpage 134. You might have expected to use Object instead of Stack. When using generics, Java checks for type safety at compile time, but throws away that information at run time, so it is left with Stack<Object>[] or just Stack[], for short, which we must cast to Stack<String>[].
Q. What happens if my program calls pop() for an empty stack?
www.it-ebooks.info
 Q&A
  A. It depends on the implementation. For our implementation opnage 149, you will get a NullPointerException. In our implementations on the booksite, we throw a runtime exception to help users pinpoint the error. Generally, including as many such checks as possible is wise in code that is likely to be used by many people.
Q. Why do we care about resizing arrays, when we have linked lists?
A. We will see several examples of ADT implementations that need to use ar- rays to perform other operations that are not easily supported with linked lists. ResizingArrayStack is a model for keeping their memory usage under control.
Q. Why declare Node as a nested class? Why private?
A. BydeclaringthenestedclassNodetobeprivate,werestrictitsaccessonlytometh- ods and instance variables within the enclosing class. One characteristic of a private nested class is that its instance variables can be directly accessed from within the enclos- ing class but nowhere else, so there is no need to declare the instance variables public or private. Note for experts : A nested class that is not static is known as an inner class, so technically our Node classes are inner classes.
Q. When I type javac Stack.java to compile Algorithm 1.2 and similar programs, I  nd Stack.class and a  le Stack$Node.class. What is the purpose of that second one?
A. That leisfortheinnerclassNode.Java’snamingconventionistouse$toseparate the name of the outer class from the inner class.
Q. Are there Java libraries for stacks and queues?
A. Yes and no. Java has a built-in library called java.util.Stack, but you should avoid using it when you want a stack. It has several additional operations that are not normally associated with a stack, e.g., getting the ith element. It also allows adding an element to the bottom of the stack (instead of the top), so it can implement a queue! Although having such extra operations may appear to be a bonus, it is actually a curse. We use data types not just as libraries of all the operations we can imagine, but also as a mechanism to precisely specify the operations we need. The prime bene t of doing so is that the system can prevent us from performing operations that we do not actually want. The java.util.Stack API is an example of a wide interface, which we generally strive to avoid.
www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 159

160 Chapter 1 n Fundamentals Q & A (continued)
Q. Should a client be allowed to insert null items onto a stack or queue?
A. ThisquestionarisesfrequentlywhenimplementingcollectionsinJava.Ourimple-
mentation (and Java’s stack and queue libraries) do permit the insertion of null values.
Q. WhatshouldtheStackiteratordoiftheclientcallspush()orpop()duringiterator?
A. Throwajava.util.ConcurrentModificationExceptiontomakeitafail-fastit- erator. See Exercise 1.3.50.
Q. Can I use a foreach loop with arrays?
A. Yes (even though arrays do not implement the Iterable interface). The following
one-liner prints out the command-line arguments:
             public static void main(String[] args)
             {  for (String s : args) StdOut.println(s);  }
Q. Can I use a foreach loop with strings?
A. No. String does not implement Iterable.
Q. WhynothaveasingleCollectiondatatypethatimplementsmethodstoadditems, remove the most recently inserted, remove the least recently inserted, remove random, iterate, return the number of items in the collection, and whatever other operations we might desire? Then we could get them all implemented in a single class that could be used by many clients.
A. Again, this is an example of a wide interface. Java has such implementations in its java.util.ArrayList and java.util.LinkedList classes. One reason to avoid them is that there is no assurance that all operations are implemented ef ciently. Throughout this book, we use APIs as starting points for designing ef cient algorithms and data structures, which is certainly easier to do for interfaces with just a few operations as opposed to an interface with many operations. Another reason to insist on narrow in- terfaces is that they enforce a certain discipline on client programs, which makes client code much easier to understand. If one client uses Stack<String> and another uses Queue<Transaction>, we have a good idea that the LIFO discipline is important to the  rst and the FIFO discipline is important to the second.
  www.it-ebooks.info

1.3.1 Add a method isFull() to FixedCapacityStackOfStrings. 1.3.2 Give the output printed by java Stack for the input
    it was - the best - of times - - - it  was - the - -
1.3.3 Suppose that a client performs an intermixed sequence of (stack) push and pop operations. The push operations put the integers 0 through 9 in order onto the stack; the pop operations print out the return values. Which of the following sequence(s) could not occur?
a. 4 3 2 1 0 9 8 7 6 5 b. 4 6 8 7 5 3 2 9 0 1 c. 2 5 6 7 4 8 9 3 1 0
d. 4 3 2 1 0 5 6 7 8 9 e. 1 2 3 4 5 6 9 8 7 0 f. 0 4 6 5 3 8 1 7 2 9 g. 1 4 7 9 8 6 5 3 0 2 h. 2 1 4 3 6 5 8 7 9 0
1.3.4 WriteastackclientParenthesesthatreadsinatextstreamfromstandardinput and uses a stack to determine whether its parentheses are properly balanced. For ex- ample, your program should print true for [()]{}{[()()]()} and false for [(]).
1.3.5 What does the following code fragment print when N is 50? Give a high-level description of what it does when presented with a positive integer N.
    Stack<Integer> stack = new Stack<Integer>();
    while (N > 0)
    {
       stack.push(N % 2);
N = N / 2; }
    for (int d : stack) StdOut.print(d);
    StdOut.println();
Answer : Prints the binary representation of N (110010 when N is 50).
www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 161
 ExErcisEs

162 Chapter 1 n Fundamentals
  www.it-ebooks.info
 ExErcisEs (continued)
1.3.6 What does the following code fragment do to the queue q?
    Stack<String> stack = new Stack<String>();
    while (!q.isEmpty())
       stack.push(q.dequeue());
    while (!stack.isEmpty())
q.enqueue(stack.pop());
1.3.7 Add a method peek() to Stack that returns the most recently inserted item on
the stack (without popping it).
1.3.8 GivethecontentsandsizeofthearrayforResizingArrayStackOfStringswith the input
    it was - the best - of times - - - it was - the - -
1.3.9 Write a program that takes from standard input an expression without left pa- rentheses and prints the equivalent in x expression with the parentheses inserted. For example, given the input:
1 + 2 ) * 3 - 4 ) * 5 - 6) ) )
your program should print
( ( 1 + 2 ) * ( ( 3 - 4 )* ( 5 - 6 ) ) )
1.3.10 Writea lterInfixToPostfixthatconvertsanarithmeticexpressionfromin-
 x to post x.
1.3.11 Write a program EvaluatePostfix that takes a post x expression from stan- dard input, evaluates it, and prints the value. (Piping the output of your program from the previous exercise to this program gives equivalent behavior to Evaluate.)
1.3.12 WriteaniterableStackclientthathasastaticmethodcopy()thattakesastack of strings as argument and returns a copy of the stack. Note: This ability is a prime example of the value of having an iterator, because it allows development of such func- tionality without changing the basic API.
1.3.13 Supposethataclientperformsanintermixedsequenceof(queue)enqueueand dequeue operations. The enqueue operations put the integers 0 through 9 in order onto
 the queue; the dequeue operations print out the return value. Which of the following sequence(s) could not occur?
a. 0 1 2 3 4 5 6 7 8 9 b. 4 6 8 7 5 3 2 9 0 1
c. 2 5 6 7 4 8 9 3 1 0 d. 4 3 2 1 0 5 6 7 8 9
1.3.14 Develop a class ResizingArrayQueueOfStrings that implements the queue abstraction with a  xed-size array, and then extend your implementation to use array resizing to remove the size restriction.
1.3.15 WriteaQueueclientthattakesacommand-lineargumentkandprintsthekth from the last string found on standard input (assuming that standard input has k or more strings).
1.3.16 UsingreadInts() onpage126asamodel,writeastaticmethodreadDates()for Date that reads dates from standard input in the format speci ed in the table opnage 119 and returns an array containing them.
1.3.17 DoExercise1.3.16forTransaction.
 1.3 n Bags, Queues, and Stacks 163
 www.it-ebooks.info
164 Chapter 1 n Fundamentals
   This list of exercises is intended to give you experience in working with linked lists. Sugges- tion: make drawings using the visual representation described in the text.
1.3.18 Supposexisalinked-listnodeandnotthelastnodeonthelist.Whatistheef- fect of the following code fragment?
x.next = x.next.next;
Answer : Deletes from the list the node immediately following x.
1.3.19 Giveacodefragmentthatremovesthelastnodeinalinkedlistwhose rstnode is first.
1.3.20 Writeamethoddelete()thattakesanintargumentkanddeletesthekthele- ment in a linked list, if it exists.
1.3.21 Write a method find() that takes a linked list and a string key as arguments and returns true if some node in the list has key as its item  eld, false otherwise.
1.3.22 SupposethatxisalinkedlistNode.Whatdoesthefollowingcodefragmentdo? t.next = x.next;
x.next = t;
Answer : Inserts node t immediately after node x.
1.3.23 Whydoesthefollowingcodefragmentnotdothesamethingasintheprevious question?
    x.next = t;
    t.next = x.next;
Answer : When it comes time to update t.next, x.next is no longer the original node following x, but is instead t itself!
1.3.24 Write a method removeAfter() that takes a linked-list Node as argument and removes the node following the given one (and does nothing if the argument or the next  eld in the argument node is null).
1.3.25 WriteamethodinsertAfter()thattakestwolinked-listNodeargumentsand inserts the second after the  rst on its list (and does nothing if either argument is null).
www.it-ebooks.info
 liNkED-list ExErcisEs
  1.3.26 Writeamethodremove()thattakesalinkedlistandastringkeyasarguments and removes all of the nodes in the list that have key as its item  eld.
1.3.27 Write a method max() that takes a reference to the  rst node in a linked list as argument and returns the value of the maximum key in the list. Assume that all keys are positive integers, and return 0 if the list is empty.
1.3.28 Develop a recursive solution to the previous question.
1.3.29 WriteaQueueimplementationthatusesacircularlinkedlist,whichisthesame as a linked list except that no links are null and the value of last.next is first when- ever the list is not empty. Keep only one Node instance variable (last).
1.3.30 Write a function that takes the  rst Node in a linked list as argument and (de- structively) reverses the list, returning the  rst Node in the result.
Iterative solution : To accomplish this task, we maintain references to three consecutive nodes in the linked list, reverse, first, and second. At each iteration, we extract the node first from the original linked list and insert it at the beginning of the reversed list. We maintain the invariant that first is the  rst node of what’s left of the original list, second is the second node of what’s left of the original list, and reverse is the  rst node of the resulting reversed list.
    public Node reverse(Node x)
    {
       Node first   = x;
       Node reverse = null;
       while (first != null)
       {
          Node second = first.next;
          first.next  = reverse;
          reverse     = first;
          first       = second;
}
       return reverse;
    }
When writing code involving linked lists, we must always be careful to properly handle the exceptional cases (when the linked list is empty, when the list has only one or two
 1.3 n Bags, Queues, and Stacks 165
 www.it-ebooks.info
166 Chapter 1 n Fundamentals
 liNkED-list ExErcisEs (continued)
nodes) and the boundary cases (dealing with the  rst or last items). This is usually much trickier than handling the normal cases.
Recursivesolution: AssumingthelinkedlisthasNnodes,werecursivelyreversethelast N – 1 nodes, and then carefully append the  rst node to the end.
    public Node reverse(Node first)
    {
       if (first == null) return null;
       if (first.next == null) return first;
       Node second = first.next;
       Node rest = reverse(second);
       second.next = first;
       first.next  = null;
       return rest;
}
1.3.31 Implement a nested class DoubleNode for building doubly-linked lists, where each node contains a reference to the item preceding it and the item following it in the list (null if there is no such item). Then implement static methods for the following tasks: insert at the beginning, insert at the end, remove from the beginning, remove from the end, insert before a given node, insert after a given node, and remove a given node.
 www.it-ebooks.info

 crEAtivE problEms
  1.3.32 Steque. A stack-ended queue or steque is a data type that supports push, pop, and enqueue. Articulate an API for this ADT. Develop a linked-list-based implementation.
1.3.33 Deque. A double-ended queue or deque (pronounced “deck”) is like a stack or a queue but supports adding and removing items at both ends. A deque stores a collec- tion of items and supports the following API:
      public class Deque<Item> implements Iterable<Item>
apI for a generic double-ended queue
Write a class Deque that uses a doubly-linked list to implement this API and a class ResizingArrayDeque that uses a resizing array.
1.3.34 Random bag. A random bag stores a collection of items and supports the fol- lowing API:
      public class RandomBag<Item> implements Iterable<Item>
1.3 n Bags, Queues, and Stacks 167
  Deque() boolean isEmpty()
int size()
void pushLeft(Item item) void pushRight(Item item) Item popLeft()
Item popRight()
create an empty deque
is the deque empty?
number of items in the deque
add an item to the left end
add an item to the right end remove an item from the left end remove an item from the right end
 RandomBag() boolean isEmpty()
int size()
void add(Item item)
create an empty random bag is the bag empty?
number of items in the bag add an item
apI for a generic random bag
Write a class RandomBag that implements this API. Note that this API is the same as for Bag, except for the adjective random, which indicates that the iteration should provide
www.it-ebooks.info
168 Chapter 1 n Fundamentals
  the items in random order (all N ! permutations equally likely, for each iterator). Hint : Put the items in an array and randomize their order in the iterator’s constructor.
1.3.35 Random queue. A random queue stores a collection of items and supports the following API:
public class RandomQueue<Item>
RandomQueue() boolean isEmpty()
void enqueue(Item item) Item dequeue()
Item sample()
create an empty random queue
is the queue empty?
add an item
remove and return a random item (sample without replacement)
return a random item, but do not remove (sample with replacement)
 apI for a generic random queue
Write a class RandomQueue that implements this API. Hint : Use an array representation (with resizing). To remove an item, swap one at a random position (indexed 0 through N-1) with the one at the last position (index N-1). Then delete and return the last ob- ject, as in ResizingArrayStack. Write a client that deals bridge hands (13 cards each) using RandomQueue<Card>.
1.3.36 Random iterator. Write an iterator for RandomQueue<Item> from the previous exercise that returns the items in random order.
1.3.37 Josephus problem. In the Josephus problem from antiquity, N people are in dire straits and agree to the following strategy to reduce the population. They arrange them- selves in a circle (at positions numbered from 0 to N–1) and proceed around the circle, eliminating every Mth person until only one person is left. Legend has it that Josephus  gured out where to sit to avoid being eliminated. Write a Queue client Josephus that takes M and N from the command line and prints out the order in which people are eliminated (and thus would show Josephus where to sit in the circle).
% java Josephus 2 7 135042 6
www.it-ebooks.info
 crEAtivE problEms (continued)

  1.3.38 Delete kth element. Implement a class that supports the following API: public class GeneralizedQueue<Item>
  GeneralizedQueue() boolean isEmpty()
void insert(Item x) Item delete(int k)
create an empty queue
is the queue empty?
add an item
delete and return the kth least recently inserted item
apI for a generic generalized queue
First, develop an implementation that uses an array implementation, and then develop one that uses a linked-list implementation. Note: the algorithms and data structures that we introduce in Chapter 3 make it possible to develop an implementation that can guarantee that both insert() and delete() take time prortional to the logarithm of the number of items in the queue—see Exercise 3.5.27.
1.3.39 Ring buffer. A ring buffer, or circular queue, is a FIFO data structure of a  xed size N. It is useful for transferring data between asynchronous processes or for storing log  les. When the buffer is empty, the consumer waits until data is deposited; when the buffer is full, the producer waits to deposit data. Develop an API for a RingBuffer and an implementation that uses an array representation (with circular wrap-around).
1.3.40 Move-to-front. Read in a sequence of characters from standard input and maintain the characters in a linked list with no duplicates. When you read in a previ- ously unseen character, insert it at the front of the list. When you read in a duplicate character, delete it from the list and reinsert it at the beginning. Name your program MoveToFront: it implements the well-known move-to-front strategy, which is useful for caching, data compression, and many other applications where items that have been recently accessed are more likely to be reaccessed.
1.3.41 Copy a queue. Create a new constructor so that Queue<Item> r = new Queue<Item>(q);
makes r a reference to a new and independent copy of the queue q. You should be able to enqueue and dequeue from either q or r without in uencing the other. Hint : Delete all of the elements from q and add these elements to both q and r.
 1.3 n Bags, Queues, and Stacks 169
 www.it-ebooks.info
170 Chapter 1 n Fundamentals
   www.it-ebooks.info
 crEAtivE problEms (continued)
1.3.42 Copy a stack. Create a new constructor for the linked-list implementation of Stack so that
Stack<Item> t = new Stack<Item>(s);
makes t a reference to a new and independent copy of the stack s.
1.3.43 Listing  les. A folder is a list of  les and folders. Write a program that takes the name of a folder as a command-line argument and prints out all of the  les contained in that folder, with the contents of each folder recursively listed (indented) under that folder’s name. Hint : Use a queue, and see java.io.File.
1.3.44 Text editor buffer. Develop a data type for a buffer in a text editor that imple- ments the following API:
     public class Buffer
Buffer()
void insert(char c)
char get()
char delete() void left(int k) void right(int k)
int size()
Hint : Use two stacks.
create an empty buffer
insert c at the cursor position
character at the cursor position
delete and return the character at the cursor move the cursor k positions to the left
move the cursor k positions to the right number of characters in the buffer
  apI for a text buffer
1.3.45 Stack generability. Suppose that we have a sequence of intermixed push and pop operations as with our test stack client, where the integers 0, 1, ..., N-1 in that order (push directives) are intermixed with N minus signs (pop directives). Devise an algorithm that determines whether the intermixed sequence causes the stack to under-  ow. (You may use only an amount of space independent of N—you cannot store the integers in a data structure.) Devise a linear-time algorithm that determines whether a given permutation can be generated as output by our test client (depending on where the pop directives occur).
  1.3.46 Forbidden triple for stack generability. Prove that a permutation can be gener- ated by a stack (as in the previous question) if and only if it has no forbidden triple (a, b, c) such that a < b < c with c  rst, a second, and b third (possibly with other intervening integers between c and a and between a and b).
Partial solution: Suppose that there is a forbidden triple (a, b, c). Item c is popped before a and b, but a and b are pushed before c. Thus, when c is pushed, both a and b are on the stack. Therefore, a cannot be popped before b.
1.3.47 Catenable queues, stacks, or steques. Add an extra operation catenation that (de- structively) concatenates two queues, stacks, or steques (see Exercise 1.3.32). Hint : Use a circular linked list, maintaining a pointer to the last item.
1.3.48 Two stacks with a deque. Implement two stacks with a single deque so that each operation takes a constant number of deque operations (see Exercise 1.3.33).
1.3.49 Queue with a constant number of stacks. Implement a queue with a constant number of stacks so that each queue operation takes a constant (worst-case) number of stack operations. Warning : high degree of dif culty.
1.3.50 Fail-fast iterator. Modify the iterator code in Stack to immediately throw a java.util.ConcurrentModificationException if the client modi es the collection (via push() or pop()) during iteration?
Solution: Maintain a counter that counts the number of push() and pop() operations. When creating an iterator, store this value as an Iterator instance variable. Before each call to hasNext() and next(), check that this value has not changed since con- struction of the iterator; if it has, throw the exception.
www.it-ebooks.info
1.3 n Bags, Queues, and Stacks 171

   172
AS people gain experience using computers, they use them to solve dif cult prob- lems or to process large amounts of data and are invariably led to questions like these:
How long will my program take? Why does my program run out of memory?
You certainly have asked yourself these questions, perhaps when rebuilding a music or photo library, installing a new application, working with a large document, or work- ing with a large amount of experimental data. The questions are much too vague to be answered precisely—the answers depend on many factors such as properties of the particular computer being used, the particular data being processed, and the particular program that is doing the job (which implements some algorithm). All of these factors leave us with a daunting amount of information to analyze.
Despite these challenges, the path to developing useful answers to these basic ques- tions is often remarkably straightforward, as you will see in this section. This process is based on the scienti c method, the commonly accepted body of techniques used by sci- entists to develop knowledge about the natural world. We apply mathematical analysis to develop concise models of costs and do experimental studies to validate these models.
Scienti c method The very same approach that scientists use to understand the natural world is effective for studying the running time of programs:
n Observe some feature of the natural world, generally with precise measurements. n Hypothesize a model that is consistent with the observations.
n Predict events using the hypothesis.
n Verify the predictions by making further observations.
n Validate by repeating until the hypothesis and observations agree.
One of the key tenets of the scienti c method is that the experiments we design must be reproducible, so that others can convince themselves of the validity of the hypothesis. Hypotheses must also be falsi able, so that we can know for sure when a given hypoth- esis is wrong (and thus needs revision). As Einstein famously is reported to have said (“No amount of experimentation can ever prove me right; a single experiment can prove me wrong”), we can never know for sure that any hypothesis is absolutely correct; we can only validate that it is consistent with our observations.
www.it-ebooks.info
 1.4 AnAlySiS oF AlgorithMS

 1.4 n Analysis of Algorithms 173
Observations Our  rst challenge is to determine how to make quantitative mea- surements of the running time of our programs. This task is far easier than in the natu- ral sciences. We do not have to send a rocket to Mars or kill laboratory animals or split an atom—we can simply run the program. Indeed, every time you run a program, you are performing a scienti c experiment that relates the program to the natural world and answers one of our core questions: How long will my program take?
Our  rst qualitative observation about most programs is that there is a problem size that characterizes the dif culty of the computational task. Normally, the problem size is either the size of the input or the value of a command-line argument. Intuitively, the running time should increase with problem size, but the question of by how much it increases naturally comes up every time we develop and run a program.
Another qualitative observation for many programs is that the running time is rela- tively insensitive to the input itself; it depends primarily on the problem size. If this relationship does not hold, we need to take steps to better understand and perhaps better control the running time’s sensitivity to the input. But it does often hold, so we now focus on the goal of better quantifying the relationship between problem size and running time.
Example As a running example, we will work with the program ThreeSum shown here, which counts the number of triples in a  le of N integers that sum to 0 (assum- ing that over ow plays no role). This
computation may seem contrived to you,
but it is deeply related to numerous fun- damental computational tasks (for exam- ple, see Exercise 1.4.26). As a test input, consider the  le 1Mints.txt from the booksite, which contains 1 million ran- domly generated int values. The second, eighth, and tenth entries in 1Mints.txt sum to 0. How many more such triples are there in the  le? ThreeSum can tell us, but can it do so in a reasonable amount of time? What is the relationship between the problem size N and running time for ThreeSum? As a  rst experiment, try running ThreeSum on your computer for the  les 1Kints.txt, 2Kints.txt, 4Kints.txt, and 8Kints.txt on the
    public class ThreeSum
  {
     public static int count(int[] a)
     {  // Count triples that sum to 0.
        int N = a.length;
        int cnt = 0;
        for (int i = 0; i < N; i++)
           for (int j = i+1; j < N; j++)
              for (int k = j+1; k < N; k++)
                 if (a[i] + a[j] + a[k] == 0)
                    cnt++;
return cnt; }
     public static void main(String[] args)
     {
        int[] a = In.readInts(args[0]);
        StdOut.println(count(a));
     }
}
given n, how long will this program take?
 www.it-ebooks.info

174 Chapter 1
n Fundamentals
booksite that contain the  rst 1,000, 2,000, 4,000, and 8,000 integers from 1Mints.txt, respectively. You can quickly determine that there are 70 triples that sum to 0 in 1Kints.txt and that there are 528 triples that sum to 0 in 2Kints.txt. The program takes substantially more time to determine that there are 4,039 triples that sum to 0 in 4Kints.txt, and as you wait for the program to  nish for 8Kints.txt, you will  nd yourself asking the question How long will my program take ? As you will see, answering this question for this program turns out to be easy. In- deed, you can often come up with
 % more 1Mints.txt
 324110
-442472
 626686
-157678
 508681
 123414
 -77867
 155091
 129801
 287381
 604242
 686904
-247109
  77867
 982455
-210707
-922943
-738817
  85168
 855430
...
 a fairly accurate prediction while the program is running.
Stopwatch Reliably measuring the exact running time of a given program can be dif cult. Fortu- nately, we are usually happy with estimates. We want to be able to distinguish programs that will  nish in a few seconds or a few minutes from those that might
require a few days or a few months or more, and we want to know when one program is twice as fast as another for the same task. Still, we need accurate measurements to generate experimental data that we can use to formulate and to check the validity of hypotheses about the relationship between running time and problem size. For this purpose, we use the Stopwatch data type shown on the facing page. Its elapsedTime() method returns the elapsed time since it was created, in seconds. The implementation is based on using the Java system’s currentTimeMillis() method, which gives the current time in milliseconds, to save the time when the constructor is invoked, then uses it again to compute the elapsed time when elapsedTime() is invoked.
4039
% java ThreeSum 1Kints.txt
tick tick tick
70
% java ThreeSum 2Kints.txt
tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick
528
% java ThreeSum 4Kints.txt
      tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick
  www.it-ebooks.info
Observing the running time of a program

typical client
apI public class Stopwatch
Stopwatch() double elapsedTime()
create a stopwatch
return elapsed time since creation
1.4 n Analysis of Algorithms 175
   public static void main(String[] args)
{
   int N = Integer.parseInt(args[0]);
   int[] a = new int[N];
   for (int i = 0; i < N; i++)
      a[i] = StdRandom.uniform(-1000000, 1000000);
   Stopwatch timer = new Stopwatch();
   int cnt = ThreeSum.count(a);
   double time = timer.elapsedTime();
   StdOut.println(cnt + " triples " + time + "seconds");
}
  application
implementation
 % java Stopwatch 1000
51 triples 0.488 seconds
% java Stopwatch 2000
516 triples 3.855 seconds
 public class Stopwatch
{
   private final long start;
   public Stopwatch()
   {  start = System.currentTimeMillis();  }
   public double elapsedTime()
   {
      long now = System.currentTimeMillis();
      return (now - start) / 1000.0;
   }
}
 an abstract data type for a stopwatch
 www.it-ebooks.info

176 Chapter 1 n Fundamentals
Analysis of experimental data The program DoublingTest on the facing page is a more sophisticated Stopwatch client that produces experimental data for ThreeSum. It generates a sequence of random input arrays, doubling the array size at each step, and prints the running times of ThreeSum.count() for each input size. These experiments are certainly reproducible—you can also run them on your own computer, as many times as you like. When you run DoublingTest, you will  nd yourself in a prediction- veri cation cycle: it prints several lines very quickly, but then slows down considerably. Each time it prints a line, you  nd yourself wondering how long it will be until it prints the next line. Of course, since you have a different computer from ours, the actual run- ning times that you get are likely to be different from those shown for our computer. Indeed, if your computer is twice as fast as ours, your running times will be about half ours, which leads immediately to the well-founded hypothesis that running times on different computers are likely to differ by a constant factor. Still, you will  nd yourself asking the more detailed question How long will my program take, as a function of the input size? To help answer this question, we plot the data. The diagrams at the bottom of the facing page show the result of plotting the data, both on a normal and on a log-log scale, with the problem size N on the x-axis and the running time T(N ) on the y-axis. The log-log plot immediately leads to a hypothesis about the running time—the data  ts a straight line of slope 3 on the log-log plot. The equation of such a line is
lg(T(N )) = 3 lg N + lg a (where a is a constant) which is equivalent to
T(N) = aN3
the running time, as a function of the input size, as desired. We can use one of our data points to solve for a—for example, T(8000) = 51.1 = a 8000 3, so a = 9.9810 –11—and then use the equation
T(N ) = 9.9810 –11 N 3
to predict running times for large N. Informally, we are checking the hypothesis that the data points on the log-log plot fall close to this line. Statistical methods are available for doing a more careful analysis to  nd estimates of a and the exponent b, but our quick calculations suf ce to estimate running time for most purposes. For example, we can estimate the running time on our computer for N = 16,000 to be about 9.9810 –11 16000 3 = 408.8 seconds, or about 6.8 minutes (the actual time was 409.3 seconds). While waiting for your computer to print the line for N = 16,000 in DoublingTest, you might use this method to predict when it will  nish, then check the result by waiting to see if your prediction is true.
 www.it-ebooks.info

standard plot
50
40
30
20
10
log-log plot 51.2 25.6
12.8 6.4 3.2 1.6 .8 .4 .2 .1
straight line of slope 3
1.4 n Analysis of Algorithms 177
program to perform experiments
  public class DoublingTest
{
   public static double timeTrial(int N)
   {  // Time ThreeSum.count() for N random 6-digit ints.
      int MAX = 1000000;
      int[] a = new int[N];
      for (int i = 0; i < N; i++)
         a[i] = StdRandom.uniform(-MAX, MAX);
      Stopwatch timer = new Stopwatch();
      int cnt = ThreeSum.count(a);
      return timer.elapsedTime();
}
   public static void main(String[] args)
   {  // Print table of running times.
      for (int N = 250; true; N += N)
      {  // Print time for problem size N.
         double time = timeTrial(N);
         StdOut.printf("%7d %5.1f\n", N, time);
      }
} }
                                           1K 2K
4K
8K
1K 2K 4K 8K
lg N
problem size N
Analysis of experimental data (the running time of ThreeSum.count())
www.it-ebooks.info
results of experiments
  % java DoublingTest
250 0.0
500 0.0
   1000   0.1
   2000   0.8
   4000   6.4
   8000  51.1
...
 running time T(N )
lg (T(N ))
178 Chapter 1 n Fundamentals
So far, this process mirrors the process scientists use when trying to understand properties of the real world. A straight line in a log-log plot is equivalent to the hy- pothesis that the data  ts the equation T(N ) = a N b . Such a  t is known as a power law. A great many natural and synthetic phenomena are described by power laws, and it is reasonable to hypothesize that the running time of a program does, as well. Indeed, for the analysis of algorithms, we have mathematical models that strongly support this and similar hypotheses, to which we now turn.
Mathematical models In the early days of computer science, D. E. Knuth postu- lated that, despite all of the complicating factors in understanding the running times of our programs, it is possible, in principle, to build a mathematical model to describe the running time of any program. Knuth’s basic insight is simple: the total running time of a program is determined by two primary factors:
n The cost of executing each statement
n The frequency of execution of each statement
The former is a property of the computer, the Java compiler and the operating system; the latter is a property of the program and the input. If we know both for all instruc- tions in the program, we can multiply them together and sum for all instructions in the program to get the running time.
The primary challenge is to determine the frequency of execution of the statements. Some statements are easy to analyze: for example, the statement that sets cnt to 0 in ThreeSum.count() is executed exactly once. Others require higher-level reasoning: for example, the if statement in ThreeSum.count() is executed precisely
N (N1)(N2)/6
times (the number of ways to pick three different numbers from the input array—see Exercise 1.4.1). Others depend on the input data: for example the number of times the instruction cnt++ in ThreeSum.count() is executed is precisely the number of triples that sum to 0 in the input, which could range from 0 of them to all of them. In the case of DoublingTest, where we generate the numbers randomly, it is possible to do a prob- abilistic analysis to determine the expected value of this quantity (see Exercise 1.4.40).
Tilde approximations Frequency analyses of this sort can lead to complicated and lengthy mathematical expressions. For example, consider the count just considered of the number of times the if statement in ThreeSum is executed:
N (N1)(N2)/6 = N 3/6  N 2/2  N/3
 www.it-ebooks.info

As is typical in such expressions, the terms after
the leading term are relatively small (for exam- ple, when N = 1,000 the value of  N2/2  N/3
 499,667 is certainly insigni cant by com- parison with N 3/6  166,666,667). To allow us
to ignore insigni cant terms and therefore sub- stantially simplify the mathematical formulas that we work with, we often use a mathemati-
cal device known as the tilde notation (~). This N notation allows us to work with tilde approxi- mations, where we throw away low-order terms that complicate formulas and represent a negli- gible contribution to values of interest:
N (N  1)(N  2)/6 166,167,000
1.4 n
Analysis of Algorithms 179 N 3/6
     166,666,667
Leading-term approximation
     function
tilde approximation
~ N3/6 ~ N 2/2 ~ lg N
order of growth
N3
N 2 lg N
1,000
   N3/6  N2/2  N/3 N 2/2  N/2
lg N + 1
 Definition. We write ~f(N) to represent any function that, when divided by f(N), approaches 1 as N grows, and we write g(N) ~ f(N) to indicate that g(N)/f(N) approaches 1 as N grows.
order of growth
3 ~3 1
typical tilde approximations
For example, we use the approximation ~N3/6 to de- scribe the number of times the if statement in ThreeSum is executed, since N 3/6  N 2/2  N/3 di- vided by N3/6 approaches 1 as N grows. Most of- ten, we work with tilde approximations of the form g(N) ~ a f(N) where f(N) = Nb(log N)c with a, b, and c constants and refer to f (N ) as the order of growth of g (N ). When using the logarithm in the order of growth, we gener- ally do not specify the base, since the constant a can absorb that detail. This usage covers the relatively few functions that are commonly encountered in studying the order of growth of a program’s running time shown in the table at left (with the exception of the exponential, which we defer to CONTEXT). We will describe these functions in more de- tail and brie y discuss why they appear in the analysis of algorithms after we complete our treatment of ThreeSum.
description
constant
logarithmic
linear
linearithmic
quadratic
cubic
exponential
function
1 log N N
N log N N 2
N 3
2 N
 Commonly encountered order-of-growth functions
www.it-ebooks.info

180 Chapter 1 n Fundamentals
Approximate running time To follow through on Knuth’s approach to develop a mathematical expression for the total running time of a Java program, we can (in prin- ciple) study our Java compiler to  nd the number of machine instructions correspond- ing to each Java instruction and study our machine speci cations to  nd the time of execution of each of the machine instructions, to produce a grand total. This process, for ThreeSum, is brie y summarized on the facing page. We classify blocks of Java state- ments by their frequency of execution, develop leading-term approximations for the frequencies, determine the cost of each statement, and then compute a total. Note that some frequencies may depend on the input. In this case, the number of times cnt++ is executed certainly depends on the input—it is the number of triples that sum to 0, and could range from 0 to ~N 3/6. We stop short of exhibiting the details (values of the constants) for any particular system, except to highlight that by using constant values t0, t1, t2, ... for the time taken by the blocks of statements, we are assuming that each block of Java statements corresponds to machine instructions that require a speci ed  xed amount of time. A key observation from this exercise is to note that only the instruc- tions that are executed the most frequently play a role in the  nal total—we refer to these instructions as the inner loop of the program. For ThreeSum, the inner loop is the statements that increment k and test that it is less than N and the statements that test whether the sum of three given numbers is 0 (and possibly the statement that imple- ments the count, depending on the input). This behavior is typical: the running times of a great many programs depend only on a small subset of their instructions.
Order-of-growth hypothesis In summary, the experiments onpage 177 and the math- ematical model on page 181 both support the following hypothesis:
  property A. The order of growth of the running time of ThreeSum (to compute the number of triples that sum to 0 among N numbers) is N 3.
Evidence: Let T(N ) be the running time of ThreeSum for N numbers. The math- ematical model just described suggests that T(N) ~ aN3 for some machine-de- pendent constant a; experiments on many computers (including yours and ours) validate that approximation.
Throughout this book, we use the term property to refer to a hypothesis that needs to be validated through experimentation. The end result of our mathematical analysis is precisely the same as the end result of our experimental analysis—the running time of ThreeSum is ~ a N 3 for a machine-dependent constant a. This match validates both the experiments and the mathematical model and also exhibits more insight about the
www.it-ebooks.info

 public class ThreeSum
 {
    public static int count(int[] a)
    {
A
B
C D E
}
    public static void main(String[] args)
    {
       int[] a = In.readInts(args[0]);
       StdOut.println(count(a));
} }
1
N ~N 2/ 2
~N 3/ 6 x
inner loop
1.4
n Analysis of Algorithms 181
 int N = a.length;
int cnt = 0;
for (int i = 0;            )
             i < N; i++
for (int j = i+1;
               j < N; j++
for (int k = j+1; k < N; k
)
++ )
      if (a[i] + a[j] + a[k] == 0)
   cnt++;
           return cnt;
                  statement block
time in seconds
frequency
x (depends on input) N3/6  N2/2  N/3
total time
t0 x
t1 (N3/6  N2/2  N/3) t2 (N2/2  N/2)
Anatomy of a program’s statement execution frequencies
 e t0 D t1
C t2 B t3 A t4
N2/2  N/2
N t3N
1 t4
grand total
tilde approximation order of growth
(t1/6) N 3
 (t2/2  t1/2) N 2
 (t1/3  t2/2  t3) N
t4 t0x
~ (t1 / 6) N 3 (assuming x is small) N 3
analyzing the running time of a program (example)
www.it-ebooks.info
 blocks of statements
frequencies of execution
182 Chapter 1 n Fundamentals
program because it does not require experimentation to determine the exponent. With some effort, we could validate the value of a on a particular system as well, though that activity is generally reserved for experts in situations where performance is critical.
Analysis of algorithms Hypotheses such as Property A are signi cant because they relate the abstract world of a Java program to the real world of a computer running it. Working with the order of growth allows us to take one further step: to separate a pro- gram from the algorithm it implements. The idea that the order of growth of the run- ning time of ThreeSum is N 3 does not depend on the fact that it is implemented in Java or that it is running on your laptop or someone else’s cellphone or a supercomputer; it depends primarily on the fact that it examines all the different triples of numbers in the input. The algorithm that you are using (and sometimes the input model) determines the order of growth. Separating the algorithm from the implementation on a particular computer is a powerful concept because it allows us to develop knowledge about the performance of algorithms and then apply that knowledge to any computer. For ex- ample, we might say that ThreeSum is an implementation of the brute-force algorithm “compute the sum of all different triples, counting those that sum to 0”—we expect that an implementation of this algorithm in any programming language on any computer will lead to a running time that is proportional to N 3. In
fact, much of the knowledge about the performance of classic algorithms was developed decades ago, but that knowledge is still relevant to today’s computers.
Cost model We focus attention on properties of al-
gorithms by articulating a cost model that de nes the
basic operations used by the algorithms we are study-
ing to solve the problem at hand. For example, an ap-
propriate cost model for the 3-sum problem, shown
at right, is the number of times we access an array
entry. With this cost model, we can make precise mathematical statements about prop- erties of an algorithm, not just a particular implementation, as follows:
  3-sum cost model. When studying algorithms to solve the 3-sum problem, we count array accesses (the number of times an array entry is accessed, for read or write).
 propositionb. The brute-force 3-sum algorithm uses ~N3/2 array accesses to compute the number of triples that sum to 0 among N numbers.
proof: Thealgorithmaccesseseachofthe3numbersforeachofthe~N3/6triples.
We use the term proposition to refer to mathematical truths about algorithms in terms of a cost model. Throughout this book, we study the algorithms that we consider within
www.it-ebooks.info

www.it-ebooks.info
1.4 n Analysis of Algorithms 183
the framework of a speci c cost model. Our intent is to articulate cost models such that the order of growth of the running time for a given implementation is the same as the order of growth of the cost of the underlying algorithm (in other words, the cost model should include operations that fall within the inner loop). We seek precise mathemati- cal results about algorithms (propositions) and also hypotheses about performance of implementations (properties) that you can check through experimentation. In this case, Proposition B is a mathematical truth that supports the hypothesis stated in Property A, which we have validated with experiments, in accordance with the scien- ti c method.

184 Chapter 1 n Fundamentals
Summary For many programs, developing a mathematical model of running time reduces to the following steps:
n Develop an input model, including a de nition of the problem size.
n Identify the inner loop.
n De ne a cost model that includes operations in the inner loop.
n Determine the frequency of execution of those operations for the given input.
Doing so might require mathematical analysis—we will consider some examples
in the context of speci c fundamental algorithms later in the book.
If a program is de ned in terms of multiple methods, we normally consider the methods separately. As an example, consider our example program of Section 1.1, BinarySearch.
Binary search The input model is the array a[] of size N; the inner loop is the statements in the single while loop; the cost model is the compare operation (compare the values of two array entries); and the analysis, discussed in Section 1.1 and given in full detail in Proposition B in Section 3.1, shows that the num- ber of compares is at most lg N  1.
Whitelist The input model is the N numbers in the whitelist and the M numbers on standard input where we assume M >> N; the inner loop is the statements in the single while loop; the cost model is the compare operation (inherited from binary search); and the analysis is immediate given the analysis of binary search— the number of compares is at most M (lg N  1).
Thus, we draw the conclusion that the order of growth of the running time of the whitelist computation is at most M lg N , subject to the following considerations:
n If N is small, the input-output cost might dominate.
n The number of compares depends on the input—it lies between ~M and ~M
lg N, depending on how many of the numbers on standard input are in the whitelist and on how long the binary search takes to  nd the ones that are (typi- cally it is ~M lgN).
n We are assuming that the cost of Arrays.sort() is small compared to M lg N. Arrays.sort() implements the mergesort algorithm, and in Section 2.2, we will see that the order of growth of the running time of mergesort is N log N (see Proposition G in chapter 2), so this assumption is justi ed.
Thus, the model supports our hypothesis from Section 1.1 that the binary search algo- rithm makes the computation feasible when M and N are large. If we double the length of the standard input stream, then we can expect the running time to double; if we double the size of the whitelist, then we can expect the running time to increase only slightly.
 www.it-ebooks.info

Developing MATHEMATICal models for the analysis of algorithms is a fruitful area of research that is somewhat beyond the scope of this book. Still, as you will see with binary search, mergesort, and many other algorithms, understanding certain math- ematical models is critical to understanding the ef ciency of fundamental algorithms, so we often present details and/or quote the results of classic studies. When doing so, we encounter various functions and approximations that are widely used in mathemati- cal analysis. For reference, we summarize some of this information in the tables below.
description
 oor ceiling natural logarithm binary logarithm
integer binary logarithm
harmonic numbers factorial
notation
⎣x⎦
⎡x⎤ ln N lg N
⎣lg N⎦
HN
definition
largest integer not greater than x
smallest integer not smaller than x
log e N (x such that e x = N)
log 2 N (x such that 2x = N) largest integer not greater than lg N
(# bits in binary representation of N ) – 1 1  1/2  1/3  1/4  . . .  1/N
description
harmonic sum
triangular sum
geometric sum
Stirling’s approximation
binomial coef cients
exponential
approximation
HN = 1  1/2  1/3  1/4  . . .  1/N ~ ln N
1  2  3  4  . . .  N ~ N 2/2
1  2  4  8  . . .  N = 2N – 1 ~ 2N when N = 2n
lgN! = lg1lg2lg3lg4...lgN~NlgN ( N ) ~ N k/k! when k is a small constant
(1 – 1/x) x ~ 1/e Useful approximations for the analysis of algorithms
k
www.it-ebooks.info
1234... N
1.4 n Analysis of Algorithms 185
  N!
Commonly encountered functions in the analysis of algorithms

186 Chapter 1 n Fundamentals
Order-of-growth classi cations We use just a few structural primitives (state- ments, conditionals, loops, nesting, and method calls) to implement algorithms, so very often the order of growth of the cost is one of just a few functions of the problem size N. These functions are summarized in the table on the facing page, along with the names that we use to refer to them, typical code that leads to each function, and examples.
Constant A program whose running time’s order of growth is constant executes a  xed number of operations to  nish its job; consequently its running time does not depend on N. Most Java operations take constant time.
Logarithmic A program whose running time’s order of growth is logarithmic is barely slower than a constant-time program. The classic example of a program whose running time is logarithmic in the problem size is binary search (see BinarySearch on page 47). The base of the logarithm is not relevant with respect to the order of growth (since all logarithms with a constant base are related by a constant factor), so we use log N when referring to order of growth.
Linear Programs that spend a constant amount of time processing each piece of input data, or that are based on a single for loop, are quite common. The order of growth of such a program is said to be linear —its running time is proportional to N.
Linearithmic We use the term linearithmic to describe programs whose running time for a problem of size N has order of growth N log N. Again, the base of the logarithm is not relevant with respect to the order of growth. The prototypical examples of lin- earithmic algorithms are Merge.sort() (see Algorithm 2.4) and Quick.sort() (see Algorithm 2.5).
Quadratic A typical program whose running time has order of growth N2 has two nested for loops, used for some calculation involving all pairs of N elements. The elementary sorting algorithms Selection.sort() (see Algorithm 2.1) and Insertion.sort() (see Algorithm 2.2) are prototypes of the programs in this classi cation.
Cubic A typical program whose running time has order of growth N 3 has three nested for loops, used for some calculation involving all triples of N elements. Our example for this section, ThreeSum, is a prototype.
Exponential In ChAPter 6 (but not until then!) we will consider programs whose running times are proportional to 2N or higher. Generally, we use the term exponential to refer to algorithms whose order of growth is b N for any constant b > 1, even though different values of b lead to vastly different running times. Exponential algorithms are extremely slow—you will never run one of them to completion for a large problem. Still, exponential algorithms play a critical role in the theory of algorithms because
 www.it-ebooks.info

description
constant
logarithmic
linear
linearithmic
quadratic
cubic
exponential
order of growth
1
log N
N
N log N
N 2
N 3
2 N
a = b + c;
typical code framework
[ see page 47 ]
description
statement
divide in half
loop
divide and conquer
example
add two numbers
binary search
 nd the maximum
mergesort
check all pairs
check all triples
check all subsets
  double max = a[0];
  for (int i = 1; i < N; i++)
     if (a[i] > max) max = a[i];
[ see Algorithm 2.4 ]
  for (int i = 0; i < N; i++)
     for (int j = i+1; j < N; j++)
        if (a[i] + a[j] == 0)
           cnt++;
  for (int i = 0; i < N; i++)
     for (int j = i+1; j < N; j++)
        for (int k = j+1; k < N; k++)
           if (a[i] + a[j] + a[k] == 0)
cnt++;
[ see chapter 6 ]
Summary of common order-of-growth hypotheses
double loop
triple loop
exhasutive search
www.it-ebooks.info
1.4
n
Analysis of Algorithms 187

188 Chapter 1 n Fundamentals
there exists a large class of problems for which it seems that an exponential algorithm
is the best possible choice.
These classifications are the most common, but certainly not a complete set. The order of growth of an algorithm’s cost might be N 2 log N or N 3/2 or some similar func-
 standard plot
tion. Indeed, the detailed analysis of algorithms can require the full gamut of mathematical tools that have been developed over the centuries.
A great many of the algorithms that we con- sider have straightforward performance charac- teristics that can be accurately described by one of the orders of growth that we have considered. Accordingly, we can usually work with speci c propositions with a cost model, such as mergesort uses between 1⁄2Nlg N and NlgN compares that immediately imply hypotheses (properties) such as the order of growth of mergesort’s running time is linearithmic. For economy, we abbreviate such a statement to just say mergesort is linearithmic.
The plots at left indicate the importance of the order of growth in practice. The x-axis is the problem size; the y-axis is the running time. These charts make plain that quadratic and cubic algorithms are not feasible for use on large prob- lems. As it turns out, several important prob- lems have natural solutions that are quadratic but clever algorithms that are linearithmic. Such algorithms (including mergesort) are critically important in practice because they enable us to address problem sizes far larger than could be addressed with quadratic solutions. Naturally, we therefore focus in this book on developing loga- rithmic, linear, and linearithmic algorithms for fundamental problems.
  500T
200T
100T
exponential cubic
quadratic
            logarithmic constant
             log-log plot
512T
64T
8T 4T 2T
T
logarithmic constant
100K 200K 500K
problem size
                        1K 2K 4K 8K
problem size
Typical orders of growth
512K
www.it-ebooks.info
 linearithmic linear
linearithmic linear
cubic
quadratic
time
time
exponential
Designing faster algorithms One of the primary reasons to study the order of growth of a program is to help design a faster algorithm to solve the same problem. To illustrate this point, we consider next a faster algorithm for the 3-sum problem. How can we devise a faster algorithm, before even embarking on the study of algorithms? The answer to this question is that we have discussed and used two classic algorithms, mergesort and binary search, have introduced the facts that the mergesort is linearith- mic and binary search is logarithmic. How can we take advantage of these algorithms to solve the 3-sum problem?
Warmup: 2-sum Consider the easier problem of determining the number of pairs of integers in an input  le that sum to 0. To simplify the discussion, assume also that the integers are distinct. This problem is easily solved in quadratic time by deleting the k loop and a[k] from ThreeSum.count(), leaving a double loop that examines all pairs, as shown in the quadratic entry in the table onpage 187 (we refer to such an implementa- tion as TwoSum). The implementation below shows how mergesort and binary search (see page 47) can serve as a basis for a linearithmic solution to the 2-sum problem. The improved algorithm is based on the fact that an entry a[i] is one of a pair that sums to 0 if and only if the value -a[i] is in the array (and a[i] is not zero). To solve the prob- lem, we sort the array (to enable binary search) and then, for every entry a[i] in the ar- ray, do a binary search for -a[i] with rank() in BinarySearch. If the result is an index j with j > i, we increment the count.
This succinct test covers three cases:
n An unsuccessful binary search re-
turns -1, so we do not increment
the count.
n If the binary search re-
turns j > i, we have
a[i] + a[j] = 0, so we incre- ment the count.
n If the binary search returns j between 0 and i, we also have a[i] + a[j] = 0 but do not increment the count, to avoid double counting.
The result of the computation is precise- ly the same as the result of the quadratic algorithm, but it takes much less time. The running time of the mergesort is
1.4 n Analysis of Algorithms 189
   import java.util.Arrays;
  public class TwoSumFast
  {
     public static int count(int[] a)
     {  // Count pairs that sum to 0.
        Arrays.sort(a);
        int N = a.length;
        int cnt = 0;
        for (int i = 0; i < N; i++)
           if (BinarySearch.rank(-a[i], a) > i)
              cnt++;
return cnt; }
     public static void main(String[] args)
     {
        int[] a = In.readInts(args[0]);
        StdOut.println(count(a));
     }
}
Linearithmic solution to the 2-sum problem
 www.it-ebooks.info

190 Chapter 1 n Fundamentals
proportional to N log N, and the N binary searches each take time proportional to log N, so the running time of the whole algorithm is proportional to N log N. Developing a faster algorithm like this is not merely an academic exercise—the faster algorithm enables us to address much larger problems. For example, you are likely to be able to solve the 2-sum problem for 1 million integers (1Mints.txt) in a reasonable amount of time on your computer, but you would have to wait quite a long time to do it with the quadratic algorithm (see Exercise 1.4.41).
Fast algorithm for 3-sum The very same idea is effective for the 3-sum problem. Again, assume also that the integers are distinct. A pair a[i] and a[j] is part of a triple thatsumsto0ifandonlyifthevalue-(a[i]+ a[j])isinthearray(andnota[i]or a[j]). The code below sorts the array, then does N (N1)/ 2 binary searches that each take time proportional to log N, for a total running time proportional to N 2 log N. Note that in this case the cost of the sort is insigni cant. Again, this solution enables us to ad- dress much larger problems (see Exercise 1.4.42). The plots in the  gure at the bottom of the next page show the disparity in costs among these four algorithms for problem sizes in the range we have considered. Such differences certainly motivate the search for faster algorithms.
Lower bounds The table on page 191 summarizes the discussion of this section. An in- teresting question immediately arises: Can we  nd algorithms for the 2-sum and 3-sum problems that are substantially faster than TwoSumFast and ThreeSumFast? Is there a linear algorithm for 2-sum or a linea- rithmic algorithm for 3-sum? The answer to this question is no for 2-sum (under a model that counts and allows only compari- sons of linear or quadratic func- tions of the numbers) and no one knows for 3-sum, though experts believe that the best possible al- gorithm for 3-sum is quadratic. The idea of a lower bound on the order of growth of the worst-case running time for all possible al- gorithms to solve a problem is a very powerful one, which we will
   import java.util.Arrays;
 public class ThreeSumFast
 {
    public static int count(int[] a)
    {  // Count triples that sum to 0.
       Arrays.sort(a);
       int N = a.length;
       int cnt = 0;
       for (int i = 0; i < N; i++)
          for (int j = i+1; j < N; j++)
            if (BinarySearch.rank(-a[i]-a[j], a) > j)
               cnt++;
return cnt; }
     public static void main(String[] args)
     {
        int[] a = In.readInts(args[0]);
        StdOut.println(count(a));
     }
}
N 2 lg N solution to the 3-sum problem
 www.it-ebooks.info

revisit in detail in Section 2.2 in the context of sorting. Non- trivial lower bounds are dif cult to establish, but very helpful in guiding our search for ef cient algorithms.
The examples in this section set the stage for our treat- ment of algorithms in this book. Throughout the book, our strategy for addressing new problems is the following:
n Implement and analyze a straighforward solution to the problem. We usually refer to such solutions, like ThreeSum and TwoSum, as the brute-force solution.
algorithm
   TwoSum
 TwoSumFast
  ThreeSum
ThreeSumFast
order of growth of running time
N 2
N log N
N3
N 2 log N
1.4
n
Analysis of Algorithms 191
  n Examine algorithmic improvements, usually designed
to reduce the order of growth of the running time, such as TwoSumFast and ThreeSumFast.
n Run experiments to validate the hypotheses that the new algorithms are faster. In many cases, we examine several algorithms for the same problem, because running time is only one consideration when choosing an algorithm for a practical problem. We will develop this idea in detail in the context of fundamental problems throughout the book.
Summary of running times
    100
80
60
40
20
N2
TwoSum
TwoSumFast
1000 N3/2 ThreeSum
N2 lgN
    800
600
400
200
                4N lgN
ThreeSumFast
                 1K 2K
4K 8K
problem size N
1K 2K
4K
problem size N
8K
Costs of algorithms to solve the 2-sum and 3-sum problems
www.it-ebooks.info
 array accesses (thousands)
array accesses (millions)
192 Chapter 1 n Fundamentals
Doubling ratio experiments The following is a simple and effective shortcut for predicting performance and for determining the approximate order of growth of the running time of any program:
n Develop an input generator that produces inputs that model the inputs expected in practice (such as the random integers in timeTrial() in DoublingTest).
n Run the program DoublingRatio given below, a modi cation of DoublingTest that calculates the ratio of each running time with the previous.
n Run until the ratios approach a limit 2b.
This test is not effective if the ratios do not approach a limiting value, but they do for many, many programs, implying the following conclusions:
n The order of growth of the running time is approximately N b.
n To predict running times, multiply the last observed running time by 2b and
double N, continuing as long as desired. If you want to predict for an input size that is not a power of 2 times N, you can adjust ratios accordingly (see Exercise 1.4.9).
As illustrated below, the ratio for ThreeSum is about 8 and we can predict the running times for N = 16,000, 32,000, 64,000 to be 408.8, 3270.4, 26163.2 seconds, respectively, just by successively multiplying the last time for 8,000 (51.1) by 8.
 program to perform experiments
  public class DoublingRatio
{
   public static double timeTrial(int N)
   // same as for DoublingTest (page 177)
   public static void main(String[] args)
   {
      double prev = timeTrial(125);
      for (int N = 250; true; N += N)
      {
         double time = timeTrial(N);
         StdOut.printf("%6d %7.1f ", N, time);
         StdOut.printf("%5.1f\n", time/prev);
         prev = time;
} }
}
  www.it-ebooks.info
results of experiments
% java DoublingRatio
250 0.0 2.7
500 0.0 4.8
  1000     0.1   6.9
  2000     0.8   7.7
  4000     6.4   8.0
  8000    51.1   8.0
predictions
  16000   408.8   8.0
32000  3270.4   8.0
64000 26163.2   8.0

This test is roughly equivalent to the process described onpage 176 (run experiments, plot values on a log-log plot to develop the hypothesis that the running time is aNb, determine the value of b from the slope of the line, then solve for a), but it is sim- pler to apply. Indeed, you can accurately predict preformance by hand when you run DoublingRatio. As the ratio approaches a limit, just multiply by that ratio to  ll in later values in the table. Your approximate model of the order of growth is a power law with the binary logarithm of that ratio as the power.
Why does the ratio approach a constant? A simple mathematical calculation shows that to be the case for all of the common orders of growth just discussed (except exponential):
1.4 n Analysis of Algorithms 193
  proposition c. (Doubling ratio) If T(N) ~ a N b lg N then T(2N)/T(N) ~ 2b . proof: Immediate from the following calculation:
T(2N)/T(N) = a(2N)b lg(2N)/aNb lgN =2b (1+lg2/lgN)
~ 2b
Generally, the logarithmic factor cannot be ignored when developing a mathematical model, but it plays a less important role in predicting performance with a doubling hypothesis.
You should consider running doubling ratio experiments for every program that you write where performance matters—doing so is a very simple way to estimate the order of growth of the running time, perhaps revealing a performance bug where a program may turn out to be not as ef cient as you might think. More generally, we can use hypotheses about the order of growth of the running time of programs to predict performance in one of the following ways:
Estimating the feasibility of solving large problems You need to be able to answer this basic question for every program that you write: Will the program be able to process this given input data in a reasonable amount of time? To address such questions for a large amount of data, we extrapolate by a much larger factor than for doubling, say 10, as shown in the fourth column in the table at the bottom of the next page. Whether it is an investment banker running daily  nancial models or a scientist running a program to analyze experimental data or an engineer running simulations to test a design, it is not unusual for people to regularly run programs that take several hours to complete,
www.it-ebooks.info

194 Chapter 1 n Fundamentals
so the table focuses on that situation. Knowing the order of growth of the running time of an algorithm provides precisely the information that you need to understand limita- tions on the size of the problems that you can solve. Developing such understanding is the most important reason to study performance. Without it, you are likely have no idea how much time a program will consume; with it, you can make a back-of-the-envelope calculation to estimate costs and proceed accordingly.
Estimating the value of using a faster computer You also may be faced with this basic question, periodically: How much faster can I solve the problem if I get a faster computer? Generally, if the new computer is x times faster than the old one, you can improve your running time by a factor of x. But it is usually the case that you can address larger prob- lems with your new computer. How will that change affect the running time? Again, the order of growth is precisely the information needed to answer that question.
A famous rule of thumb known as Moore’s Law implies that you can expect to have a computer with about double the speed and double the memory 18 months from now, or a computer with about 10 times the speed and 10 times the memory in about 5 years. The table below demonstrates that an algorithm cannot keep pace with Moore’s Law (solving a problem that is twice as big with a computer that is twice as fast) if its run- ning time is quadratic or cubic. You can quickly determine whether that is the case by doing a doubling ratio test and checking that the ratio of running times as the input size doubles approaches 2 (linear or linearithmic), not 4 (quadratic) or 8 (cubic).
 order of growth of time
description function
for a program that takes a few hours for input of size n
2x 10x
predicted time for10N on a 10x faster computer
factor
factor predicted time for 10N
    linear linearithmic quadratic cubic exponential
N
N log N N 2
N 3
2 N
2
2
4
8 2 N
10
10
100
1,000 2 9N
a day
a day
a few weeks
several months never
a few hours a few hours a day
a few weeks never
predictions on the basis of order-of-growth function
 www.it-ebooks.info

Caveats There are many reasons that you might get inconsistent or misleading re- sults when trying to analyze program performance in detail. All of them have to do with the idea that one or more of the basic assumptions underlying our hypotheses might be not quite correct. We can develop new hypotheses based on new assumptions, but the more details that we need to take into account, the more care is required in the analysis.
Large constants With leading-term approximations, we ignore constant coef cients in lower-order terms, which may not be justifed. For example, when we approximate the function 2N2 + c N by ~2N2, we are assuming that c is small. If that is not the case (suppose that c is 103 or 106) the approximation is misleading. Thus, we have to be sensitive to the possibility of large constants.
Nondominant inner loop The assumption that the inner loop dominates may not always be correct. The cost model might miss the true inner loop, or the problem size N might not be suf ciently large to make the leading term in the mathematical descrip- tion of the frequency of execution of instructions in the inner loop so much larger than lower-order terms that we can ignore them. Some programs have a signi cant amount of code outside the inner loop that needs to be taken into consideration. In other words, the cost model may need to be re ned.
Instruction time The assumption that each instruction always takes the same amount of time is not always correct. For example, most modern computer systems use a tech- nique known as caching to organize memory, in which case accessing elements in huge arrays can take much longer if they are not close together in the array. You might ob- serve the effect of caching for ThreeSum by letting DoublingRatio run for a while. After seeming to converge to 8, the ratio of running times may jump to a larger value for large arrays because of caching.
System considerations Typically, there are many, many things going on in your com- puter. Java is one application of many competing for resources, and Java itself has many options and controls that signi cantly affect performance. A garbage collector or a just- in-time compiler or a download from the internet might drastically affect the results of experiments. Such considerations can interfere with the bedrock principle of the scienti c method that experiments should be reproducible, since what is happening at this moment in your computer will never be reproduced again. Whatever else is going on in your system should in principle be negligible or possible to control.
Too close to call Often, when we compare two different programs for the same task, one might be faster in some situations, and slower in others. One or more of the consid- erations just mentioned could make the difference. There is a natural tendency among
1.4 n Analysis of Algorithms 195
 www.it-ebooks.info

196 Chapter 1 n Fundamentals
some programmers (and some students) to devote an extreme amount of energy run- ning races to  nd the “best” implementation, but such work is best left for experts.
Strong dependence on inputs One of the  rst assumptions that we made in order to determine the order of growth of the program’s running time of a program was that the running time should be relatively insensitive to the inputs. When that is not the case, we may get inconsistent results or be unable to validate our hypotheses. For example, sup- pose that we modify ThreeSum to answer the question Does the input have a triple that sums to 0 ? by changing it to return a boolean value, replacing cnt++ by return true and adding return false as the last statement. The order of growth of the running time of this program is constant if the  rst three integers sum to 0 and cubic if there are no such triples in the input.
Multiple problem parameters We have been focusing on measuring performance as a function of a single parameter, generally the value of a command-line argument or the size of the input. However, it is not unusual to have several parameters. A typical ex- ample arises when an algorithm involves building a data structure and then performing a sequence of operations that use that data structure. Both the size of the data structure and the number of operations are parameters for such applications. We have already seen an example of this in our analysis of the problem of whitelisting using binary search, where we have N numbers in the whitelist and M numbers on standard input and a typical running time proportional to M log N.
Despite all these caveats, understanding the order of growth of the running time of each program is valuable knowledge for any programmer, and the methods that we have described are powerful and broadly applicable. Knuth’s insight was that we can carry these methods through to the last detail in principle to make detailed, accurate predictions. Typical computer systems are extremely complex and close analysis is best left for experts, but the same methods are effective for developing approximate esti- mates of the running time of any program. A rocket scientist needs to have some idea of whether a test  ight will land in the ocean or in a city; a medical researcher needs to know whether a drug trial will kill or cure all the subjects; and any scientist or engineer using a computer program needs to have some idea of whether it will run for a second or for a year.
 www.it-ebooks.info

Coping with dependence on inputs For many problems, one of the most sig- ni cant of the caveats just mentioned is the dependence on inputs, because running times can vary widely. The running time of the modi cation of ThreeSum mentioned on the facing page ranges from constant to cubic, depending on the input, so a closer analysis is required if we want to predict performance. We brie y consider here some of the approaches that are effective and that we will consider for speci c algorithms later in the book.
Input models One approach is to more carefully model the kind of input to be pro- cessed in the problems that we need to solve. For example, we might assume that the numbers in the input to ThreeSum are random int values. This approach is challenging for two reasons:
n The model may be unrealistic.
n The analysis may be extremely dif cult, requiring mathematical skills quite be-
yond those of the typical student or programmer.
The  rst of these is the more signi cant, often because the goal of a computation is to discover characteristics of the input. For example, if we are writing a program to process a genome, how can we estimate its performance on a different genome? A good model describing the genomes found in nature is precisely what scientists seek, so estimating the running time of our programs on data found in nature actually amounts to con- tributing to that model! The second challenge leads to a focus on mathematical results only for our most important algorithms. We will see several examples where a simple and tractable input model, in conjunction with classical mathematical analysis, helps us predict performance.
Worst-case performance guarantees Some applications demand that the running time of a program be less than a certain bound, no matter what the input. To provide such performance guarantees, theoreticians take an extremely pessimistic view of the performance of algorithms: what would the running time be in the worst case? For example, such a conservative approach might be appropriate for the software that runs a nuclear reactor or a pacemaker or the brakes in your car. We want to guarantee that such software completes its job within the bounds that we set because the result could be catastrophic if it does not. Scientists normally do not contemplate the worst case when studying the natural world: in biology, the worst case might be the extinction of the human race; in physics, the worst case might be the end of the universe. But the worst case can be a very real concern in computer systems, where the input may be generated by another (potentially malicious) user, rather than by nature. For example, websites that do not use algorithms with performance guarantees are subject to denial- of-service attacks, where hackers  ood them with pathological requests that make them
1.4 n Analysis of Algorithms 197
 www.it-ebooks.info

198 Chapter 1 n Fundamentals
run much more slowly than planned. Accordingly, many of our algorithms are designed to provide performance guarantees, such as the following:
 proposition D. In the linked-list implementations of Bag (Algorithm 1.4), Stack (Algorithm 1.2), and Queue (Algorithm 1.3), all operations take constant time in the worst case.
proof: Immediate from the code. The number of instructions executed for each operation is bounded by a small constant. Caveat : This argument depends upon the (reasonable) assumption that the Java system creates a new Node in constant time.
 Randomized algorithms One important way to provide a performance guarantee is to introduce randomness. For example, the quicksort algorithm for sorting that we study in Section 2.3 (perhaps the most widely used sorting algorithm) is quadratic in the worst case, but randomly ordering the input gives a probabilistic guarantee that its running time is linearithmic. Every time you run the algorithm, it will take a different amount of time, but the chance that the time will not be linearithmic is so small as to be negligible. Similarly, the hashing algorithms for symbol tables that we study in Section 3.4 (again, perhaps the most widely used approach) are linear-time in the worst case, but constant-time under a probabilistic guarantee. These guarantees are not absolute, but the chance that they are invalid is less than the chance your computer will be struck by lightning. Thus, such guarantees are as useful in practice as worst-case guarantees.
Sequences of operations For many applications, the algorithm “input” might be not just data, but the sequence of operations performed by the client. For example, a pushdown stack where the client pushes N values, then pops them all, may have quite different performance characteristics from one where the client issues an alternating sequence N of push and pop operations. Our analysis has to take both situations into account (or to include a reasonable model of the sequence of operations).
Amortized analysis Accordingly, another way to provide a performance guarantee is to amortize the cost, by keeping track of the total cost of all operations, divided by the number of operations. In this setting, we can allow some expensive operations, while keeping the average cost of operations low. The prototypical example of this type of analysis is the study of the resizing array data structure for Stack that we considered in Section1.3(Algorithm1.1 onpage141).Forsimplicity,supposethatNisapowerof2. Starting with an empty structure, how many array entries are accessed for N consecu- tive calls to push()? This quantity is easy to calculate: the number of array accesses is
www.it-ebooks.info

256 The  rst term accounts for the array access
within each of the N calls to push(); the sub-
sequent terms account for the array accesses to
initialize the data structure each time it doubles
in size. Thus the average number of array access-
es per operation is constant, even though the last
operation takes linear time. This is known as an
“amortized” analysis because we spread the cost
of the few expensive operations, by assigning a
portion of it to each of a large number of inexpensive operations. Amortized analysis provides a worst case guarantee on any sequence of operations, starting from an empty data structure. VisualAccumulator illustrates the process, shown above.
N + 4 + 8 + 16 + ... + 2N = 5N  4
1.4 n
Analysis of Algorithms 199
  one gray dot for each operation
128
  64
  red dots give cumulative average
5
    0
                                                               This kind of analysis is widely applicable. In particular, we use resizing arrays as the underlying data structure for several algorithms that we consider later in this book.
It is the task of the algorithm analyst to discover as much relevant information about an algorithm as possible, and it is the task of the applications programmer to apply that knowledge to develop programs that effectively solve the problems at hand. Ideally, we want algorithms that lead to clear and compact code that provides both a good guarantee and good performance on input values of interest. Many of the classic algorithms that we consider in this chapter are important for a broad variety of ap- plications precisely because they have these properties. Using them as models, you can develop good solutions yourself for typical problems that you face while programming.
www.it-ebooks.info
0
number of add() operations 128 Amortized cost of adding to a RandomBag
 proposition E. In the resizing array implementation of Stack (Algorithm 1.1), the average number of array accesses for any sequence of push and pop operations starting from an empty data structure is constant in the worst case.
proofsketch: Foreachpushoperationthatcausesthearraytogrow(sayfromsize N to size 2N), consider the N/2  1 push operations that most recently caused the stack size to grow to k, for k from N/2 + 2 to N. Averaging the 4N array accesses to grow the array to size 2N (2N array accesses to copy the N items and 2N array accesses to initialize an array) with N/2  1 array accesses (one for each push), we get an average cost of 9 array accesses for each of these N/2  1 push operations. Establishing this proposition for any sequence of push and pop operations is more intricate (see Exercise 1.4.32)
 cost (array references)
200
Chapter 1 n Fundamentals
Memory As with running time, a program’s memory usage connects directly to the physical world: a substantial amount of your computer’s circuitry enables your pro- gram to store values and later retrieve them. The more values you need to have stored at any given instant, the more circuitry you need. You probably are aware of limits on memory usage on your computer (even more so than for time) because you probably have paid extra money to get more memory.
Memory usage is well-de ned for Java on your computer (every value requires pre- cisely the same amount of memory each time that you run your program), but Java is implemented on a very wide range of computational devices, and memory consump- tion is implementation-dependent. For economy, we use the word typical to signal that values are subject to machine dependencies.
 type bytes
boolean 1 byte 1 char 2
int 4 float 4 long 8 double 8
typical memory requirements for primitive types
One of Java’s most signi cant features is its memory allocation system, which is supposed to relieve you from having to worry about memory. Certainly, you are well-advised to take advantage of this feature when ap- propriate. Still, it is your responsibility to know, at least approximately, when a program’s memory requirements will prevent you from solving a given problem.
Analyzing memory usage is much easier than analyzing running time, primarily because not as many program statements are involved (just dec- larations) and because the analysis reduces complex objects to the primi- tive types, whose memory usage is well-de ned and simple to understand: we can count up the number of variables and weight them by the number of bytes according to their type. For example, since the Java int data type is the set of integer values between2,147,483,648 and 2,147,483,647, a grand total of 232 different values, typical Java implementations use 32 bits
 to represent int values. Similar considerations hold for other primitive types: typical Java implementations use 8-bit bytes, representing each char value with 2 bytes (16 bits), each int value with 4 bytes (32 bits), each double and each long value with 8 bytes (64 bits), and each boolean value with 1 byte (since computers typically access memory one byte at a time). Combined with knowledge of the amount of memory available, you can calculate limitations from these values. For example, if you have 1GB of memory on your computer (1 billion or 230 bytes), you cannot  t more than about 256 million int values or 128 million double values in memory at any one time.
On the other hand, analyzing memory usage is subject to various differences in ma- chine hardware and in Java implementations, so you should consider the speci c ex- amples that we give as indicative of how you might go about determining memory usage when warranted, not the  nal word for your computer. For example, many data structures involve representation of machine addresses, and the amount of memory
www.it-ebooks.info

needed for a machine address varies from machine to machine. For consistency, we assume that 8 bytes are needed to represent addresses, as is typical for 64-bit architectures that are now widely used, recognizing that many older machines use a 32-bit architecture that would involve just 4 bytes per machine address.
Objects To determine the memory usage of an object, we add the amount of memory used by each instance variable to the overhead associated with each object, typically 16 bytes. The overhead includes a reference to the object’s class, garbage collection information, and synchronization information. Moreover, the memory usage is typically padded to be a multiple of 8 bytes (machine words, on a 64-bit machine). For example, an Integer object uses 24 bytes (16 bytes of overhead, 4 bytes for its int instance variable, and 4 bytes of padding). Similarly, a Date (page 91) object also uses 32 bytes: 16 bytes of overhead, 4 bytes for each of its three int instance variables, and 4 bytes of padding. A ref- erence to an object typically is a memory address and thus uses 8 bytes of memory. For example, a Counter (page 89) object uses 32 bytes: 16 bytes of overhead, 8 bytes for its String instance variable (a reference), 4 bytes for its int instance variable, and 4 bytes of pad- ding. When we account for the memory for a reference, we account separately for the memory for the object itself, so this total does not count the memory for the String value.
Linked lists A nested non-static (inner) class such
as our Node class (page 142) requires an extra 8 bytes of
overhead (for a reference to the enclosing instance). Thus, a Node object uses 40 bytes (16 bytes of object overhead, 8 bytes each for the references to the Item and Node ob- jects, and 8 bytes for the extra overhead). Thus, since an Integer object uses 24 bytes, a stack with N integers built with a linked-list representation (Algorithm 1.2) uses 32 + 64N bytes, the usual 16 for object overhead for Stack, 8 for its reference instance vari- able, 4 for its int instance variable, 4 for padding, and 64 for each entry, 40 for a Node and 24 for an Integer.
1.4 n Analysis of Algorithms 201
 integer wrapper object
public class Integer
{
private int x;
... }
date object
public class Date
{
private int day; private int month; private int year;
... }
counter object
public class Counter
{ private String name; ...private int count;
}
node object (inner class)
private class Node
{
Item item;
Node next; ...
}
24 bytes
32 bytes
32 bytes
40 bytes
int
value
int
values
String
reference
int
value
  object overhead
  x
padding
    object overhead
 day
  month year
    padding
  object overhead
  name count
    padding
  object overhead
 extra overhead
 item
 next
 www.it-ebooks.info
references
 Typical object memory requirements

202 Chapter 1 n Fundamentals
Arrays Typical memory requirements for various types of arrays in Java are summa- rized in the diagrams on the facing page. Arrays in Java are implemented as objects, typically with extra overhead for the length. An array of primitive-type values typically requires 24 bytes of header information (16 bytes of object overhead, 4 bytes for the length, and 4 bytes of padding) plus the memory needed to store the values. For ex- ample, an array of N int values uses 24  4N bytes (rounded up to be a multiple of 8), and an array of N double values uses 24  8N bytes. An array of objects is an array of references to the objects, so we need to add the space for the references to the space required for the objects. For example, an array of N Date objects (page 91) uses 24 bytes (array overhead) plus 8N bytes (references) plus 32 bytes for each object, for a grand total of 24 + 40N bytes. A two-dimensional array is an array of arrays (each array is an object). For example, a two-dimensional M-by-N array of double values uses 24 bytes (overhead for the array of arrays) plus 8 M bytes (references to the row arrays) plus M times 24 bytes (overhead from the row arrays) plus M times N times 8 bytes (for the N double values in each of the M rows) for a grand total of 8NM  32M  24 ~ 8NM bytes. When array entries are objects, a similar accounting leads to a total of 8NM  32M  24 ~ 8NM bytes for the array of arrays  lled with references to objects, plus the memory for the objects themselves.
String objects (Java 7 and later) The standard String representation (used in typi- cal Java 7 implementitons) has two instance variables: a reference to a character array value[] that stores the sequence of characters and an int value hash (that stores a hash code that saves recomputation in certain circumstances that need not concern us now). Therefore, a String of length N typically uses 40 bytes for the String object (16 bytes for object overhead plus 8 bytes for the array reference plus 4 bytes for the int instance variables plus 4 bytes of padding) plus 24  2N bytes for the character array for a total of 56 + 2N bytes.
String objects (Java 6 and earlier) An alternate String representation (used in typical Java 6 implementations) maintains two extra int instance variables (offset and count) and represents the sequence of characters value[offset] through value[offset + count - 1]. Now, a String of length N typically uses 40 bytes (for the String object) plus 24  2N bytes (for the character array) for a total of 64 + 2N bytes. This representation saves memory when extracting substrings because two String ob- jects can share the same underlying character array.
Substring extraction When using the Java 7 representation to implement the substring() method, we must create a new character array, so substring extraction takes linear time and linear space (in the length of the resulting substring). When
 www.it-ebooks.info

1.4 n int[] a = new int[N]; double[] c = new double[N];
Analysis of Algorithms 203
array of int values array of double values ac
   object overhead
 N
padding
             object overhead
 N
  padding
             intvalue (4 bytes)
Total: 24 + 4N (N even)
array of objects
Date[] d;
d = new Date[N];
for (int k = 0; k < N; k++) {
...
a[k] = new Date (...);
d
16 bytes
N int values (4N bytes)
32 bytes
int value (4 bytes)
Total: 24 + 8N
16 bytes
N double values (8N bytes)
24 + 8N bytes
16 bytes
                    object overhead
   N
padding
                   array of arrays (two-dimensional array)
double[][] t;
t = new double[M][N];
t
16 bytes
int value
(4 bytes)
M references (8M bytes)
4 bytes
N double values (8N bytes)
        object overhead
   M
padding
               }
    object overhead
 N
 padding
       object overhead
   length
padding
               16 bytes
int value
(4 bytes)
N references (8N bytes)
                     Total: 24 + 8N + N 32 = 24 + 40N
summary
int[] ~4N double[] ~8N
. .
. .
    object overhead
  day
 month
 year
 padding
    object overhead
 N
 padding
   type bytes
  Date[] ~40N double[][] ~8NM
Total: 24 + 8M + M (24 + 8N ) = 24 + 32M + 8MN
Typical memory requirements for arrays of int values, double values, objects, and arrays
www.it-ebooks.info

204 Chapter 1 n String object (Java 7 library)
public class String
Fundamentals
32 bytes + char array
reference
int
value
40 bytes + char array
reference
int
values
using the Java 6 representation, we can implement the substring() method without having to make copies of the string’s characters: the character array contain- ing the original string is aliased in the object for the substring; the offset and count  elds identify the sub- string. Thus, a substring of an existing string takes just 40 bytes. In summary, extracting a substring takes either constant extra memory or linear extra memory depend- ing on the underlying implementation. We will assume the Java 7 representation in this book.
These basic mechanisms are effective for esti- mating the memory usage of a great many programs, but there are numerous complicating factors that can make the task signi cantly more dif cult. We have already noted the potential effect of aliasing. More- over, memory consumption is a complicated dynamic process when function calls are involved because the system memory allocation mechanism plays a more important role, with more system dependencies. For example, when your program calls a method, the sys- tem allocates the memory needed for the method (for its local variables) from a special area of memory called the stack (a system pushdown stack), and when the method returns to the caller, the memory is returned to the stack. For this reason, creating arrays or other large objects in recursive programs is dangerous, since each recursive call implies signi cant memory usage. When you create an object with new, the system allocates the memory needed for the object from another special area of memory known as the heap (not the same as the binary heap data structure we consider in Sec- tion 2.4), and you must remember that every object lives until no references to it remain, at which point a system process known as garbage collection reclaims its memory for the heap. Such dynamics can make the task of precisely estimating memory usage of a pro- gram challenging.
  object overhead
  value
   hash
 padding
{
private int hash; ...
}
String object (Java 6 library)
public class String
{
private char[] value; private int offset; private int count;
...private int hash; }
substring example (Java 6 aliasing)
private char[] value;
    object overhead
  value
   offset count
   hash
 padding
     String genome = "CGCCTGGCGTCTGTAC"; String codon = genome.substring(6, 9);
genome
codon
40 bytes
  object overhead
  value
    0
object overhead
 16
  hash
padding
16
  padding
 C
G
  C
  object overhead
 value
 6
 3
 hash
 padding
T
G
G
C
G
C
G
C
T
T
T
. char . values
56 bytes
   40 bytes
A String and a substring
A
C
www.it-ebooks.info

www.it-ebooks.info
1.4 n Analysis of Algorithms 205
Perspective Good performance is important. An impossibly slow program is al- most as useless as an incorrect one, so it is certainly worthwhile to pay attention to the cost at the outset, to have some idea of which kinds of problems you might feasibly address. In particular, it is always wise to have some idea of which code constitutes the inner loop of your programs.
Perhaps the most common mistake made in programming is to pay too much at- tention to performance characteristics. Your  rst priority is to make your code clear and correct. Modifying a program for the sole purpose of speeding it up is best left for experts. Indeed, doing so is often counterproductive, as it tends to create code that is complicated and dif cult to understand. C. A. R. Hoare (the inventor of quicksort and a leading proponent of writing clear and correct code) once summarized this idea by saying that “premature optimization is the root of all evil,” to which Knuth added the quali er “(or at least most of it) in programming.” Beyond that, improving the running time is not worthwhile if the available cost bene ts are insigni cant. For example, im- proving the running time of a program by a factor of 10 is inconsequential if the run- ning time is only an instant. Even when a program takes a few minutes to run, the total time required to implement and debug an improved algorithm might be substantially more than the time required simply to run a slightly slower one—you may as well let the computer do the work. Worse, you might spend a considerable amount of time and effort implementing ideas that should in theory improve a program but do not do so in practice.
Perhaps the second most common mistake made in programming is to ignore per- formance characteristics. Faster algorithms are often more complicated than brute- force ones, so you might be tempted to accept a slower algorithm to avoid having to deal with more complicated code. However, you can sometimes reap huge savings with just a few lines of good code. Users of a surprising number of computer systems lose substantial time unknowingly waiting for brute-force quadratic algorithms to  nish solving a problem, when linear or linearithmic algorithms are available that could solve the problem in a fraction of the time. When we are dealing with huge problem sizes, we often have no choice but to seek better algorithms.
We generally take as implicit the methodology described in this section to estimate memory usage and to develop an order-of-growth hypothesis of the running time from a tilde approximation resulting from a mathematical analysis within a cost model, and to check those hypotheses with experiments. Improving a program to make it more clear, ef cient, and elegant should be your goal every time that you work on it. If you pay attention to the cost all the way through the development of a program, you will reap the bene ts every time you use it.

206 Chapter 1 n Fundamentals
   Q. Why not use StdRandom to generate random values instead of maintaining the  le 1Mints.txt ?
A. Itiseasiertodebugcodeindevelopmentandtoreproduceexperiments.StdRandom produces different values each time it is called, so running a program after  xing a bug may not test the  x! You could use StdRandom.setSeed() to address this problem, but a reference  le such as 1Mints.txt makes it easier to add test cases while debugging. Also, different programmers can compare performance on different systems, without worrying about the input model. Once you have debugged a program and have a good idea of how it performs, it is certainly worthwhile to test it on random data. For ex- ample, DoublingTest and DoublingRatio take this approach.
Q. I ran DoublingRatio on my computer, but the results were not as consistent as in the book. Some of the ratios were not close to 8. Why?
A. That is why we discussed “caveats” opnage 195. Most likely, your computer’s operating system decided to do something else during the experiment. One way to mitigate such problems is to invest more time in more experiments. For example, you could change DoublingTest to run the experiments 1,000 times for each N, giving a much more ac- curate estimate for the running time for each size (see Exercise 1.4.39).
Q. What, exactly, does “as N grows” mean in the de nition of the tilde notation? A. The formal de nition of f(N) ~ g(N) is limN→∞ f (N )/g (N ) = 1.
Q. I’ve seen other notations for describing order of growth. What’s the story?
A. The “big-Oh” notation is widely used: we say that f (N ) is O(g (N )) if there exist constantscandN0 suchthat|f(N)|≤c|g(N)|forallN>N0.Thisnotationisveryuse- ful in providing asymptotic upper bounds on the performance of algorithms, which is important in the theory of algorithms. But it is not useful for predicting performance or for comparing algorithms.
Q. Why not?
A. The primary reason is that it describes only an upper bound on the running time. Actual performance might be much better. The running time of an algorithm might be both O(N2) and ~ a N log N. As a result, it cannot be used to justify tests like our doubling ratio test (see Proposition C on page 193).
www.it-ebooks.info
 Q&A
  Q. So why is the big-Oh notation so widely used?
A. It facilitates development of bounds on the order of growth, even for complicated algorithms for which more precise analysis might not be feasible. Moreover, it is com- patible with the “big-Omega” and “big-Theta” notations that theoretical computer sci- entists use to classify algorithms by bounding their worst-case performance. We say that f(N) is (g(N)) if there exist constants c and N0 such that |f(N)| ≥ c |g(N)|for N>N0;andif f(N)isO(g(N))and(g(N)),wesaythat f(N)is(g(N)).The“big- Omega” notation is typically used to describe a lower bound on the worst case, and the “big-Theta” notation is typically used to describe the performance of algorithms that are optimal in the sense that no algorithm can have better asymptotic worst-case order of growth. Optimal algorithms are certainly worth considering in practical applica- tions, but there are many other considerations, as you will see.
Q. Aren’t upper bounds on asymptotic performance important?
A. Yes, but we prefer to discuss precise results in terms of frequency of statement ex- ceution with respect to cost models, because they provide more information about algorithm performance and because deriving such results is feasible for the algorithms that we discuss. For example, we say “ThreeSum uses ~N 3/2 array accesses” and “the number of times cnt++ is executed in ThreeSum is ~N 3/6 in the worst case,” which is a bit more verbose but much more informative than the statement “the running time of ThreeSum is O (N 3).”
Q. WhentheorderofgrowthoftherunningtimeofanalgorithmisNlogN,thedou- bling test will lead to the hypothesis that the running time is ~ a N for a constant a. Isn’t that a problem?
A. We have to be careful not to try to infer that the experimental data implies a par- ticular mathematical model, but when we are just predicting performance, this is not really a problem. For example, when N is between 16,000 and 32,000, the plots of 14N and N lg N are very close to one another. The data  ts both curves. As N increases, the curves become closer together. It actually requires some care to experimentally check the hypothesis that an algorithm’s running time is linearithmic but not linear.
Q. Does int[] a = new int[N] count as N array accesses (to initialize entries to 0)?
A. Most likely yes, so we make that assumption in this book, though a sophisticated compiler implementation might try to avoid this cost for huge sparse arrays.
 1.4 n Analysis of Algorithms 207
 www.it-ebooks.info
208 Chapter 1 n Fundamentals
   1.4.1 ShowthatthenumberofdifferenttriplesthatcanbechosenfromNitemsispre- cisely N (N1)(N2)/6. Hint : Use mathematical induction or a counting argument.
1.4.2 Modify ThreeSum to work properly even when the int values are so large that adding two of them might cause over ow.
1.4.3 Modify DoublingTest to use StdDraw to produce plots like the standard and log-log plots in the text, rescaling as necessary so that the plot always  lls a substantial portion of the window.
1.4.4 Develop a table like the one on page 181 for TwoSum. 1.4.5 Give tilde approximations for the following quantities:
a. b. c. d. e. f. g.
N1
11/N
(1  1/N ) (1  2/N ) 2N315N2N lg(2N) / lg N
lg(N 2 + 1) / lg N N100/2N
1.4.6 Givetheorderofgrowth(asafunctionofN)oftherunningtimesofeachofthe following code fragments:
a. int sum = 0;
for (int n = N; n > 0; n /= 2)
          for(int i = 0; i < n; i++)
             sum++;
b. int sum = 0;
for (int i = 1; i < N; i *= 2)
            for (int j = 0; j < i; j++)
                sum++;
www.it-ebooks.info
 ExErcisEs
1.4 n Analysis of Algorithms 209
   c. int sum = 0;
for (int i = 1; i < N; i *= 2)
           for (int j = 0; j < N; j++)
               sum++;
1.4.7 Analyze ThreeSum under a cost model that counts arithmetic operations (and comparisons) involving the input numbers.
1.4.8 Write a program to determine the number pairs of values in an input  le that are equal. If your  rst try is quadratic, think again and use Arrays.sort() to develop a linearithmic solution.
1.4.9 GiveaformulatopredicttherunningtimeofaprogramforaproblemofsizeN when doubling experiments have shown that the doubling factor is 2b and the running time for problems of size N0 is T.
1.4.10 Modify binary search so that it always returns the element with the smallest index that matches the search element (and still guarantees logarithmic running time).
1.4.11 AddaninstancemethodhowMany()toStaticSETofInts (page99)that ndsthe number of occurrences of a given key in time proportional to log N in the worst case.
1.4.12 Write a program that, given two sorted arrays of N int values, prints all ele- ments that appear in both arrays, in sorted order. The running time of your program should be proportional to N in the worst case.
1.4.13 Usingtheassumptionsdevelopedinthetext,givetheamountofmemoryneed- ed to represent an object of each of the following types:
a.
b.
c.
d.
e.
f. Interval2D g. Double
Accumulator
Transaction
FixedCapacityStackOfStrings with capacity C and N entries Point2D
Interval1D
www.it-ebooks.info

210 Chapter 1 n Fundamentals
   1.4.14 4-sum. Develop an algorithm for the 4-sum problem.
1.4.15 Faster 3-sum. As a warmup, develop an implementation TwoSumFaster that
uses a linear algorithm to count the pairs that sum to zero after the array is sorted (in- stead of the binary-search-based linearithmic algorithm). Then apply a similar idea to develop a quadratic algorithm for the 3-sum problem.
1.4.16 Closest pair (in one dimension). Write a program that, given an array a[] of N double values,  nds a closest pair : two values whose difference is no greater than the the difference of any other pair (in absolute value). The running time of your program should be linearithmic in the worst case.
1.4.17 Farthest pair (in one dimension). Write a program that, given an array a[] of N double values,  nds a farthest pair : two values whose difference is no smaller than the the difference of any other pair (in absolute value). The running time of your program should be linear in the worst case.
1.4.18 Local minimum of an array. Write a program that, given an array a[] of N distinct integers,  nds a local minimum: an entry a[i] that is strictly less than its neigh- bors. Each internal entry (other than a[0] and a[N-1]) has 2 neighbors. Your program should use ~2 lg N compares in the worst case.
1.4.19 Local minimum of a matrix. Given an N-by-N array a[] of N 2 distinct integers, design an algorithm that  nds a local minimum: an entry a[i][j] that is strictly less than its neighbors. Internal entries have 4 neighbors; entries on an edge have 3 neigh- bors; entries on a corner have 2 neighbors. The running time of your program should be proportional to N in the worst case, which means that you cannot afford to examine all N 2 entries.
1.4.20 Bitonic search. An array is bitonic if it is comprised of an increasing sequence of integers followed immediately by a decreasing sequence of integers. Write a program that, given a bitonic array of N distinct int values, determines whether a given integer is in the array. Your program should use ~3 lg N compares in the worst case. Extra credit: use only ~2 lg N compares in the worst case.
1.4.21 Binary search on distinct values. Develop an implementation of binary search for StaticSETofInts (see page 99) where the running time of contains() is guar- anteed to be ~ lg R, where R is the number of different integers in the array given as
www.it-ebooks.info
 crEAtivE problEms
  argument to the constructor.
1.4.22 Binary search with only addition and subtraction. [Mihai Patrascu] Write a program that, given an array of N distinct int values in ascending order, determines whether a given integer is in the array. You may use only additions and subtractions and a constant amount of extra memory. The running time of your program should be proportional to log N in the worst case.
1.4.23 Binary search for a fraction. Devise a method that uses a logarithmic number of compares of the form Is the number less than x? to  nd a rational number p/q such that 0 < p < q < N. Hint : Two different fractions with denominators less than N must differ by at least 1/N 2.
1.4.24 Throwing eggs from a building. Suppose that you have an N-story building and plenty of eggs. Suppose also that an egg is broken if it is thrown off  oor F or higher, and intact otherwise. First, devise a strategy to determine the value of F such that the number of broken eggs is ~lg N when using ~lg N throws, then  nd a way to reduce the cost to ~2 lg F.
1.4.25 Throwing two eggs from a building. Consider the previous question, but now suppose you only have two eggs, and your cost model is the number of throws. Devise a strategy to determine F such that the number of throws is at most 2√N, then  nd a way to reduce the cost to ~c √F for some constant c. This is analogous to a situation where search hits (egg intact) are much cheaper than misses (egg broken).
1.4.26 3-collinearity. Suppose that you have an algorithm that takes as input N dis- tinct points in the plane and can return the number of triples that fall on the same line. Show that you can use this algorithm to solve the 3-sum problem. Strong hint: Use algebra to show that (a, a3), (b, b3), and (c, c3) are collinear if and only if a + b + c = 0.
www.it-ebooks.info
1.4 n Analysis of Algorithms 211

212 Chapter 1 n Fundamentals
   1.4.27 Queue with two stacks. Implement a queue with two stacks so that each queue operation takes a constant amortized number of stack operations. Hint: If you push elements onto a stack and then pop them all, they appear in reverse order. If you repeat this process, they’re now back in order.
1.4.28 Stack with a queue. Implement a stack with a single queue so that each stack operations takes a linear number of queue operations. Hint : To delete an item, get all of the elements on the queue one at a time, and put them at the end, except for the last one which you should delete and return. (This solution is admittedly very inef cient.)
1.4.29 Steque with two stacks. Implement a steque with two stacks so that each steque operation (see Exercise 1.3.32) takes a constant amortized number of stack operations.
1.4.30 Deque with a stack and a steque. Implement a deque with a stack and a steque (see Exercise 1.3.32) so that each deque operation takes a constant amortized number of stack and steque operations.
1.4.31 Deque with three stacks. Implement a deque with three stacks so that each deque operation takes a constant amortized number of stack operations.
1.4.32 Amortized analysis. Prove that, starting from an empty stack, the number of ar- ray accesses used by any sequence of M operations in the resizing array implementation of Stack is proportional to M.
1.4.33 Memory requirements on a 32-bit machine. Give the memory requirements for Integer, Date, Counter, int[], double[], double[][], String, Node, and Stack (linked-list representation) for a 32-bit machine. Assume that references are 4 bytes, object overhead is 8 bytes, and padding is to a multiple of 4 bytes.
1.4.34 Hot or cold. Your goal is to guess a secret integer between 1 and N. You repeat- edly guess integers between 1 and N. After each guess you learn if your guess equals the secret integer (and the game stops). Otherwise, you learn if the guess is hotter (closer to) or colder (farther from) the secret number than your previous guess. Design an algo- rithm that  nds the secret number in at most ~2 lg N guesses. Then design an algorithm that  nds the secret number in at most ~ 1 lg N guesses.
www.it-ebooks.info
 crEAtivE problEms (continued)
  1.4.35 Time costs for pushdown stacks. Justify the entries in the table below, which shows typical time costs for various pushdown stack implementations, using a cost model that counts both data references (references to data pushed onto the stack, either an array reference or a reference to an object’s instance variable) and objects created. As- sume that the Integer objects are not cached (so they must be created for each push).
data structure
linked list resizing array
item type
cost to push N int values
data references objects created
 data structure
linked list
resizing array
item type space usage for N int values (bytes)
int ~32N
int 2N N
Integer 3N 2N
int ~5 N lg N Integer ~5 N ~N
time costs for pushdown stacks (various implementations)
1.4.36 Space usage for pushdown stacks. Justify the entries in the table below, which shows typical space usage for various pushdown stack implementations. Use a static nested class for linked-list nodes to avoid the non-static nested class overhead. Assume that the Integer objects are not cached (so they must be created for each push).
 Integer int
~ 56 N between
~4 N and ~16 N between
Integer
~32 N and ~56 N Space usage in pushdown stacks (various implementations)
 1.4 n Analysis of Algorithms 213
 www.it-ebooks.info
214 Chapter 1 n Fundamentals
   1.4.37 Autoboxing performance penalty. Run experiments to determine the perfor- mance penalty on your machine for using autoboxing and auto-unboxing. Develop an implementation FixedCapacityStackOfInts and use a client such as DoublingRatio to compare its performance with the generic FixedCapacityStack<Integer>, for a large number of push() and pop() operations.
1.4.38 Naive 3-sum implementation. Run experiments to evaluate the following im- plementation of the inner loop of ThreeSum:
     for (int i = 0; i < N; i++)
         for (int j = 0; j < N; j++)
            for (int k = 0; k < N; k++)
               if (i < j && j < k)
                  if (a[i] + a[j] + a[k] == 0)
                     cnt++;
Do so by developing a version of DoublingTest that computes the ratio of the running times of this program and ThreeSum.
1.4.39 Improved accuracy for doubling test. Modify DoublingRatio to take a second command-line argument that speci es the number of calls to make to timeTrial() for each value of N. Run your program for 10, 100, and 1,000 trials and comment on the precision of the results.
1.4.40 3-sum for random values. Formulate and validate a hypothesis describing the number of triples of N random int values that sum to 0. If you are skilled in math- ematical analysis, develop an appropriate mathematical model for this problem, where the values are uniformly distributed between –M and M, where M is not small.
1.4.41 Running times. Estimate the amount of time it would take to run TwoSumFast, TwoSum, ThreeSumFast and ThreeSum on your computer to solve the problems for a  le of 1 million numbers. Use DoublingRatio to do so.
1.4.42 Problem sizes. Estimate the size of the largest value of P for which you can run TwoSumFast, TwoSum, ThreeSumFast, and ThreeSum on your computer to solve the problems for a  le of 2P thousand numbers. Use DoublingRatio to do so.
1.4.43 Resizing arrays versus linked lists. Run experiments to validate the hypothesis that resizing arrays are faster than linked lists for stacks (see Exercise 1.4.35 and Exer- cise 1.4.36). Do so by developing a version of DoublingRatio that computes the ratio
www.it-ebooks.info
 ExpErimENts
  of the running times of the two programs.
1.4.44 Birthday problem. Write a program that takes an integer N from the command line and uses StdRandom.uniform() to generate a random sequence of integers be- tween 0 and N – 1. Run experiments to validate the hypothesis that the number of integers generated before the  rst repeated value is found is ~√N/2.
1.4.45 Coupon collector problem. Generating random integers as in the previous exer- cise, run experiments to validate the hypothesis that the number of integers generated before all possible values are generated is ~N HN.
  1.4 n Analysis of Algorithms 215
 www.it-ebooks.info
   216
To illustrate our basic approach to developing and analyzing algorithms, we now consider a detailed example. Our purpose is to emphasize the following themes.
n Good algorithms can make the difference between being able to solve a practical problem and not being able to address it at all.
n An ef cient algorithm can be as simple to code as an inef cient one.
n Understanding the performance characteristics of an implementation can be an
interesting and satisfying intellectual challenge.
n The scienti c method is an important tool in helping us choose among different
methods for solving the same problem.
n An iterative re nement process can lead to increasingly ef cient algorithms.
These themes are reinforced throughout the book. This prototypical example sets the stage for our use of the same general methodology for many other problems.
The problem that we consider is not a toy problem; it is a fundamental compu- tational task, and the solution that we develop is of use in a variety of applications, from percolation in physical chemistry to connectivity in communications networks. We start with a simple solution, then seek to understand that solution’s performance characteristics, which help us to see how to improve the algorithm.
Dynamic connectivity We start with the following problem speci cation: The input is a sequence of pairs of integers, where each integer represents an object of some type and we are to interpret the pair p q as meaning “p is connected to q.” We assume that “is connected to” is an equivalence relation, which means that it is
n Re exive : p is connected to p.
n Symmetric : If p is connected to q, then q is connected to p.
n Transitive : If p is connected to q and q is connected to r, then p is connected to r.
An equivalence relation partitions the objects into equivalence classes. In this case, two objects are in the same equivalence class if and only if they are connected. Our goal is to write a program to  lter out extraneous pairs (pairs where both objects are in the same equivalence class) from the sequence. In other words, when the program reads a pair p q from the input, it should write the pair to the output only if the pairs it has seen to that point do not imply that p is connected to q. If the previous pairs do imply that p is connected to q, then the program should ignore the pair p q and proceed to read in the next pair. The  gure on the facing page gives an example of this process. To achieve the desired goal, we need to devise a data structure that can remember suf cient
www.it-ebooks.info
 1.5 CASe StUDy: Union-FinD

 information about the pairs it has seen to be able to decide whether or not a new pair of objects is connected. Informally, we refer to the task of designing such a method as the dynamic connectivity problem. This problem arises applications such as the following:
Networks The integers might represent computers in a large network, and the pairs might represent connections in the network. Then, our program determines whether we need to establish a new direct connection for p and q to be able
to communicate or whether we can use existing connections to
1.5 n Case Study: Union-Find
217
       set up a communications path. Or, the integers might represent contact sites in an electrical circuit, and the pairs might represent wires connecting the sites. Or, the integers might represent people in a social network, and the pairs might represent friendships. In such applications, we might need to process millions of objects and billions of connections.
Variable-name equivalence In certain programming environ- ments, it is possible to declare two variable names as being equiv- alent (references to the same object). After a sequence of such dec- larations, the system needs to be able to determine whether two given names are equivalent. This application is an early one (for the FORTRAN programming language) that motivated the devel- opment of the algorithms that we are about to consider.
Mathematical sets On a more abstract level, you can think of the integers as belonging to mathematical sets. When we process a pairp q,weareaskingwhethertheybelongtothesameset.Ifnot, we unite p’s set and q’s set, putting them in the same set.
01234 56789
            43
38
65
94
21
89
                                                                            50
72
61
10
67
2 components
don’t print pairs that are already connected
                                                                 To fix ideas, we will use networking terminology for the rest of this section and refer to the objects as sites, the pairs as connec- tions, and the equivalence classes as connected components, or just components for short. For simplicity, we assume that we have N sites with integer names, from 0 to N-1. We do so without loss of generality because we shall be considering a host of algorithms in Chapter 3 that can associate arbitrary names with such integer identi ers in an ef cient manner.
Dynamic connectivity example
                 A larger example that gives some indication of the dif culty of the connectivity problem is depicted in the  gure at the top of the next page. You can quickly identify the component consisting of a single site in the left middle of the diagram and the
www.it-ebooks.info

 218
Chapter 1 n Fundamentals
connected component
Medium connectivity example (625 sites, 900 edges, 3 connected components)
component consisting of  ve sites at the bottom left, but you might have dif culty veri- fying that all of the other sites are connected to one another. For a program, the task is even more dif cult, because it has to work just with site names and connections and has no access to the geometric placement of sites in the diagram. How can we tell quickly whether or not any given two sites in such a network are connected?
The  rst task that we face in developing an algorithm is to specify the problem in a precise manner. The more we require of an algorithm, the more time and space we may expect it to need to  nish the job. It is impossible to quantify this relationship a priori, and we often modify a problem speci cation on  nding that it is dif cult or expensive to solve or, in happy circumstances, on  nding that an algorithm can provide informa- tion more useful than what was called for in the original speci cation. For example, our
www.it-ebooks.info
1.5 n Case Study: Union-Find 219
 connectivity problem speci cation requires only that our program be able to determine whetherornotanygivenpairp qisconnected,andnotthatitbeabletodemonstratea set of connections that connect that pair. Such a requirement makes the problem more dif cult and leads us to a different family of algorithms, which we consider in Section 4.1.
To specify the problem, we develop an API that encapsulates the basic operations that we need: initialize, add a connection between two sites, identify the component containing a site, determine whether two sites are in the same component, and count the number of components. Thus, we articulate the following API:
public class UF
  UF(int N)
void union(int p, int q)
int find(int p)
boolean connected(int p, int q)
int count()
initialize N sites with integer names (0 to N-1) add connection between p and q
component identi er for p (0 to N-1)
return true if p and q are in the same component number of components
Union-find apI
 The union() operation merges two components if the two sites are in different com- ponents, the find() operation returns an integer component identi er for a given site, the connected() operation determines whether two sites are in the same component, and the count() method returns the number of components. We start with N compo- nents, and each union() that merges two different components decrements the num- ber of components by 1.
As we shall soon see, the development of an algorithmic solution for dynamic con- nectivity thus reduces to the task of developing an implementation of this API. Every implementation has to
n De ne a data structure to represent the known connections
n Develop ef cient union(), find(), connected(), and count() implementa-
tions that are based on that data structure
As usual, the nature of the data structure has a direct impact on the ef ciency of the algorithms, so data structure and algorithm design go hand in hand. The API already speci es the convention that both sites and components will be identi ed by int val- ues between 0 and N-1, so it makes sense to use a site-indexed array id[] as our basic
www.it-ebooks.info

220 Chapter 1 n Fundamentals
data structure to represent the components. We always use the name of one of the sites in a component as the component identi er, so you can think of each component as being represented by one of its sites. Initially, we start with N components, each site in its own component, so we initialize id[i] to i for all i from 0 to N-1. For each site i, we keep the information needed by find() to determine the component contain- ing i in id[i], using various algorithm-dependent strategies. All of our implementa- tions use a one-line implementation of connected() that returns the boolean value find(p) == find(q).
In summary, our starting point is Algorithm 1.5 on the facing page. We maintain two instance variables, the count of components and the array id[]. Implementations of find() and union() are the topic of the remainder of this section.
To test the utility of the API and to provide a basis for develop- ment, we include a client in main() that uses it to solve the dy- namic connectivity problem. It reads the value of N followed by a sequence of pairs of integers (each in the range 0 to N-1), calling connected() for each pair: If the two sites in the pair are already connected, it moves on to the next pair; if they are not, it calls union() and prints the pair. Before considering implementations, we also prepare test data: the  le tinyUF.txt contains the 11 con- nections among 10 sites used in the small example illustrated on page 217, the  le mediumUF.txt contains the 900 connections among 625 sites illustrated on page 218, and the  le largeUF.txt is an example with 2 million connections among 1 millions sites. Our goal is to be able to handle inputs such as largeUF.txt in a reasonable amount of time.
To analyze the algorithms, we focus on the number of times each algorithm accesses an array entry. By doing so, we are implicitly for- mulating the hypothesis that the running times of the algorithms on a particular machine are
within a constant factor of this quantity. This hypothesis is immediate from the code, is not dif cult to validate through ex- perimentation, and provides a useful starting
point for comparing algorithms, as we will see.
  % more tinyUF.txt 10
43
38
65 94 21 89 50 72 61 10 67
% more mediumUF.txt
625
528 503
548 523
...
[900 connections]
% more largeUF.txt
1000000
786321 134521
696834 98245
...
[2000000 connections]
 www.it-ebooks.info
Union-find cost model. When studying algorithms to imple- ment the union- nd API, we count array accesses (the num- ber of times an array entry is accessed, for read or write).

  aLgorIthM 1.5 Union-find implementation
  public class UF
  {
     private int[] id;     // access to component id (site indexed)
     private int count;    // number of components
     public UF(int N)
     {  // Initialize component id array.
        count = N;
        id = new int[N];
        for (int i = 0; i < N; i++)
id[i] = i; }
     public int count()
     {  return count;  }
     public boolean connected(int p, int q)
     {  return find(p) == find(q);  }
     public int  find(int p)
     public void union(int p, int q)
// See page 222 (quick-find),page 224 (quick-union) andpage 228 (weighted).
     public static void main(String[] args)
     {  // Solve dynamic connectivity problem on StdIn.
          int N = StdIn.readInt();
        UF uf = new UF(N);
        while (!StdIn.isEmpty())
        {
           int p = StdIn.readInt();
           int q = StdIn.readInt();
           if (uf.connected(p, q)) continue;  // Ignore if connected.
           uf.union(p, q);                    // Combine components
           StdOut.println(p + " " + q);       //   and print connection.
}
        StdOut.println(uf.count() + " components");
     }
}
Our UF implementations are based on this code, which maintains an array of integers id[] such that the find() method returns the same integer for every site in each connected component. The union() method must maintain this invariant.
www.it-ebooks.info
1.5 n Case Study: Union-Find 221
% java UF < tinyUF.txt 43
38
65
94
21
50
72
61
2 components
// Read number of sites.
// Initialize N components.
// Read pair to connect.

222 Chapter 1 n Fundamentals
Implementations We shall consider three different implementations, all based on using the site-indexed id[] array, to determine whether two sites are in the same con- nected component.
Quick- nd One approach is to maintain the invariant that p and q are connected if and only if id[p] is equal to id[q]. In other words, all sites in a component must have the same value in id[]. This method is called quick- nd because find(p) just returns id[p], which immediately implies that connected(p, q) reduces to just the test id[p] == id[q] and returns true if and only
if p and q are in the same component. To maintain theinvariantforthecallunion(p, q),we rstcheck
whether they are already in the same component, in
which case there is nothing to do. Otherwise, we are
faced with the situation that all of the id[] entries
corresponding to sites in the same component as p
have one value and all of the id[] entries correspond-
ing to sites in the same component as q have another
value. To combine the two components into one, we
have to make all of the id[] entries corresponding
to both sets of sites the same value, as shown in the
example at right. To do so, we go through the array, changing all the entries with values equal to id[p] to the value id[q]. We could have decided to change all the entries equal to id[q] to the value id[p]—the choice between these two alternatives is arbitrary. The
code for find() and union() based on these descriptions, given at left, is straightforward. A full trace for our development client with our sample test data tinyUF.txt is shown on the next page.
find examines id[5] and id[9]
pq 0123456789 59 11188 1 118 8
 union has to change all 1s to 8s
pq 59
0123456789 11188 1 118 8
 888 88 888 88 Quick- nd overview
   public int find(int p)
  {  return id[p];  }
  public void union(int p, int q)
  {  // Put p and q into the same component.
     int pID = find(p);
     int qID = find(q);
     // Nothing to do if p and q are already
          in the same component.
     if (pID == qID) return;
     // Change values from id[p] to id[q].
     for (int i = 0; i < id.length; i++)
         if (id[i] == pID) id[i] = qID;
count--; }
Quick-find
 www.it-ebooks.info

1.5 n Case Study: Union-Find 223
Quick- nd analysis The find() operation is certainly quick, as it only accesses the id[] array once in order to complete the operation. But quick- nd is typically not use- ful for large problems because union() needs to scan through the whole id[] array for each input pair.
 proposition F. The quick- nd algorithm uses one array access for each call to find(), two array accesses for each call to connected(), and between N + 3 and 2N + 1 array accesses for each call to union() that combines two components.
proof: Immediatefromthecode.Eachcalltoconnected()teststwoentriesinthe id[] array, one for each of the two calls to find(). Each call to union() that com- bines two components does so by making two calls to find(), testing each of the N entries in the id[] array, and changing between 1 and N  1 of them.
id[]
pq 0 12 3 4 5 43 0 1 2 3 45 0 1 2 3 35 38 01233 5 0 1 2 8 85 65 0 1 2 8 85
678 9
678 9
6 7 8 9 6 78 9 6 7 8 9 678 9
In particular, suppose that we use quick- nd for the dynamic connectivity problem and wind up with a single component. This requires at least N1 calls to union(), and, consequently, at least (N3)(N1) ~ N 2 array accesses—we are led immediately to the hy- pothesis that dynamic connectivity with quick- nd can be a quadratic-time process. This analysis gener- alizes to say that quick- nd is quadratic for typical applications where we end up with a small number of components. You can easily validate this hypothesis on your computer with a doubling test (see Exercise 1.5.23 for an instructive example). Modern comput- ers can execute hundreds of millions or billions of in- structions per second, so this cost is not noticeable if N is small, but we also might  nd ourselves with mil- lions or billions of sites and connections to process in a modern application, as represented by our test  le largeUF.txt. If you are still not convinced and feel that you have a particularly fast computer, try using quick- nd to determine the number of components implied by the pairs in largeUF.txt. The inescap- able conclusion is that we cannot feasibly solve such a problem using the quick- nd algorithm, so we seek better algorithms.
 0 1 2 8 8 55 7 8 9 94 0 1 2 8 85 5 7 8 9 0 1 2 8 8 5 5 7 88 21 0 128855788 0 11 8 8 5 5 7 8 8 89 0 1 1 8 8 5 5 78 8 50 0 1 1 8 85 5 7 8 8 0 1 1 8 80 0 7 8 8 72 0 1 1 8 8 0 07 8 8 0 1 1 8 8 0 01 8 8 61 0 1 1 8 8 00 1 8 8 1 1 1 8 81 1 1 8 8 10 1 118811188 67 1 1 1 8 8 11 1 8 8
id[p] and id[q] differ, so union() changes entries equal
to id[p] to id[q] (in red) id[p] and id[q]
match, so no change
Quick- nd trace
     www.it-ebooks.info

224 Chapter 1 n Fundamentals
Quick-union The next algorithm that we consider is a complementary method that concentrates on speeding up the union() operation. It is based on the same data structure—the site-indexed id[] ar-
ray—but we interpret the values dif-
ferently, to de ne more complicated
structures. Speci cally, the id[] entry
for each site is the name of another
site in the same component (possibly
itself)—we refer to this connection as
a link. To implement find(), we start
at the given site, follow its link to an-
other site, follow that site’s link to yet
another site, and so forth, following
links until reaching a root, a site that
has a link to itself (which is guaran-
teed to happen, as you will see). Two
sites are in the same component if and
only if this process leads them to the
same root. To validate this process, we need union(p,
which is easily arranged: we follow links to  nd the roots associated with p and q, then rename one of the components by linking one of these roots to the other; hence the name quick-union. Again, we have an arbitrary choice of whether to rename the com- ponent containing p or the component containing q; the implementation above re-
names the one containing p. The  gure on the next page shows a trace of the quick-union algo- rithm for tinyUF.txt. This trace is best understood in terms of the graphical representation depict- ed at left, which we consider next.
    public int find(int p)
  {  // Find component name.
     while (p != id[p]) p = id[p];
return p; }
  public void union(int p, int q)
  {  // Give p and q the same root.
     int i = find(p);
     int j = find(q);
     if (i == j) return;
id[i] = j;
count--; }
Quick-union
 q) to maintain this invariant,
 id[] is parent-link representation of a forest of trees
root
find has to follow links to the root
     18 02739 54
6
p q 5 9
0123456789 1 11 8 30 5 18 8
                      find(5) is id[id[id[5]]]
find(9) is id[id[9]]
         8 becomes parent of 1
union changes just one link
8 139
                  0274 5
6
p q 5 9
0123456789 1 11 8 30 5 18 8
 18 1 8 3 0 5 1 8 8 Quick-union overview
     www.it-ebooks.info

Forest-of-trees representation The code for quick-union is compact, but a bit opaque. Representing sites as nodes (labeled circles) and links as arrows from one node to an- other gives a graphical representation of the data structure that makes it relatively easy to understand the operation of the algorithm. The resulting structures are trees—in technical terms, our id[] array
id[]
pq 0 123456789
65 01283 56 789 012835 5 789
94 0 128355789
01 1 8355788
72 01 1 8 3 0 5 78 8 0118305 1 88
61 01 183 05 188 11 1 8 3 0 5 1 8 8
10 11 18305188 67 11 18305188
Quick-union trace (with corresponding forests of trees)
1.5 n Case Study: Union-Find 225
  is a parent-link representation
of a forest (set) of trees. To sim-
plify the diagrams, we often omit
both the arrowheads in the links
(because they all point upwards)
and the self-links in the roots
of the trees. The forests corre-
sponding to the id[] array for
tinyUF.txt are shown at right.
When we start at the node cor-
responding to any site and follow
links, we eventually end up at the
root of the tree containing that
node. We can prove this prop-
erty to be true by induction: It is
true after the array is initialized
to have every node link to itself,
and if it is true before a given
union() operation, it is certainly
true afterward. Thus, the find()
method on page 224 returns the
name of the site at the root (so
that connected() checks wheth-
er two sites are in the same tree).
This representation is useful for
this problem because the nodes
corresponding to two sites are in
the same tree if and only if the
sites are in the same component.
Moreover, the trees are not dif cult to build: the union() implementation on page 224 combines two trees into one in a single statement, by making the root of one the parent of the other.
                           43 012 34 56789 0 1 2 3 35 6 7 8 9 38 012 3 3567 8 9 012 8 356789
                                                                                                      012835578 8 21 0 128355788
                                         89 01183557 88 50 0 1183 5 5788 01183 0 5788
                                                                                          www.it-ebooks.info

226
Chapter 1 n Fundamentals
Quick-union analysis The quick-union algorithm would seem to be faster than the quick- nd algorithm, because it does not have to go through the entire array for each
       pq 01 01 01
id[]
2 3 4 ...
012 3
12 3 0
2 3 1
0
4 ...
4 ... 4 ...
input pair; but how much faster is it? Analyzing the cost of quick-union is more dif cult than it was for quick- nd, because the cost is more dependent on the nature of the input. In the best case, find() just needs one array access to  nd the identi er associ- ated with a site, as in quick- nd; in the worst case, it needs 2N  1 array accesses, as for 0 in the example at left (this count is conservative since compiled code will typically not do an array access for the second reference to id[p] in the while loop). Ac- cordingly, it is not dif cult to construct a best-case input for which the running time of our dynamic connectivity client is linear; on the other hand it is also not dif cult to construct a worst-case input for which the running time is quadratic (see the dia- gram at left and Proposition G below). Fortunate- ly, we do not need to face the problem of analyzing quick union and we will not dwell on comparative performance of quick- nd and quick-union be-
     2 3 4 ... 11 2 3 4 ...
     02 01
2 3 4 ... 12 2 3 4 ...
    03 01
12 3 3 4 ...
3 4 ... 2
1
0
4 ...
2 3 4 ...
       04 01
2 3 4 ... 12 3 4 4 ...
   3 .2
  . .
1 depth4 0
Quick-union worst case
   cause we will next examine another variant that is far more ef cient than either. For the moment, you can regard quick-union as an improvement over quick- nd because it removes quick- nd’s main liability (that union() always takes linear time). This differ- ence certainly represents an improvement for typical data, but quick-union still has the liability that we cannot guarantee it to be substantially faster than quick- nd in every case (for certain input data, quick-union is no faster than quick- nd).
 Definition. The size of a tree is its number of nodes. The depth of a node in a tree is the number of links on the path from it to the root. The height of a tree is the maximum depth among its nodes.
 proposition G. The number of array accesses used by find() in quick-union is 1 plus the twice the depth of the node corresponding to the given site. The number of array accesses used by union() and connected() is the cost of the two find() operations (plus 1 for union() if the given sites are in different trees).
proof: Immediate from the code.
www.it-ebooks.info

www.it-ebooks.info
1.5 n Case Study: Union-Find 227
Again, suppose that we use quick-union for the dynamic connectivity problem and wind up with a single component. An immediate implication of Proposition G is that the running time is quadratic, in the worst case. Suppose that the input pairs come in the order 0-1, then 0-2, then 0-3, and so forth. After N  1 such pairs, we have N sites all in the same set, and the tree that is formed by the quick-union algorithm has height N  1, with 0 linking to 1, which links to 2, which links to 3, and so forth (see the diagram on the facing page). By Proposition G, the number of array accesses for theunion()operationforthepair0 iisexactly2i+3(site0isatdepthiandsiteiat depth 0). Thus, the total number of array accesses for the find() operations for these N pairs is (3 + 5 + 7 + . . . + 2N+ 1 ) ~N 2.
Weighted quick-union Fortunately, there is an
easy modi cation to quick-union that allows us
to guarantee that bad cases such as this one do
not occur. Rather than arbitrarily connecting the
second tree to the  rst for union(), we keep track
of the size of each tree and always connect the
smaller tree to the larger. This change requires
slightly more code and another array to hold the
node counts, as shown on page 228, but it leads
to substantial improvements in ef ciency. We re-
fer to this algorithm as the weighted quick-union
algorithm. The forest of trees constructed by this
algorithm for tinyUF.txt is shown in the  gure
at left on the top of page 229. Even for this small example, the tree height is substan- tially smaller than the height for the unweighted version.
Weighted quick-union analysis The  gure at right on the top of page 229 illustrates the worst case for weighted quick union, when the sizes of the trees to be merged by union() are always equal (and a power
of 2). These tree structures look complex,
but they have the simple property that the height of a tree of 2n nodes is n. Fur- thermore, when we merge two trees of 2n nodes, we get a tree of 2n1 nodes, and we increase the height of the tree to n1. This observation generalizes to provide a proof that the weighted algorithm can guarantee logarithmic performance.
 quick-union
larger tree
weighted
q
smaller tree
might put the larger tree lower
always chooses the better alternative
p q
       p
    p
larger tree
larger tree
p
smaller smaller
tree tree tree
smaller tree
        qq
    Weighted quick-union
larger
 % java WeightedQuickUnionUF < mediumUF.txt
528 503
548 523
...
3 components
% java WeightedQuickUnionUF < largeUF.txt
786321 134521
696834 98245
...
6 components

 228 Chapter 1 n Fundamentals
 aLgorIthM 1.5 (continued) Union-find implementation (weighted quick-union) public class WeightedQuickUnionUF
 {
private int[] id;
private int[] sz;
private int count;
// parent link (site indexed)
// size of component for roots (site indexed)
// number of components
public WeightedQuickUnionUF(int N)
{
   count = N;
   id = new int[N];
   for (int i = 0; i < N; i++) id[i] = i;
   sz = new int[N];
   for (int i = 0; i < N; i++) sz[i] = 1;
}
public int count()
{  return count;  }
public boolean connected(int p, int q)
{  return find(p) == find(q);  }
public int find(int p)
{  // Follow links to find a root.
   while (p != id[p]) p = id[p];
return p; }
public void union(int p, int q)
{
   int i = find(p);
   int j = find(q);
   if (i == j) return;
   // Make smaller root point to larger one.
   if   (sz[i] < sz[j]) { id[i] = j; sz[j] += sz[i]; }
else
count--; }
}
{ id[j] = i; sz[i] += sz[j]; }
 This code is best understood in terms of the forest-of-trees representation described in the text. We add a site-indexed array sz[] as an instance variable so that union() can link the root of the smaller tree to the root of the larger tree. This addition makes it feasible to address large problems.
www.it-ebooks.info
 reference input
pq 43
38
65
94
21
89
50
72
61
10 67
1.5 n worst-case input
pq 01
23 45 67 02
46
04
Weighted quick-union traces (forests of trees)
Case Study: Union-Find 229
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   proposition H. The depth of any node in a forest built by weighted quick-union for N sites is at most lg N.
proof: We prove a stronger fact by (strong) induction: The height of every tree of size k in the forest is at most lg k. The base case follows from the fact that the tree height is 0 when k is 1. By the inductive hypothesis, assume that the tree height of a tree of size i is at most lg i for all i < k. When we combine a tree of size i with a tree of size j with i  j and i  j = k, we increase the depth of each node in the smaller set by 1, but they are now in a tree of size i  j = k, so the property is preserved because 1+lg i = lg(ii)  lg(ij) = lg k.
www.it-ebooks.info

230 Chapter 1 n Fundamentals
quick-union
                                                                                                                                                  weighted
average depth: 5.11
average depth: 1.52
                                                                                    Quick-union and weighted quick-union (100 sites, 88 union() operations)
 corollary. For weighted quick-union with N sites, the worst-case order of growth of the cost of find(), connected(), and union() is log N.
proof. Each operation does at most a constant number of array accesses for each node on the path from a node to a root in the forest.
 For dynamic connectivity, the practical implication of Proposition H and its corollary is that weighted quick-union is the only one of the three algorithms that can feasibly be used for huge practical problems. The weighted quick-union algorithm uses at most c M lg N array accesses to process M connections among N sites for a small constant c. This result is in stark contrast to our  nding that quick- nd always (and quick-union sometimes) uses at least MN array accesses. Thus, with weighted quick-union, we can guarantee that we can solve huge practical dynamic connectivity problems in a reason- able amount of time. For the price of a few extra lines of code, we get a program that can be millions of times faster than the simpler algorithms for the huge dynamic con- nectivity problems that we might encounter in practical applications.
A 100-site example is shown on the top of this page. It is evident from this diagram that relatively few nodes fall far from the root with weighted quick-union. Indeed it is frequently the case that a 1-node tree is merged with a larger tree, which puts the node just one link from the root. Empirical studies on huge problems tell us that weighted quick-union typically solves practical problems in constant time per operation. We could hardly expect to  nd a more ef cient algorithm.
www.it-ebooks.info

1.5 n Case Study: Union-Find 231
 algorithm
order of growth for N sites (worst case)
constructor union find
 quick- nd quick-union
weighted quick-union
weighted quick-union with path compresson
N N1
N tree height tree height
N lg N lg N
N very, very nearly, but not quite 1 (amortized )
(see Exercise 1.5.13) N 11
impossible
performance characteristics of union-find algorithms
Optimal algorithms Can we  nd an algorithm that has guaranteed constant-time- per-operation performance? This question is an extremely dif cult one that plagued researchers for many years. In pursuit of an answer, a number of variations of quick- union and weighted quick-union have been studied. For example, the following meth- od, known as path compression, is easy to implement. Ideally, we would like every node to link directly to the root of its tree, but we do not want to pay the price of changing a large number of links, as we did in the quick- nd algorithm. We can approach the ideal simply by making all the nodes that we do examine directly link to the root. This step seems drastic at  rst blush, but it is easy to implement, and there is nothing sacrosanct about the structure of these trees: if we can modify them to make the algorithm more ef cient, we should do so. To implement path compression, we just add another loop to find() that sets the id[] entry corresponding to each node encountered along the way to link directly to the root. The net result is to  atten the trees almost completely, ap- proximating the ideal achieved by the quick- nd algorithm. The method is simple and effective, but you are not likely to be able to discern any improvement over weighted quick-union in a practical situation (see Exercise 1.5.24). Theoretical results about the situation are extremely complicated and quite remarkable. Weighted quick union with path compression is optimal but not quite constant-time per operation. That is, not only is weighted quick-union with path compression not constant-time per operation in the worst case (amortized), but also there exists no algorithm that can guarantee to perform each union- nd operation in amortized constant time (under the very general “cell probe” model of computation). Weighted quick-union with path compression is very close to the best that we can do for this problem.
www.it-ebooks.info

 232
Chapter 1 n Fundamentals
quick- nd
1300
Amortized cost plots As with any data type implementation, it is worthwhile to run experiments to test the validity of our performance hypotheses for typical clients, as dis- cussion in Section 1.4. The  gure at left shows details of the performance of the algorithms for our dynamic connectivity development client when solving our 625-site connectivity example (mediumUF.txt). Such diagrams are easy to pro- duce (see Exercise 1.5.16): For the i th connec- tion processed, we maintain a variable cost that counts the number of array accesses (to id[] or sz[]) and a variable total that is the sum of the total number of array accesses so far. Then we plot a gray dot at (i, cost) and a red dot at (i, total/i). The red dots are the average cost per operation, or amortized cost. These plots provide good insights into algorithm be- havior. For quick- nd, every union() opera- tion uses at least 625 accesses (plus 1 for each component merged, up to another 625) and every connected() operation uses 2 accesses. Initially, most of the connections lead to a call on union(), so the cumulative average hovers around 625; later, most connections are calls to connected() that cause the call to union() to be skipped, so the cumulative average decreas- es, but still remains relatively high. (Inputs that lead to a large number of connected() calls that cause union() to be skipped will exhibit signi - cantly better performance—see Exercise 1.5.23 for an example). For quick-union, all operations initially require only a few array accesses; eventu- ally, the height of the trees becomes a signi cant factor and the amortized cost grows noticably. For weighted quick-union, the tree height stays small, none of the operations are expensive, and the amortized cost is low. These experiments validate our conclusion that weighted quick-union is certainly worth implementing
and that there is not much further room for improvement for practical problems.
0
0
quick-union
100 0
weighted quick-union
900
20 0
20
8
union() operations use at least 625 references
red dots give cumulative average
connected() operations use exactly 2 array accesses
number of connections
find() operations become expensive
no expensive operations
Cost of all operations (625 sites)
458
one gray dot
for each connection processed by client
number of array accesses
www.it-ebooks.info
www.it-ebooks.info
1.5 n Case Study: Union-Find 233
Perspective Each of the UF implementations that we considered is an improvement over the previous in some intuitive sense, but the process is arti cially smooth because we have the bene t of hindsight in looking over the development of the algorithms as they were studied by researchers over the years. The implementations are simple and the problem is well speci ed, so we can evaluate the various algorithms directly by run- ning empirical studies. Furthermore, we can use these studies to validate mathematical results that quantify the performance of these algorithms. When possible, we follow the same basic steps for fundamental problems throughout the book that we have taken for union– nd algorithms in this section, some of which are highlighted in this list:
n Decide on a complete and speci c problem statement, including identifying fundamental abstract operations that are intrinsic to the problem and an API. n Carefully develop a succinct implementation for a straightforward algorithm,
using a well-thought-out development client and realistic input data.
n Know when an implementation could not possibly be used to solve problems on
the scale contemplated and must be improved or abandoned.
n Develop improved implementations through a process of stepwise re nement,
validating the ef cacy of ideas for improvement through empirical analysis,
mathematical analysis, or both.
n Find high-level abstract representations of data structures or algorithms in op-
eration that enable effective high-level design of improved versions.
n Strive for worst-case performance guarantees when possible, but accept good
performance on typical data when available.
n Know when to leave further improvements for detailed in-depth study to skilled
researchers and move on to the next problem.
The potential for spectacular performance improvements for practical problems such as those that we saw for union– nd makes algorithm design a compelling  eld of study. What other design activities hold the potential to reap savings factors of millions or billions, or more?
Developing an ef cient algorithm is an intellectually satisfying activity that can have direct practical payoff. As the dynamic connectivity problem indicates, a simply stated problem can lead us to study numerous algorithms that are not only both useful and interesting, but also intricate and challenging to understand. We shall encounter many ingenious algorithms that have been developed over the years for a host of practical problems. As the scope of applicability of computational solutions to scienti c and commercial problems widens, so also grows the importance of being able to use ef-  cient algorithms to solve known problems and of being able to develop ef cient solu- tions to new problems.

234 Chapter 1 n Fundamentals
 Q&A
 Q. I’d like to add a delete() method to the API that allows clients to delete connec- tions. Any advice on how to proceed?
A. Noonehasdevisedanalgorithmassimpleandef cientastheonesinthissection that can handle deletions. This theme recurs throughout this book. Several of the data structures that we consider have the property that deleting something is much more dif cult than adding something.
Q. What is the cell-probe model?
A. Amodelofcomputationwhereweonlycountaccessestoarandom-accessmemory
large enough to hold the input and consider all other operations to be free.
www.it-ebooks.info

    public void union(int p, int q)
    {
       if (connected(p, q)) return;
       // Rename p’s component to q’s name.
       for (int i = 0; i < id.length; i++)
           if (id[i] == id[p]) id[i] = id[q];
count--; }
1.5.9 Drawthetreecorrespondingtotheid[]arraydepictedat right. Can this be the result of running weighted quick-union? Explain why this is impossible or give a sequence of operations that results in this array.
i 0123456789
1.5 n Case Study: Union-Find 235
 ExErcisEs
 1.5.1 Show the contents of the id[] array and the number of times the ar- ray is accessed for each input pair when you use quick- nd for the sequence 9-0 3-4 5-8 7-2 2-1 5-7 0-3 4-2.
1.5.2 Do Exercise 1.5.1, but use quick-union (page 224). In addition, draw the forest of trees represented by the id[] array after each input pair is processed.
1.5.3 Do Exercise 1.5.1, but use weighted quick-union (page 228).
1.5.4 Showthecontentsofthesz[]andid[]arraysandthenumberofarrayaccesses for each input pair corresponding to the weighted quick-union examples in the text (both the reference input and the worst-case input).
1.5.5 Estimate the minimum amount of time (in days) that would be required for quick- nd to solve a dynamic connectivity problem with 109 sites and 106 input pairs, on a computer capable of executing 109 instructions per second. Assume that each itera- tion of the inner for loop requires 10 machine instructions.
1.5.6 Repeat Exercise 1.5.5 for weighted quick-union.
1.5.7 Develop classes QuickUnionUF and QuickFindUF that implement quick-union
and quick- nd, respectively.
1.5.8 Giveacounterexamplethatshowswhythisintuitiveimplementationofunion() for quick- nd is not correct:
 www.it-ebooks.info
id[i]
1 1 3 1 5 6 1 3 4 5

236 Chapter 1 n Fundamentals
 ExErcisEs (continued)
1.5.10 Intheweightedquick-unionalgorithm,supposethatwesetid[find(p)]toq instead of to id[find(q)]. Would the resulting algorithm be correct?
Answer : Yes, but it would increase the tree height, so the performance guarantee would be invalid.
1.5.11 Implement weighted quick- nd, where you always change the id[] entries of the smaller component to the identi er of the larger component. How does this change affect performance?
 www.it-ebooks.info

1.5.12 Quick-union with path compression. Modify quick-union (page 224) to in- clude path compression, by adding a loop to find() that links every site on the path from p to the root. Give a sequence of input pairs that causes this method to produce a path of length 4. Note : The amortized cost per operation for this algorithm is known to be logarithmic.
1.5.13 Weighted quick-union with path compression. Modify weighted quick-union (Algorithm 1.5) to implement path compression, as described in Exercise 1.5.12. Give a sequence of input pairs that causes this method to produce a tree of height 4. Note : The amortized cost per operation for this algorithm is known to be bounded by a function known as the inverse Ackermann function and is less than 5 for any conceivable practical value of N.
1.5.14 Weighted quick-union by height. Develop a UF implementation that uses the same basic strategy as weighted quick-union but keeps track of tree height and always links the shorter tree to the taller one. Prove a logarithmic upper bound on the height of the trees for N sites with your algorithm.
1.5.15 Binomial trees. Show that the number of nodes at each level in the worst-case trees for weighted quick-union are binomial coef cients. Compute the average depth of a node in a worst-case tree with N = 2n nodes.
1.5.16 Amortized costs plots. Instrument your implementations from Exercise 1.5.7 to make amortized costs plots like those in the text.
1.5.17 Random connections. Develop a UF client ErdosRenyi that takes an integer value N from the command line, generates random pairs of integers between 0 and N-1, calling connected() to determine if they are connected and then union() if not (as in our development client), looping until all sites are connected, and printing the number of connections generated. Package your program as a static method count() that takes N as argument and returns the number of connections and a main() that takes N from the command line, calls count(), and prints the returned value.
1.5.18 Random grid generator. Write a program RandomGrid that takes an int value N from the command line, generates all the connections in an N-by-N grid, puts them in random order, randomly orients them (so that p q and q p are equally likely to oc- cur), and prints the result to standard output. To randomly order the connections, use aRandomBag (seeExercise1.3.34onpage167).Toencapsulatepandqinasingleobject,
www.it-ebooks.info
1.5 n Case Study: Union-Find 237
 crEAtivE problEms

238 Chapter 1 n Fundamentals
 crEAtivE problEms (continued)
use the Connection nested class shown below. Package your program as two static methods: generate(), which takes N as argument and returns an array of connec- tions, and main(), which takes N from the command line, calls generate(), and iterates through the returned array to print the connections.
1.5.19 Animation. Write a RandomGrid client (see Exercise 1.5.18) that uses UnionFind as in our development client to check connectivity and uses StdDraw to draw the connections as they are processed.
1.5.20 Dynamic growth. Using linked lists or a resizing array, develop a weighted quick-union implementation that removes the restriction on needing the number of objects ahead of time. Add a method newSite() to the API, which returns an int identi er.
   private class Connection
  {
int p; int q;
     public Connection(int p, int q)
     {  this.p = p; this.q = q;  }
  }
record to encapsulate connections
  www.it-ebooks.info

1.5.21 Erdös-Renyi model. Use your client from Exercise 1.5.17 to test the hypothesis that the number of pairs generated to get one component is ~ 1⁄2N ln N.
1.5.22 Doubling test for Erdös-Renyi model. Develop a performance-testing client that takes an int value T from the command line and performs T trials of the following ex- periment: Use your client from Exercise 1.5.17 to generate random connections, using UnionFind to determine connectivity as in our development client, looping until all sites are connected. For each N, print the value of N, the average number of connections processed, and the ratio of the running time to the previous. Use your program to vali- date the hypotheses in the text that the running times for quick- nd and quick-union are quadratic and weighted quick-union is near-linear.
1.5.23 Compare quick- nd with quick-union for Erdös-Renyi model. Develop a perfor- mance-testing client that takes an int value T from the command line and performs T trials of the following experiment: Use your client from Exercise 1.5.17 to generate random connections. Save the connections, so that you can use both quick-union and quick- nd to determine connectivity as in our development client, looping until all sites are connected. For each N, print the value of N and the ratio of the two running times.
1.5.24 Fast algorithms for Erdös-Renyi model. Add weighted quick-union and weight- ed quick-union with path compression to your tests from Exercise 1.5.23 . Can you discern a difference between these two algorithms?
1.5.25 Doubling test for random grids. Develop a performance-testing client that takes an int value T from the command line and performs T trials of the following experie- ment: Use your client from Exercise 1.5.18 to generate the connections in an N-by-N square grid, randomly oriented and in random order, then use UnionFind to determine connectivity as in our development client, looping until all sites are connected. For each N, print the value of N, the average number of connections processed, and the ratio of the running time to the previous. Use your program to validate the hypotheses in the text that the running times for quick- nd and quick-union are quadratic and weighted quick-union is near-linear. Note : As N doubles, the number of sites in the grid increases by a factor of 4, so expect a doubling factor of 16 for quadratic and 4 for linear.
www.it-ebooks.info
1.5 n Case Study: Union-Find 239
 ExpErimENts

240 Chapter 1 n Fundamentals
 ExpErimENts (continued)
1.5.26 Amortized plot for Erdös-Renyi. Develop a client that takes an int value N from the command line and does an amortized plot of the cost of all operations in the style of the plots in the text for the process of generating random pairs of integers between 0 and N-1, calling connected() to determine if they are connected and then union() if not (as in our development client), looping until all sites are connected.
 www.it-ebooks.info

This page intentionally left blank
www.it-ebooks.info

 tWo
Sorting
2.1 elementary Sorts 244
     2.2 Mergesort
2.3 Quicksort
2.4 Priority Queues
2.5 Applications
270
288
308
336
www.it-ebooks.info
 Sorting is the process of rearranging a sequence of objects so as to put them in some logical order. For example, your credit card bill presents transactions in order by date—they were likely put into that order by a sorting algorithm. In the early days of computing, the common wisdom was that up to 30 percent of all com- puting cycles was spent sorting. If that fraction is lower today, one likely reason is that sorting algorithms are relatively ef cient, not that sorting has diminished in relative importance. Indeed, the ubiquity of computer usage has put us awash in data, and the  rst step to organizing data is often to sort it. All computer systems have implementa- tions of sorting algorithms, for use by the system and by users.
There are three practical reasons for you to study sorting algorithms, even though you might just use a system sort:
n Analyzing sorting algorithms is a thorough introduction to the approach that we use to compare algorithm performance throughout the book.
n Similar techniques are effective in addressing other problems.
n We often use sorting algorithms as a starting point to solve other problems. More important than these practical reasons is that the algorithms are elegant, classic, and effective.
Sorting plays a major role in commercial data processing and in modern scienti c computing. Applications abound in transaction processing, combinatorial optimiza- tion, astrophysics, molecular dynamics, linguistics, genomics, weather prediction, and many other  elds. Indeed, a sorting algorithm (quicksort, in Section 2.3) was named as one of the top ten algorithms for science and engineering of the 20th century.
In this chapter, we consider several classical sorting methods and an ef cient imple- mentation of a fundamental data type known as the priority queue. We discuss the theoretical basis for comparing sorting algorithms and conclude the chapter with a survey of applications of sorting and priority queues.
www.it-ebooks.info
243

   244
For our first excursion into the area of sorting algorithms, we shall study two ele- mentary sorting methods and a variation of one of them. Among the reasons for study- ing these relatively simple algorithms in detail are the following: First, they provide context in which we can learn terminology and basic mechanisms. Second, these simple algorithms are more effective in some applications than the sophisticated algorithms that we shall discuss later. Third, they are useful in improving the ef ciency of more sophisticated algorithms, as we will see.
Rules of the game Our primary concern is algorithms for rearranging arrays of items where each item contains a key. The objective of the sorting algorithm is to rear- range the items such that their keys are ordered according to some well-de ned order- ing rule (usually numerical or alphabetical order). We want to rearrange the array so that each entry’s key is no smaller than the key in each entry with a lower index and no larger than the key in each entry with a larger index. Speci c characteristics of the keys and the items can vary widely across applications. In Java, items are just objects, and the abstract notion of a key is captured in a built-in mechanism—the Comparable interface—that is described on page 247.
The class Example on the facing page illustrates the conventions that we shall use: we put our sort code in a sort() method within a single class along with private helper functionsless()andexch() (andperhapssomeothers)andasampleclientmain(). Example also illustrates code that might be useful for initial debugging: its test client main() sorts strings from standard input using the private method show() to print the contents of the array. Later in this chapter, we will examine various test clients for com- paring algorithms and for studying their performance. To differentiate sorting meth- ods, we give our various sort classes different names. Clients can call different imple- mentations by name: Insertion.sort(), Merge.sort(), Quick.sort(), and so forth.
With but a few exceptions, our sort code refers to the data only through two opera- tions: the method less() that compares items and the method exch() that exchanges them. The exch() method is easy to implement, and the Comparable interface makes it easy to implement less(). Restricting data access to these two operations makes our code readable and portable, and makes it easier for us certify that algorithms are cor- rect, to study performance and to compare algorithms. Before proceeding to consider sort implementations, we discuss a number of important issues that need to be care- fully considered for every sort.
www.it-ebooks.info
2.1 eleMentAry SortS

  2.1 n Elementary Sorts 245
 template for sort classes
  public class Example
  {
     public static void sort(Comparable[] a)
     {  /* See Algorithms 2.1, 2.2, 2.3, 2.4, 2.5, or 2.7. */  }
     private static boolean less(Comparable v, Comparable w)
     {  return v.compareTo(w) < 0;  }
     private static void exch(Comparable[] a, int i, int j)
     {  Comparable t = a[i]; a[i] = a[j]; a[j] = t;  }
     private static void show(Comparable[] a)
     {  // Print the array, on a single line.
        for (int i = 0; i < a.length; i++)
           StdOut.print(a[i] + " ");
        StdOut.println();
}
     public static boolean isSorted(Comparable[] a)
     {  // Test whether the array entries are in order.
        for (int i = 1; i < a.length; i++)
           if (less(a[i], a[i-1]))  return false;
        return true;
     }
     public static void main(String[] args)
     {  // Read strings from standard input, sort them, and print.
        String[] a = In.readStrings();
        sort(a);
        assert isSorted(a);
        show(a);
} }
This class illustrates our conventions for imple- menting array sorts. For each sorting algorithm that we consider, we present a sort() method for a class like this with Example changed to a name that corresponds to the algorithm. The test client sorts strings taken from standard input, but, with this code, our sort methods are effective for any type of data that implements Comparable.
  www.it-ebooks.info
% more tiny.txt
S ORTEXAMPLE
% java Example < tiny.txt A EELMOPRSTX
  % more words3.txt
bed bug dad yes zoo ... all bad yet
% java Example < words3.txt
all bad bed bug dad ... yes yet zoo
246 Chapter 2 n Sorting
Certi cation Does the sort implementation always put the array in order, no mat- ter what the initial order? As a conservative practice, we include the statement assert isSorted(a); in our test client to certify that array entries are in order after the sort. It is reasonable to include this statement in every sort implementation, even though we normally test our code and develop mathematical arguments that our al- gorithms are correct. Note that this test is suf cient only if we use exch() exclusively to change array entries. When we use code that stores values into the array directly, we do not have full assurance (for example, code that destroys the original input array by setting all values to be the same would pass this test).
Running time We also test algorithm performance. We start by proving facts about the number of basic operations (compares and exchanges, or perhaps the number of times the array is ac- cessed, for read or write) that the various sorting algorithms per- form for various natural input models. Then we use these facts to develop hypotheses about the comparative performance of the algorithms and present tools that you can use to experimentally check the validity of such hypotheses. We use a consistent coding style to facilitate the development of valid hypotheses about per- formance that will hold true for typical implementations.
The amount of extra memory used by a sorting algorithm is often as important a factor as running time. The sorting algorithms divide into two basic types: those that sort in place and use no extra memory except perhaps for a small function- call stack or a constant number of instance variables, and those that need enough extra memory to hold another copy of the array to be sorted.
Types of data Our sort code is effective for any item type that implements the Comparable interface. Adhering to Java’s convention in this way is convenient be- cause many of the types of data that you might want to sort implement Comparable. For example, Java’s numeric wrapper types such as Integer and Double implement Comparable, as do String and various advanced types such as File or URL. Thus, you can just call one of our sort methods with an array of any of these types as argu- ment. For example, the code at right uses quicksort (see Section 2.3) to sort N random Double values. When we create types of our
own, we can enable client code to sort that type of data by implementing the Comparable in- terface. To do so, we just need to implement a compareTo() method that de nes an ordering on objects of that type known as the natural
 sorting cost model.
When studying sorting algorithms, we count compares and exchanges. For algorithms that do not use exchanges, we count array accesses.
Extra memory
   Double a[] = new Double[N];
  for (int i = 0; i < N; i++)
     a[i] = StdRandom.uniform();
  Quick.sort(a);
Sorting an array of random values
 www.it-ebooks.info

order for that type, as shown here for our Date data type (seepage 91). Java’s convention is that the call v.compareTo(w) returns an integer that is negative, zero, or positive (usually -1, 0, or +1) when v<w, v=w,
or v>w, respectively. For economy, we
use standard notation like v>w as short- hand for code like v.compareTo(w)>0 for the remainder of this paragraph. By convention, v.compareTo(w) throws an exception if v and w are incompatible types or either is null. Furthermore, compareTo() must implement a total order: it must be
n Re exive (for all v, v = v)
n Antisymmetric (for all v and w, if
v<w then w>v and if v=w then
w=v)
n Transitive (for all v, w, and x, if
v<=w and w<=x then v<=x)
These rules are intuitive and standard
in mathematics—you will have little
dif culty adhering to them. In short,
compareTo() implements our key ab-
straction—it de nes the ordering of
the items (objects) to be sorted, which
can be any type of data that implements
Comparable. Note that compareTo() need not use all of the instance variables. Indeed, the key might be a small part of each item.
For the remainder of this chapter, we shall address numerous algorithms for sort- ing arrays of objects having a natural order. To compare and contrast the algorithms, we shall examine a number of their properties, including the number of compares and exchanges that they use for various types of inputs and the amount of extra memory that they use. These properties lead to the development of hypotheses about perfor- mance properties, many of which have been validated on countless computers over the past several decades. Speci c implementations always need to be checked, so we also consider tools for doing so. After considering the classic selection sort, insertion sort, shellsort, mergesort, quicksort, and heapsort algorithms, we will consider practical is- sues and applications, in Section 2.5.
2.1 n Elementary Sorts 247
   public class Date implements Comparable<Date>
  {
     private final int day;
     private final int month;
     private final int year;
     public Date(int d, int m, int y)
     {  day = d; month = m; year = y; }
     public int day()   {  return day;    }
     public int month() {  return month;  }
     public int year()  {  return year;   }
     public int compareTo(Date that)
     {
        if (this.year  > that.year ) return +1;
        if (this.year  < that.year ) return -1;
        if (this.month > that.month) return +1;
        if (this.month < that.month) return -1;
        if (this.day   > that.day  ) return +1;
        if (this.day   < that.day  ) return -1;
        return 0;
}
     public String toString()
     { return month + "/" + day + "/" + year; }
  }
Defining a comparable type
 www.it-ebooks.info

248 Chapter 2 n Sorting
Selection sort One of the simplest sorting algorithms works as follows: First,  nd the smallest item in the array and exchange it with the  rst entry (itself if the  rst entry is already the smallest). Then,  nd the next smallest item and exchange it with the sec- ond entry. Continue in this way until the entire array is sorted. This method is called selection sort because it works by repeatedly selecting the smallest remaining item.
As you can see from the implementation in Algorithm 2.1, the inner loop of selec- tion sort is just a compare to test a current item against the smallest item found so far (plus the code necessary to increment the current index and to check that it does not exceed the array bounds); it could hardly be simpler. The work of moving the items around falls outside the inner loop: each exchange puts an item into its  nal position, so the number of exchanges is N. Thus, the running time is dominated by the number of compares.
 proposition A. Selection sort uses N 2/2 compares and N exchanges to sort an array of length N.
proof: You can prove this fact by examining the trace, which is an N-by-N table in which unshaded letters correspond to compares. About one-half of the entries in the table are unshaded—those on and above the diagonal. The entries on the diagonal each correspond to an exchange. More precisely, examination of the code revealsthat,foreachifrom0toN1,thereisoneexchangeandN1i com- pares, so the totals are N exchanges and (N  1) + (N  2) + . . . + 2 + 1+ 0 = N(N  1) / 2  N 2 / 2 compares.
In summary, selection sort is a simple sorting method that is easy to understand and to implement and is characterized by the following two signature properties:
Running time is insensitive to input The process of  nding the smallest item on one pass through the array does not give much information about where the smallest item might be on the next pass. This property can be disadvantageous in some situations. For example, the person using the sort client might be surprised to realize that it takes about as long to run selection sort for an array that is already in order or for an array with all keys equal as it does for a randomly-ordered array! As we shall see, other algo- rithms are better able to take advantage of initial order in the input.
Data movement is minimal Each of the N exchanges changes the value of two array entries, so selection sort uses N exchanges—the number of exchanges is a linear func- tion of the array size. None of the other sorting algorithms that we consider have this property (most involve linearithmic or quadratic growth).
www.it-ebooks.info

  aLgorIthM 2.1 Selection sort
  public class Selection
  {
     public static void sort(Comparable[] a)
     {  // Sort a[] into increasing order.
        int N = a.length;               // array length
        for (int i = 0; i < N; i++)
        {  // Exchange a[i] with smallest entry in a[i+1...N).
           int min = i;                 // index of a minimal entry.
           for (int j = i+1; j < N; j++)
              if (less(a[j], a[min])) min = j;
           exch(a, i, min);
} }
     // See page 245 for less(), exch(), isSorted(), and main().
}
For each i, this implementation puts the ith smallest item in a[i]. The entries to the left of position i are the i smallest items in the array and are not examined again.
   i min
a[]
0 1 2 3 4 5 6 7 8 9 10 SORTEXAMPLE
entries in black are examined to find the minimum
entries in red are a[min]
entries in gray are in final position
  06SORTEXAMPLE 14AORTEXSMPLE 2 10 A E R T O X S M P L E 39AEETOXSMPLR 47AEELOXSMPTR 57AEELMXSOPTR 68AEELMOSXPTR 7 10 A E E L M O P X S T R 88AEELMOPRSTX 99 AEELMOPRSTX
10 10 A E E L M O P R S T X AEELMOPRSTX
Trace of selection sort (array contents just after each exchange)
  www.it-ebooks.info
2.1 n Elementary Sorts 249
250 Chapter 2 n Sorting
Insertion sort The algorithm that people often use to sort bridge hands is to con- sider the cards one at a time, inserting each into its proper place among those already considered (keeping them sorted). In a computer implementation, we need to make space to insert the current item by moving larger items one position to the right, before inserting the current item into the vacated position. Algorithm 2.2 is an implementa- tion of this method, which is called insertion sort.
As in selection sort, the items to the left of the current index are in sorted order dur- ing the sort, but they are not in their  nal position, as they may have to be moved to make room for smaller items encountered later. The array is, however, fully sorted when the index reaches the right end.
Unlike that of selection sort, the running time of insertion sort depends on the ini- tial order of the items in the input. For example, if the array is large and its entries are already in order (or nearly in order), then insertion sort is much, much faster than if the entries are randomly ordered or in reverse order.
 propositionb. InsertionsortusesN2/4comparesandN2/4exchangestosort a randomly ordered array of length N with distinct keys, on the average. The worst case is N 2/2 compares and N 2/2 exchanges and the best case is N  1 compares and 0 exchanges.
proof: JustasforPropositionA,thenumberofcomparesandexchangesiseasyto visualize in the N-by-N diagram that we use to illustrate the sort. We count entries below the diagonal—all of them, in the worst case, and none of them, in the best case. For randomly ordered arrays, we expect each item to go about halfway back, on the average, so we count one-half of the entries below the diagonal.
The number of compares is the number of exchanges plus an additional term equal to N minus the number of times the item inserted is the smallest so far. In the worst case (array in reverse order), this term is negligible in relation to the total; in the best case (array in order) it is equal to N  1.
Insertion sort works well for certain types of nonrandom arrays that often arise in practice, even if they are huge. For example, as just mentioned, consider what happens when you use insertion sort on an array that is already sorted. Each item is immediately determined to be in its proper place in the array, and the total running time is linear. (The running time of selection sort is quadratic for such an array.) The same is true for arrays whose keys are all equal (hence the condition in Proposition B that the keys must be distinct).
www.it-ebooks.info

  aLgorIthM 2.2 insertion sort
  public class Insertion
  {
     public static void sort(Comparable[] a)
     {  // Sort a[] into increasing order.
        int N = a.length;
        for (int i = 1; i < N; i++)
        {  // Insert a[i] among a[i-1], a[i-2], a[i-3]....
           for (int j = i; j > 0 && less(a[j], a[j-1]); j--)
              exch(a, j, j-1);
} }
     // See page 245 for less(), exch(), isSorted(), and main().
}
For each i from 1 to N-1, exchange a[i] with the entries that are larger in a[0] through a[i-1]. As the index i travels from left to right, the entries to its left are in sorted order in the array, so the array is fully sorted when i reaches the right end.
                          a[]
 i   j   0  1  2  3  4  5  6  7  8  9 10
SORTEXAMPLE 10OSRTEXAMPLE
21ORSTEXAMPLE 33ORSTEXAMPLE 40EORSTXAMPLE 55EORSTXAMPLE 60AEORSTXMPLE 72AEMORSTXPLE 84AEMOPRSTXLE 92AELMOPRSTXE
10 2 A E E L M O P R S T X AEELMOPRSTX
Trace of insertion sort (array contents just after each insertion)
entries in gray do not move
entry in red is a[j]
entries in black moved one position right for insertion
   www.it-ebooks.info
2.1 n Elementary Sorts 251
252 Chapter 2 n Sorting
More generally, we consider the concept of a partially sorted array, as follows: An in- versionisapairofentriesthatareoutoforderinthearray.Forinstance,E X A M P L E has 11 inversions: E-A, X-A, X-M, X-P, X-L, X-E, M-L, M-E, P-L, P-E, and L-E. If the number of inversions in an array is less than a constant multiple of the array size, we say that the array is partially sorted. Typical examples of partially sorted arrays are the following:
n An array where each entry is not far from its  nal position n A small array appended to a large sorted array
n An array with only a few entries that are not in place
Insertion sort is an ef cient method for such arrays; selection sort is not. Indeed, when the number of inversions is low, insertion sort is likely to be faster than any sorting method that we consider in this chapter.
 proposition c. The number of exchanges used by insertion sort is equal to the number of inversions in the array, and the number of compares is at least equal to the number of inversions and at most equal to the number of inversions plus the array size minus 1.
proof: Everyexchangeinvolvestwoinvertedadjacententriesandthusreducesthe number of inversions by one, and the array is sorted when the number of inver- sions reaches zero. Every exchange corresponds to a compare, and an additional compare might happen for each value of i from 1 to N-1 (when a[i] does not reach the left end of the array).
It is not dif cult to speed up insertion sort substantially, by shortening its inner loop to move the larger entries to the right one position rather than doing full exchanges (thus cutting the number of array accesses in half ). We leave this improvement for an exercise (see Exercise 2.1.25).
In summary, insertion sort is an excellent method for partially sorted arrays and is also a  ne method for tiny arrays. These facts are important not just because such arrays frequently arise in practice, but also because both types of arrays arise in intermediate stages of advanced sorting algorithms, so we will be considering insertion sort again in relation to such algorithms.
www.it-ebooks.info

Visualizing sorting algorithms Throughout this chapter, we will be using a simple visual representation to help describe the properties of sorting algorithms. Rather than tracing the progress of a sort with key values such as letters, numbers, or words, we use vertical bars, to be sorted by their
2.1 n Elementary Sorts 253
   heights. The advantage of such a representation is that it can give insights into the behavior of a sort- ing method.
For example, you can see at a glance on the visual traces at right that insertion sort does not touch entries to the right of the scan pointer and selec- tion sort does not touch entries to the left of the scan pointer. Moreover, it is clear from the visual traces that, since insertion sort also does not touch entries smaller than the inserted item, it uses about half the number of compares as selection sort, on the average.
With our StdDraw library, developing a visual trace is not much more dif cult than doing a stan- dard trace. We sort Double values, instrument the algorithm to call show() as appropriate (just as we do for a standard trace), and develop a version of show() that uses StdDraw to draw the bars instead of printing the results. The most complicated task is setting the scale for the y-axis so that the lines of the trace appear in the expected order. You are en- couraged to work Exercise 2.1.18 in order to gain a better appreciation of the value of visual traces and the ease of creating them.
An even simpler task is to animate the trace so
that you can see the array dynamically evolve to
the sorted result. Developing an animated trace in-
volves essentially the same process described in the previous paragraph, but without having to worry about the y-axis (just clear the window and redraw the bars each time). Though we cannot make the case on the printed page, such animated representations are also effective in gaining insight into how an algorithm works. You are also encour- aged to work Exercise 2.1.17 to see for yourself.
gray entries are untouched
   www.it-ebooks.info
insertion sort
selection sort
black entries are involved in compares
Visual traces of elementary sorting algorithms

254 Chapter 2 n Sorting
Comparing two sorting algorithms Now that we have two implementations, we are naturally interested in knowing which one is faster: selection sort (Algorithm 2.1) or insertion sort (Algorithm 2.2). Questions like this arise again and again and again in the study of algorithms and are a major focus throughout this book. We have discussed some fundamental ideas in Chapter 1, but we use this  rst case in point to illustrate our basic approach to answering such questions. Generally, following the ap- proach introduced in Section 1.4, we compare algorithms by
n Implementing and debugging them
n Analyzing their basic properties
n Formulating a hypothesis about comparative performance n Running experiments to validate the hypothesis
These steps are nothing more than the time-honored scienti c method, applied to the study of algorithms.
In the present context, Algorithm 2.1 and Algorithm 2.2 are evidence of the  rst step; Propositions A, B, and C constitute the second step; Property D on page 255 constitutes the third step; and the class SortCompare onpage 256 enables the fourth step. These activities are all interrelated.
Our brief descriptions mask a substantial amount of effort that is required to prop- erly implement, analyze, and test algorithms. Every programmer knows that such code is the product of a long round of debugging and re nement, every mathematician knows that proper analysis can be very dif cult, and every scientist knows that formu- lating hypotheses and designing and executing experiments to validate them require great care. Full development of such results is reserved for experts studying our most important algorithms, but every programmer using an algorithm should be aware of the scienti c context underlying its performance properties.
Having developed implementations, our next choice is to settle on an appropriate model for the input. For sorting, a natural model, which we have used for Proposi- tions A, B, and C, is to assume that the arrays are randomly ordered and that the key values are distinct. In applications where signi cant numbers of equal key values are present we will need a more complicated model.
How do we formulate a hypothesis about the running times of insertion sort and selection sort for randomly ordered arrays? Examining Algorithms 2.1 and 2.2 and Propositions A and B, it follows immediately that the running time of both algorithms should be quadratic for randomly ordered arrays. That is, the running time of insertion sort for such an input is proportional to some small constant times N 2 and the running time of selection sort is proportional to some other small constant times N 2. The values of the two constants depend on the cost of compares and exchanges on the particular computer being used. For many types of data and for typical computers, it is reasonable
www.it-ebooks.info

2.1 n Elementary Sorts 255 to assume that these costs are similar (though we will see a few signi cant exceptions).
The following hypothesis follows directly:
 property D. The running times of insertion sort and selection sort are quadratic and within a small constant factor of one another for randomly ordered arrays of distinct values.
Evidence: This statement has been validated on many different computers over the past half-century. Insertion sort was about twice as fast as selection sort when the  rst edition of this book was written in 1980 and it still is today, even though it took several hours to sort 100,000 items with these algorithms then and just several seconds today. Is insertion sort a bit faster than selection sort on your computer? To  nd out, you can use the class SortCompare on the next page, which uses the sort() methods in the classes named as command-line arguments to perform the given number of experiments (sorting arrays of the given size) and prints the ratio of the observed running times of the algorithms.
To validate this hypothesis, we use SortCompare (see page 256) to perform the experi- ments. As usual, we use Stopwatch to compute the running time. The implementation of time() shown here does the job for the basic sorts in this chapter. The “randomly or- dered” input model is embedded in the timeRandomInput() method in SortCompare, which generates random Double values, sorts them, and returns the total measured time of the sort for the given
number of trials. Using ran-
dom Double values between
0.0 and 1.0 is much simpler
than the alternative of us-
ing a library function such
as StdRandom.shuffle()
and is effective because equal
key values are very unlikely
(see Exercise 2.5.31). As
discussed in Chapter 1, the
number of trials is taken as an
argument both to take advan-
tage of the law of large numbers (the more trials, the total running time divided by the number of trials is a more accurate estimate of the true average running time) and to help damp out system effects. You are encouraged to experiment with SortCompare
 public static double time(String alg, Comparable[] a)
{
   Stopwatch timer = new Stopwatch();
   if (alg.equals("Insertion")) Insertion.sort(a);
   if (alg.equals("Selection")) Selection.sort(a);
   if (alg.equals("Shell"))
   if (alg.equals("Merge"))
   if (alg.equals("Quick"))
   if (alg.equals("Heap"))
   return timer.elapsedTime();
}
Shell.sort(a);
Merge.sort(a);
Quick.sort(a);
Heap.sort(a);
timing one of the sort algorithms in this chapter on a given input
 www.it-ebooks.info

 256 Chapter 2 n Sorting
 Comparing two sorting algorithms
  public class SortCompare
  {
     public static double time(String alg, Double[] a)
     {  /* See text. */  }
     public static double timeRandomInput(String alg, int N, int T)
     {  // Use alg to sort T random arrays of length N.
        double total = 0.0;
        Double[] a = new Double[N];
        for (int t = 0; t < T; t++)
        {  // Perform one experiment (generate and sort an array).
           for (int i = 0; i < N; i++)
              a[i] = StdRandom.uniform();
           total += time(alg, a);
        }
        return total;
     }
     public static void main(String[] args)
     {
        String alg1 = args[0];
        String alg2 = args[1];
        int N = Integer.parseInt(args[2]);
        int T = Integer.parseInt(args[3]);
        double t1 = timeRandomInput(alg1, N, T); // total for alg1
        double t2 = timeRandomInput(alg2, N, T); // total for alg2
        StdOut.printf("For %d random Doubles\n    %s is", N, alg1);
        StdOut.printf(" %.1f times faster than %s\n", t2/t1, alg2);
} }
This client runs the two sorts named in the  rst two command-line arguments on arrays of N (the third command-line argument) random Double values between 0.0 and 1.0, repeating the experi- ment T (the fourth command-line argument) times, then prints the ratio of the total running times.
   % java SortCompare Insertion Selection 1000 100
For 1000 random Doubles
  Insertion is 1.7 times faster than Selection
www.it-ebooks.info
 2.1 n Elementary Sorts 257 on your computer to learn the extent to which its conclusion about insertion sort and
selection sort is robust.
Property D is intentionally a bit vague—the value of the small constant factor is left unstated and the assumption that the costs of compares and exchanges are similar is left unstated—so that it can apply in a broad variety of situations. When possible, we try to capture essential aspects of the performance of each of the algorithms that we study in statements like this. As discussed in Chapter 1, each Property that we consider needs to be tested scienti cally in a given situation, perhaps supplemented with a more re ned hypothesis based upon a related Proposition (mathematical truth).
For practical applications, there is one further step, which is crucial: run experiments to validate the hypothesis on the data at hand. We defer consideration of this step to Section 2.5 and the exercises. In this case, if your sort keys are not distinct and/or not randomly ordered, Property D might not hold. You can randomly order an array with StdRandom.shuffle(), but applications with signi cant numbers of equal keys involve more careful analysis.
Our discussions of the analyses of algorithms are intended to be starting points, not  nal conclusions. If some other question about performance of the algorithms comes to mind, you can study it with a tool like SortCompare. Many opportunities to do so are presented in the exercises.
We do not dwell further on the comparative performance of insertion sort and selec- tion sort because we are much more interested in algorithms that can run a hundred or a thousand or a million times faster than either. Still, understanding these elementary algorithms is worthwhile for several reasons:
n They help us work out the ground rules.
n They provide performance benchmarks.
n They often are the method of choice in some specialized situations. n They can serve as the basis for developing better algorithms.
For these reasons, we will use the same basic approach and consider elementary algo- rithms for every problem that we study throughout this book, not just sorting. Pro- grams like SortCompare play a critical role in this incremental approach to algorithm development. At every step along the way, we can use such a program to help evaluate whether a new algorithm or an improved version of a known algorithm provides the performance gains that we expect.
www.it-ebooks.info

258 Chapter 2 n Sorting
Shellsort To exhibit the value of knowing properties of elementary sorts, we next consider a fast algorithm based on insertion sort. Insertion sort is slow for large un- ordered arrays because the only exchanges it does involve adjacent entries, so items can move through the array only one place at a time. For example, if the item with the smallest key happens to be at the end of the array, N1 exchanges are needed to get that one item where it belongs. Shellsort is a simple extension of insertion sort that gains speed by allowing exchanges of array entries that are far apart, to produce partially sorted arrays that can be ef ciently sorted, eventually by insertion sort.
The idea is to rearrange the array to give it the property that taking every hth entry (starting anywhere) yields a sorted subsequence. Such an array is said to be h-sorted. Put another way, an h-sorted array is h inde- pendent sorted subsequences, interleaved together. By h-sorting for some large val- ues of h, we can move items in the array long distances and thus make it easier to h-sort for smaller values of h. Using such a procedure for any sequence of values of h that ends in 1 will produce a sorted ar- ray: that is shellsort. The implementation in Algorithm 2.3 on the facing page uses the sequence of decreasing values 1⁄2(3k1), starting at the smallest increment greater than or equal to ⎣N/3⎦ and decreasing to 1. We refer to such a sequence as an increment sequence. Algorithm 2.3 computes its
increment sequence; another alternative is to store an increment sequence in an array. One way to implement shellsort would be, for each h, to use insertion sort indepen- dently on each of the h subsequences. Because the subsequences are independent, we can use an even simpler approach: when h-sorting the array, we insert each item among the previous items in its h-subsequence by exchanging it with those that have larger keys (moving them each one position to the right in the subsequence). We accomplish this task by using the insertion-sort code, but modi ed to decrement by h instead of 1 when moving through the array. This observation reduces the shellsort implementa-
tion to an insertion-sort-like pass through the array for each increment.
Shellsort gains ef ciency by making a tradeoff between size and partial order in the subsequences. At the beginning, the subsequences are short; later in the sort, the subse- quences are partially sorted. In both cases, insertion sort is the method of choice. The extent to which the subsequences are partially sorted is a variable factor that depends strongly on the increment sequence. Understanding shellsort’s performance is a chal- lenge. Indeed, Algorithm 2.3 is the only sorting method we consider whose perfor-
mance on randomly ordered arrays has not been precisely characterized.
h= 4 LEEAMHLEPSOLTSXR LMPT
EHSS ELOX
AELR
An h-sorted sequence is h interleaved sorted subsequences
             www.it-ebooks.info

 aLgorIthM 2.3 Shellsort
  public class Shell
  {
     public static void sort(Comparable[] a)
     {  // Sort a[] into increasing order.
        int N = a.length;
        int h = 1;
        while (h < N/3) h = 3*h + 1; // 1, 4, 13, 40, 121, 364, 1093, ...
        while (h >= 1)
        {  // h-sort the array.
           for (int i = h; i < N; i++)
           {  // Insert a[i] among a[i-h], a[i-2*h], a[i-3*h]... .
              for (int j = i; j >= h && less(a[j], a[j-h]); j -= h)
                 exch(a, j, j-h);
}
h = h/3; }
}
     // See page 245 for less(), exch(), isSorted(), and main().
}
If we modify insertion sort (Algorithm 2.2) to h-sort the array and add an outer loop to decrease h throughasequenceofincrementsstartingatanincrementaslargeasaconstantfractionofthear- ray length and ending at 1, we are led to this compact shellsort implementation.
2.1 n
Elementary Sorts 259
   % java SortCompare Shell Insertion 100000 100
For 100000 random Doubles
  Shell is 600 times faster than Insertion
 input S H E L L S O R T E X A M P L E 13-sort P H E L L S O R T E X A M S L E 4-sort L E E A M H L E P S O L T S X R 1-sort A E E E H L L L M O P R S S T X
Shellsort trace (array contents after each pass)
www.it-ebooks.info
260 Chapter 2 n Sorting
How do we decide what increment sequence to use? In general, this question is a dif-  cult one to answer. The performance of the algorithm depends not just on the num- ber of increments, but also on arithmetical interactions among the increments such as
the size of their common divi- sors and other properties. Many different increment sequences have been studied in the lit- erature, but no provably best sequence has been found. The increment sequence that is used in Algorithm 2.3 is easy to compute and use, and performs nearly as well as more sophisti- cated increment sequences that have been discovered that have provably better worst-case per- formance. Increment sequences that are substantially better still may be waiting to be discovered.
Shellsort is useful even for large arrays, particularly by contrast with selection sort and insertion sort. It also performs well on arrays that are in arbi- trary order (not necessarily ran- dom). Indeed, constructing an array for which shellsort runs slowly for a particular incre- ment sequence is usually a chal- lenging exercise.
As you can learn with SortCompare, shellsort is much faster than insertion sort and selection sort, and its speed ad- vantage increases with the array
size. Before reading further, try using SortCompare to compare shellsort with insertion sort and selection sort for array sizes that are increasing powers of 2 on your computer (see Exercise 2.1.27). You will see that shellsort makes it possible to address sorting
input SHELLSORTEXAMPLE
13-sort P H E L L S O R T E X A M S L E PHELLSORTEXAMSLE PHELLSORTEXAMSLE
4-sort
 1-sort
ELEAMHLEPSOLTSXR EELAMHLEPSOLTSXR AEELMHLEPSOLTSXR AEELMHLEPSOLTSXR AEEHLMLEPSOLTSXR AEEHLLMEPSOLTSXR AEEEHLLMPSOLTSXR AEEEHLLMPSOLTSXR AEEEHLLMPSOLTSXR AEEEHLLMOPSLTSXR AEEEHLLLMOPSTSXR AEEEHLLLMOPSTSXR AEEEHLLLMOPSSTXR AEEEHLLLMOPSSTXR AEEEHLLLMOPRSSTX
LHELPSORTEXAMSLE LHELPSORTEXAMSLE LHELPSORTEXAMSLE LHELPSORTEXAMSLE LHELPSORTEXAMSLE LEELPHORTSXAMSLE LEELPHORTSXAMSLE LEEAPHOLTSXRMSLE LEEAMHOLPSXRTSLE LEEAMHOLPSXRTSLE LEEAMHLLPSORTSXE LEEAMHLEPSOLTSXR
result AEEEHLLLMOPRSSTX Detailed trace of shellsort (insertions)
www.it-ebooks.info

input
40-sorted
13-sorted
4-sorted
result
2.1 n
Elementary Sorts 261
     Visual trace of shellsort
problems that could not be addressed with the more elementary algorithms. This ex- ample is our  rst practical illustration of an important principle that pervades this book: achieving speedups that enable the solution of problems that could not otherwise be solved is one of the prime reasons to study algorithm performance and design.
The study of the performance characteristics of shellsort requires mathematical ar- guments that are beyond the scope of this book. If you want to be convinced, start by thinking about how you would prove the following fact: when an h-sorted array is k-sorted, it remains h-sorted. As for the performance of Algorithm 2.3, the most im- portant result in the present context is the knowledge that the running time of shellsort is not necessarily quadratic—for example, it is known that the worst-case number of compares for Algorithm 2.3 is proportional to N 3/2. That such a simple modi cation
www.it-ebooks.info

262 Chapter 2 n Sorting
can break the quadratic-running-time barrier is quite interesting, as doing so is a prime goal for many algorithm design problems.
No mathematical results are available about the average-case number of compares for shellsort for randomly ordered input. Increment sequences have been devised that drive the asymptotic growth of the worst-case number of compares down to N 4/3, N 5/4, N 6/5, . . . , but many of these results are primarily of academic interest because these functions are hard to distinguish from one another (and from a constant factor of N ) for practical values of N.
In practice, you can safely take advantage of the past scienti c study of shellsort just by using the increment sequence in Algorithm 2.3 (or one of the increment sequences in the exercises at the end of this section, which may improve performance by 20 to 40 percent). Moreover, you can easily validate the following hypothesis:
 property E. The number of compares used by shellsort with the increments 1, 4, 13, 40, 121, 364, . . . is bounded by a small multiple of N times the number of incre- ments used.
Evidence: Instrumenting Algorithm 2.3 to count compares and divide by the number of increments used is a straightforward exercise (see Exercise 2.1.12). Ex- tensive experiments suggest that the average number of compares per increment might be N 1/5, but it is quite dif cult to discern the growth in that function unless N is huge. This property also seems to be rather insensitive to the input model.
Experienced programmers sometimes choose shellsort because it has acceptable running time even for moderately large arrays; it requires a small amount of code; and it uses no extra space. In the next few sections, we shall see methods that are more ef-  cient, but they are perhaps only twice as fast (if that much) except for very large N, and they are more complicated. If you need a solution to a sorting problem, and are work- ing in a situation where a system sort may not be available (for example, code destined for hardware or an embedded system), you can safely use shellsort, then determine sometime later whether it will be worthwhile to replace it with a more sophisticated method.
www.it-ebooks.info

Q. Sorting seems like a toy problem. Aren’t many of the other things that we do with computers much more interesting?
A. Perhaps, but many of those interesting things are made possible by fast sorting al- gorithms. You will  nd many examples in Section 2.5 and throughout the rest of the book. Sorting is worth studying now because the problem is easy to understand, and you can appreciate the ingenuity behind the faster algorithms.
Q. Why so many sorting algorithms?
A. One reason is that the performance of many algorithms depends on the input val- ues, so different algorithms might be appropriate for different applications having dif- ferent kinds of input. For example, insertion sort is the method of choice for partially sorted or tiny arrays. Other constraints, such as space and treatment of equal keys, also come into play. We will revisit this question in Section 2.5.
Q. Why bother using the tiny helper methods less() and exch()?
A. They are basic abstract operations needed by any sort algorithm, and the code is easier to understand in terms of these abstractions. Moreover, they make the code di- rectly portable to other settings. For example, much of the code in Algorithms 2.1 and 2.2 is legal code in several other programming languages. Even in Java, we can use this code as the basis for sorting primitive types (which are not Comparable): simply implement less() with the code v < w.
Q. When I run SortCompare, I get different values each time that I run it (and those are different from the values in the book). Why?
A. For starters, you have a different computer from the one we used, not to mention a different operating system, Java runtime, and so forth. All of these differences might lead to slight differences in the machine code for the algorithms. Differences each time that you run it on your computer might be due to other applications that you are run- ning or various other conditions. Running a very large number of trials should dampen the effect. The lesson is that small differences in algorithm performance are dif cult to notice nowadays. That is a primary reason that we focus on large ones!
www.it-ebooks.info
2.1 n Elementary Sorts 263
 Q&A

264 Chapter 2 n Sorting
 ExErcisEs
 2.1.1 Show, in the style of the example trace with Algorithm 2.1, how selection sort sorts the array E A S Y Q U E S T I O N.
2.1.2 Whatisthemaximumnumberofexchangesinvolvinganyparticularitemduring selection sort? What is the average number of exchanges involving an item?
2.1.3 GiveanexampleofanarrayofNitemsthatmaximizesthenumberoftimesthe test a[j] < a[min] succeeds (and, therefore, min gets updated) during the operation of selection sort (Algorithm 2.1).
2.1.4 Show,inthestyleoftheexampletracewithAlgorithm2.2,howinsertionsort sorts the array E A S Y Q U E S T I O N.
2.1.5 For each of the two conditions in the inner for loop in insertion sort (Algo- rithm 2.2), describe an array of N items where that condition is always false when the loop terminates.
2.1.6 Which method runs faster for an array with all keys identical, selection sort or insertion sort?
2.1.7 Which method runs faster for an array in reverse order, selection sort or inser- tion sort?
2.1.8 Supposethatweuseinsertionsortonarandomlyorderedarraywhereitemshave only one of three values. Is the running time linear, quadratic, or something in between?
2.1.9 Show,inthestyleoftheexampletracewithAlgorithm2.3,howshellsortsorts the array E A S Y S H E L L S O R T Q U E S T I O N.
2.1.10 Why not use selection sort for h-sorting in shellsort?
2.1.11 Implementaversionofshellsortthatkeepstheincrementsequenceinanarray,
rather than computing it.
2.1.12 Instrumentshellsorttoprintthenumberofcomparesdividedbythearraysize for each increment. Write a test client that tests the hypothesis that this number is a small constant, by sorting arrays of random Double values, using array sizes that are increasing powers of 10, starting at 100.
www.it-ebooks.info

2.1.13 Deck sort. Explain how you would put a deck of cards in order by suit (in the order spades, hearts, clubs, diamonds) and by rank within each suit, with the restriction that the cards must be laid out face down in a row, and the only allowed operations are to check the values of two cards and to exchange two cards (keeping them face down).
2.1.14 Dequeue sort. Explain how you would sort a deck of cards, with the restric- tion that the only allowed operations are to look at the values of the top two cards, to exchange the top two cards, and to move the top card to the bottom of the deck.
2.1.15 Expensive exchange. A clerk at a shipping company is charged with the task of rearranging a number of large crates in order of the time they are to be shipped out. Thus, the cost of compares is very low (just look at the labels) relative to the cost of ex- changes (move the crates). The warehouse is nearly full—there is extra space suf cient to hold any one of the crates, but not two. What sorting method should the clerk use?
2.1.16 Certi cation. Write a check() method that calls sort() for a given array and returns true if sort() puts the array in order and leaves the same set of objects in the array as were there initially, false otherwise. Do not assume that sort() is restricted to move data only with exch(). You may use Arrays.sort() and assume that it is correct.
2.1.17 Animation. Add code to Insertion, Selection and Shell to make them draw the array contents as vertical bars like the visual traces in this section, redrawing the bars after each pass, to produce an animated effect, ending in a “sorted” picture where the bars appear in order of their height. Hint : Use a client like the one in the text that generates random Double values, insert calls to show() as appropriate in the sort code, and implement a show() method that clears the canvas and draws the bars.
2.1.18 Visual trace. Modify your solution to the previous exercise to make Insertion, Selection and Shell produce visual traces such as those depicted in this section. Hint : Judicious use of setYscale() makes this problem easy. Extra credit : Add the code nec- essary to produce red and gray color accents such as those in our  gures.
2.1.19 Shellsort worst case. Construct an array of 100 elements containing the num- bers1through100forwhichshellsort,withtheincrements1 4 13 40,usesaslargea number of compares as you can  nd.
2.1.20 Shellsort best case. What is the best case for shellsort? Justify your answer.
www.it-ebooks.info
2.1 n Elementary Sorts 265
 crEAtivE problEms

266 Chapter 2 n Sorting
crEAtivE problEms (continued)
2.1.21 Comparable transactions. Using our code for Date (page 247) as a model, ex- pand your implementation of Transaction (Exercise 1.2.13) so that it implements Comparable, such that transactions are kept in order by amount.
Solution :
             public class Transaction implements Comparable<Transaction>
             {
                ...
                private final double amount;
                ...
                public int compareTo(Transaction that)
                {
                   if (this.amount > that.amount) return +1;
                   if (this.amount < that.amount) return -1;
                   return 0;
}
... }
2.1.22 Transaction sort test client. Write a class SortTransactions that consists of a static method main() that reads a sequence of transactions from standard input, sorts them, and prints the result on standard output (see Exercise 1.3.17).
Solution :
             public class SortTransactions
             {
                public static Transaction[] readTransactions()
                {  /* See Exercise 1.3.17 */  }
                public static void main(String[] args)
                {
                   Transaction[] transactions = readTransactions();
                   Shell.sort(transactions);
                   for (Transaction t : transactions)
                      StdOut.println(t);
                }
}
 www.it-ebooks.info

2.1.23 Deck sort. Ask a few friends to sort a deck of cards (see Exercise 2.1.13). Ob- serve them carefully and write down the method(s) that they use.
2.1.24 Insertion sort with sentinel. Develop an implementation of insertion sort that eliminates the j>0 test in the inner loop by  rst putting the smallest item into position. Use SortCompare to evaluate the effectiveness of doing so. Note : It is often possible to avoid an index-out-of-bounds test in this way—the element that enables the test to be eliminated is known as a sentinel.
2.1.25 Insertion sort without exchanges. Develop an implementation of insertion sort that moves larger elements to the right one position with one array access per entry, rather than using exch(). Use SortCompare to evaluate the effectiveness of doing so.
2.1.26 Primitive types. Develop a version of insertion sort that sorts arrays of int values and compare its performance with the implementation given in the text (which sorts Integer values and implicitly uses autoboxing and auto-unboxing to convert).
2.1.27 Shellsort is subquadratic. Use SortCompare to compare shellsort with insertion sort and selection sort on your computer. Use array sizes that are increasing powers of 2, starting at 128.
2.1.28 Equal keys. Formulate and validate hypotheses about the running time of in- sertion sort and selection sort for arrays that contain just two key values, assuming that the values are equally likely to occur.
2.1.29 Shellsort increments. Run experiments to compare the increment sequence in Algorithm 2.3 with the sequence 1, 5, 19, 41, 109, 209, 505, 929, 2161, 3905, 8929, 16001, 36289, 64769, 146305, 260609 (which is formed by merging together the se- quences 9·4k 9·2k 1 and 4k 3·2k 1). See Exercise 2.1.11.
2.1.30 Geometric increments. Run experiments to determine a value of t that leads to the lowest running time of shellsort for random arrays for the increment sequence 1, ⎣t⎦, ⎣t 2⎦, ⎣t 3⎦, ⎣t 4⎦, . . . for N = 10 6. Give the values of t and the increment sequences for the best three values that you  nd.
www.it-ebooks.info
2.1 n Elementary Sorts 267
 ExpErimENts

268 Chapter 2 n Sorting
  The following exercises describe various clients for helping to evaluate sorting methods. They are intended as starting points for helping to understand performance properties, using ran- dom data. In all of them, use time(), as in SortCompare, so that you can get more accurate results by specifying more trials in the second command-line argument. We refer back to these exercises in later sections when evaluating more sophisticated methods.
2.1.31 Doubling test. Write a client that performs a doubling test for sort algorithms. Start at N equal to 1000, and print N, the predicted number of seconds, the actual num- ber of seconds, and the ratio as N doubles. Use your program to validate that insertion sort and selection sort are quadratic for random inputs, and formulate and test a hy- pothesis for shellsort.
2.1.32 Plot running times. Write a client that uses StdDraw to plot the average running times of the algorithm for random inputs and various values of the array size. You may add one or two more command-line arguments. Strive to design a useful tool.
2.1.33 Distribution. Write a client that enters into an in nite loop running sort() on arrays of the size given as the third command-line argument, measures the time taken for each run, and uses StdDraw to plot the average running times. A picture of the dis- tribution of the running times should emerge.
2.1.34 Corner cases. Write a client that runs sort() on dif cult or pathological cases that might turn up in practical applications. Examples include arrays that are already in order, arrays in reverse order, arrays where all keys are the same, arrays consisting of only two distinct values, and arrays of size 0 or 1.
2.1.35 Nonuniform distributions. Write a client that generates test data by randomly ordering objects using other distributions than uniform, including the following:
n Gaussian
n Poisson
n Geometric
n Discrete (see Exercise 2.1.28 for a special case)
Develop and test hypotheses about the effect of such input on the performance of the algorithms in this section.
www.it-ebooks.info
 ExpErimENts (continued)
  2.1.36 Nonuniform data. Write a client that generates test data that is not uniform, including the following:
n Half the data is 0s, half 1s.
n Half the data is 0s, half the remainder is 1s, half the remainder is 2s, and so forth. n Half the data is 0s, half random int values.
Develop and test hypotheses about the effect of such input on the performance of the algorithms in this section.
2.1.37 Partially sorted. Write a client that generates partially sorted arrays, including the following:
n 95 percent sorted, last percent random values
n All entries within 10 positions of their  nal place in the array
n Sorted except for 5 percent of the entries randomly dispersed throughout the
array
Develop and test hypotheses about the effect of such input on the performance of the algorithms in this section.
2.1.38 Various types of items. Write a client that generates arrays of items of various types with random key values, including the following:
n String key (at least ten characters), one double value
n double key, ten String values (all at least ten characters) n int key, one int[20] value
Develop and test hypotheses about the effect of such input on the performance of the algorithms in this section.
www.it-ebooks.info
2.1 n Elementary Sorts 269

   270
The algorithms that we consider in this section are based on a simple operation known as merging: combining two ordered arrays to make one larger ordered array. This operation immediately leads to a simple recursive sort method known as merge- sort: to sort an array, divide it into two halves, sort the two halves (recursively), and then merge the results. As you will see, one of mergesort’s most attractive properties is that it guarantees to sort any array of N items in time proportional to N log N. Its prime disadvantage is that it uses extra space proportional to N.
input M E R G E S O R T E X A M P L E sort left half E E G M O R R S T E X A M P L E sort right half E E G M O R R S A E E L M P T X merge results A E E E E G L M M O P R R S T X
Mergesort overview
Abstract in-place merge The straightforward approach to implementing merg- ing is to design a method that merges two disjoint ordered arrays of Comparable ob- jects into a third array. This strategy is easy to implement: create an output array of the requisite size and then choose successively the smallest remaining item from the two input arrays to be the next item added to the output array.
However, when we mergesort a large array, we are doing a huge number of merges, so the cost of creating a new array to hold the output every time that we do a merge is problematic. It would be much more desirable to have an in-place method so that we could sort the  rst half of the array in place, then sort the second half of the array in place, then do the merge of the two halves by moving the items around within the ar- ray, without using a signi cant amount of other extra space. It is worthwhile to pause momentarily to consider how you might do that. At  rst blush, this problem seems to be one that must be simple to solve, but solutions that are known are quite complicated, especially by comparison to alternatives that use extra space.
Still, the abstraction of an in-place merge is useful. Accordingly, we use the method signature merge(a, lo, mid, hi) to specify a merge method that puts the result of merging the subarrays a[lo..mid] with a[mid+1..hi] into a single ordered array, leaving the result in a[lo..hi]. The code on the next page implements this merge method in just a few lines by copying everything to an auxiliary array and then merging back to the original. Another approach is described in Exercise 2.2.9.
 www.it-ebooks.info
2.2 MergeSort

   Abstract in-place merge
  public static void merge(Comparable[] a, int lo, int mid, int hi)
  {  // Merge a[lo..mid] with a[mid+1..hi].
     int i = lo, j = mid+1;
     for (int k = lo; k <= hi; k++)  // Copy a[lo..hi] to aux[lo..hi].
        aux[k] = a[k];
     for (int k = lo; k <= hi; k++)  // Merge back to a[lo..hi].
        if      (i > mid)              a[k] = aux[j++];
        else if (j > hi )              a[k] = aux[i++];
        else if (less(aux[j], aux[i])) a[k] = aux[j++];
        else                           a[k] = aux[i++];
  }
This method merges by  rst copying into the auxiliary array aux[] then merging back to a[]. In the merge (the second for loop), there are four conditions: left half exhausted (take from the right), right half exhausted (take from the left), current key on right less than current key on left (take from the right), and current key on right greater than or equal to current key on left (take from the left).
a[] aux[]
k0123456789ij0123456789 input EEGMRACERT ---------- copy EEGMRACERT EEGMRACERT
      merged result
0A
1AC
2ACE
3ACEE
4ACEEE 5ACEEEG 6ACEEEGM 7ACEEEGMR 8ACEEEGMRR 9ACEEEGMRRT
A C E E E G M R R T
05 06EEGMRACERT 07EEGMR CERT 17EEGMR ERT
Abstract in-place merge trace
www.it-ebooks.info
27 28 38 48 58 59 6 10
EGMR ERT GMR ERT GMR RT
MR RT R RT RT T
2.2 n Mergesort 271
272 Chapter 2 n Sorting
Top-down mergesort Algorithm 2.4 is a recur- sive mergesort implementation based on this abstract in- place merge. It is one of the best-known examples of the utility of the divide-and-conquer paradigm for ef cient algorithm design. This recursive code is the basis for an inductive proof that the algorithm sorts the array: if it sorts the two subarrays, it sorts the whole array, by merg- ing together the subarrays.
To understand mergesort, it is worthwhile to consider carefully the dynamics of the method calls, shown in the trace at right. To sort a[0..15], the sort() method calls itself to sort a[0..7] then calls itself to sort a[0..3] and a[0..1] before  nally doing the  rst merge of a[0] with a[1] after calling itself to sort a[0] and then a[1] (for brevity, we omit the calls for the base-case 1-entry sorts in the trace). Then the next merge is a[2] with a[3] and then a[0..1] with a[2..3] and so forth. From this trace, we see that the sort code simply provides an orga- nized way to sequence the calls to the merge() method. This insight will be useful later in this section.
The recursive code also provides us with the basis for analyzing mergesort’s running time. Because mergesort is a prototype of the divide-and-conquer algorithm de- sign paradigm, we will consider this analysis in detail.
 www.it-ebooks.info
sort left half
sort(a, 0, 7)
  sort(a, 0, 3)
    sort(a, 0, 1)
      merge(a, 0, 0, 1)
    sort(a, 2, 3)
      merge(a, 2, 2, 3)
    merge(a, 0, 1, 3)
  sort(a, 4, 7)
    sort(a, 4, 5)
      merge(a, 4, 4, 5)
    sort(a, 6, 7)
      merge(a, 6, 6, 7)
merge results
    sort(a, 8, 11)
      sort(a, 8, 9)
        merge(a, 8, 8, 9)
      sort(a, 10, 11)
        merge(a, 10, 10, 11)
      merge(a, 8, 9, 11)
    sort(a, 12, 15)
      sort(a, 12, 13)
        merge(a, 12, 12, 13)
      sort(a, 14, 15)
        merge(a, 14, 14,15)
      merge(a, 12, 13, 15)
    merge(a, 8, 11, 15)
  merge(a, 0, 7, 15)
Top-down mergesort call trace
sort(a, 0, 15)
  merge(a, 4, 5, 7)
merge(a, 0, 3, 7)
sort
right half sort(a, 8, 15)
 proposition F. Top-down mergesort uses between 1⁄2 N lg N and N lg N compares to sort any array of length N.
proof: Let C(N) be the number of compares needed to sort an array of length N. We have C(0)=C(1)=0 and for N > 0 we can write a recurrence relationship that directly mirrors the recursive sort() method to establish an upper bound:
C(N) C (⎡N/2⎤)  C (⎣N/2⎦)  N.
The  rst term on the right is the number of compares to sort the left half of the ar- ray, the second term is the number of compares to sort the right half, and the third

 aLgorIthM 2.4 top-down mergesort
  public class Merge
  {
     private static Comparable[] aux;      // auxiliary array for merges
     public static void sort(Comparable[] a)
     {
        aux = new Comparable[a.length];    // Allocate space just once.
        sort(a, 0, a.length - 1);
     }
     private static void sort(Comparable[] a, int lo, int hi)
     {  // Sort a[lo..hi].
        if (hi <= lo) return;
        int mid = lo + (hi - lo)/2;
        sort(a, lo, mid);       // Sort left half.
        sort(a, mid+1, hi);     // Sort right half.
        merge(a, lo, mid, hi);  // Merge results (code on page 271).
} }
To sort a subarray a[lo..hi] we divide it into two parts: a[lo..mid] and a[mid+1..hi], sort them independently (via recursive calls), and merge the resulting ordered subarrays to produce the result.
2.2 n Mergesort 273
   lo hi merge(a, 0, 0, 1)
      merge(a,  2,  2,  3)
    merge(a,  0,  1,  3)
      merge(a,  4,  4,  5)
      merge(a,  6,  6,  7)
    merge(a,  4,  5,  7)
  merge(a,  0,  3,  7)
      merge(a,  8,  8,  9)
      merge(a, 10, 10, 11)
    merge(a,  8,  9, 11)
      merge(a, 12, 12, 13)
      merge(a, 14, 14, 15)
    merge(a, 12, 13, 15)
  merge(a,  8, 11, 15)
merge(a,  0,  7, 15)
a[]
0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
MERGESORTEXAMPLE
   EMRGESORT EMGRESORT EGMRESORT EGMRESORT EGMRESORT EGMREORST EEGMORRST EEGMORRSE EEGMORRSE EEGMORRSA EEGMORRSA EEGMORRSA EEGMORRSA EEGMORRSA AEEEEGLMM
EXAMPLE EXAMPLE EXAMPLE EXAMPLE EXAMPLE EXAMPLE EXAMPLE TXAMPLE TAXMPLE ETXMPLE ETXMPLE ETXMPEL ETXELMP EELMPTX OPRRSTX
Trace of merge results for top-down mergesort
www.it-ebooks.info
274 Chapter 2 n Sorting
 term is the number of compares for the merge. The lower bound C(N )  C (⎡N/2⎤)  C(⎣N/2⎦)  ⎣N/2⎦
follows because the number of compares for the merge is at least ⎣N/2⎦ .
We derive an exact solution to the recurrence when equality holds and N is a
power of 2 (say N = 2n). First, since ⎣N/2⎦ = ⎡N/2⎤ = 2n1, we have C(2n ) = 2C(2n1)  2n.
Dividing both sides by 2n gives
C(2n )/2n = C(2n1)/2n1  1.
Applying the same equation to the  rst term on the right, we have C(2n )/2n = C(2n2)/2n2  1  1.
Repeating the previous step n  1 additional times gives C(2n )/2n =C(20)/20  n.
which, after multiplying both sides by 2n, leaves us with the solution C(N ) = C(2n ) = n 2n = N lg N.
Exact solutions for general N are more complicated, but it is not dif cult to apply the same argument to the inequalities describing the bounds on the number of compares to prove the stated result for all values of N. This proof is valid no matter what the input values are and no matter in what order they appear.
Another way to understand Proposition F is to examine the tree drawn below, where each node depicts a subarray for which sort() does a merge(). The tree has precisely n levels. For k from 0 to n  1, the kth level from the top depicts 2k subarrays, each of length 2nk, each of which thus requires at most 2nk compares for the merge. Thus we have 2k · 2nk = 2n total cost for each of the n levels, for a total of n2n =NlgN.
 a[0..15]
     a[0..7]
a[0..3] a[4..7]
a[0..1] a[2..3] a[4..5] a[6..7]
a[8..15]
a[8..11] a[12..15]
lg N
            a[8..9] a[10..11] a[12..13] a[14..15]
 Mergesort subarray dependence tree for N = 16
www.it-ebooks.info

PropositionS F and G tell us that we can expect the time required by mergesort to be proportional to Nlog N. That fact brings us to a different level from the elementary methods in Section 2.1 because it tells us that we can sort huge arrays using just a logarithmic factor more time than it takes to examine every entry. You can sort millions of items (or more) with mergesort, but not with insertion sort or selection sort. The primary drawback of mergesort is that it requires extra space proportional to N, for the auxiliary array for merging. If space is at a premium, we need to consider another method. On the other hand, we can cut the running time of mergesort substantially with some carefully considered modi cations to the implementation.
Use insertion sort for small subarrays We can improve most recursive algorithms by handling small cases differently, because the recursion guarantees that the method will be used often for small cases, so improvements in handling them lead to improvements in the whole algorithm. In the case of sorting, we know that insertion sort (or selection sort) is simple and therefore likely to be faster than mergesort for tiny subarrays. As usual, a visual trace provides insight into the operation of mergesort. The visual trace on the next page shows the operation of a mergesort implementation with a cutoff for small subarrays. Switching to insertion sort for small subarrays (length 15 or less, say) will improve the running time of a typical mergesort implementation by 10 to 15 per- cent (see Exercise 2.2.23).
Test whether the array is already in order We can reduce the running time to be linear for arrays that are already in order by adding a test to skip the call to merge() if a[mid] is less than or equal to a[mid+1]. With this change, we still do all the recursive calls, but the running time for any sorted subarray is linear (see Exercise 2.2.8).
Eliminate the copy to the auxiliary array It is possible to eliminate the time (but not the space) taken to copy to the auxiliary array used for merging. To do so, we use two invocations of the sort method: one takes its input from the given array and puts the sorted output in the auxiliary array; the other takes its input from the auxiliary array and puts the sorted output in the given array. With this approach, in a bit of recursive trickery, we can arrange the recursive calls such that the computation switches the roles of the input array and the auxiliary array at each level (see Exercise 2.2.11).
www.it-ebooks.info
2.2 n Mergesort 275
 proposition G. Top-down mergesort uses at most 6NlgN array accesses to sort an array of length N.
proof: Each merge uses at most 6N array accesses (2N for the copy, 2N for the move back, and at most 2N for compares). The result follows from the same argu- ment as for Proposition F.

 276 Chapter 2 n Sorting
 rst subarray second subarray  rst merge
 rst half sorted
second half sorted result
Visual trace of top-down mergesort with cuto  for small subarrays
www.it-ebooks.info
                                                                                                                                                                                                                                                                                                                                                                                                                                  It is appropriate to repeat here a point raised in Chapter 1 that is easily forgotten and needs reemphasis. Locally, we treat each algorithm in this book as if it were critical in some application. Globally, we try to reach general conclusions about which approach to recommend. Our discussion of such improvements is not necessarily a recommen- dation to always implement them, rather a warning not to draw absolute conclusions about performance from initial implementations. When addressing a new problem, your best bet is to use the simplest implementation with which you are comfortable and then re ne it if it becomes a bottleneck. Addressing improvements that decrease running time just by a constant factor may not otherwise be worthwhile. You need to test the effectiveness of speci c improvements by running experiments, as we indicate in exercises throughout.
In the case of mergesort, the three improvements just listed are simple to implement and are of interest when mergesort is the method of choice—for example, in situations discussed at the end of this chapter.
Bottom-up mergesort The recursive implementation of mergesort is prototypi- cal of the divide-and-conquer algorithm design paradigm, where we solve a large prob- lem by dividing it into pieces, solving the subproblems, then using the solutions for the pieces to solve the whole problem. Even though we are thinking in terms of merging together two large subarrays, the fact is that most merges are merging together tiny subarrays. Another way to implement mergesort is to organize the merges so that we do all the merges of tiny subarrays on one pass, then do a second pass to merge those sub- arrays in pairs, and so forth, continuing until we
sz = 1
4
8 16
do a merge that encompasses the whole array. This method requires even less code than the standard recursive implementation. We start by doing a pass 2 of 1-by-1 merges (considering individual items as subarrays of size 1), then a pass of 2-by-2 merges (merge subarrays of size 2 to make subarrays of
size 4), then 4-by-4 merges, and so forth. The sec- ond subarray may be smaller than the  rst in the last merge on each pass (which is no problem for merge()), but otherwise all merges involve subar- rays of equal size, doubling the sorted subarray size for the next pass.
www.it-ebooks.info
Visual trace of bottom-up mergesort
2.2 n Mergesort 277

 278 Chapter 2 n Sorting
 Bottom-up mergesort
  public class MergeBU
  {
     private static Comparable[] aux;      // auxiliary array for merges
     // See page 271 for merge() code.
     public static void sort(Comparable[] a)
     {  // Do lg N passes of pairwise merges.
 } }
int N = a.length;
aux = new Comparable[N];
for (int sz = 1; sz < N; sz = sz+sz)
                                         // sz: subarray size
for (int lo = 0; lo < N-sz; lo += sz+sz) // lo: subarray index
merge(a, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1));
 Bottom-up mergesort consists of a sequence of passes over the whole array, doing sz-by-sz merges, starting with sz equal to 1 and doubling sz on each pass. The  nal subarray is of size sz only when the array size is an even multiple of sz (otherwise it is less than sz).
 a[i]
         0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
MERGESORTEXAMPLE EMRGESORTEXAMPLE EMGRESORTEXAMPLE EMGRESORTEXAMPLE EMGRESORTEXAMPLE EMGRESORETXAMPLE EMGRESORETAXMPLE EMGRESORETAXMPLE EMGRESORETAXMPEL
EGMRESORETAXMPEL EGMREORSETAXMPEL EGMREORSAETXMPEL EGMREORSAETXELMP
EEGMORRSAETXELMP EEGMORRSAEELMPTX
AEEEEGLMMOPRRSTX
Trace of merge results for bottom-up mergesort
 sz = 1
      merge(a,  0,  0,  1)
      merge(a,  2,  2,  3)
      merge(a,  4,  4,  5)
      merge(a,  6,  6,  7)
      merge(a,  8,  8,  9)
      merge(a, 10, 10, 11)
      merge(a, 12, 12, 13)
      merge(a, 14, 14, 15)
sz = 2
    merge(a,  0,  1,  3)
    merge(a,  4,  5,  7)
    merge(a,  8,  9, 11)
    merge(a, 12, 13, 15)
sz = 4
  merge(a,  0,  3,  7)
  merge(a,  8, 11, 15)
sz = 8
merge(a,  0,  7, 15)
www.it-ebooks.info
 When the array length is a power of 2, top-down and bottom-up mergesort per- form precisely the same compares and array accesses, just in a different order. When the array length is not a power of 2, the sequence of compares and array accesses for the two algorithms will be different (see Exercise 2.2.5).
A version of bottom-up mergesort is the method of choice for sorting data orga- nized in a linked list. Consider the list to be sorted sublists of size 1, then pass through to make sorted sublists of size 2 linked together, then size 4, and so forth. This method rearranges the links to sort the list in place (without creating any new list nodes).
Both the top-down and bottom-up approaches to implementing a divide-and- conquer algorithm are intuitive. The lesson that you can take from mergesort is this: Whenever you encounter an algorithm based on one of these approaches, it is worth considering the other. Do you want to solve the problem by breaking it up into smaller problems (and solving them recursively) as in Merge.sort() or by building small solu- tions into larger ones as in MergeBU.sort()?
The complexity of sorting One important reason to know about mergesort is that we use it as the basis for proving a fundamental result in the  eld of computational complexity that helps us understand the intrinsic dif culty of sorting. In general, com- putational complexity plays an important role in the design of algorithms, and this result in particular is directly relevant to the design of sorting algorithms, so we next consider it in detail.
The  rst step in a study of complexity is to establish a model of computation. Gen- erally, researchers strive to understand the simplest model relevant to a problem. For sorting, we study the class of compare-based algorithms that make their decisions about items only on the basis of comparing keys. A compare-based algorithm can do an ar- bitrary amount of computation between compares, but cannot get any information about a key except by comparing it with another one. Because of our restriction to the Comparable API, all of the algorithms in this chapter are in this class (note that we are ignoring the cost of array accesses), as are many algorithms that we might imagine. In Chapter 5, we consider algorithms that are not restricted to Comparable items.
www.it-ebooks.info
2.2 n Mergesort 279
 proposition H. Bottom-up mergesort uses between 1⁄2 N lg N and N lg N compares and at most 6N lg N array accesses to sort an array of length N.
proof: Thenumberofpassesthroughthearrayisprecisely⎡lgN⎤(thatisprecisely the value of n such that 2n – 1 < N  2n). For each pass, the number of array accesses is exactly 6N and the number of compares is at most N and no less than N/ 2.

 280 Chapter 2 n Sorting
 propositioni. Nocompare-basedsortingalgorithmcanguaranteetosortNitems with fewer than lg(N !) ~ N lg N compares.
proof: First, we assume that the keys are all distinct, since any algorithm must be able to sort such inputs. Now, we use a binary tree to describe the sequence of com- pares.Eachnodeinthetreeiseitheraleaf i0 i1 i2 ... iN-1 thatindicatesthatthe sort is complete and has discovered that the original inputs were in the order a[i0], a[i1], ...a[iN-1], or an internal node i:j that corresponds to a com- pare operation between a[i] and a[j], with a left subtree corresponding to the sequence of compares in the case that a[i] is less than a[j], and a right subtree corresponding to what happens if a[i] is greater than a[j]. Each path from the root to a leaf corresponds to the sequence of compares that the algorithm uses to establish the ordering given in the leaf. For example, here is a compare tree for N = 3:
     0:1
   1:2
0 1 2 0:2
021
1 0 2
0:2
120
1:2
           201
210
We never explicitly construct such a tree—it is a mathematical device for describ- ing the compares used by any algorithm.
The  rst key observation in the proof is that the tree must have at least N ! leaves because there are N ! different permutations of N distinct keys. If there are fewer than N ! leaves, then some permutation is missing from the leaves, and the algo- rithm would fail for that permutation.
The number of internal nodes on a path from the root to a leaf in the tree is the number of compares used by the algorithm for some input. We are interested in the length of the longest such path in the tree (known as the tree height) since it mea- sures the worst-case number of compares used by the algorithm. Now, it is a basic combinatorial property of binary trees that a tree of height h has no more than 2h leaves—the tree of height h with the maximum number of leaves is perfectly bal- anced, or complete. An example for h = 4 is diagrammed on the next page.
www.it-ebooks.info

complete tree of height 4 (gray) has 2 4 = 16 leaves
any other tree of height 4 (black) has fewer than 16 leaves
2.2 n Mergesort 281
                                    Combining the previous two paragraphs, we have shown that any compare-based sorting algorithm corresponds to a compare tree of height h with
N !  number of leaves  2h
                                                    h
                                                    at least N! leaves
no more than 2h leaves
The value of h is precisely the worst-case number of compares, so we can take the logarithm (base 2) of both sides of this equation and conclude that the number of compares used by any algorithm must be at least lg (N !). The approximation lg (N !) ~ N lg N follows immediately from Stirling’s approximation to the factorial function (see page 185).
This result serves as a guide for us to know, when designing a sorting algorithm, how well we can expect to do. For example, without such a result, one might set out to try to design a compare-based sorting algorithm that uses half as many compares as does mergesort, in the worst case. The lower bound in Proposition I says that such an effort is futile—no such algorithm exists. It is an extremely strong statement that applies to any conceivable compare-based algorithm.
Proposition H asserts that the number of compares used by mergesort in the worst case is ~ N lg N. This result is an upper bound on the dif culty of the sorting problem in the sense that a better algorithm would have to guarantee to use a smaller number of compares. Proposition I asserts that no sorting algorithm can guarantee to use fewer
www.it-ebooks.info

282 Chapter 2 n Sorting
than ~ N lg N compares. It is a lower bound on the dif culty of the sorting problem in the sense that even the best possible algorithm must use at least that many compares in the worst case. Together, they imply:
 proposition J. Mergesort is an asymptotically optimal compare-based sorting algorithm.
proof: Precisely,wemeanbythisstatementthatboththenumberofcomparesused by mergesort in the worst case and the minimum number of compares that any com- pare-based sorting algorithm can guarantee are ~N lg N. Propositions H and I es- tablish these facts.
It is important to note that, like the model of computation, we need to precisely de ne what we mean by an optimal algorithm. For example, we might tighten the de nition of optimality and insist that an optimal algorithm for sorting is one that uses precisely lg (N !) compares. We do not do so because we could not notice the difference between such an algorithm and (for example) mergesort for large N. Or, we might broaden the de nition of optimality to include any sorting algorithm whose worst-case number of compares is within a constant factor of N lg N. We do not do so because we might very well notice the difference between such an algorithm and mergesort for large N.
Computational complexity may seem rather abstract, but fundamental re- search on the intrinsic dif culty of solving computational problems hardly needs jus- ti cation. Moreover, when it does apply, it is emphatically the case that computational complexity affects the development of good software. First, good upper bounds allow software engineers to provide performance guarantees; there are many documented instances where poor performance has been traced to someone using a quadratic sort instead of a linearithmic one. Second, good lower bounds spare us the effort of search- ing for performance improvements that are not attainable.
But the optimality of mergesort is not the end of the story and should not be mis- used to indicate that we need not consider other methods for practical applications. That is not the case because the theory in this section has a number of limitations. For example:
n Mergesort is not optimal with respect to space usage.
n The worst case may not be likely in practice.
n Operations other than compares (such as array accesses) may be important. n One can sort certain data without using any compares.
Thus, we shall be considering several other sorting methods in this book.
www.it-ebooks.info

Q. Is mergesort faster than shellsort?
A. In practice, their running times are within a small constant factor of one another (when shellsort is using a well-tested increment sequence like the one in Algorithm 2.3), so comparative performance depends on the implementations.
    % java SortCompare Merge Shell 100000
    For 100000 random Double values
        Merge is 1.2 times faster than Shell
In theory, no one has been able to prove that shellsort is linearithmic for random data, so there remains the possibility that the asymptotic growth of the average-case perfor- mance of shellsort is higher. Such a gap has been proven for worst-case performance, but it is not relevant in practice.
Q. Why not make the aux[] array local to merge()?
A. Toavoidtheoverheadofcreatinganarrayforeverymerge,eventhetinyones.This cost would dominate the running time of mergesort (see Exercise 2.2.26). A more proper solution (which we avoid in the text to reduce clutter in the code) is to make aux[] local to sort() and pass it as an argument to merge() (see Exercise 2.2.9).
Q. How does mergesort fare when there are duplicate values in the array?
A. Ifalltheitemshavethesamevalue,therunningtimeislinear(withtheextratestto skip the merge when the array is sorted), but if there is more than one duplicate value, this performance gain is not necessarily realized. For example, suppose that the input array consists of N items with one value in odd positions and N items with another value in even positions. The running time is linearithmic for such an array (it satis es the same recurrence as for items with distinct values), not linear.
www.it-ebooks.info
2.2 n Mergesort 283
 Q&A

284 Chapter 2 n Sorting
 ExErcisEs
 2.2.1 Giveatrace,inthestyleofthetracegivenatthebeginningofthissection,show- inghowthekeysA E Q S U Y E I N O S Taremergedwiththeabstractin-place merge() method.
2.2.2 Givetraces,inthestyleofthetracegivenwithAlgorithm2.4,showinghowthe keys E A S Y Q U E S T I O N are sorted with top-down mergesort.
2.2.3 Answer Exercise 2.2.2 for bottom-up mergesort.
2.2.4 Does the abstract in-place merge produce proper output if and only if the two
input subarrays are in sorted order? Prove your answer, or provide a counterexample. 2.2.5 Give the sequence of subarray sizes in the merges performed by both the top-
down and the bottom-up mergesort algorithms, for N = 39.
2.2.6 Writeaprogramtocomputetheexactvalueofthenumberofarrayaccessesused by top-down mergesort and by bottom-up mergesort. Use your program to plot the val- ues for N from 1 to 512, and to compare the exact values with the upper bound 6N lg N.
2.2.7 Showthatthenumberofcomparesusedbymergesortismonotonicallyincreas- ing (C(N+1) > C(N) for all N > 0).
2.2.8 Suppose that Algorithm 2.4 is modi ed to skip the call on merge() whenever a[mid] <= a[mid+1].Provethatthenumberofcomparesusedtomergesortasorted array is linear.
2.2.9 Useofastaticarraylikeaux[]isinadvisableinlibrarysoftwarebecausemultiple clients might use the class concurrently. Give an implementation of Merge that does not use a static array. Do not make aux[] local to merge() (see the Q&A for this section). Hint : Pass the auxiliary array as an argument to the recursive sort().
www.it-ebooks.info

2.2.10 Faster merge. Implement a version of merge() that copies the second half of a[] to aux[] in decreasing order and then does the merge back to a[]. This change al- lows you to remove the code to test that each of the halves has been exhausted from the inner loop. Note: The resulting sort is not stable (see page 341).
2.2.11 Improvements. Implement the three improvements to mergesort that are de- scribed in the text onpage 275: Add a cutoff for small subarrays, test whether the array is already in order, and avoid the copy by switching arguments in the recursive code.
2.2.12 Sublinear extra space. Develop a merge implementation that reduces the extra space requirement to max(M, N/M), based on the following idea: Divide the array into N/M blocks of size M (for simplicity in this description, assume that N is a multiple of M). Then, (i) considering the blocks as items with their  rst key as the sort key, sort them using selection sort; and (ii) run through the array merging the  rst block with the second, then the second block with the third, and so forth.
2.2.13 Lower bound for average case. Prove that the expected number of compares used by any compare-based sorting algorithm must be at least ~N lg N (assuming that all possible orderings of the input are equally likely). Hint: The expected number of com- pares is at least the external path length of the compare tree (the sum of the lengths of the paths from the root to all leaves), which is minimized when it is balanced.
2.2.14 Merging sorted queues. Develop a static method that takes two queues of sorted items as arguments and returns a queue that results from merging the queues into sorted order.
2.2.15 Bottom-up queue mergesort. Develop a bottom-up mergesort implementation based on the following approach: Given N items, create N queues, each containing one of the items. Create a queue of the N queues. Then repeatedly apply the merging opera- tion of Exercise 2.2.14 to the  rst two queues and reinsert the merged queue at the end. Repeat until the queue of queues contains only one queue.
2.2.16 Natural mergesort. Write a version of bottom-up mergesort that takes advan- tage of order in the array by proceeding as follows each time it needs to  nd two arrays to merge:  nd a sorted subarray (by incrementing a pointer until  nding an entry that is smaller than its predecessor in the array), then  nd the next, then merge them. Ana- lyze the running time of this algorithm in terms of the array size and the number of
www.it-ebooks.info
2.2 n Mergesort 285
 crEAtivE problEms

286 Chapter 2 n Sorting
crEAtivE problEms (continued)
maximal increasing sequences in the array.
2.2.17 Linked-list sort. Implement a natural mergesort for linked lists. (This is the method of choice for sorting linked lists because it uses no extra space and is guaranteed to be linearithmic.)
2.2.18 Shuf ing a linked list. Develop and implement a divide-and-conquer algo- rithm that randomly shuf es a linked list in linearithmic time and logarithmic extra space.
2.2.19 Inversions. Develop and implement a linearithmic algorithm for computing the number of inversions in a given array (the number of exchanges that would be performed by insertion sort for that array—see Section 2.1). This quantity is related to the Kendall tau distance; see Section 2.5.
2.2.20 Index sort. Develop and implement a version of mergesort that does not rear- range the array, but returns an int[] array perm such that perm[i] is the index of the i th smallest entry in the array.
2.2.21 Triplicates. Given three lists of N names each, devise a linearithmic algorithm to determine if there is any name common to all three lists, and if so, return the lexico- graphically  rst such name.
2.2.22 3-way mergesort. Suppose instead of dividing in half at each step, you divide into thirds, sort each third, and combine using a 3-way merge. What is the order of growth of the overall running time of this algorithm?
 www.it-ebooks.info

2.2.23 Improvements. Run empirical studies to evaluate the effectiveness of each of the three improvements to mergesort that are described in the text (see Exercise 2.2.11). Also, compare the performance of the merge implementation given in the text with the merge described in Exercise 2.2.10. In particular, empirically determine the best value of the parameter that decides when to switch to insertion sort for small subarrays.
2.2.24 Sort-test improvement. Run empirical studies for large randomly ordered ar- rays to study the effectiveness of the modi cation described in Exercise 2.2.8 for ran- dom data. In particular, develop a hypothesis about the average number of times the test (whether an array is sorted) succeeds, as a function of N (the original array size for the sort).
2.2.25 Multiway mergesort. Develop a mergesort implementation based on the idea of doing k-way merges (rather than 2-way merges). Analyze your algorithm, develop a hy- pothesis regarding the best value of k, and run experiments to validate your hypothesis.
2.2.26 Array creation. Use SortCompare to get a rough idea of the effect on perfor- mance on your machine of creating aux[] in merge() rather than in sort().
2.2.27 Subarray lengths. Run mergesort for large random arrays, and make an empiri- cal determination of the average length of the other subarray when the  rst subarray exhausts, as a function of N (the sum of the two subarray sizes for a given merge).
2.2.28 Top-down versus bottom-up. Use SortCompare to compare top-down and bot- tom-up mergesort for N=103, 104, 105, and 106.
2.2.29 Natural mergesort. Determine empirically the number of passes needed in a natural mergesort (see Exercise 2.2.16) for random Long keys with N=103, 106, and 109. Hint: You do not need to implement a sort (or even generate full 64-bit keys) to complete this exercise.
www.it-ebooks.info
2.2 n Mergesort 287
 ExpErimENts

   The subject of this section is the sorting algorithm that is probably used more widely than any other, quicksort. Quicksort is popular because it is not dif cult to implement, works well for a variety of different kinds of input data, and is substantially faster than any other sorting method in typical applications. The quicksort algorithm’s desirable features are that it is in-place (uses only a small auxiliary stack) and that it requires time proportional to N log N on the average to sort an array of length N. None of the algorithms that we have so far considered combine these two properties. Furthermore, quicksort has a shorter inner loop than most other sorting algorithms, which means that it is fast in practice as well as in theory. Its primary drawback is that it is fragile in the sense that some care is involved in the implementation to be sure to avoid bad performance. Numerous examples of mistakes leading to quadratic perfor- mance in practice are documented in the literature. Fortunately, the lessons learned from these mistakes have led to various improvements to the algorithm that make it of even broader utility, as we shall see.
The basic algorithm Quicksort is a divide-and-conquer method for sorting. It works by partitioning an array into two subarrays, then sorting the subarrays indepen- dently. Quicksort is complementary to mergesort: for mergesort, we break the array into two subarrays to be sorted and then combine the ordered subarrays to make the whole ordered array; for quicksort, we rearrange the array such that, when the two subarrays are sorted, the whole array is ordered. In the  rst instance, we do the two recursive calls before working on the whole array; in the second instance, we do the two recursive calls after working on the whole array. For mergesort, the array is divided in half; for quicksort, the position of the partition depends on the contents of the array.
input shu e
partition
sort left sort right result
QUICKSORTEXAMPLE KRATELEPUIMQCXOS
partitioning item
ECAIEKLPUTMQRXOS not greater not less
ACEEIKLPUTMQRXOS ACEEIKLMOPQRSTUX ACEEIKLMOPQRSTUX
Quicksort overview
      288
www.it-ebooks.info
2.3 QUiCkSort

  aLgorIthM 2.5 Quicksort
  public class Quick
  {
     public static void sort(Comparable[] a)
     {
        StdRandom.shuffle(a);          // Eliminate dependence on input.
        sort(a, 0, a.length - 1);
     }
     private static void sort(Comparable[] a, int lo, int hi)
     {
        if (hi <= lo) return;
        int j = partition(a, lo, hi);  // Partition (see page 291).
        sort(a, lo, j-1);              // Sort left part a[lo .. j-1].
        sort(a, j+1, hi);              // Sort right part a[j+1 .. hi].
} }
Quicksort is a recursive program that sorts a subarray a[lo..hi] by using a partition() method that puts a[j] into position and arranges the rest of the entries such that the recursive calls  nish the sort.
initial values random shu e
no partition for subarrays of size 1
lojhi   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 QUICKSORTEXAMPLE KRATELEPUIMQCXOS 0 5 15 E C A I E K L P U T M Q R X O S 034ECAEIKLPUTMQRXOS 022ACEEIKLPUTMQRXOS 001ACEEIKLPUTMQRXOS 1 1ACEEIKLPUTMQRXOS 4 4ACEEIKLPUTMQRXOS 6 6 15 A C E E I K L P U T M Q R X O S 7 9 15 A C E E I K L M O P T Q R X U S 778ACEEIKLMOPTQRXUS 8 8ACEEIKLMOPTQRXUS 10 13 15 A C E E I K L M O P S Q R T U X 10 12 12 A C E E I K L M O P R Q S T U X 10 11 11 A C E E I K L M O P Q R S T U X 10 10ACEEIKLMOPQRSTUX 14 14 15 A C E E I K L M O P Q R S T U X 15 15ACEEIKLMOPQRSTUX
ACEEIKLMOPQRSTUX
Quicksort trace (array contents after each partition)
2.3 n Quicksort 289
         result
www.it-ebooks.info
290 Chapter 2 n Sorting
The crux of the method is the partitioning process, which rearranges the array to make the following three conditions hold:
n The entry a[j] is in its  nal place in the array, for some j. n No entry in a[lo] through a[j-1] is greater than a[j].
n No entry in a[j+1] through a[hi] is less than a[j].
We achieve a complete sort by partitioning, then recursively applying the method. Because the partitioning process always  xes one item into its position, a formal proof by induction that the recursive method constitutes a proper sort is not dif cult to develop: if the left subarray and the right subarray are both properly sorted, then the result array, made up of the left subarray (in order, with no entry larger than the par- titioning item), the partitioning item, and the right subarray (in order, with no entry smaller that the partitioning item), is in order. Algorithm 2.5 is a recursive program that implements this idea. It is a randomized algorithm, be- cause it randomly shuf es the array before sorting it. Our reason for doing so is to be able to predict (and depend
upon) its performance characteristics, as discussed below. To complete the implementation, we need to implement the partitioning method. We use the following general strat- egy: First, we arbitrarily choose a[lo] to be the partitioning item—the one that will go into its  nal position. Next, we scan from the left end of the array until we  nd an entry greater than (or equal to) the partitioning item, and we scan from the right end of the array until we  nd an entry less than (or equal to) the partitioning item. The two items that stopped the scans are out of place in the  nal partitioned array, so we exchange them. Continuing in this way, we ensure that no array entries to the left of the left index i are greater than the partitioning item, and no array entries to the right of the right index j are less than the partitioning item. When the scan indices cross, all that we need to do to complete the partitioning process is to exchange the partitioning item a[lo] with the
rightmost entry of the left subarray (a[j]) and return its index j.
There are several subtle issues with respect to implementing quicksort that are re-  ected in this code and worthy of mention, because each either can lead to incorrect code or can signi cantly impact performance. Next, we discuss several of these is- sues. Later in this section, we will consider three important higher-level algorithmic
improvements.
   v
before
during
after
Quicksort partitioning overview
    lo
hi
    v
 v
 v
     ij
    vv
 v
      lo j hi
www.it-ebooks.info

 2.3 n Quicksort 291
 Quicksort partitioning
  private static int partition(Comparable[] a, int lo, int hi)
  {  // Partition into a[lo..i-1], a[i], a[i+1..hi].
     int i = lo, j = hi+1;            // left and right scan indices
     Comparable v = a[lo];            // partitioning item
     while (true)
     {  // Scan right, scan left, check for scan complete, and exchange.
        while (less(a[++i], v)) if (i == hi) break;
        while (less(v, a[--j])) if (j == lo) break;
        if (i >= j) break;
        exch(a, i, j);
 }
}
exch(a, lo, j);
return j;
// Put v = a[j] into position
// with a[lo..j-1] <= a[j] <= a[j+1..hi].
 This code partitions on the item v in a[lo]. The main loop exits when the scan indices i and j cross. Within the loop, we increment i while a[i] is less than v and decrement j while a[j] is greater than v, then do an exchange to maintain the invariant property that no entries to the left of i are greater than v and no entries to the right of j are smaller than v. Once the indices meet, we complete the partitioning by exchanging a[lo] with a[j] (thus leaving the partitioning value in a[j]).
 initial values 016 scan left, scan right 112 exchange 112 scan left, scan right 3 9 exchange 3 9 scan left, scan right 5 6 exchange 5 6 scan left, scan right 6 5  nal exchange 6 5
KRATELEPUIMQCXOS KRATELEPUIMQCXOS KCATELEPUIMQRXOS KCATELEPUIMQRXOS KCAIELEPUTMQRXOS KCAIELEPUTMQRXOS KCAIEELPUTMQRXOS KCAIEELPUTMQRXOS ECAIEKLPUTMQRXOS
v a[]
ij 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
                          result
5 ECAIEKLPUTMQRXOS Partitioning trace (array contents before and after each exchange)
www.it-ebooks.info
292 Chapter 2 n Sorting
Partitioning in place If we use an extra array, partitioning is easy to implement, but not so much easier that it is worth the extra cost of copying the partitioned version back into the original. A novice Java programmer might even create a new spare array within the recursive method, for each partition, which would drastically slow down the sort.
Staying in bounds If the smallest item or the largest item in the array is the partition- ing item, we have to take care that the pointers do not run off the left or right ends of the array, respectively. Our partition() implementation has explicit tests to guard againstthiscircumstance.Thetest(j == lo)isredundant,sincethepartitioningitem is at a[lo] and not less than itself. With a similar technique on the right it is not dif-  cult to eliminate both tests (see Exercise 2.3.17).
Preserving randomness The random shuf e puts the array in random order. Since it treats all items in the subarrays uniformly, Algorithm 2.5 has the property that its two subarrays are also in random order. This fact is crucial to the predictability of the algo- rithm’s running time. An alternate way to preserve randomness is to choose a random item for partitioning within partition().
Terminating the loop Experienced programmers know to take special care to ensure that any loop must always terminate, and the partitioning loop for quicksort is no ex- ception. Properly testing whether the pointers have crossed is a bit trickier than it might seem at  rst glance. A common error is to fail to take into account that the array might contain other items with the same key value as the partitioning item.
Handling items with keys equal to the partitioning item’s key It is best to stop the left scan for items with keys greater than or equal to the partitioning item’s key and the right scan for items with key less than or equal to the partitioning item’s key, as in Algorithm 2.5. Even though this policy might seem to create unnecessary exchanges involving items with keys equal to the partitioning item’s key, it is crucial to avoiding quadratic running time in certain typical applications (see Exercise 2.3.11). Later, we discuss a better strategy for the case when the array contains a large number of items with equal keys.
Terminating the recursion Experienced programmers also know to take special care to ensure that any recursive method must always terminate, and quicksort is again no exception. For instance, a common mistake in implementing quicksort involves not ensuring that one item is always put into position, then falling into an in nite recursive loop when the partitioning item happens to be the largest or smallest item in the array.
www.it-ebooks.info

Performance characteristics Quicksort has been subjected to very thorough mathematical analysis, so that we can make precise statements about its performance. The analysis has been validated through extensive empirical experience, and is a useful tool in tuning the algorithm for optimum performance.
The inner loop of quicksort (in the partitioning method) increments an index and compares an array entry against a  xed value. This simplicity is one factor that makes quicksort quick: it is hard to envision a shorter inner loop in a sorting algorithm. For example, mergesort and shellshort are typically slower than quicksort because they also do data movement within their inner loops.
The second factor that makes quicksort quick is that it uses few compares. Ulti- mately, the ef ciency of the sort depends on how well the partitioning divides the array, which in turn depends on the value of the partitioning item’s key. Partitioning divides a large randomly ordered array into two smaller randomly ordered subarrays, but the actual split is equally likely (for distinct keys) to be anywhere in the array. Next, we consider the analysis of the algorithm, which allows us to see how this choice compares to the ideal choice.
The best case for quicksort is when each partitioning stage divides the array exactly in half. This circumstance would make the number of compares used by quicksort satisfy the divide-and-conquer recurrence CN = 2CN/2 + N. The 2CN/2 term covers the cost of sorting the two subarrays; the N is the cost of examining each entry, using one partitioning index or the other. As in the proof of Proposition F for mergesort, we know that this recurrence has the solution CN ~ N lg N. Although things do not always go this well, it is true that the partition falls in the middle on the average. Taking into account the precise probability of each partition position makes the recurrence more complicated and more dif cult to solve, but the  nal result is similar. The proof of this result is the basis for our con dence in quicksort. If you are not mathematically inclined, you may wish to skip (and trust) it; if you are mathematically inclined, you may  nd it intriguing.
2.3 n Quicksort 293
 proposition k. Quicksort uses ~ 2N ln N compares (and one-sixth that many ex- changes) on the average to sort an array of length N with distinct keys.
proof: Let CN be the average number of compares needed to sort N items with distinct values. We have C0 = C1 = 0 and for N > 1 we can write a recurrence relation- ship that directly mirrors the recursive program:
www.it-ebooks.info

294 Chapter 2 n Sorting
 CN = N  1  (C0  C1 . . . CN2  CN1) / N + (CN1  CN2 . . . C0 )/N
The  rst term is the cost of partitioning (always N  1), the second term is the average cost of sorting the left subarray (which is equally likely to be any size from 0 to N  1), and the third term is the average cost for the right subarray (which is the same as for the left subarray). Multiplying by N and collecting terms transforms this equation to
NCN = N(N  1) + 2(C0 + C1+ . . .+CN2+CN1) Subtracting the same equation for N  1 from this equation gives
NCN  (N  1)CN1= 2N + 2CN1 Rearranging terms and dividing by N(N  1) leaves
CN /(N  1) = CN1 /N  2/(N  1) which telescopes to give the result
CN ~ 2(N  1)(1/3  1/4  . . .  1/(N  1) )
The parenthesized quantity is the discrete estimate of the area under the curve 1 /x from 3 to N  1 and CN ~ 2NlnN by integration. Note that 2Nln N  1.39Nlg N, so the average number of compares is only about 39 percent higher than in the best case.
A similar (but much more complicated) analysis is needed to establish the stated result for exchanges.
When keys may not be distinct, as is typical in practical applications, precise analysis is considerably more complicated, but it is not dif cult to show that the average number of compares is no greater than CN , even when duplicate keys may be present (on page 296, we will look at a way to improve quicksort in this case).
Despite its many assets, the basic quicksort program has one potential liability: it can be extremely inef cient if the partitions are unbalanced. For example, it could be the case that the  rst partition is on the smallest item, the second partition on the next smallest item, and so forth, so that the program will remove just one item for each call, leading to an excessive number of partitions of large subarrays. Avoiding this situation is the primary reason that we randomly shuf e the array before using quicksort. This action makes it so unlikely that bad partitions will happen consistently that we need not worry about the possibility.
www.it-ebooks.info

In summary, you can be sure that the running time of Algorithm 2.5 will be within a constant factor of 1.39N lg N whenever it is used to sort N items. The same is true of mergesort, but quicksort is typically faster because (even though it does 39 per- cent more compares) it does much less data movement. This mathematical assurance is probabilistic, but you can certainly rely upon it.
Algorithmic improvements Quicksort was invented in 1960 by C. A. R. Hoare, and many people have studied and re ned it since that time. It is tempting to try to develop ways to improve quicksort: a faster sorting algorithm is computer science’s “better mousetrap,” and quicksort is a venerable method that seems to invite tinkering. Almost from the moment Hoare  rst published the algorithm, people began proposing ways to improve the algorithm. Not all of these ideas are fully successful, because the al- gorithm is so well-balanced that the effects of improvements can be more than offset by unexpected side effects, but a few of them, which we now consider, are quite effective.
www.it-ebooks.info
2.3 n Quicksort 295
 proposition l. Quicksort uses ~ N 2/2 compares in the worst case, but random shuf ing protects against this case.
proof: Bytheargumentjustgiven,thenumberofcomparesusedwhenoneofthe subarrays is empty for every partition is
N  (N  1) + (N  2)  . . .  2  1 = (N  1) N / 2
This behavior means not only that the time required will be quadratic but also that the space required to handle the recursion will be linear, which is unacceptable for large arrays. But (with quite a bit more work) it is possible to extend the analysis that we did for the average to  nd that the standard deviation of the number of compares is about .65 N, so the running time tends to the average as N grows and is unlikely to be far from the average. For example, even the rough estimate provided by Chebyshev’s inequality says that the probability that the running time is more than ten times the average for an array with a million elements is less than .00001 (and the true probability is far smaller). The probability that the running time for a large array is close to quadratic is so remote that we can safely ignore the pos- sibility (see Exercise 2.3.10). For example, the probability that quicksort will use as many compares as insertion sort or selection sort when sorting a large array on your computer is much less than the probability that your computer will be struck by lightning during the sort!

296 Chapter 2 n Sorting
If your sort code is to be used a great many times or to sort a huge array (or, in par- ticular, if it is to be used as a library sort that will be used to sort arrays of unknown characteristics), then it is worthwhile to consider the improvements that are discussed in the next few paragraphs. As noted, you need to run experiments to determine the effectiveness of these improvements and to determine the best choice of parameters for your implementation. Typically, improvements of 20 to 30 percent are available.
Cutoff to insertion sort As with most recursive algorithms, an easy way to improve the performance of quicksort is based on the following two observations:
n Quicksort is slower than insertion sort for tiny subarrays.
n Being recursive, quicksort’s sort() is certain to call itself for tiny subarrays. Accordingly, it pays to switch to insertion sort for tiny subarrays. A simple change to Algorithm 2.5 accomplishes this improvement: replace the statement
if (hi <= lo) return;
in sort() with a statement that invokes insertion sort for small subarrays:
if (hi <= lo + M) { Insertion.sort(a, lo, hi); return; }
The optimum value of the cutoff M is system-dependent, but any value between 5 and
15 is likely to work well in most situations (see Exercise 2.3.25).
Median-of-three partitioning A second easy way to improve the performance of quicksort is to use the median of a small sample of items taken from the subarray as the partitioning item. Doing so will give a slightly better partition, but at the cost of com- puting the median. It turns out that most of the available improvement comes from choosing a sample of size 3 and then partitioning on the middle item (see Exercises 2.3.18 and 2.3.19). As a bonus, we can use the sample items as sentinels at the ends of the array and remove both array bounds tests in partition().
Entropy-optimal sorting Arrays with large numbers of duplicate keys arise fre- quently in applications. For example, we might wish to sort a large personnel  le by year of birth, or perhaps to separate females from males. In such situations, the quicksort implementation that we have considered has acceptable performance, but it can be substantially improved. For example, a subarray that consists solely of items that are equal (just one key value) does not need to be processed further, but our implementation keeps partitioning down to small subarrays. In a situation where there are large numbers of duplicate keys in the input array, the recursive nature of quicksort ensures that subarrays consisting solely of items with keys that are equal will occur often. There is potential for signi cant improvement, from the linearithmic-time performance of the implementations seen so far to linear-time performance.
www.it-ebooks.info

 input
result of  rst partition
partitioning element
left subarray partially sorted
both subarrays partially sorted
result
Quicksort with median-of-3 partitioning and cuto  for small subarrays
www.it-ebooks.info
2.3 n
Quicksort 297
298 Chapter 2 n Sorting
One straightforward idea is to partition the array into three parts, one each for items with keys smaller than, equal to, and larger than the partitioning item’s key. Accomplishing this partitioning is more complicated than the 2-way partitioning that we have been using, and various different methods have been suggested for the task. It was a classical programming exercise popularized by E. W. Dijkstra as the Dutch National Flag problem, because it is like sorting an array with three possible key values, which might correspond to the three colors on the  ag.
Dijkstra’s solution to this problem leads to the remarkably simple partition code shown on the next page. It is based on a single left-to-right pass through the array that maintains a pointer lt such that a[lo..lt-1] is less than v, a pointer gt such that a[gt+1, hi] is greater than v, and a pointer i such that a[lt..i-1] are equal to v and a[i..gt] are not yet examined. Starting with i equal to lo, we process a[i] using the 3-way comparison given by the Comparable interface (instead of using less()) to directly handle the three possible cases:
n a[i] less than v: exchange a[lt] with a[i] and increment both lt and i n a[i] greater than v: exchange a[i] with a[gt] and decrement gt
n a[i] equal to v: increment i
Each of these operations both maintains the invariant and decreases the value of gt-i (so that the loop terminates). Furthermore, every item encountered leads to an exchange except for those items with keys equal to the partitioning item’s key.
Though this code was developed not long after quicksort in the 1970s, it fell out of favor because it uses many more exchanges
than the standard 2-way partitioning method
for the common case when the number of
duplicate keys in the array is not high. In the
1990s J. Bentley and D. McIlroy developed a
clever implementation that overcomes this
problem (see Exercise 2.3.22), and observed
that 3-way partitioning makes quicksort
asymptotically faster than mergesort and
other methods in practical situations
involving large numbers of equal keys. Later,
J. Bentley and R. Sedgewick developed a proof of this fact, which we discuss next.
But we proved that mergesort is optimal. How have we defeated that lower bound? The answer to this question is that Proposition I in Section 2.2 addresses worst- case performance over all possible inputs, while now we are looking at worst-case performance with some information about the key values at hand. Mergesort does not guarantee optimal performance for any given distribution of duplicates in the input:
       www.it-ebooks.info
before v lo
hi
     during after
lti gt
<v
=v
>v
          <v
=v
>v
        lo lt gt hi
3-way partitioning overview

 2.3 n Quicksort 299
 Quicksort with 3-way partitioning
  public class Quick3way
  {
     private static void sort(Comparable[] a, int lo, int hi)
     {  // See page 289 for public sort() that calls this method.
        if (hi <= lo) return;
        int lt = lo, i = lo+1, gt = hi;
        Comparable v = a[lo];
        while (i <= gt)
        {
           int cmp = a[i].compareTo(v);
           if      (cmp < 0) exch(a, lt++, i++);
           else if (cmp > 0) exch(a, i, gt--);
           else              i++;
        }  // Now a[lo..lt-1] < v = a[lt..gt] < a[gt+1..hi].
        sort(a, lo, lt - 1);
        sort(a, gt + 1, hi);
} }
This sort code partitions to put keys equal to the partitioning element in place and thus does not have to include those keys in the subarrays for the recursive calls. It is far more ef cient than the standard quicksort implementation for arrays with large numbers of duplicate keys (see text).
  a[] lt igt     0123456
v
www.it-ebooks.info
7 8 9 10 11
 0 011
0 111
1 211
1 210
1 310
139 BRRBRWBRRWWW 249 BBRRRWBRRWWW 259 BBRRRWBRRWWW 258 BBRRRWBRRWWW 257 BBRRRRBRWWWW 267 BBRRRRBRWWWW 377 BBBRRRRRWWWW 387 BBBRRRRRWWWW 387 BBBRRRRRWWWW
3-way partitioning trace (array contents after each loop iteration)
RBWWRWB RBWWRWB BRWWRWB BRRWRWB BRRWRWB
RRWBR RRWBR RRWBR RRWBW RRWBW

300 Chapter 2 n Sorting
    equal to partitioning element
Visual trace of quicksort with 3-way partitioning
for example, mergesort is linearithmic for a randomly ordered array that has only a constant number of distinct key values, but quicksort with 3-way partitioning is linear for such an array. Indeed, by examining the visual trace above, you can see that N times the number of key values is a conservative bound on the running time.
The analysis that makes these notions precise takes the distribution of key values into account. Given N keys with k distinct key values, for each i from 1 to k de ne fi to be frequency of occurrence of the i th key value and pi to be fi / N, the probability that the i th key value is found when a random entry of the array is sampled. The Shannon entropy of the keys (a classic measure of their information content) is de ned as
H =  ( p1 lg p1  p2 lg p2  . . .  pk lg pk ).
Given any array of items to be sorted, we can calculate its entropy by counting the fre- quency of each key value. Remarkably, we can also derive from the entropy both a lower bound on the number of compares and an upper bound on the number of compares used by quicksort with 3-way partitioning.
      propositionm. Nocompare-basedsortingalgorithmcanguaranteetosortNitems with fewer than NH  N compares, where H is the Shannon entropy, de ned from the frequencies of key values.
proofsketch: Thisresultfollowsfroma(relativelyeasy)generalizationofthelow- er bound proof of Proposition I in Section 2.2.
www.it-ebooks.info

Note that H = lg N when the keys are all distinct (all the probabilities are 1/N), which is consistent with Proposition I in Section 2.2 and Proposition K. The worst case for 3-way partitioning happens when the keys are distinct; when duplicate keys are present, it can do much better than mergesort. More important, these two properties together imply that quicksort with 3-way partitioning is entropy-optimal, in the sense that the average number of compares used by the best possible compare-based sorting algorithm and the average number of compares used by 3-way quicksort are within a constant factor of one another, for any given distribution of input key values.
As with standard quicksort, the running time tends to the average as the array size grows, and large deviations from the average are extremely unlikely, so that you can depend on 3-way quicksort’s running time to be proportional to N times the entropy of the distribution of input key values. This property of the algorithm is important in practice because it reduces the time of the sort from linearithmic to linear for arrays with large numbers of duplicate keys. The order of the keys is immaterial, because the algo- rithm shuf es them to protect against the worst case. The distribution of keys de nes the entropy and no compare-based algorithm can use fewer compares than de ned by the entropy. This ability to adapt to duplicates in the input makes 3-way quicksort the algorithm of choice for a library sort—clients that sort arrays containing large numbers of duplicate keys are not unusual.
A carefully tuned version of quicksort is likely to run signi cantly faster on most computers for most applications than will any other compare-based sorting method. Quicksort is widely used throughout today’s computational infrastructure because the mathematical models that we have discussed suggest that it will outperform other methods in practical applications, and extensive experiments and experience over the past several decades have validated that conclusion.
We will see in Chapter 5 that this is not quite the end of the story in the development of sorting algorithms, because it is possible to develop algorithms that do not use compares at all! But a version of quicksort turns out to be best in that situation, as well.
www.it-ebooks.info
2.3 n Quicksort 301
 proposition N. Quicksort with 3-way partitioning uses ~ (2ln 2) N H compares to sort N items, where H is the Shannon entropy, de ned from the frequencies of key values.
proof sketch: This result follows from a (relatively dif cult) generalization of the average-case analysis of quicksort in Proposition K. As with distinct keys, this costs about 39 percent more than the optimum (but within a constant factor).

302 Chapter 2 n Sorting
 Q&A
 Q. Is there some way to just divide the array into two halves, rather than letting the partitioning element fall where it may?
A. Thatisaquestionthatstumpedexpertsforoveradecade.Itistantamountto nd- ing the median key value in the array and then partitioning on that value. We discuss the problem of  nding the median onpage 346. It is possible to do so in linear time, but the cost of doing so with known algorithms (which are based on quicksort partition- ing!) far exceeds the 39 percent savings available from splitting the array into equal parts.
Q. Randomly shuf ing the array seems to take a signi cant fraction of the total time for the sort. Is doing so really worthwhile?
A. Yes.Itprotectsagainsttheworstcaseandmakestherunningtimepredictable.Hoare proposed this approach when he presented the algorithm in 1960—it is a prototypical (and among the  rst) randomized algorithm.
Q. Why all the focus on items with equal keys?
A. Theissuedirectlyimpactsperformanceinpracticalsituations.Itwasoverlookedby many for decades, with the result that some older implementations of quicksort take quadratic time for arrays with large numbers of items with equal keys, which certainly do arise in applications. Better implementations such as Algorithm 2.5 take linearith- mic time for such arrays, but improving that to linear-time as in the entropy-optimal sort at the end of this section is worthwhile in many situations.
www.it-ebooks.info

2.3.1 Show,inthestyleofthetracegivenwithpartition(),howthatmethodparti- tions the array E A S Y Q U E S T I O N.
2.3.2 Show,inthestyleofthequicksorttracegiveninthissection,howquicksortsorts thearrayE A S Y Q U E S T I O N(forthepurposesofthisexercise,ignorethe initial shuf e).
2.3.3 What is the maximum number of times during the execution of Quick.sort() that the largest item can be exchanged, for an array of length N ?
2.3.4 Supposethattheinitialrandomshuf eisomitted.Givesixarraysoftenelements for which Quick.sort() uses the worst-case number of compares.
2.3.5 Giveacodefragmentthatsortsanarraythatisknowntoconsistofitemshaving just two distinct keys.
2.3.6 WriteaprogramtocomputetheexactvalueofCN,andcomparetheexactvalue with the approximation 2N ln N, for N = 100, 1,000, and 10,000.
2.3.7 Findtheexpectednumberofsubarraysofsize0,1,and2whenquicksortisused to sort an array of N items with distinct keys. If you are mathematically inclined, do the math; if not, run some experiments to develop hypotheses.
2.3.8 About how many compares will Quick.sort() make when sorting an array of N items that are all equal?
2.3.9 ExplainwhathappenswhenQuick.sort()isrunonanarrayhavingitemswith just two distinct keys, and then explain what happens when it is run on an array having just three distinct keys.
2.3.10 Chebyshev’s inequality says that the probability that a random variable is more than k standard deviations away from the mean is less than 1/k 2. For N = 1 million, use Chebyshev’s inequality to bound the probability that the number of compares used by quicksort is more than 100 billion (.1 N 2).
2.3.11 Suppose that we scan over items with keys equal to the partitioning item’s key instead of stopping the scans when we encounter them. Show that the running time of this version of quicksort is quadratic for all arrays with just a constant number of distinct keys.
www.it-ebooks.info
2.3 n Quicksort 303
 ExErcisEs

304 Chapter 2 n Sorting ExErcisEs (continued)
2.3.12 Show,inthestyleofthetracegivenwiththecode,howthe3-wayquicksort rst partitions the array B A B A B A B A C A D A B R A.
2.3.13 What is the recursive depth of quicksort, in the best, worst, and average cases? This is the size of the stack that the system needs to keep track of the recursive calls. See Exercise 2.3.20 for a way to guarantee that the recursive depth is logarithmic in the worst case.
2.3.14 ProvethatwhenrunningquicksortonanarraywithNdistinctitems,theprob- ability of comparing the i th and j th smallest items is 2 / (j  i  1). Then use this result to prove Proposition K.
 www.it-ebooks.info

2.3.15 Nuts and bolts. (G. J. E. Rawlins) You have a mixed pile of N nuts and N bolts and need to quickly  nd the corresponding pairs of nuts and bolts. Each nut matches exactly one bolt, and each bolt matches exactly one nut. By  tting a nut and bolt to- gether, you can see which is bigger, but it is not possible to directly compare two nuts or two bolts. Give an ef cient method for solving the problem.
2.3.16 Best case. Write a program that produces a best-case array (with no duplicates) for sort() in Algorithm 2.5: an array of N items with distinct keys having the prop- erty that every partition will produce subarrays that differ in size by at most 1 (the same subarray sizes that would happen for an array of N equal keys). (For the purposes of this exercise, ignore the initial shuf e.)
The following exercises describe variants of quicksort. Each of them calls for an implementa- tion, but naturally you will also want to use SortCompare for experiments to evaluate the effectiveness of each suggested modi cation.
2.3.17 Sentinels. Modify the code in Algorithm 2.5 to remove both bounds checks in the inner while loops. The test against the left end of the subarray is redundant since the partitioning item acts as a sentinel (v is never less than a[lo]). To enable removal of the other test, put an item whose key is the largest in the whole array into a[length-1] just after the shuf e. This item will never move (except possibly to be swapped with an item having the same key) and will serve as a sentinel in all subarrays involving the end of the array. Note : For a subarray that does not involve the end of the array, the leftmost entry to its right serves as a sentinel for the right end of the subarray.
2.3.18 Median-of-3 partitioning. Add median-of-3 partitioning to quicksort, as de- scribed in the text (see page 296). Run doubling tests to determine the effectiveness of the change.
2.3.19 Median-of-5 partitioning. Implement a quicksort based on partitioning on the median of a random sample of  ve items from the subarray. Put the items of the sample at the appropriate ends of the array so that only the median participates in partitioning. Run doubling tests to determine the effectiveness of the change, in comparison both to the standard algorithm and to median-of-3 partitioning (see the previous exercise). Extra credit : Devise a median-of-5 algorithm that uses fewer than seven compares on any input.
www.it-ebooks.info
2.3 n Quicksort 305
 crEAtivE problEms

306 Chapter 2 n Sorting
crEAtivE problEms (continued)
2.3.20 Nonrecursive quicksort. Implement a nonrecursive version of quicksort based on a main loop where a subarray is popped from a stack to be partitioned, and the re- sulting subarrays are pushed onto the stack. Note : Push the larger of the subarrays onto the stack  rst, which guarantees that the stack will have at most lg N entries.
2.3.21 Lower bound for sorting with equal keys. Complete the  rst part of the proof of Proposition M by following the logic in the proof of Proposition I and using the observation that there are N! / f1!f2! . . . fk! different ways to arrange keys with k different values, where the i th value appears with frequency fi (= Npi , in the notation of Proposi- tion M), with f1+. . . +fk = N.
2.3.22 Fast 3-way partitioning. (J. Bentley and D. McIlroy) Implement an entropy- optimal sort based on keeping items with equal keys at both the left and right ends of the subarray. Maintain indices p and q such that a[lo..p-1] and a[q+1..hi] are all equal to a[lo], an index i such that a[p..i-1] are all less than a[lo], and an index j such that a[j+1..q] are all greater than a[lo]. Add to the inner partitioning loop code to swap a[i] with a[p] (and increment p) if it is equal to v and to swap a[j] with a[q] (and decrement q) if it is equal to v before the usual comparisons of a[i] and a[j] with v. After the partitioning loop has terminated, add code to swap the items with equal keys into position. Note: This code complements the code given in the text, in the sense that it does extra swaps for keys equal to the partitioning item’s key, while the code in the text does extra swaps for keys that are not equal to the partitioning
item’s key.
2.3.23 Tukey's ninther. Add to your implementation from Exercise 2.3.22 code to use the Tukey ninther to compute the partitioning item—choose three sets of three items, take the median of each, then use the median of the three medians as the partitioning item. Also, add a cutoff to insertion sort for small subarrays.
2.3.24 Samplesort. (W. Frazer and A. McKellar) Implement a quicksort based on us- ing a sample of size 2k  1. First, sort the sample, then arrange to have the recursive routine partition on the median of the sample and to move the two halves of the rest of the sample to each subarray, such that they can be used in the subarrays, without having to be sorted again. This algorithm is called samplesort.
    before v
lo hi
during
after
         =v
<v
>v
=v
             lo p i j q hi
   <v
=v
>v
        loj ihi
Bentley-McIlroy 3-way partitioning
www.it-ebooks.info

2.3.25 Cutoff to insertion sort. Implement quicksort with a cutoff to insertion sort for subarrays with less than M elements, and empirically determine the value of M for which quicksort runs fastest in your computing environment to sort random arrays of N doubles, for N = 103, 104, 105, and 106. Plot average running times for M from 0 to 30 for each value of M. Note : You need to add a three-argument sort() method to Algorithm2.2forsortingsubarrayssuchthatthecallInsertion.sort(a, lo, hi) sorts the subarray a[lo..hi].
2.3.26 Subarray sizes. Write a program that plots a histogram of the subarray sizes left for insertion sort when you run quicksort for an array of size N with a cutoff for subar- rays of size less than M. Run your program for M=10, 20, and 50 and N = 105.
2.3.27 Ignore small subarrays. Run experiments to compare the following strategy for dealing with small subarrays with the approach described in Exercise 2.3.25: Simply ignore the small subarrays in quicksort, then run a single insertion sort after the quick- sort completes. Note : You may be able to estimate the size of your computer’s cache memory with these experiments, as the performance of this method is likely to degrade when the array does not  t in the cache.
2.3.28 Recursion depth. Run empirical studies to determine the average recursive depth used by quicksort with cutoff for arrays of size M, when sorting arrays of N distinct elements, for M=10, 20, and 50 and N = 103, 104, 105, and 106.
2.3.29 Randomization. Run empirical studies to compare the effectiveness of the strategy of choosing a random partitioning item with the strategy of initially randomizing the array (as in the text). Use a cutoff for arrays of size M, and sort arrays of N distinct elements, for M=10, 20, and 50 and N = 103, 104, 105, and 106.
2.3.30 Corner cases. Test quicksort on large nonrandom arrays of the kind described in Exercises 2.1.35 and 2.1.36 both with and without the initial random shuf e. How does shuf ing affect its performance for these arrays?
2.3.31 Histogram of running times. Write a program that takes command-line argu- ments N and T, does T trials of the experiment of running quicksort on an array of N random Double values, and plots a histogram of the observed running times. Run your program for N = 103, 104, 105, and 106, with T as large as you can afford to make the curves smooth. Your main challenge for this exercise is to appropriately scale the experimental results.
www.it-ebooks.info
2.3 n Quicksort 307
 ExpErimENts

   308
Many applications require that we process items having keys in order, but not nec- essarily in full sorted order and not necessarily all at once. Often, we collect a set of items, then process the one with the largest key, then perhaps collect more items, then process the one with the current largest key, and so forth. For example, you are likely to have a computer (or a cellphone) that is capable of running several applications at the same time. This effect is typically achieved by assigning a priority to events associated with applications, then always choosing to process next the highest-priority event. For example, most cellphones are likely to process an incoming call with higher priority than a game application.
An appropriate data type in such an environment supports two operations: remove the maximum and insert. Such a data type is called a priority queue. Using priority queues is similar to using queues (remove the oldest) and stacks (remove the newest), but implementing them ef ciently is more challenging.
In this section, after a short discussion of elementary representations where one or both of the operations take linear time, we consider a classic priority-queue implemen- tation based on the binary heap data structure, where items are kept in an array, subject to certain ordering constraints that allow for ef cient (logarithmic-time) implementa- tions of remove the maximum and insert.
Some important applications of priority queues include simulation systems, where the keys correspond to event times, to be processed in chronological order; job schedul- ing, where the keys correspond to priorities indicating which tasks are to be performed  rst; and numerical computations, where the keys represent computational errors, in- dicating in which order we should deal with them. We consider in Chapter 6 a detailed case study showing the use of priority queues in a particle-collision simulation.
We can use any priority queue as the basis for a sorting algorithm by inserting a se- quence of items, then successively removing the smallest to get them out, in order. An important sorting algorithm known as heapsort also follows naturally from our heap- based priority-queue implementations. Later on in this book, we shall see how to use priority queues as building blocks for other algorithms. In Chapter 4, we shall see how priority queues are an appropriate abstraction for implementing several fundamental graph-searching algorithms; in Chapter 5, we shall develop a data-compression algo- rithm using methods from this section. These are but a few examples of the important role played by the priority queue as a tool in algorithm design.
www.it-ebooks.info
 2.4 Priority QUeUeS

 API The priority queue is a prototypical abstract data type (see Section 1.2): it rep- resents a set of values and operations on those values, and it provides a convenient ab- straction that allows us to separate application programs (clients) from various imple- mentations that we will consider in this section. As in Section 1.2, we precisely de ne the operations by specifying an applications programming interface (API) that provides the information needed by clients. Priority queues are characterized by the remove the maximum and insert operations, so we shall focus on them. We use the method names delMax() for remove the maximum and insert() for insert. By convention, we will compare keys only with a helper less() method, as we have been doing for sorting. Thus, if items can have duplicate keys, maximum means any item with the largest key value. To complete the API, we also need to add constructors (like the ones we used for stacks and queues) and a test if empty operation. For  exibility, we use a generic imple- mentation with a parameterized type Key that implements the Comparable interface. This choice eliminates our distinction between items and keys and enables clearer and more compact descriptions of data structures and algorithms. For example, we refer to the “largest key” instead of the “largest item” or the “item with the largest key.”
For convenience in client code, the API includes three constructors, which enable clients to build priority queues of an initial  xed size (perhaps initialized with a given array of keys). To clarify client code, we will use a separate class MinPQ whenever ap- propriate, which is the same as MaxPQ except that it has a delMin() method that deletes and returns an item with the smallest key in the queue. Any MaxPQ implementation is easily converted into a MinPQ implementation and vice versa, simply by reversing the sense of the comparison in less().
2.4 n Priority Queues 309
 public class MaxPQ<Key extends Comparable<Key>>
          MaxPQ()
        MaxPQ(int max)
        MaxPQ(Key[] a)
void insert(Key v) Key max()
Key delMax()
boolean isEmpty() int size()
create a priority queue
create a priority queue of initial capacity max create a priority queue from the keys in a[] insert a key into the priority queue
return the largest key
return and remove the largest key
is the priority queue empty?
number of keys in the priority queue
apI for a generic priority queue
www.it-ebooks.info

310 Chapter 2 n Sorting
A priority-queue client To appreciate the
value of the priority-queue abstraction, con-
sider the following problem: You have a huge
input stream of N strings and associated inte-
ger values, and your task is to  nd the largest
or smallest M integers (and associated strings)
in the input stream. You might imagine the
stream to be  nancial transactions, where
your interest is to  nd the big ones, or pesti-
cide levels in an agricultural product, where
your interest is to  nd the small ones, or re-
quests for service, or results from a scienti c
experiment, or whatever. In some applications, the size of the input stream is so huge that it is best to consider it to be unbounded. One way to address this problem would be to sort the input stream and take the M largest keys from the result, but we have just stipulated that the input stream is too large for that. Another approach would be to compare each new key against the M largest seen so far, but that is also likely to be prohibitively expensive unless M is small. With priority queues, we can solve the prob- lem with the MinPQ client TopM on the next page provided that we can develop ef cient implementations of both insert() and delMin(). That is precisely our aim in this sec- tion. For the huge values of N that are likely to be encountered in our modern compu- tational infrastructure, these implementations can make the difference between being able to address such a problem and not having the resources to do it at all.
Elementary implementations The basic data structures that we discussed in Chapter 1 provide us with four immediate starting points for implementing priority queues. We can use an array or a linked list, kept in order or unordered. These imple- mentations are useful for small priority queues, situations where one of the two opera- tions are predominant, or situations where some assumptions can be made about the order of the keys involved in the operations. Since these implementations are elemen- tary, we will be content with brief descriptions here in the text and leave the code for exercises (see Exercise 2.4.3).
Array representation (unordered) Perhaps the simplest priority-queue implementa- tion is based on our code for pushdown stacks in Section 1.3. The code for insert in the priority queue is the same as for push in the stack. To implement remove the maximum, we can add code like the inner loop of selection sort to exchange the maximum item with the item at the end and then delete that one, as we did with pop() for stacks. As with stacks, we can add resizing-array code to ensure that the data structure is always at least one-quarter full and never over ows.
www.it-ebooks.info
client
sort client
order of growth
PQ client using elementary implementation
N log N N NM M
PQ client using heap-based implementation
N log M M Costs of finding the largest M in a stream of N items
time
space

  A priority-queue client
  public class TopM
  {
     public static void main(String[] args)
     {  // Print the top M lines in the input stream.
        int M = Integer.parseInt(args[0]);
        MinPQ<Transaction> pq = new MinPQ<Transaction>(M+1);
        while (StdIn.hasNextLine())
        {  // Create an entry from the next line and put on the PQ.
           pq.insert(new Transaction(StdIn.readLine()));
           if (pq.size() > M)
              pq.delMin();     // Remove minimum if M+1 entries on the PQ.
        }  // Top M entries are on the PQ.
        Stack<Transaction> stack = new Stack<Transaction>();
        while (!pq.isEmpty()) stack.push(pq.delMin());
        for (Transaction t : stack) StdOut.println(t);
} }
Given an integer M from the command line and an input stream where each line contains a trans- action, this MinPQ client prints the M lines whose numbers are the highest. It does so by using our Transaction class (see page 79, Exercise 1.2.19, and Exercise 2.1.21) to build a priority queue using
the numbers as keys, deleting the minimum after each insertion once the size of the priority queue reaches M. Once all the transactions have been processed, the top M come off the priority queue in increasing order, so this code puts them on a stack, then iterates through the stack to reverse the order and print them in decreasing order.
   % more tinyBatch.txt
Turing      6/17/1990   644.08
vonNeumann  3/26/2002  4121.85
Dijkstra    8/22/2007  2678.40
vonNeumann  1/11/1999  4409.74
Dijkstra   11/18/1995   837.42
Hoare       5/10/1993  3229.27
vonNeumann  2/12/1994  4732.35
Hoare
Turing
Thompson
Turing
Hoare
vonNeumann 10/13/1993  2520.97
Dijkstra    9/10/2000   708.95
Turing     10/12/1993  3532.36
Hoare       2/10/2005  4050.20
8/18/1992  4381.21
1/11/2002    66.10
2/27/2000  4747.08
2/11/1991  2156.86
8/12/2003  1025.70
 www.it-ebooks.info
2.4 n Priority Queues 311
% java TopM 5 < tinyBatch.txt
Thompson    2/27/2000  4747.08
vonNeumann  2/12/1994  4732.35
vonNeumann  1/11/1999  4409.74
Hoare       8/18/1992  4381.21
vonNeumann  3/26/2002  4121.85
312 Chapter 2 n Sorting
data structure
ordered array
unordered array
heap
impossible
insert
N
1
log N
1
remove maximum
1
N
log N
1
Using unordered sequences is the prototypical lazy approach to this problem, where we defer doing work until necessary (to  nd the maximum); us- ing ordered sequences is the prototypical eager ap- proach to the problem, where we do as much work as we can up front (keep the list sorted on insertion) to make later operations ef cient.
The signi cant difference between implementing stacks or queues and implementing priority queues has to do with performance. For stacks and queues, we were able to develop implementations of all the
Array representation (ordered) Another approach is to add code for insert to move larger entries one position to the right, thus keeping the keys in the array in order (as in insertion sort). Thus, the largest entry is always at the end, and the code for remove the maximum in the priority queue is the same as for pop in the stack.
Linked-list representations Similarly, we can start with our linked-list code for push- down stacks, modifying either the code for pop() to  nd and return the maximum or the code for push() to keep keys in reverse order and the code for pop() to unlink and return the  rst (maximum) item on the list.
 order of growth of worst-case running time for priority-queue implementations
operations that take constant time; for priority queues, all of the elementary imple- mentations just discussed have the property that either the insert or the remove the maximum operation takes linear time in the worst case. The heap data structure that we consider next enables implementations where both operations are guaranteed to be fast.
operation
insert insert insert remove max insert
insert
insert remove max insert insert insert remove max
argument return value size contents (unordered) contents (ordered)
P1PP Q2PQPQ
E 3PQE EPQ
 X A M
P L E
Q2PE EP
3PEX EPX
4 PEXA AEPX
5 PEXAM AEMPX
4 PEMA AEMP
5 PEMAP AEMPP
6 PEMAPL AELMPP
7 PEMAPLE AEELMPP 6 EEMAPL AEELMP
A sequence of operations on a priority queue
X
P
www.it-ebooks.info

Heap de nitions The binary heap is a data structure that can ef ciently support the basic priority-queue operations. In a binary heap, the keys are stored in an array such that each key is guaranteed to be larger than (or equal to) the keys at two other speci c positions. In turn, each of those keys must be larger than (or equal to) two ad- ditional keys, and so forth. This ordering is easy to see if we view the keys as being in a binary tree structure with edges from each key to the two keys known to be smaller.
Equivalently, the key in each node of a heap-ordered binary tree is smaller than or equal to the key in that node’s parent (if any). Moving up from any node, we get a nondecreasing sequence of keys; moving down from any node, we get a nonincreasing sequence of keys. In particular:
Binary heap representation If we use a linked representation for heap-ordered binary trees, we would need to have three links associated with each key to allow travel up and down the tree (each node would have one pointer to its parent and one to each child). It is particularly convenient, instead, to use a complete binary tree like the one drawn at right. We draw such a structure by placing the root node
 Definition. A binary tree is heap-ordered if the key in each node is larger than or equal to the keys in that node’s two children (if any).
and then proceeding down the page and from left to right,
drawing and connecting two nodes beneath each node on
the previous level until we have drawn N nodes. Complete
trees provide the opportunity to use a compact array rep-
resentation that does not involve explicit links. Speci cally, EIHG we represent complete binary trees sequentially within an
2.4 n Priority Queues 313
 proposition o. The largest key in a heap-ordered binary tree is found at the root. proof: By induction on the size of the tree.
 T SR
       PNOA
    array by putting the nodes in level order, with the root at position 1, its children at positions 2 and 3, their children in positions 4, 5, 6, and 7, and so on.
A heap-ordered complete binary tree
www.it-ebooks.info

314 Chapter 2
n Sorting
 Definition. A binary heap is a collection of keys arranged in a complete heap-or- dered binary tree, represented in level order in an array (not using the  rst entry).
(For brevity, from now on we drop the “binary” modi er and use the term heap when referring to a binary heap.) In a heap, the parent of the node in position k is in position ⎣k /2⎦ and, con- versely, the two children of the node in position k are in positions 2k and 2k + 1. Instead of using explicit links (as in the binary tree structures that we will consider in Chapter 3), we can travel up and down by doing simple arithmetic on array indices: to move up the tree from a[k] we set k to k/2; to move down the tree we set k to 2*k or 2*k+1.
Complete binary trees represented as arrays (heaps) are rigid structures, but they have just enough  exibility to allow us to implement ef - cient priority-queue operations. Speci cally, we
will use them to develop logarithmic-time insert and remove the maximum implemen- tations. These algorithms take advantage of the capability to move up and down paths in the tree without pointers and have guaranteed logarithmic performance because of the following property of complete binary trees:
   i   0  1  2  3  4  5  6  7  8  9 10 11
a[i]  -  T  S  R  P  N  O  A  E  I  H  G
            T
SR
1T
2S 3R
      PNOA
     EIHG
         4P5N6O7A 8 E 9 I 10 H 11 G
Heap representations
     proposition p. The height of a complete binary tree of size N is ⎣ lg N ⎦ .
proof: The stated result is easy to prove by induction or by noting that the height increases by 1 only when N is incremented to become a power of 2.
www.it-ebooks.info

Algorithms on heaps We represent a heap of size N in private array pq[] of length N + 1, with pq[0] unused and the heap in pq[1] through pq[N]. As for sort- ing algorithms, we access keys only through private helper functions less() and exch(), but since all items are in
the instance variable pq[], we use
the more compact implementations
that do not involve passing the ar-
ray name as a parameter. The heap
operations that we consider work by
 rst making a simple modi cation
that could violate the heap condi-
tion, then traveling through the heap, modifying the heap as required to ensure that the heap condition is satis ed everywhere. We refer to this process as reheapifying, or restoring heap order.
There are two cases. When the priority of some node is increased (or a new node is added at the bottom of a heap), we have to travel up the heap to restore the heap order. When the priority of some node is decreased (for example, if we replace the node at the root with a new node that has a smaller key), we have to travel down the heap to restore the heap order. First, we will consider how to implement these two basic auxil- iary operations; then, we shall see how to use them to implement insert and remove the maximum.
Bottom-up reheapify (swim) If the heap order is violated because a node’s key be- comes larger than that node’s parent’s key, then we can make progress toward  xing the violation by exchanging the node with its parent. After the exchange, the node is larger than both its children (one is the old parent, and the other is smaller than the old parent because it was a child of that node) but the node may still be larger than its par- ent. We can  x that violation in the same way, and so forth, moving up the heap until we reach a node with a larger key, or the root. Coding this process is straightforward when you keep in mind that the parent of the node at position k in a heap is at po- sition k/2. The loop in swim() preserves the invariant that the only place the heap
2.4 n Priority Queues 315
   private boolean less(int i, int j)
  {  return pq[i].compareTo(pq[j]) < 0;  }
  private void exch(int i, int j)
  {  Key t = pq[i]; pq[i] = pq[j]; pq[j] = t;  }
Compare and exchange methods for heap implementations
   S PR
N5TOA
            violates heap order (larger key than parent)
1
T
2SR N5POA
EIHG
Bottom-up reheapify (swim)
    EIHG
            www.it-ebooks.info

316 Chapter 2 n Sorting
order could be violated is when the node at position k might be larger than its parent. Therefore, when we get to a place where that node is not larger than its parent, we know that the heap order is satis ed throughout
the heap. To jus-
tify the method’s
name, we think
of the new node,
having too large a
key, as having to swim to a higher level in the heap.
Top-down reheapify (sink) If the heap order is violated be- cause a node’s key becomes smaller than one or both of that node’s children’s keys, then we can make progress toward  x- ing the violation by exchanging the node with the larger of its two children. This switch may cause a violation at the child; we  x that violation in the same way, and so forth, moving down the heap until we reach a node with both children smaller (or equal), or the bottom. The code again follows di- rectly from
the fact that the children of the node at position k in a heap are at positions 2k and 2k+1. To justify the method’s name, we think about the node, having too small a key, as having to sink to a low-
er level in the heap.
If we imagine the heap to represent
a cutthroat corporate hierarchy, with
each of the children of a node repre-
senting subordinates (and the parent
representing the immediate superior), then these operations have amusing interpreta- tions. The swim() operation corresponds to a promising new manager arriving on the scene, being promoted up the chain of command (by exchanging jobs with any lower- quali ed boss) until the new person encounters a higher-quali ed boss. The sink() operation is analogous to the situation when the president of the company resigns and is replaced by someone from the outside. If the president’s most powerful subordinate
   private void swim(int k)
  {
     while (k > 1 && less(k/2, k))
     {
        exch(k/2, k);
k = k/2; }
}
Bottom-up reheapify (swim) implementation
 violates heap order (smaller than a child)
 T 2HR
          P5SOA EING
T 2SR
P5NOA 10
EIHG Top-down reheapify (sink)
                           private void sink(int k)
  {
     while (2*k <= N)
     {
        int j = 2*k;
        if (j < N && less(j, j+1)) j++;
        if (!less(k, j)) break;
        exch(k, j);
        k = j;
} }
top-down reheapify (sink) implementation
 www.it-ebooks.info

is stronger than the new person, they exchange jobs, and we move down the chain of command, demoting the new person and promoting others until the level of compe- tence of the new person is reached, where there is no higher-quali ed subordinate. These idealized scenarios may rarely be seen in the real world, but they may help you better understand basic operation on heaps.
These sink() and swim() operations provide the basis for ef cient implementation of the priority-queue API, as diagrammed below and implemented in Algorithm 2.6.
Insert We add the new key at the end of the array, increment the size of the heap, and then swim up through the heap with that key to restore the heap condition.
Remove the maximum. We take the largest item off the top, put the item from the end of the heap at the top, decrement the size of the heap, and then sink down through the heap with that key to restore the heap condition.
Algorithm 2.6 solves the basic problem that we posed at the beginning of this section: it is a priority-queue API implementation for which both insert and delete the maxi- mum are guaranteed to take time logarithmic in the size of the queue.
2.4 n Priority Queues 317
insert T remove the maximum T PR SR
NHOA NPOA
   key to remove
               exchange key with root
violates heap order
NHOA NPOA
E I G S add key to heap E I G T remove node
       E I G S key to insert E I G H
    TH PR SR
                             swim up
violates heap order from heap
TS
S R sink down P R
               NPOA NHOA EIGH EIG
Heap operations
         www.it-ebooks.info

 318 Chapter 2 n Sorting
 aLgorIthM 2.6 heap priority queue
  public class MaxPQ<Key extends Comparable<Key>>
  {
     private Key[] pq;             // heap-ordered complete binary tree
     private int N = 0;            //    in pq[1..N] with pq[0] unused
     public MaxPQ(int maxN)
     {  pq = (Key[]) new Comparable[maxN+1];  }
 public boolean isEmpty()
{  return N == 0;  }
public int size()
{  return N;  }
public void insert(Key v)
{
pq[++N] = v;
swim(N); }
public Key delMax()
{
   Key max = pq[1];
   exch(1, N--);
   pq[N+1] = null;
   sink(1);
return max; }
// Retrieve max key from top.
// Exchange with last item.
// Avoid loitering.
// Restore heap property.
     // See pages 315-316 for implementations of these helper methods.
     private boolean less(int i, int j)
     private void exch(int i, int j)
     private void swim(int k)
     private void sink(int k)
}
The priority queue is maintained in a heap-ordered complete binary tree in the array pq[] with pq[0] unused and the N keys in the priority queue in pq[1] through pq[N]. To implement insert(), we increment N, add the new element at the end, then use swim() to restore the heap order. For delMax(), we take the value to be returned from pq[1], then move pq[N] to pq[1], decrement the size of the heap, and use sink() to restore the heap condition. We also set the now-unused position pq[N+1] to null to allow the system to reclaim the memory associated with it. Code for dynamic array resizing is omitted, as usual (see Section 1.3). See Exercise 2.4.19 for the other constructors.
 www.it-ebooks.info
 For typical applications that require a large number of inter- mixed insert and remove the maximum operations in a large priority queue, Proposition Q represents an important per- formance breakthrough, summarized in the table shown on page 312. Where elementary implementations using an or- dered array or an unordered array require linear time for one of the operations, a heap-based implementation provides a guarantee that both operations complete in logarithmic time. This improvement can make the difference between solving a problem and not being able to address it at all.
Multiway heaps It is not dif cult to modify our code to build heaps based on an array representation of complete heap-ordered ternary trees, with an entry at position k larger than or equal to entries at positions 3k1, 3k, and 3k1 and smaller than or equal to entries at position ⎣(k+1)  3⎦, for all indices between 1 and N in an array of N items, and not much more dif cult to use d-ary heaps for any given d. There is a tradeoff between the lower cost from the reduced tree height (logd N) and the higher cost of  nding the largest of the d children at each node. This tradeoff is dependent on details of the implementation and the expected relative frequency of operations.
www.it-ebooks.info
2.4 n
Priority Queues 319
  insert P insert Q
P
Q P
Q
E P
X EP
X MP
    insert E
P
remove max (Q)
E
      insert X
insert A
       insert M
AE
      remove max (X)
A
P ME
P PE
     insert P
AM
     insert L
insert E
remove max (P)
P PL
AME P
PL AMEE P ML
                  AEE Priority queue operations in a heap
 proposition Q. In an N-key priority queue, the heap al- gorithms require no more than 1 + lg N compares for in- sert and no more than 2lg N compares for remove the maximum.
proof: By Proposition P, both operations involve mov- ing along a path between the root and the bottom of the heap whose number of links is no more than lg N. The remove the maximum operation requires two compares for each node on the path (except at the bottom): one to  nd the child with the larger key, the other to decide whether that child needs to be promoted.
 A
X EP
320 Chapter 2 n Sorting
Array resizing We can add a no-argument constructor, code for array doubling in insert(), and code for array halving in delMax(), just as we did for stacks in Section 1.3. Thus, clients need not be concerned about arbitrary size restrictions. The logarith- mic time bounds implied by PROPOSITION Q are amortized when the size of the priority queue is arbitrary and the arrays are resized (see Exercise 2.4.22).
Immutability of keys The priority queue contains objects that are created by clients but assumes that client code does not change the keys (which might invalidate the heap-order invariant). It is possible to develop mechanisms to enforce this assumption, but programmers typically do not do so because they complicate the code and are likely to degrade performance.
Index priority queue In many applications, it makes sense to allow clients to refer to items that are already on the priority queue. One easy way to do so is to associate a unique integer index with each item. Moreover, it is often the case that clients have a universe of items of a known size N and perhaps are using (parallel) arrays to store information about the items, so other unrelated client code might already be using an integer index to refer to items. These considerations lead us to the following API:
 public class IndexMinPQ<Key extends Comparable<Key>>
         IndexMinPQ(int maxN)
void insert(int i, Key key)
void changeKey(int k, Key key) boolean contains(int i)
void delete(int i) Key minKey()
int minIndex() int delMin()
boolean isEmpty() int size()
Key keyOf(int i)
create a priority queue of capacity maxN with possible indices between 0 and maxN-1
insert key ; associate it with index i change the key associated with i to key
is index i associated with some key? remove i and its associated key
return a minimal key
return a minimal key’s index
remove a minimal key and return its index is the priority queue empty?
number of keys in the priority queue return key associated with index i
apI for a generic priority queue with associated indices
www.it-ebooks.info

A useful way of thinking of this data type is as implementing an array, but with fast ac- cess to the smallest entry in the array. Actually it does even better—it gives fast access to the minimum entry in a speci ed subset of an array’s entries (the ones that have been inserted). In other words, you can think of an IndexMinPQ named pq as representing a subsetofanarraypq[0..N-1]ofitems.Thinkofthecallpq.insert(i, key)asadd- ing i to the subset and setting pq[i] = key and the call pq.changeKey(i, key) as settingpq[i] = key,bothalsomaintainingdatastructuresneededtosupporttheother operations, most importantly delMin() (remove and return the index of the minimum key) and changeKey() (change the item associated with an index that is already in the data structure—just as in pq[i] = key). These operations are im-
portant in many applications and are enabled by our ability to refer to the key (with the index). Exercise 2.4.33 describes how to extend Algorithm 2.6 to implement index priority queues with remarkable ef ciency and with remarkably little code. Intuitively, when an item in the heap changes, we can restore the heap invariant with a sink operation (if the key decreases) and a swim operation (if the key in- creases). To perform the operations, we use the index to  nd the item in the heap. The ability to locate an item in the heap also allows us to add the delete() operation to the API.
operation
  insert()
changeKey()
 contains()
  delete()
  minKey()
 minIndex()
  delMin()
order of growth of number of compares
log N log N 1 log N 1
1 log N
2.4 n Priority Queues
321
  proposition Q (continued). In an index priority queue of size N, the number of compares required is proportional to at most log N for insert, change priority, delete, and remove the minimum.
proof: Immediatefrominspectionofthecodeandthefactthatall paths in a heap are of length at most ~lg N.
This discussion is for a minimum-oriented queue; as usual, we also im- plement on the booksite a maximum-oriented version IndexMaxPQ.
Worst-case costs for an N-item heap-based indexed priority queue
Index priority-queue client The IndexMinPQ client Multiway on page 322 solves the multiway merge problem: it merges together several sorted input streams into one sorted output stream. This problem arises in many applications: the streams might be the output of scienti c instruments (sorted by time), lists of information from the web such as music or movies (sorted by title or artist name), commercial transactions (sorted by account number or time), or whatever. If you have the space, you might just read them all into an array and sort them, but with a priority queue, you can read input streams and put them in sorted order on the output no matter how long they are.
www.it-ebooks.info

 322 Chapter 2 n Sorting
 Multiway merge priority-queue client
  public class Multiway
  {
     public static void merge(In[] streams)
     {
        int N = streams.length;
        IndexMinPQ<String> pq = new IndexMinPQ<String>(N);
        for (int i = 0; i < N; i++)
           if (!streams[i].isEmpty())
               pq.insert(i, streams[i].readString());
        while (!pq.isEmpty())
        {
           StdOut.println(pq.minKey());
           int i = pq.delMin();
           if (!streams[i].isEmpty())
               pq.insert(i, streams[i].readString());
} }
     public static void main(String[] args)
     {
        int N = args.length;
        In[] streams = new In[N];
        for (int i = 0; i < N; i++)
            streams[i] = new In(args[i]);
        merge(streams);
} }
This IndexMinPQ client merges together the sorted input streams given as command-line arguments into a single sorted output stream on standard output (see text). Each stream index is associated with a key (the next string in the stream). After initialization, it enters a loop that prints the smallest string in the queue and removes the corresponding entry, then adds a new entry for the next string in that stream. For economy, the output is shown on one line below—the actual output is one string per line.
   % more m1.txt ABCFGII Z % more m2.txt BDHPQ Q
% more m3.txt ABEFJ N
 % java Multiway m1.txt m2.txt m3.txt
A A B B B C DEFFGHIIJNPQQZ
www.it-ebooks.info
 Heapsort We can use any priority queue to develop a sorting method. We insert all the items to be sorted into a minimum-oriented priority queue, then repeatedly use remove the minimum to remove them all in order. Using a priority queue represented as an unordered array in this way corresponds to doing a selection sort; using an ordered array corresponds to doing an insertion sort. What sorting method do we get if we use a heap? An entirely different one! Next, we use the heap to develop a classic elegant sort- ing algorithm known as heapsort.
Heapsort breaks into two phases: heap construction, where we reorganize the original array into a heap, and the sortdown, where we pull the items out of the heap in decreas- ing order to build the sorted result. For consistency with the code we have studied, we use a maximum-oriented priority queue and repeatedly remove the maximum. Focus- ing on the task of sorting, we abandon the notion of hiding the representation of the priority queue and use swim() and sink() directly. Doing so allows us to sort an array without needing any extra space, by maintaining the heap within the array to be sorted.
Heap construction How dif cult is the process of building a heap from N given items? Certainly we can accomplish this task in time proportional to N log N, by proceeding from left to right through the array, using swim() to ensure that the items to the left of the scanning pointer make up a heap-ordered complete tree, like successive priority- queue insertions. A clever method that is much more ef cient is to proceed from right to left, using sink() to make subheaps as we go. Every position in the array is the root of a small subheap; sink() works for such subheaps, as well. If the two children of a node are heaps, then calling sink() on that node makes the subtree rooted at the par- ent a heap. This process establishes the heap order inductively. The scan starts halfway back through the array because we can skip the subheaps of size 1. The scan ends at position 1, when we  nish building the heap with one call to sink(). As the  rst phase of a sort, heap construction is a bit counterintuitive, because its goal is to produce a heap-ordered result, which has the largest item  rst in the array (and other larger items near the beginning), not at the end, where it is destined to  nish.
2.4 n Priority Queues 323
 proposition r. Sink-based heap construction uses fewer than 2N compares and fewer than N exchanges to construct a heap from N items.
proof: Thisfactfollowsfromtheobservationthatmostoftheheapsprocessedare small. For example, to build a heap of 127 items, we process 32 heaps of size 3, 16 heaps of size 7, 8 heaps of size 15, 4 heaps of size 31, 2 heaps of size 63, and 1 heap of size 127, so 32·1 + 16·2 + 8·3 + 4·4 + 2·5 + 1·6 = 120 exchanges (twice as many compares) are required (at worst). See Exercise 2.4.20 for a complete proof.
www.it-ebooks.info

 324 Chapter 2 n Sorting
 aLgorIthM 2.7 heapsort
  public static void sort(Comparable[] a)
  {
     int N = a.length;
     for (int k = N/2; k >= 1; k--)
        sink(a, k, N);
     while (N > 1)
     {
        exch(a, 1, N--);
        sink(a, 1, N);
     }
}
This code sorts a[1] through a[N] using the sink() method (modi ed to take a[] and N as argu- ments). The for loop constructs the heap; then the while loop exchanges the largest element a[1] with a[N] and then repairs the heap, continuing until the heap is empty. Decrementing the array in- dices in the implementations of exch() and less() gives an implementation that sorts a[0] through a[N-1], consistent with our other sorts.
  N k
initial values
115 114 113 112 111 heap-ordered 10 1
91 81 71 61 51 41 31 21 11
sorted result
a[i]
0  1  2  3  4  5  6  7  8  9 10 11
SORTEXAMPLE SORTLXAMPEE SORTLXAMPEE SOXTLRAMPEE STXPLRAMOEE XTSPLRAMOEE XTSPLRAMOEE TPSOLRAMEEX SPROLEAMETX RPEOLEAMSTX POEMLEARSTX OMEALEPRSTX MLEAEOPRSTX LEEAMOPRSTX EAELMOPRSTX EAELMOPRSTX AEELMOPRSTX AEELMOPRSTX
 Heapsort trace (array contents just after each sink)
www.it-ebooks.info
 2.4 n Priority Queues 325 heap construction sortdown
1 S X exch(1, 6) M sink(1, 5)
2O3RTSLE 4T5E6X7A PLRAAEOP
8M9P10L11E MOEE RSTX starting point (arbitrary order) starting point (heap-ordered)
sink(5, 11) S exch(1, 11) T exch(1, 5) L sink(1, 10) sink(1, 4)
ORPSEE TLXA OLRAAMOP
MPEE MEEX RSTX sink(4, 11) S exch(1, 10) S exch(1, 4) E
sink(1, 9) sink(1, 3) ORPRAE
TLXA OLEALMOP MPEE METX RSTX
sink(3, 11) S exch(1, 9) R exch(1, 3) E sink(1, 8) sink(1, 2)
OXPEAE TLRA OLEALMOP
MPEE MSTX RSTX sink(2, 11) S exch(1, 8) P exch(1, 2) A
sink(1, 7) sink(1, 1) TXOEEE
PLRA MLEALMOP MOEE RSTX RSTX
                                                                                                                                                             sink(1, 11) TS
P LRA
MOEE
result (heap-ordered)
exch(1, 7) O 1 A
sink(1, 6)
ME2E3E ALEP4L5M6O7P
RSTX 8R9S10T11X result (sorted)
 X
                     Heapsort: constructing (left) and sorting down (right) a heap
www.it-ebooks.info

326 Chapter 2
n Sorting
Sortdown Most of the work during heapsort is done during the second phase, where we remove the largest remaining item from the heap and put it into the array position vacated as the heap shrinks. This process is a bit like selection sort (taking the items in decreasing order instead of in increasing order), but it uses many fewer compares because the heap provides a much more ef cient way to  nd the largest item in the unsorted part of the array.
  input
heap- ordered
    red entries are items that sank
   gray entries do not move
black entries are involved in exchanges
  sorted result
 Visual trace of heapsort
 proposition s. Heapsort uses fewer than 2N lg N + 2N compares (and half that many exchanges) to sort N items.
proof: The 2N term covers the cost of heap construc- tion (see Proposition R). The 2 N lg N term follows from bounding the cost of each sink operation during the sort- down by 2lg N (see Proposition Q ).
Algorithm 2.7 is a full implementation based on these ideas, the classical heapsort algorithm, which was invented by J. W. J. Williams and re ned by R. W. Floyd in 1964. Although the loops in this program seem to do different tasks (the  rst constructs the heap, and the second destroys the heap for the sortdown), they are both built around the sink() method. We provide an implementation outside of our priority-queue API to highlight the simplicity of the sorting algorithm (eight lines of code for sort() and another eight lines of code for sink()) and to make it an in-place sort.
As usual, you can gain some insight into the operation of the algorithm by studying a visual trace. At  rst, the process seems to do anything but sort, because large items are moving to the beginning of the array as the heap is being constructed. But then the method looks more like a mirror image of selection sort (except that it uses far fewer compares).
As for all of the other methods that we have studied, various people have investigated ways to improve heap-based priority- queue implementations and heapsort. We now brie y consider one of them.
www.it-ebooks.info

Sink to the bottom, then swim Most items reinserted into the heap during sortdown go all the way to the bottom. Floyd observed in 1964 that we can thus save time by avoiding the check for whether the item has reached its position, simply promoting the larger of the two children until the bottom is reached, then moving back up the heap to the proper position. This idea cuts the number of compares by a factor of 2 as- ymptotically—close to the number used by mergesort (for a randomly-ordered array). The method requires extra bookkeeping, and it is useful in practice only when the cost of compares is relatively high (for example, when we are sorting items with strings or other types of long keys).
Heapsort is significant in the study of the complexity of sorting (speeage 279) because it is the only method that we have seen that is optimal (within a constant factor) in its use of both time and space—it is guaranteed to use ~2N lg N compares and constant extra space in the worst case. When space is very tight (for example, in an embedded system or on a low-cost mobile device) it is popular because it can be implemented with just a few dozen lines (even in machine code) while still providing optimal per- formance. However, it is rarely used in typical applications on modern systems because it has poor cache performance: array entries are rarely compared with nearby array entries, so the number of cache misses is far higher than for quicksort, mergesort, and even shellsort, where most compares are with nearby entries.
On the other hand, the use of heaps to implement priority queues plays an increas- ingly important role in modern applications, because it provides an easy way to guar- antee logarithmic running time for dynamic situations where large numbers of insert and remove the maximum operations are intermixed. We will encounter several ex- amples later in this book.
www.it-ebooks.info
2.4 n Priority Queues 327

328 Chapter 2 n Sorting
 Q&A
 Q. I’mstillnotclearonthepurposeofpriorityqueues.Whyexactlydon’twejustsort and then consider the items in increasing order in the sorted array?
A. Insomedata-processingexamplessuchasTopMandMultiway,thetotalamountof data is far too large to consider sorting (or even storing in memory). If you are looking for the top ten entries among a billion items, do you really want to sort a billion-entry array? With a priority queue, you can do it with a ten-entry priority queue. In other ex- amples, all the data does not even exist together at any point in time: we take something from the priority queue, process it, and as a result of processing it perhaps add some more things to the priority queue.
Q. Why not use Comparable, as we do for sorts, instead of the generic Item in MaxPQ? A. DoingsowouldrequiretheclienttocastthereturnvalueofdelMax()toanactual
type, such as String. Generally, casts in client code are to be avoided.
Q. Why not use a[0] in the heap representation?
A. Doing so simpli es the arithmetic a bit. It is not dif cult to implement the heap methods based on a 0-based heap where the children of a[0] are a[1] and a[2], the children of a[1] are a[3] and a[4], the children of a[2] are a[5] and a[6], and so forth, but most programmers prefer the simpler arithmetic that we use. Also, us- ing a[0] as a sentinel value (in the parent of a[1]) is useful in some heap applications.
Q. Buildingaheapinheapsortbyinsertingitemsonebyoneseemssimplertomethan the tricky bottom-up method described on page 323 in the text. Why bother?
A. For a sort implementation, it is 20 percent faster and requires half as much tricky code (no swim() needed). The dif culty of understanding an algorithm has not neces- sarily much to do with its simplicity, or its ef ciency.
Q. WhathappensifIleaveofftheextends Comparable<Key>phraseinanimplemen- tation like MaxPQ ?
A. As usual, the easiest way for you to answer a question of this sort for yourself is to simply try it. If you do so for MaxPQ you will get a compile-time error:
    MaxPQ.java:21: cannot find symbol
    symbol  : method compareTo(Key)
which is Java’s way of telling you that it does not know about compareTo() in Item because you neglected to declare that Key extends Comparable<Key>.
www.it-ebooks.info

2.4.1 SupposethatthesequenceP R I O * R * * I * T * Y * * * Q U E * * * U * E (where a letter means insert and an asterisk means remove the maximum) is ap- plied to an initially empty priority queue. Give the sequence of letters returned by the remove the maximum operations.
2.4.2 Criticize the following idea: To implement  nd the maximum in constant time, why not use a stack or a queue, but keep track of the maximum value inserted so far, then return that value for  nd the maximum?
2.4.3 Provide priority-queue implementations that support insert and remove the maximum, one for each of the following underlying data structures: unordered array, ordered array, unordered linked list, and ordered linked list. Give a table of the worst- case bounds for each operation for each of your four implementations.
2.4.4 Is an array that is sorted in decreasing order a max-oriented heap?
2.4.5 GivetheheapthatresultswhenthekeysE A S Y Q U E S T I O N areinserted
in that order into an initially empty max-oriented heap.
2.4.6 Using the conventions of Exercise 2.4.1, give the sequence of heaps produced whentheoperationsP R I O * R * * I * T * Y * * * Q U E * * * U * E are performed on an initially empty max-oriented heap.
2.4.7 Thelargestiteminaheapmustappearinposition1,andthesecondlargestmust be in position 2 or position 3. Give the list of positions in a heap of size 31 where the kth largest (i) can appear, and (ii) cannot appear, for k=2, 3, 4 (assuming the values to be distinct).
2.4.8 Answer the previous exercise for the kth smallest item.
2.4.9 Draw all of the different heaps that can be made from the  ve keys A B C D E,
then draw all of the different heaps that can be made from the  ve keys A A A B B.
2.4.10 Suppose that we wish to avoid wasting one position in a heap-ordered array pq[], putting the largest value in pq[0], its children in pq[1] and pq[2], and so forth, proceeding in level order. Where are the parents and children of pq[k]?
2.4.11 Supposethatyourapplicationwillhaveahugenumberofinsertoperations,but only a few remove the maximum operations. Which priority-queue implementation do you think would be most effective: heap, unordered array, or ordered array?
www.it-ebooks.info
2.4 n Priority Queues 329
 ExErcisEs

330 Chapter 2 n Sorting ExErcisEs (continued)
2.4.12 Suppose that your application will have a huge number of  nd the maximum operations, but a relatively small number of insert and remove the maximum operations. Which priority-queue implementation do you think would be most effective: heap, unordered array, or ordered array?
2.4.13 Describe a way to avoid the j < N test in sink().
2.4.14 What is the minimum number of items that must be exchanged during a re- move the maximum operation in a heap of size N with no duplicate keys? Give a heap of size 15 for which the minimum is achieved. Answer the same questions for two and three successive remove the maximum operations.
2.4.15 Design a linear-time certi cation algorithm to check whether an array pq[] is a min-oriented heap.
2.4.16 ForN=32,givearraysofitemsthatmakeheapsortuseasmanyandasfewcom- pares as possible.
2.4.17 Prove that building a minimum-oriented priority queue of size k then doing N  k replace the minimum (insert followed by remove the minimum) operations leaves the k largest of the N items in the priority queue.
2.4.18 In MaxPQ, suppose that a client calls insert() with an item that is larger than all items in the queue, and then immediately calls delMax(). Assume that there are no duplicate keys. Is the resulting heap identical to the heap as it was before these op- erations? Answer the same question for two insert() operations (the  rst with a key larger than all keys in the queue and the second for a key larger than that one) followed by two delMax() operations.
2.4.19 Implement the constructor for MaxPQ that takes an array of items as argument, using the bottom-up heap construction method described on page 323 in the text.
2.4.20 Prove that sink-based heap construction uses fewer than 2N compares and fewer than N exchanges.
 www.it-ebooks.info

2.4.21 Elementary data structures. Explain how to use a priority queue to implement the stack, queue, and randomized queue data types from Section 1.3 and Exercise 1.3.35.
2.4.22 Array resizing. Add array resizing to MaxPQ, and prove bounds like those of Proposition Q for array accesses, in an amortized sense.
2.4.23 Multiway heaps. Considering the cost of compares only, and assuming that it takes t compares to  nd the largest of t items,  nd the value of t that minimizes the coef cient of N lg N in the compare count when a t-ary heap is used in heapsort. First, assume a straightforward generalization of sink(); then, assume that Floyd’s method can save one compare in the inner loop.
2.4.24 Priority queue with explicit links. Implement a priority queue using a heap- ordered binary tree, but use a triply linked structure instead of an array. You will need three links per node: two to traverse down the tree and one to traverse up the tree. Your implementation should guarantee logarithmic running time per operation, even if no maximum priority-queue size is known ahead of time.
2.4.25 Computational number theory. Write a program that prints out all integers of the form a3 + b3 where a and b are integers between 0 and N in sorted order, without using excessive space. That is, instead of computing an array of the N2 sums and sorting them, build a minimum-oriented priority queue, initially containing (03, 0, 0), (13, 1, 0), (23, 2, 0), . . . , (N3, N, 0). Then, while the priority queue is nonempty, remove the smallest item(i3 + j3, i, j ), print it, and then, if j < N, insert the item (i3 + ( j+1)3, i, j+1). Use this program to  nd all distinct integers a, b, c, and d between 0 and 106 such that a3 + b3 = c3 + d3.
2.4.26 Heap without exchanges. Because the exch() primitive is used in the sink() and swim() operations, the items are loaded and stored twice as often as necessary. Give more ef cient implementations that avoid this inef ciency, a la insertion sort (see Exercise 2.1.25).
2.4.27 Find the minimum. Add a min() method to MaxPQ. Your implementation should use constant time and constant extra space.
2.4.28 Selection  lter. Write a program similar to TopM that reads points (x, y, z) from standard input, takes a value M from the command line, and prints the M points that
www.it-ebooks.info
2.4 n Priority Queues 331
 crEAtivE problEms

332 Chapter 2 n Sorting
  are closest to the origin in Euclidean distance. Estimate the running time of your client for N = 108 and M = 104.
2.4.29 Min/max priority queue. Design a data type that supports the following opera- tions: insert, delete the maximum, and delete the minimum (all in logarithmic time); and  nd the maximum and  nd the minimum (both in constant time). Hint: Use two heaps.
2.4.30 Dynamic median- nding. Design a data type that supports insert in logarith- mic time,  nd the median in constant time, and delete the median in logarithmic time. Hint: Use a min-heap and a max-heap.
2.4.31 Fast insert. Develop a compare-based implementation of the MinPQ API such that insert uses ~ log log N compares and delete the minimum uses ~2 log N compares. Hint : Use binary search on parent pointers to  nd the ancestor in swim().
2.4.32 Lower bound. Prove that it is impossible to develop a compare-based imple- mentation of the MinPQ API such that both insert and delete the minimum guarantee to use ~log log N compares per operation.
2.4.33 Index priority-queue implementation. Implement the basic operations in the index priority-queue API onpage 320 by modifying Algorithm 2.6 as follows: Change pq[] to hold indices, add an array keys[] to hold the key values, and add an array qp[] that is the inverse of pq[] — qp[i] gives the position of i in pq[] (the index j such that pq[j] is i). Then modify the code in Algorithm 2.6 to maintain these data structures. Use the convention that qp[i] = -1 if i is not on the queue, and include a method contains() that tests this condition. You need to modify the helper methods exch() and less() but not sink() or swim().
www.it-ebooks.info
 crEAtivE problEms (continued)
  Partial solution :
public class IndexMinPQ<Key extends Comparable<Key>>
{
private int N;
private int[] pq;
private int[] qp;
private Key[] keys;
public IndexMinPQ(int maxN)
{
keys = (Key[]) new Comparable[maxN + 1];
pq   = new int[maxN + 1];
qp   = new int[maxN + 1];
for (int i = 0; i <= maxN; i++) qp[i] = -1;
}
   public boolean isEmpty()
   {  return N == 0;  }
   public boolean contains(int i)
   {  return qp[i] != -1;  }
   public void insert(int i, Key key)
   {
N++;
      qp[i] = N;
      pq[N] = i;
      keys[i] = key;
      swim(N);
   }
   public Key minKey()
   {  return keys[pq[1]];  }
   public int delMin()
   {
      int indexOfMin = pq[1];
      exch(1, N--);
      sink(1);
      keys[pq[N+1]] = null;
      qp[pq[N+1]] = -1;
      return indexOfMin;
} }
// number of elements on PQ
// binary heap using 1-based indexing
// inverse: qp[pq[i]] = pq[qp[i]] = i
// items with priorities
www.it-ebooks.info
2.4 n Priority Queues 333

334 Chapter 2 n Sorting
crEAtivE problEms (continued)
2.4.34 Index priority-queue implementation (additional operations). Add minIndex(), changeKey(), and delete() to your implementation of Exercise 2.4.33.
Solution :
public int minIndex()
                {  return pq[1];  }
                public void changeKey(int i, Key key)
                {
                   keys[i] = key;
                   swim(qp[i]);
                   sink(qp[i]);
}
                public void delete(int i)
                {
                   int index = qp[i];
                   exch(index, N--);
                   swim(index);
                   sink(index);
                   keys[i] = null;
                   qp[i] = -1;
}
2.4.35 Sampling from a discrete probability distribution. Write a class Sample with a constructor that takes an array p[] of double values as argument and supports the fol- lowing two operations: random()—return an index i with probability p[i]/T (where T is the sum of the numbers in p[])—and changeKey(i, v)—change the value of p[i] to v. Hint: Use a complete binary tree where each node has implied weight p[i]. Store in each node the cumulative weight of all the nodes in its subtree. To generate a random index, pick a random number between 0 and T and use the cumulative weights to determine which branch of the subtree to explore. When updating p[i], change all of the weights of the nodes on the path from the root to i. Avoid explicit pointers, as we do for heaps.
 www.it-ebooks.info

2.4.36 Performance driver I. Write a performance driver client program that uses in- sert to  ll a priority queue, then uses remove the maximum to remove half the keys, then uses insert to  ll it up again, then uses remove the maximum to remove all the keys, doing so multiple times on random sequences of keys of various lengths ranging from small to large; measures the time taken for each run; and prints out or plots the average running times.
2.4.37 Performance driver II. Write a performance driver client program that uses in- sert to  ll a priority queue, then does as many remove the maximum and insert opera- tions as it can do in 1 second, doing so multiple times on random sequences of keys of various lengths ranging from small to large; and prints out or plots the average number of remove the maximum operations it was able to do.
2.4.38 Exercise driver. Write an exercise driver client program that uses the methods in our priority-queue interface of Algorithm 2.6 on dif cult or pathological cases that might turn up in practical applications. Simple examples include keys that are already in order, keys in reverse order, all keys the same, and sequences of keys having only two distinct values.
2.4.39 Cost of construction. Determine empirically the percentage of time heapsort spends in the construction phase for N = 103, 106, and 109.
2.4.40 Floyd’s method. Implement a version of heapsort based on Floyd’s sink-to-the- bottom-and-then-swim idea, as described in the text. Count the number of compares used by your program and the number of compares used by the standard implementa- tion, for randomly ordered distinct keys with N = 103, 106, and 109.
2.4.41 Multiway heaps. Implement a version of heapsort based on complete heap- ordered 3-ary and 4-ary trees, as described in the text. Count the number of compares used by each and the number of compares used by the standard implementation, for randomly ordered distinct keys with N = 103, 106, and 109.
2.4.42 Preorder heaps. Implement a version of heapsort based on the idea of repre- senting the heap-ordered tree in preorder rather than in level order. Count the number of compares used by your program and the number of compares used by the standard implementation, for randomly ordered keys with N = 103, 106, and 109.
www.it-ebooks.info
2.4 n Priority Queues 335
 ExpErimENts

   336
Sorting algorithms and priority queues are widely used in a broad variety of ap- plications. Our purpose in this section is to brie y survey some of these applications, consider ways in which the ef cient methods that we have considered play a critical role in such applications, and discuss some of the steps needed to make use of our sort and priority-queue code.
A prime reason why sorting is so useful is that it is much easier to search for an item in a sorted array than in an unsorted one. For over a century, people found it easy to look up someone’s phone number in a phone book where items are sorted by last name. Now digital music players organize song  les by artist name or song title; search engines display search results in descending order of importance; spreadsheets display columns sorted by a particular  eld; matrix-processing packages sort the real eigenvalues of a symmetric matrix in descending order; and so forth. Other tasks are also made easier once an array is in sorted order: from looking up an item in the sorted index in the back of this book; to removing duplicates from a long list such as a mailing list, a list of vot- ers, or a list of websites; to performing statistical calculations such as removing outliers,  nding the median, or computing percentiles.
Sorting also arises as a critical subproblem in many applications that appear to have nothing to do with sorting at all. Data compression, computer graphics, computational biology, supply-chain management, combinatorial optimization, social choice, and voting are but a few of many examples. The algorithms that we have considered in this chapter play a critical role in the development of effective algorithms in each of the later chapters in this book.
Most important is the system sort, so we begin by considering a number of practical considerations that come into play when building a sort for use by a broad variety of clients. While some of these topics are speci c to Java, they each re ect challenges that need to be met in any system.
Our primary purpose is to demonstrate that, even though we have used mechanisms that are relatively simple, the sorting implementations that we are studying are widely applicable. The list of proven applications of fast sorting algorithms is vast, so we can consider just a small fraction of them: some scienti c, some algorithmic, and some commercial. You will  nd many more examples in the exercises, and many more than that on the booksite. Moreover, we will often refer back to this chapter to effectively ad- dress the problems that we later consider in this book!
www.it-ebooks.info
 2.5 APPliCAtionS

 Sorting various types of data Our implementations sort arrays of Comparable objects. This Java convention allows us to use Java’s callback mechanism to sort arrays of objects of any type that implements the Comparable interface. As described in Section 2.1, implementing Comparable amounts to de ning a compareTo() method that implements a natural ordering for the type. We can use our code immediately to sort arrays of type String, Integer, Double, and other types such as File and URL, because these data types all implement Comparable. Being able to use the same code for all of those types is convenient, but typical applications involve working with data types that are de ned for use within the application. Accordingly it is common to im- plement a compareTo() method for user-de ned data types, so that they implement Comparable, thus enabling client code to sort arrays of that type (and build priority queues of values of that type).
Transaction example A prototypical breeding ground for sorting applications is commercial data processing. For example, imagine that a company engaged in internet commerce maintains a record for each transaction involving a customer account that contains all of the pertinent information, such as the customer name, date, amount, and so forth. Nowadays, a successful company needs to be able to handle millions and millions of such transactions. As we saw in Exercise 2.1.21, it is reasonable to decide that a natural ordering of such transactions is that they be ordered by amount, which we can implement by adding an appropriate compareTo() method in the class de ni- tion. With such a de nition, we could process an array a[] of Transactions by, for ex- ample,  rst sorting it with the call Quick.sort(a). Our sorting methods know nothing about our Transaction data type, but Java’s Comparable interface allows us to de ne a natural ordering so that we can use any of our methods to sort Transaction objects. Alternatively, we might specify that Transaction objects are to be ordered by date by implementing compareTo() to compare the Date  elds. Since Date objects are them- selves Comparable, we can just invoke the compareTo() method in Date rather than having to implement it from scratch. It is also reasonable to consider ordering this data by its customer  eld; arranging to allow clients the  exibility to switch among multiple different orders is an interesting challenge that we will soon consider.
2.5 n Applications 337
   public int compareTo(Transaction that)
  {  return this.when.compareTo(that.when);  }
alternate compareTo() implementation for sorting transactions by date
 www.it-ebooks.info

338 Chapter 2 n Sorting
Pointer sorting The approach we are using is known in the classical literature as pointer sorting, so called because we process references to items and do not move the data itself. In programming languages such as C and C++, programmers explicitly de- cide whether to manipulate data or pointers to data; in Java, pointer manipulation is implicit. Except for primitive numeric types, we always manipulate references to ob- jects (pointers), not the objects themselves. Pointer sorting adds a level of indirection: the array contains references to the objects to be sorted, not the objects themselves. We brie y consider some associated issues, in the context of sorting. With multiple refer- ence arrays, we can have multiple different sorted representations of different parts of a single body of data (perhaps using multiple keys, as described below).
Keys are immutable It stands to reason that an array might not remain sorted if a client is allowed to change the values of keys after the sort. Similarly, a priority queue can hardly be expected to operate properly if the client can change the values of keys between operations. In Java, it is wise to ensure that key values do not change by using immutable keys. Most of the standard data types that you are likely to use as keys, such as String, Integer, Double, and File, are immutable.
Exchanges are inexpensive Another advantage of using references is that we avoid the cost of moving full items. The cost saving is signi cant for arrays with large items (and small keys) because the compare needs to access just a small part of the item, and most of the item is not even touched during the sort. The reference approach makes the cost of an exchange roughly equal to the cost of a compare for general situations involving arbitrarily large items (at the cost of the extra space for the references). Indeed, if the keys are long, the exchanges might even wind up being less costly than the compare. One way to study the performance of algorithms that sort arrays of numbers is to sim- ply look at the total number of compares and exchanges they use, implicitly making the assumption that the cost of exchanges is the same as the cost of compares. Conclusions based on this assumption are likely to apply to a broad class of applications in Java, because we are sorting reference objects.
Alternate orderings There are many applications where we want to use differ- ent orders for the objects that we are sorting, depending on the situation. The Java Comparator interface allows us to build multiple orders within a single class. It has a single public method compare() that compares two objects. If we have a data type that implements this interface, we can pass a Comparator to sort() (which passes it to less()) as in the example on the next page. The Comparator mechanism allows us to sort arrays of any type of object, using any total order that we wish to de ne for them. Using a Comparator instead of working with Comparable types better separates the de nition of the type from the de nition of what it means to compare two objects of
www.it-ebooks.info

that type. Indeed, there are typically many possible ways to compare objects, and the Comparator mechanism allows us to choose among them. For instance, to sort an ar- ray a[] of strings without regard to whether characters are uppercase or lowercase you can just call Insertion.sort(a, String.CASE_INSENSITIVE_ORDER) which makes use of the CASE_INSENSITIVE_ORDER comparator de ned in Java’s String class. As you can imagine, the precise rules for ordering strings are complicated and quite differ- ent for various natural languages, so Java has many String comparators.
Items with multiple keys In typical applications, items have multiple instance variables that might need to serve as sort keys. In our transaction example, one client may need to sort the transaction list by customer (for example, to bring together all transactions involving each customer); another client might need to sort the list by amount (for example, to identify high-value transactions); and other clients might need to use other  elds as sort keys. The Comparator mechanism is precisely what we need to allow this  exibility. We can de ne multiple comparators, as in the alternate implementation of Transaction shown on the bottom of the next page. With this de nition, a client can sort an array of Transaction objects by time with the call
    Insertion.sort(a, new Transaction.WhenOrder())
or by amount with the call
    Insertion.sort(a, new Transaction.HowMuchOrder()).
The sort does each compare through a callback to the compare() method in Transaction that is speci ed by the client code. To avoid the cost of making a new Comparator object for each sort, we could use public static final instance variables to de ne the comparators (as Java does for CASE_INSENSITIVE_ORDER).
2.5 n Applications 339
   public static void sort(Object[] a, Comparator c)
  {
     int N = a.length;
     for (int i = 1; i < N; i++)
        for (int j = i; j > 0 && less(c, a[j], a[j-1]); j--)
           exch(a, j, j-1);
}
  private static boolean less(Comparator c, Object v, Object w)
  {  return c.compare(v, w) < 0;  }
  private static void exch(Object[] a, int i, int j)
  {  Object t = a[i]; a[i] = a[j]; a[j] = t; }
Insertion sorting with a Comparator
 www.it-ebooks.info

340 Chapter 2 n Sorting
Priority queues with comparators The same  exibility to use comparators is also useful for priority queues. Extending our standard implementation in Algorithm 2.6 to support comparators involves the following steps:
n Import java.util.Comparator.
n Add to MaxPQ an instance variable comparator and a constructor that takes a
comparator as argument and initializes comparator to that value.
n Add code to less() that checks whether comparator is null (and uses it if it is
not null).
For example, with these changes, you could build different priority queues with Transaction keys, using the time, place, or account number for the ordering. If you removetheKey extends Comparable<Key>phrasefromMinPQ,youevencansupport keys with no natural order.
   import java.util.Comparator;
  public class Transaction
  {
     ...
     private final String who;
     private final Date when;
     private final double amount;
     ...
     public static class WhoOrder implements Comparator<Transaction>
     {
        public int compare(Transaction v, Transaction w)
        {  return v.who.compareTo(w.who);  }
     }
     public static class WhenOrder implements Comparator<Transaction>
     {
        public int compare(Transaction v, Transaction w)
        {  return v.when.compareTo(w.when);  }
     }
     public static class HowMuchOrder implements Comparator<Transaction>
     {
        public int compare(Transaction v, Transaction w)
        {
           if (v.amount < w.amount) return -1;
           if (v.amount > w.amount) return +1;
           return 0;
} }
}
Comparator implementation for Transaction data type
 www.it-ebooks.info

Stability A sorting method is stable if it preserves the relative order of equal keys in the array. This property is frequently important. For example, consider an internet com- merce application where we have to process a large number of events that have loca- tions and timestamps. To begin, suppose that we store events in an array as they arrive, so they are in order of the timestamp in the array. Now suppose that the application requires that the transactions be separated out by location for further processing. One easy way to do so is to sort the array by location. If the sort is unstable, the transac- tions for each city may not necessarily be in order by timestamp after the sort. Often, programmers who are unfamiliar with stability are surprised, when they  rst encounter the situation, by the way an unstable algorithm seems to scramble the data. Some of the sorting methods that we have considered in this chapter are stable (insertion sort and mergesort); many are not (selection sort, shellsort, quicksort, and heapsort). There are ways to trick any sort into stable behavior (see Exercise 2.5.18), but using a stable algorithm is generally preferable when stability is an essential requirement. It is easy to take stability for granted; actually, no practical method in common use achieves stability without using signi cant extra time or space (researchers have developed al- gorithms that do so, but applications programmers have judged them too complicated to be useful).
sorted by time
Chicago  09:00:00
Phoenix  09:00:03
Houston  09:00:13
Chicago  09:00:59
Houston  09:01:10
Chicago  09:03:13
Seattle  09:10:11
Seattle  09:10:25
Phoenix  09:14:25
Chicago  09:19:32
Chicago  09:19:46
Chicago  09:21:05
Seattle  09:22:43
Seattle  09:22:54
Chicago  09:25:52
Chicago  09:35:21
Seattle  09:36:14
Phoenix  09:37:44
sorted by location (not stable)
 Chicago 09:25:52
 Chicago 09:03:13
 Chicago 09:21:05
 Chicago 09:19:46
 Chicago 09:19:32
 Chicago 09:00:00
 Chicago 09:35:21
 Chicago 09:00:59
 Houston 09:01:10
 Houston 09:00:13
 Phoenix 09:37:44
 Phoenix 09:00:03
 Phoenix 09:14:25
 Seattle 09:10:25
 Seattle 09:36:14
 Seattle 09:22:43
 Seattle 09:10:11
 Seattle 09:22:54
no longer sorted by time
sorted by location (stable)
Chicago 09:00:00
Chicago 09:00:59
Chicago 09:03:13
Chicago 09:19:32
Chicago 09:19:46
Chicago 09:21:05
Chicago 09:25:52
Chicago 09:35:21
Houston 09:00:13
Houston 09:01:10
Phoenix 09:00:03
Phoenix 09:14:25
Phoenix 09:37:44
Seattle 09:10:11
Seattle 09:10:25
Seattle 09:22:43
Seattle 09:22:54
Seattle 09:36:14
still sorted by time
2.5 n Applications 341
              Stability when sorting on a second key
www.it-ebooks.info

342 Chapter 2 n Sorting
Which sorting algorithm should I use? We have considered numerous sorting algorithms in this chapter, so this question is natural. Knowing which algorithm is best possible depends heavily on details of the application and implementation, but we have studied some general-purpose methods that can be nearly as effective as the best possible for a wide variety of applications.
The table at the bottom of this page is a general guide that summarizes the impor- tant characteristics of the sort algorithms that we have studied in this chapter. In all cases but shellsort (where the growth rate is only an estimate), insertion sort (where the growth rate depends on the order of the input keys), and both versions of quicksort (where the growth rate is probabilistic and may depend on the distribution of input key values), multiplying these growth rates by appropriate constants gives an effective way to predict running time. The constants involved are partly algorithm-dependent (for example, heapsort uses twice the number of compares as mergesort and both do many more array accesses than quicksort) but are primarily dependent on the implementa- tion, the Java compiler, and your computer, which determine the number of machine instructions that are executed and the time that each requires. Most important, since they are constants, you can generally predict the running time for large N by running experiments for smaller N and extrapolating, using our standard doubling protocol.
algorithm
selection sort insertion sort
shellsort quicksort
3-way quicksort
mergesort heapsort
stable? in place?
no yes yes yes
no yes no yes
no yes
yes no no yes
order of growth to sort N items
running time extra space
N21
notes
depends on order of items
 between2 N and N
N log N ? N6/5?
N log N between
N and N log N N log N
1
1 lg N
lg N N
1
probabilistic guarantee
probabilistic, also depends on distribution of input keys
N log N
performance characteristics of sorting algorithms
www.it-ebooks.info

Thus, in most practical situations, quicksort is the method of choice. Still, given the broad reach of sorting and the broad variety of computers and systems, a  at statement like this is dif cult to justify. For example, we have already seen one notable exception: if stability is important and space is available, mergesort might be best. We will see oth- er exceptions in Chapter 5. With tools like SortCompare and a considerable amount of time and effort, you can do a more detailed study of comparative performance of these algorithms and the re nements that we have discussed for your computer, as discussed in several exercises at the end of this section. Perhaps the best way to interpret Prop- erty T is as saying that you certainly should seriously consider using quicksort in any sort application where running time is important.
Sorting primitive types In some performance-critical applications, the focus may be on sorting numbers, so it is reasonable to avoid the costs of using references and sort primitive types instead. For example, consider the difference between sorting an array of int values and sorting an array of Integer values. In the former case, we exchange the numbers themselves and put them in order in the array; in the latter, we exchange references to Integer objects, which contain the numbers. If we are doing nothing more than sorting a huge array of numbers, we avoid paying the cost of storing an equal number of references plus the extra cost of accessing the numbers through the refer- ences, not to mention the cost of invoking compareTo() and less() methods. We can develop ef cient versions of our sort codes for such purposes by replacing Comparable with the primitive type name, and rede ning less() or just replacing calls to less() with code like a[i] < a[j] (see Exercise 2.1.26).
Java system sort As an example of applying the information given in the table on page 342, consider Java’s primary system sort method, java.util.Arrays.sort(). With overloading of argument types, this name actually represents a collection of methods:
www.it-ebooks.info
2.5 n Applications 343
 property t. Quicksort is the fastest general-purpose sort.
Evidence: This hypothesis is supported by countless implementations of quick- sort on countless computer systems since its invention decades ago. Generally, the reason that quicksort is fastest is that it has only a few instructions in its inner loop (and it does well with cache memories because it most often references data sequentially) so that its running time is ~c N lg N with the value of c smaller than the corresponding constants for other linearithmic sorts. With 3-way partitioning, quicksort becomes linear for certain key distributions likely to arise in practice, where other sorts are linearithmic.

344 Chapter 2 n Sorting
n A different method for each primitive type
n A method for data types that implement Comparable n A method that uses a Comparator
Java’s systems programmers have chosen to use quicksort (with 3-way partitioning) to implement the primitive-type methods, and mergesort for reference-type methods. The primary practical implications of these choices are, as just discussed, to trade speed and memory usage (for primitive types) for guaranteed performance and stability (for reference types).
The algorithms and ideas that we have been considering are an essential part of many modern systems, including Java. When developing Java programs to address an application, you are likely to  nd that Java’s Arrays.sort() implementations (perhaps supplemented by your own implementation(s) of compareTo() and/or compare()) will meet your needs, because you will be using 3-way quicksort or mergesort, both proven classic algorithms.
In this book, we generally will use our own Quick.sort() (usually) or Merge.sort() (when stability is important and space is not) in sort clients. You may feel free to use Arrays.sort() unless you have a good reason to use another speci c method.
Reductions The idea that we can use sorting algorithms to solve other problems is an example of a basic technique in algorithm design known as reduction. We con- sider reduction in detail in Chapter 6 because of its importance in the theory of al- gorithms—in the meantime, we will consider several practical examples. A reduction is a situation where an algorithm developed for one problem is used to solve another. Applications programmers are quite used to the concept of reduction (whether or not it is explicitly articulated)—every time you make use of a method that solves problem B in order to solve problem A, you are doing a reduction from A to B. Indeed, one goal in implementing algorithms is to facilitate reductions by making the algorithms useful for as wide a variety as possible of applications. We begin with a few elementary exam- ples for sorting. Many of these take the form of algorithmic puzzles where a quadratic brute-force algorithm is immediate. It is often the case that sorting the data  rst makes it easy to  nish solving the problem in linear additional time, thus reducing the total cost from quadratic to linearithmic.
Duplicates Are there any duplicate keys in an array of Comparable objects? How many distinct keys are there? Which value appears most frequently? For small arrays, these kinds of questions are easy to answer with a quadratic algorithm that compares each array entry with each other array entry. For large arrays, using a quadratic algorithm
www.it-ebooks.info

is not feasible. With sorting, you can answer these questions in linearithmic time:  rst sort the array, then make a pass through the sorted array, taking note of duplicate keys that appear consecutively in the ordered array. For example, the code fragment at right counts the distinct keys in an array. With simple modi cations to this code, you can answer the questions above and perform tasks such as printing all the distinct values, all the values that are duplicated, and so forth, even for huge arrays.
Rankings A permutation (or ranking) is an
array of N integers where each of the integers
between 0 and N 1 appears exactly once. The
Kendall tau distance between two rankings is
the number of pairs that are in different order
in the two rankings. For example, the Kendall
taudistancebetween0 3 1 6 2 5 4and
1 0 3 6 4 2 5 isfourbecausethepairs
0-1, 3-1, 2-4, 5-4 are in different relative order in the two rankings, but all other pairs are in the same relative order. This statistic is widely used: in sociology to study social choice and voting theory, in molecular biology to compare genes using expression pro-  les, and in ranking search engine results on the web, among many other applications. The Kendall tau distance between a permutation and the identity permutation (where each entry is equal to its index) is the number of inversions in the permutation, and a quadratic algorithm based on insertion sort to compute the distance is not dif cult to devise (recall Proposition C in Section 2.1). Ef ciently computing the Kendall tau distance is an interesting exercise for a programmer (or a student!) who is familiar with the classical sorting algorithms that we have studied (see Exercise 2.5.19).
Priority-queue reductions In Section 2.4, we considered two examples of problems that reduce to a sequence of operations on priority queues. TopM, on page 311,  nds the M items in an input stream with the highest keys. Multiway, on page 322, merges M sorted input streams together to make a sorted output stream. Both of these prob- lems are easily addressed with a priority queue of size M.
Median and order statistics An important application related to sorting but for which a full sort is not required is the operation of  nding the median of a collection of keys (the value with the property that half the keys are no larger and half the keys are no smaller). This operation is a common computation in statistics and in various other data-processing applications. Finding the median is a special case of selection:  nding the k th smallest of a collection of numbers. Selection has many applications in the processing of experimental and other data. The use of the median and other order
2.5 n Applications 345
   Quick.sort(a);
  int count = 1; // Assume a.length > 0.
  for (int i = 1; i < a.length; i++)
     if (a[i].compareTo(a[i-1]) != 0)
        count++;
Counting the distinct keys in a[]
 www.it-ebooks.info

346 Chapter 2 n Sorting
statistics to divide an array into smaller groups is common. Often, only a small part of a large array is to be saved for further processing; in such cases, a program that can select, say, the top 10 percent of the items of the array might be more appropriate than a full sort. Our TopM application of Sec-
tion 2.4 solves this problem for an un- bounded input stream, using a priority queue. An effective alternative to TopM when you have the items in an array is to just sort it: after the call Quick.sort(a) the k smallest items in the array are in the  rst k array positions for all k less than the array length. But this approach involves a sort, so the running time is linearithmic. Can we do better? Finding the k smallest items in an array is easy
   public static Comparable
  select(Comparable[] a, int k)
  {
     StdRandom.shuffle(a);
     int lo = 0, hi = a.length - 1;
     while (hi > lo)
     {
        int j = partition(a, lo, hi);
        if     (j == k)  return a[k];
        else if (j > k)  hi = j - 1;
        else if (j < k)  lo = j + 1;
}
     return a[k];
  }
Selecting the k smallest items in a[]
  lo j hi
median
Partitioning to  nd the median
when k is very
small or very
large, but more
challenging when k is a constant fraction of the array size, such as  nding the median (k = N/2). You might be surprised to learn that it is possible to solve this problem in linear time, as in the select() method above (this implementation re- quires a client cast; for the more pedantic code needed to avoid this requirement, see the booksite). To do the job, select() maintains the variables lo and hi to delimit the subarray that contains the index k of the item to be selected and uses quick- sort partitioning to shrink the size of the subarray. Recall that partition() rearranges an array a[lo] through a[hi] and returns an integer j such that a[lo] through a[j-1] are less than or equal to a[j], and a[j+1] through a[hi] are greater than or equal to a[j]. Now, if k is equal to j, then we are done. Otherwise, if k < j, then we need to continue working in the left subarray (by changing the value of hi to j-1); if k > j, then we need to continue working in the right subarray (by changing lo to j+1). The loop maintains the invariant that no entry to the left of lo is larger and no entry to the right of hi is smaller than any element within a[lo..hi]. After partition- ing, we preserve this invariant and shrink the interval until it
www.it-ebooks.info

consists just of k. Upon termination, a[k] contains the (k+1)st smallest entry, a[0] through a[k-1] are all smaller than (or equal to) a[k], and a[k+1] through the end of the array are all greater than (or equal to) a[k]. To gain some insight into why this is a linear-time algorithm, suppose that partitioning divides the array exactly in half each time. Then the number of compares is N  N/2  N/4  N/8  . . . , terminating when the k th smallest item is found. This sum is less than 2 N. As with quicksort, it takes a bit of math to  nd the true bound, which is a bit higher. Also as with quicksort, the analysis depends on partitioning on a random item, so that the guarantee is probabilistic.
Designing a selection algorithm that is guaranteed to use a linear number of compares in the worst case is a classic result in computational complexity, but it has not yet led to a useful practical algorithm.
www.it-ebooks.info
2.5 n Applications 347
 proposition U. Partitioning-based selection is a linear-time algorithm, on average.
proof: An analysis similar to, but signi cantly more complex than, the proof of Proposition K for quicksort leads to the result that the average number of com- pares is ~ 2N  2k ln(N/k)  2(N  k) ln(N/(N  k)), which is linear for any allowed value of k. For example, this formula says that  nding the median (k = N/2) requires ~ (2  2 ln 2)N compares, on the average. Note that the worst case is quadratic but randomization protects against that possibility, as with quicksort.

348 Chapter 2 n Sorting
A brief survey of sorting applications Direct applications of sorting are fa- miliar, ubiquitous, and far too numerous for us to list them all. You sort your music by song title or by artist name, your email or phone calls by time or origin, and your pho- tos by date. Universities sort student accounts by name or ID. Credit card companies sort millions or even billions of transactions by date or amount. Scientists sort not only experimental data by time or other identi er but also to enable detailed simulations of the natural world, from the motion of particles or heavenly bodies to the structure of materials to social interactions and relationships. Indeed, it is dif cult to identify a computational application that does not involve sorting! To elaborate upon this point, we describe in this section examples of applications that are more complicated than the reductions just considered, including several that we will examine in detail later in this book.
Commercial computing The world is awash in information. Government organiza- tions,  nancial institutions, and commercial enterprises organize much of this infor- mation by sorting it. Whether the information is accounts to be sorted by name or number, transactions to be sorted by date or amount, mail to be sorted by postal code or address,  les to be sorted by name or date, or whatever, processing such data is sure to involve a sorting algorithm somewhere along the way. Typically, such information is organized in huge databases, sorted by multiple keys for ef cient search. An effective strategy that is widely used is to collect new information, add it to the database, sort it on the keys of interest, and merge the sorted result for each key into the existing data- base. The methods that we have discussed have been used effectively since the early days of computing to build a huge infrastructure of sorted data and methods for processing it that serve as the basis for all of this commercial activity. Arrays having millions or even billions of entries are routinely processed today—without linearithmic sorting algorithms, such arrays could not be sorted, making such processing extremely dif cult or impossible.
Search for information Keeping data in sorted order makes it possible to ef ciently search through it using the classic binary search algorithm (see Chapter 1). You will also see that the same scheme makes it easy to quickly handle many other kinds of queries. How many items are smaller than a given item? Which items fall within a given range? In Chapter 3, we consider such questions. We also consider in detail various extensions to sorting and binary search that allow us to intermix such queries with operations that insert and remove objects from the set, still guaranteeing logarithmic performance for all operations.
www.it-ebooks.info

Operations research The  eld of operations research (OR) develops and applies math- ematical models for problem-solving and decision-making. We will see several exam- ples in this book of relationships between OR and the study of algorithms, beginning here with the use of sorting in a classic OR problem known as scheduling. Suppose that we have N jobs to complete, where job j requires tj seconds of processing time. We need to complete all of the jobs but want to maximize customer satisfaction by minimizing the average completion time of the jobs. The shortest processing time  rst rule, where we schedule the jobs in increasing order of processing time, is known to accomplish this goal. Therefore we can sort the jobs by processing time or put them on a minimum- oriented priority queue. With various other constraints and restrictions, we get various other scheduling problems, which frequently arise in industrial applications and are well-studied. As another example, consider the load-balancing problem, where we have M identical processors and N jobs to complete, and our goal is to schedule all of the jobs on the processors so that the time at which the last job completes is as early as pos- sible. This speci c problem is NP-hard (see Chapter 6) so we do not expect to  nd a practical way to compute an optimal schedule. One method that is known to produce a good schedule is the longest processing time  rst rule, where we consider the jobs in descending order of processing time, assigning each job to the processor that becomes available  rst. To implement this algorithm, we  rst sort the jobs in reverse order. Then we maintain a priority queue of M processors, where the priority is the sum of the pro- cessing times of its jobs. At each step, we delete the processor with the minimum prior- ity, add the next job to the processor, and reinsert that processor into the priority queue.
Event-driven simulation Many scienti c applications involve simulation, where the point of the computation is to model some aspect of the real world in order to be able to better understand it. Before the advent of computing, scientists had little choice but to build mathematical models for this purpose; such models are now well-complemented by computational models. Doing such simulations ef ciently can be challenging, and use of appropriate algorithms certainly can make the difference between being able to complete the simulation in a reasonable amount of time and being stuck with the choice of accepting inaccurate results or waiting for the simulation to do the computa- tion necessary to get accurate results. We will consider in Chapter 6 a detailed example that illustrates this point.
Numerical computations Scienti c computing is often concerned with accuracy (how close are we to the true answer?). Accuracy is extremely important when we are performing millions of computations with estimated values such as the  oating-point representation of real numbers that we commonly use on computers. Some numeri- cal algorithms use priority queues and sorting to control accuracy in calculations. For
www.it-ebooks.info
2.5 n Applications 349

350 Chapter 2 n Sorting
example, one way to do numerical integration (quadrature), where the goal is to esti- mate the area under a curve, is to maintain a priority queue with accuracy estimates for a set of subintervals that comprise the whole interval. The process is to remove the least accurate subinterval, split it in half (thus achieving better accuracy for the two halves), and put the two halves back onto the priority queue, continuing until a desired toler- ance is reached.
Combinatorial search A classic paradigm in arti cial intelligence and in coping with intractable problems is to de ne a set of con gurations with well-de ned moves from one con guration to the next and a priority associated with each move. Also de ned is a start con guration and a goal con guration (which corresponds to having solved the problem). The well-known A* algorithm is a problem-solving process where we put the start con guration on the priority queue, then do the following until reaching the goal: remove the highest-priority con guration and add to the queue all con gurations that can be reached from that with one move (excluding the one just removed). As with event-driven simulation, this process is tailor-made for priority queues. It reduces solv- ing the problem to de ning an effective priority function. See Exercise 2.5.32 for an example.
Beyond such direct applications (and we have only indicated a small fraction of those), sorting and priority queues are an essential abstraction in algorithm design, so they will surface frequently throughout this book. We next list some examples of applications from later in the book. All of these applications depend upon the ef cient implementations of sorting algorithms and the priority-queue data type that we have considered in this chapter.
Prim’s algorithm and Dijkstra’s algorithm are classical algorithms from Chapter 4. That chapter is about algorithms that process graphs, a fundamental model for items and edges that connect pairs of items. The basis for these and several other algorithms is graph search, where we proceed from item to item along edges. Priority queues play a fundamental role in organizing graph searches, enabling ef cient algorithms.
Kruskal’s algorithm is another classic algorithm for graphs whose edges have weights that depends upon processing the edges in order of their weight. Its running time is dominated by the cost of the sort.
Huffmancompression isaclassicdatacompressionalgorithmthatdependsuponpro- cessing a set of items with integer weights by combining the two smallest to produce a new one whose weight is the sum of its two constituents. Implementing this opera-
www.it-ebooks.info

2.5 n Applications 351 tion is immediate, using a priority queue. Several other data-compression schemes are
based upon sorting.
String-processing algorithms, which are of critical importance in modern applica- tions in cryptology and in genomics, are often based on sorting (generally using one of the specialized string sorts discussed in Chapter 5). For example, we will discuss in Chapter 6 algorithms for  nding the longest repeated substring in a given string that is based on  rst sorting suf xes of the strings.
www.it-ebooks.info

352 Chapter 2 n Sorting
 Q&A
 Q. Is there a priority-queue data type in the Java library?
A. Yes,seejava.util.PriorityQueue.
Q. Does stability matter when sorting arrays primitive types in Java?
A. Stabilityisa(mostly)meaninglessconceptwhenappliedtoprimitivetypesbecause you cannot distinguish between two equal int or double values. There is one exotic exception that arises because there are multiple representations of NaN but they are considered equal when sorting.
www.it-ebooks.info

2.5.1 ConsiderthefollowingimplementationofthecompareTo()methodforString. How does the third line help with ef ciency?
    public int compareTo(String that)
    {
       if (this == that) return 0;  // this line
       int n = Math.min(this.length(), that.length());
       for (int i = 0; i < n; i++)
       {
          if      (this.charAt(i) < that.charAt(i)) return -1;
          else if (this.charAt(i) > that.charAt(i)) return +1;
       }
       return this.length() - that.length();
    }
2.5.2 Writeaprogramthatreadsalistofwordsfromstandardinputandprintsalltwo- word compound words in the list. For example, if after, thought, and afterthought are in the list, then afterthought is a compound word.
2.5.3 Criticize the following implementation of a class intended to represent account balances. Why is compareTo() a  awed implementation of the Comparable interface?
    public class Balance implements Comparable<Balance>
    {
       ...
       private double amount;
       public int compareTo(Balance that)
       {
          if (this.amount < that.amount - 0.005) return -1;
          if (this.amount > that.amount + 0.005) return +1;
          return 0;
}
... }
Describe a way to  x this problem.
2.5.4 ImplementamethodString[]dedup(String[] a)thatreturnstheobjectsin
a[] in sorted order, with duplicates removed. 2.5.5 Explain why selection sort is not stable.
www.it-ebooks.info
2.5 n Applications 353
 ExErcisEs

354 Chapter 2 n Sorting ExErcisEs (continued)
2.5.6 Implement a recursive version of select().
2.5.7 About how many compares are required, on the average, to  nd the smallest of
N items using select()?
2.5.8 Write a program Frequency that reads strings from standard input and prints
the number of times each string occurs, in descending order of frequency.
2.5.9 Developadatatypethatallowsyoutowriteaclientthatcansorta lesuchasthe one shown at right.
2.5.10 Create a data type Version that represents a software version number, such as 115.1.1, 115.10.1, 115.10.2. Implement the Comparable interface so that 115.1.1 is less than 115.10.1, and so forth.
2.5.11 One way to describe the result of a sorting al- gorithm is to specify a permutation p[] of the num- bers 0 to a.length-1, such that p[i] speci es where the key originally in a[i] ends up. Give the permuta- tions that describe the results of insertion sort, selec- tion sort, shellsort, mergesort, quicksort, and heapsort for an array of seven equal keys.
  input (DJi A volumes for each day)
 1-Oct-28
 2-Oct-28
 3-Oct-28
 4-Oct-28
 5-Oct-28
...
30-Dec-99
31-Dec-99
              3500000
              3850000
              4060000
              4330000
              4360000
            554680000
            374049984
            931800000
19-Aug-40 130000
26-Aug-40 160000
24-Jul-40 200000
10-Aug-42 210000
23-Jun-42 210000
...
23-Jul-02 2441019904
17-Jul-02 2566500096
15-Jul-02 2574799872
19-Jul-02 2654099968
24-Jul-02 2775559936
3-Jan-00
4-Jan-00  1009000000
5-Jan-00  1085500032
...
output
www.it-ebooks.info

2.5.12 Scheduling. Write a program SPT.java that reads job names and processing times from standard input and prints a schedule that minimizes average completion time using the shortest processing time  rst rule, as described on page 349.
2.5.13 Load balancing. Write a program LPT.java that takes an integer M as a com- mand-line argument, reads job names and processing times from standard input and prints a schedule assigning the jobs to M processors that approximately minimizes the time when the last job completes using the longest processing time  rst rule, as de- scribed on page 349.
2.5.14 Sort by reverse domain. Write a data type Domain that represents domain names, including an appropriate compareTo() method where the natural order is in order of the reverse domain name. For example, the reverse domain of cs.princeton.edu is edu.princeton.cs. This is useful for web log analysis. Hint: Use s.split("\\.") to split the string s into tokens, delimited by dots. Write a client that reads domain names from standard input and prints the reverse domains in sorted order.
2.5.15 Spam campaign. To initiate an illegal spam campaign, you have a list of email addresses from various domains (the part of the email address that follows the @ symbol). To better forge the return addresses, you want to send the email from an- other user at the same domain. For example, you might want to forge an email from wayne@princeton.edu to rs@princeton.edu. How would you process the email list to make this an ef cient task?
2.5.16 Unbiased election. In order to thwart bias against candidates whose names ap- pear toward the end of the alphabet, California sorted the candidates appearing on its 2003 gubernatorial ballot by using the following order of characters:
R WQOJMVAHBSGZXNTCIEKUPDYFL
Create a data type where this is the natural order and write a client California with a single static method main() that sorts strings according to this ordering. Assume that each string is composed solely of uppercase letters.
2.5.17 Check stability. Extend your check() method from Exercise 2.1.16 to call sort() for a given array and return true if sort() sorts the array in order in a stable manner, false otherwise. Do not assume that sort() is restricted to move data only with exch().
www.it-ebooks.info
2.5 n Applications 355
 crEAtivE problEms

356 Chapter 2 n Sorting
  2.5.18 Force stability. Write a wrapper method that makes any sort stable by creating a new key type that allows you to append each key’s index to the key, call sort(), then restore the original key after the sort.
2.5.19 Kendall tau distance. Write a program KendallTau.java that computes the Kendall tau distance between two permutations in linearithmic time.
2.5.20 Idle time. Suppose that a machine processes N jobs. Write a program that, giv- en the list of job start and  nish times,  nds the largest interval where the machine is idle and the largest interval where the machine is not idle.
2.5.21 Multidimensional sort. Write a Vector data type for use in having the sort- ing methods sort multidimensional vectors of d integers, putting the vectors in order by  rst component, those with equal  rst component in order by second component, those with equal  rst and second components in order by third component, and so forth.
2.5.22 Stock market trading. Investors place buy and sell orders for a particular stock on an electronic exchange, specifying a maximum buy or minimum sell price that they are willing to pay, and how many shares they wish to trade at that price. Develop a program that uses priority queues to match up buyers and sellers and test it through simulation. Maintain two priority queues, one for buyers and one for sellers, executing trades whenever a new order can be matched with an existing order or orders.
2.5.23 Sampling for selection. Investigate the idea of using sampling to improve selec- tion. Hint: Using the median may not always be helpful.
2.5.24 Stable priority queue. Develop a stable priority-queue implementation (which returns duplicate keys in the same order in which they were inserted).
2.5.25 Points in the plane. Write three static comparators for the Point2D data type of page 77, one that compares points by their x coordinate, one that compares them by their y coordinate, and one that compares them by their distance from the origin. Write two non-static comparators for the Point2D data type, one that compares them by their distance to a speci ed point and one that compares them by their polar angle with respect to a speci ed point.
2.5.26 Simple polygon. Given N points in the plane, draw a simple polygon with the
www.it-ebooks.info
crEAtivE problEms (continued)
  N points as vertices. Hint : Find the point p with the smallest y coordinate, breaking ties with the smallest x coordinate. Connect the points in increasing order of the polar angle they make with p.
2.5.27 One-dimensional intervals. Write three comparators for the Interval1D data type of page 77, one that compares intervals by their left endpoint, one that compares intervals by their right endpoint, and one that compares intervals by their length.
2.5.28 Sort  les by name. Write a program FileSorter that takes the name of a directory as a command-line argument and prints out all of the  les in that directory, sorted by  le name. Hint : Use the File data type.
2.5.29 Sort  les by size and date of last modi cation. Write comparators for the type File to order by increasing/decreasing order of  le size, ascending/descending order of  le name, and ascending/descending order of last modi cation date. Use these comparators in a program LS that takes a command-line argument and lists the  les in the current directory according to a speci ed order, e.g., "-t" to sort by timestamp. Support multiple  ags to break ties. Be sure to use a stable sort.
2.5.30 Boerner’s theorem. True or false: If you sort each column of a matrix, then sort each row, the columns are still sorted. Justify your answer.
www.it-ebooks.info
2.5 n Applications 357

358 Chapter 2 n Sorting
 ExpErimENts
 2.5.31 Distinct values. Write a client that takes integers M, N, and T as command-line arguments, then uses the code given in the text to perform T trials of the following ex- periment: Generate N random int values between 0 and M – 1 and count the number of distinct values. Run your program for T = 10 and N = 103, 104, 105, and 106, with M = N2, and N, and 2N. Probability theory says that the number of distinct values should be about M (1 – e –a) where a  N  M—print a table to help you con rm that your experiments validate that formula.
2.5.32 8 puzzle. The 8 puzzle is a game invented and popularized by Noyes Palmer Chapman in the 1870s. It is played on a 3-by-3 grid with 8 tiles labeled 1 through 8 and a blank square. Your goal is to rearrange the tiles so that they are in order. You are permit- ted to slide one of the available tiles horizontally or vertically (but not diagonally) into the blank square. Write a program that solves the puzzle using the A* algorithm. Start by using as priority the sum of the number of moves made to get to this board posi- tion plus the number of tiles in the wrong position. (Note that the number of moves you must make from a given board position is at least as big as the number of tiles in the wrong place.) Investigate substituting other functions for the number of tiles in the wrong position, such as the sum of the Manhattan distance from each tile to its correct position, or the sums of the squares of these distances.
2.5.33 Random transactions. Develop a generator that takes an argument N, generates N random Transaction objects (see Exercises 2.1.21 and 2.1.22), using assumptions about the transactions that you can defend. Then compare the performance of shellsort, mergesort, quicksort, and heapsort for sorting N transactions, for N=103, 104, 105, and 106.
www.it-ebooks.info

This page intentionally left blank
www.it-ebooks.info

 three
Searching
3.1 Symbol tables 362
3.2 Binary Search trees 396
3.3 Balanced Search trees 424
     3.4 hash tables
3.5 Applications
458 486
www.it-ebooks.info
 Modern computing and the internet have made accessible a vast amount of information. The ability to ef ciently search through this information is fundamental to processing it. This chapter describes classical searching algo- rithms that have proven to be effective in numerous diverse applications for decades. Without algorithms like these, the development of the computational infrastructure that we enjoy in the modern world would not have been possible.
We use the term symbol table to describe an abstract mechanism where we save in- formation (a value) that we can later search for and retrieve by specifying a key. The nature of the keys and the values depends upon the application. There can be a huge number of keys and a huge amount of information, so implementing an ef cient sym- bol table is a signi cant computational challenge.
Symbol tables are sometimes called dictionaries, by analogy with the time-honored system of providing de nitions for words by listing them alphabetically in a reference book. In an English-language dictionary, a key is a word and its value is the entry as- sociated with the word that contains the de nition, pronunciation, and etymology. Symbol tables are also sometimes called indices, by analogy with another time-honored system of providing access to terms by listing them alphabetically at the end of a book such as a textbook. In a book index, a key is a term of interest and its value is the list of page numbers that tell readers where to  nd that term in the book.
After describing the basic APIs and two fundamental implementations, we consider three classic data structures that can support ef cient symbol-table implementations: binary search trees, red-black trees, and hash tables. We conclude with several exten- sions and applications, many of which would not be feasible without the ef cient algo- rithms that you will learn about in this chapter.
www.it-ebooks.info
361

   362
The primary purpose of a symbol table is to associate a value with a key. The client can insert key-value pairs into the symbol table with the expectation of later being able to search for the value associated with a given key, from among all of the key-value pairs that have been put into the table. This chapter describes several ways to structure this data so as to make ef cient not just the insert and search operations, but several other convenient operations as well. To implement a symbol table, we need to de ne an un- derlying data structure and then specify algorithms for insert, search, and other opera- tions that create and manipulate the data structure.
Search is so important to so many computer applications that symbol tables are available as high-level abstractions in many programming environments, including Java—we shall discuss Java’s symbol-table implementations in Section 3.5. The table below gives some examples of keys and values that you might use in typical applica- tions. We consider some illustrative reference clients soon, and Section 3.5 is devoted to showing you how to use symbol tables effectively in your own clients. We also use symbol tables in developing other algorithms throughout the book.
 Definition. Asymboltableisadatastructureforkey-valuepairsthatsupportstwo operations: insert (put) a new pair into the table and search for (get) the value as- sociated with a given key.
application
dictionary
book index
 le share account management web search compiler
purpose of search
 nd de nition  nd relevant pages  nd song to download process transactions  nd relevant web pages  nd type and value
key
word
term name of song account number keyword variable name
value
de nition
list of page numbers computer ID transaction details list of page names type and value
 typical symbol-table applications
www.it-ebooks.info
 3.1 SyMBol tABleS

 API The symbol table is a prototypical abstract data type (see Chapter 1): it repre- sents a well-de ned set of values and operations on those values, enabling us to develop clients and implementations separately. As usual, we precisely de ne the operations by specifying an applications programming interface (API) that provides the contract between client and implementation:
3.1 n Symbol Tables 363
 public class ST<Key, Value>
  void
Value
         void
      boolean
      boolean
          int
Iterable<Key>
ST()
put(Key key, Value val)
get(Key key)
delete(Key key)
contains(Key key)
isEmpty()
size()
keys()
create a symbol table
put key-value pair into the table
(remove key from table if value is null) value paired with key
(null if key is absent)
remove key (and its value) from table is there a value paired with key?
is the table empty?
number of key-value pairs in the table all the keys in the table
apI for a generic basic symbol table
Before examining client code, we consider several design choices for our implementa- tions to make our code consistent, compact, and useful.
Generics As we did with sorting, we will consider the methods without specifying the types of the items being processed, using generics. For symbol tables, we emphasize the separate roles played by keys and values in search by specifying the key and value types explicitly instead of viewing keys as implicit in items as we did for priority queues in Section 2.4. After we have considered some of the characteristics of this basic API (for example, note that there is no mention of order among the keys), we will consider an extension for the typical case when keys are Comparable, which enables numerous ad- ditional methods.
Duplicate keys We adopt the following conventions in all of our implementations: n Only one value is associated with each key (no duplicate keys in a table).
n When a client puts a key-value pair into a table already containing that key (and
an associated value), the new value replaces the old one.
These conventions de ne the associative array abstraction, where you can think of a symbol table as being just like an array, where keys are indices and values are array
www.it-ebooks.info

364 Chapter 3 n Searching
entries. In a conventional array, keys are integer indices that we use to quickly access ar- ray values; in an associative array (symbol table), keys are of arbitrary type, but we can still use them to quickly access values. Some programming languages (not Java) provide special support that allows programmers to use code such as st[key] for st.get(key) andst[key] = valforst.put(key, val)wherekeyandvalareobjectsofarbitrary type.
Null keys Keys must not be null. As with many mechanisms in Java, use of a null key results in an exception at runtime (see the third Q&A on page 387).
Null values We also adopt the convention that no key can be associated with the value null. This convention is directly tied to our speci cation in the API that get() should return null for keys not in the table, effectively associating the value null with every key not in the table. This convention has two (intended) consequences: First, we can test whether or not the symbol table de nes a value associated with a given key by test- ing whether get() returns null. Second, we can use the operation of calling put() with null as its second (value) argument to implement deletion, as described in the next paragraph.
Deletion Deletion in symbol tables generally involves one of two strategies: lazy dele- tion, where we associate keys in the table with null, then perhaps remove all such keys at some later time; and eager deletion, where we remove the key from the table imme- diately. As just discussed, the code put(key, null) is an easy (lazy) implementation of delete(key). When we give an (eager) implementation of delete(), it is intended to replace this default. In our symbol-table implementations that do not use the default delete(), the put() implementations on the booksite begin with the defensive code
if (val == null) { delete(key); return; }
to ensure that no key in the table is associated with null. For economy, we do not in-
clude this code in the book (and we do not call put() with a null value in client code).
Shorthand methods For clarity in client code, we include the methods contains() and isEmpty() in the API, with the default one-line implementations shown here. For economy, we do not
repeat this code, but we
assume it to be present in all implementations of the symbol-table API and use these methods freely in client code.
 method default implementation
  void delete(Key key) put(key, null);
boolean contains(Key key) return get(key) != null; boolean isEmpty() return size() == 0;
Default implementations
www.it-ebooks.info

Iteration To enable clients to process all the keys and values in the table, we might add the phrase implements Iterable<Key> to the  rst line of the API to specify that every implementation must implement an iterator() method that returns an iterator having appropriate implementations of hasNext() and next(), as described for stacks and queues in Section 1.3. For symbol tables, we adopt a simpler alternative approach, where we specify a keys() method that returns an Iterable<Key> object for clients to use to iterate through the keys. Our reason for doing so is to maintain consistency with methods that we will de ne for ordered symbol tables that allow clients to iterate through a speci ed subset of keys in the table.
Key equality Determining whether or not a given key is in a symbol table is based on the concept of object equality, which we discussed at length in Section 1.2 (see page 102). Java’s convention that all objects inherit an equals() method and its implemen- tation of equals() both for standard types such as Integer, Double, and String and for more complicated types such as File and URL is a head start—when using these types of data, you can just use the built-in implementation. For example, if x and y are String values, then x.equals(y) is true if and only if x and y have the same length and are identical in each character position. For such client-de ned keys, you need to override equals(), as discussed in Section 1.2. You can use our implementation of equals() for Date (page 103) as a template to develop equals() for a type of your own. As discussed for priority queues on page 320, a best practice is to make Key types immutable, because consistency cannot otherwise be guaranteed.
www.it-ebooks.info
3.1 n Symbol Tables 365

366 Chapter 3 n Searching
Ordered symbol tables In typical applications, keys are Comparable objects, so the option exists of using the code a.compareTo(b) to compare two keys a and b. Several symbol-table implementations take advantage of order among the keys that is implied by Comparable to provide ef cient implementations of the put() and get() operations. More important, in such implementations, we can think of the symbol ta- ble as keeping the keys in order and consider a signi cantly expanded API that de nes numerous natural and useful operations involving relative key order. For example, sup- pose that your keys are times of the day. You might be interested in knowing the earliest or the latest time, the set of keys that fall between two given times, and so forth. In most cases, such operations are not dif cult to implement with the same data structures and methods underlying the put() and get() implementations. Speci cally, for applica- tions where keys are Comparable, we implement in this chapter the following API:
 public class ST<Key extends Comparable<Key>, Value>
    ST()
void put(Key key, Value val)
Value get(Key key)
void delete(Key key) boolean contains(Key key) boolean isEmpty()
int size()
Key min()
Key max()
Key floor(Key key) Key ceiling(Key key) int rank(Key key) Key select(int k)
void deleteMin() void deleteMax()
int size(Key lo, Key hi) Iterable<Key> keys(Key lo, Key hi)
create an ordered symbol table put key-value pair into the table
(remove key from table if value is null) value paired with key
(null if key is absent)
remove key (and its value) from table
is there a value paired with key?
is the table empty?
number of key-value pairs
smallest key
largest key
largest key less than or equal to key smallest key greater than or equal to key number of keys less than key
key of rank k
delete smallest key
delete largest key
number of keys in [lo..hi]
keys in [lo..hi], in sorted order
all keys in the table, in sorted order
Iterable<Key>
keys()
apI for a generic ordered symbol table
www.it-ebooks.info

Your signal that one of our programs is implementing this API is the presence of the Key extends Comparable<Key> generic type variable in the class declaration, which speci es that the code depends upon the keys being Comparable and implements the richer set of operations. Together, these operations de ne for client programs an or- dered symbol table.
Minimum and maximum Perhaps the most natural queries for a set of ordered keys are to ask for the smallest and largest keys. We have already encountered these opera- tions, in our discussion of priority queues in Section 2.4. In ordered symbol tables, we also have methods to delete the maximum
and minimum keys (and their associated val- ues). With this capability, the symbol table can operate like the IndexMinPQ() class that we discussed in Section 2.4. The primary differ- ences are that equal keys are allowed in prior- ity queues but not in symbol tables and that ordered symbol tables support a much larger set of operations.
keys
3.1 n Symbol Tables
367
 min()
            get(09:00:13)
          floor(09:05:00)
                select(7)
keys(09:15:00, 09:25:00)
        ceiling(09:30:00)
                    max()
size(09:15:00, 09:25:00) is 5 rank(09:10:25) is 7
values
          Chicago
09:00:03  Phoenix
09:00:13  Houston
09:00:59  Chicago
09:01:10  Houston
09:03:13  Chicago
09:10:11  Seattle
09:10:25  Seattle
09:14:25  Phoenix
09:19:32  Chicago
09:19:46  Chicago
09:21:05  Chicago
09:22:43  Seattle
09:22:54  Seattle
09:25:52  Chicago
09:35:21  Chicago
09:36:14  Seattle
09:00:00
        Floor and ceiling
Given a key, it is often use- ful to be able to perform the  oor operation ( nd the largest key that is less than or equal to the given key) and the ceiling operation ( nd the smallest key that is greater than or equal to the given key). The nomenclature comes from functions de ned on real numbers (the  oor of a real number x is the largest integer that is smaller than or equal to x and the ceiling of a real number x is the smallest integer that is
09:37:44
Phoenix
      greater than or equal to x).
Rank and selection The basic operations for determining where a new key  ts in the order are the rank operation ( nd the number of keys less than a given key) and the select operation ( nd the key with a given rank). To test your understanding of their meaning, con rm for yourself that both i == rank(select(i)) for all i between 0 and size()-1 and all keys in the table satisfy key == select(rank(key)). We have already encountered the need for these operations, in our discussion of sort applica- tions in Section 2.5. For symbol tables, our challenge is to perform these operations quickly, intermixed with insertions, deletions, and searches.
www.it-ebooks.info
Examples of ordered symbol-table operations

368 Chapter 3 n Searching
Range queries How many keys fall within a given range (between two given keys)? Which keys fall in a given range? The two-argument size() and keys() methods that answer these questions are useful in many applications, particularly in large databases. The capability to handle such queries is one prime reason that ordered symbol tables are so widely used in practice.
Exceptional cases When a method is to return a key and there is no key  tting the de- scription in the table, our convention is to throw an exception (an alternate approach, whichisalsoreasonable,wouldbetoreturnnull insuchcases).Forexample,min(), max(), deleteMin(), deleteMax(), floor(), and ceiling() all throw exceptions if the table is empty, as does select(k) if k is less than 0 or not less than size().
Shorthand methods As we have already seen with isEmpty() and contains() in our basic API, we keep some redundant methods in the API for clarity in client code. For economy in the text, we assume that the following default implementations are includ- ed in any implementation of the ordered symbol-table API unless otherwise speci ed:
 method default implementation
         void deleteMin()
         void deleteMax()
int size(Key lo, Key hi)
Iterable<Key> keys()
delete(min());
delete(max());
if (hi.compareTo(lo) < 0)
   return 0;
else if (contains(hi))
   return rank(hi) - rank(lo) + 1;
else
   return rank(hi) - rank(lo);
return keys(min(), max());
Default implementations of redundant order-based symbol-table methods
  Key equality (revisited) The best practice in Java is to make compareTo() consistent with equals() in all Comparable types. That is, for every pair of values a and b in any given Comparable type, it should be the case that (a.compareTo(b) == 0) and a.equals(b) have the same value. To avoid any potential ambiguities, we avoid the use of equals() in ordered symbol-table implementations. Instead, we use compareTo() exclusivelytocomparekeys:wetakethebooleanexpressiona.compareTo(b) == 0to
www.it-ebooks.info

mean “Are a and b equal ?” Typically, such a test marks the successful end of a search for a in the symbol table (by  nding b). As you saw with sorting algorithms, Java provides standard implementations of compareTo() for many commonly used types of keys, and it is not dif cult to develop a compareTo() implementation for your own data types (see Section 2.5).
Cost model Whether we use equals() (for symbol tables where keys are not Comparable) or compareTo() (for or- dered symbol tables with Comparable keys), we use the term compare to refer to the operation of comparing a symbol- table entry against a search key. In most symbol-table imple- mentations, this operation is in the inner loop. In the few cases where that is not the case, we also count array accesses.
Symbol-table implementations are generally character-
ized by their underlying data structures and their implemen-
tations of get() and put(). We do not always provide im-
plementations of all of the other methods in the text because
many of them make good exercises to test your understanding of the underlying data structures. To distinguish implementations, we add a descriptive pre x to ST that refers to the implementation in the class name of symbol-table implementations. In clients, we use ST to call on a reference implementation unless we wish to refer to a speci c implementation. You will gradually develop a better feeling for the rationale behind the methods in the APIs in the context of the numerous clients and symbol-table imple- mentations that we present and discuss throughout this chapter and throughout the rest of this book. We also discuss alternatives to the various design choices that we have described here in the Q&A and exercises.
3.1 n Symbol Tables 369
 searching cost model.
When studying symbol-table implementations, we count compares (equality tests or key comparisons). In (rare) cases where compares are not in the inner loop, we count array accesses.
www.it-ebooks.info

370 Chapter 3 n Searching
Sample clients While we defer detailed consideration of applications to Section 3.5, it is worthwhile to consider some client code before considering implementations. Accordingly, we now consider two clients: a test client that we use to trace algorithm behavior on small inputs and a performance client that we use to motivate the develop- ment of ef cient implementations.
Test client For tracing our algorithms on small inputs we assume that all of our im- plementations use the test client below, which takes a sequence of strings from standard input, builds a symbol table that associates the value i with the ith string in the input, and then prints the table. In the traces in the text, we assume that the input is a sequence
   public static void main(String[] args)
  {
     ST<String, Integer> st;
     st = new ST<String, Integer>();
     for (int i = 0; !StdIn.isEmpty(); i++)
     {
        String key = StdIn.readString();
        st.put(key, i);
     }
     for (String s : st.keys())
        StdOut.println(s + " " + st.get(s));
}
Basic symbol-table test client
 keys S E A R C H E X A M P L E values 0 1 2 3 4 5 6 7 8 9 10 11 12
of single-character strings. Most often, we usethestring"S E A R C H E X A M P L E". By our conventions, this client associates the key S with the value 0, the key R with the value 3, and so forth. But E is associated with the value 12 (not 1 or 6) and A with the value 8 (not 2) because our associative- array convention implies that each key is associated with the value used in the most recent call to put(). For basic (unordered) implementations, the order of the keys in the output of this test client is not speci ed (it depends on characteristics of the imple- mentation); for an ordered symbol table the test client prints the keys in sorted order. This client is an example of an indexing cli- ent, a special case of a fundamental symbol- table application that we discuss in Section
3.5.
output for basic symbol table (one possibility)
L11 P10 M9 X7 H5 C4 R3 A8 E12 S0
output for ordered symbol table
A8 C4 E12 H5 L11 M9 P10 R3 S0 X7
Keys, values, and output for test client
www.it-ebooks.info

Performance client FrequencyCounter (on the next page) is a symbol-table client that  nds the number of occurrences of each string (having at least as many characters as a given threshold length) in a sequence of strings from standard input, then iterates through the keys to  nd the one that occurs the most frequently. This client is an exam- ple of a dictionary client, an application that we discuss in more detail in Section 3.5. This client answers a simple question: Which word (no shorter than a given length) oc- curs most frequently in a given text? Throughout this chapter, we measure performance of this client with three reference inputs: the  rst  ve lines of C. Dickens’s Tale of Two Cities (tinyTale.txt), the full text of the book (tale.txt), and a popular database of 1 million sentences taken at random from the web that is known as the Leipzig Corpora Collection (leipzig1M.txt). For example, here is the content of tinyTale.txt:
Small test input
This text has 60 words taken from 20 distinct words, four of which occur ten times (the highest frequency). Given this input, FrequencyCounter will print out any of it, was, the, or of (the one chosen may vary, depending upon characteristics of the symbol- table implementation), followed by the frequency, 10.
To study performance for the larger inputs, it is clear that two measures are of inter- est: Each word in the input is used as a search key once, so the total number of words in the text is certainly relevant. Second, each distinct word in the input is put into the
3.1 n Symbol Tables 371
 % more tinyTale.txt
it was the best of times it was the worst of times
it was the age of wisdom it was the age of foolishness
it was the epoch of belief it was the epoch of incredulity
it was the season of light it was the season of darkness
it was the spring of hope it was the winter of despair
 tinyTale.txt
words distinct
60 20 3 3 2 2
tale.txt
leipzig1M.txt
 all words
at least 8 letters at least 10 letters
words
135,635 14,350 4,582
distinct
10,679 5,737 2,260
words
21,191,455 4,239,597 1,610,829
distinct
534,580 299,593 165,555
Characteristics of larger test input streams
www.it-ebooks.info

 372 Chapter 3 n Searching
 A symbol-table client
  public class FrequencyCounter
  {
     public static void main(String[] args)
     {
        int minlen = Integer.parseInt(args[0]);
        ST<String, Integer> st = new ST<String, Integer>();
        while (!StdIn.isEmpty())
        {  // Build symbol table and count frequencies.
           String word = StdIn.readString();
           if (word.length() < minlen) continue;  // Ignore short keys.
           if (!st.contains(word)) st.put(word, 1);
           else                    st.put(word, st.get(word) + 1);
}
        // Find a key with the highest frequency count.
        String max = "";
        st.put(max, 0);
        for (String word : st.keys())
           if (st.get(word) > st.get(max))
              max = word;
        StdOut.println(max + " " + st.get(max));
     }
}
This ST client counts the frequency of occurrence of the strings in standard input, then prints out one that occurs with highest frequency. The command-line argument speci es a lower bound on the length of keys considered.
 www.it-ebooks.info
// key-length cutoff
  % java FrequencyCounter 1 < tinyTale.txt
it 10
% java FrequencyCounter 8 < tale.txt
business 122
% java FrequencyCounter 10 < leipzig1M.txt
government 24763
 symbol table (and the total number of distinct words in the input gives the size of the table after all keys have been inserted), so the total number of distinct words in the input stream is certainly relevant. We need to know both of these quantities in order to estimate the running time of FrequencyCounter (for a start, see Exercise 3.1.6). We defer details until we consider some algorithms, but you should have in mind a general idea of the needs of typical applications like this one. For example, running FrequencyCounter on leipzig1M.txt for words of length 8 or more involves millions of searches in a table with hundreds of thousands of keys and values. A server on the web might need to handle billions of transactions on tables with millions of keys and values.
The basic question that this client and these examples raise is the following: Can we develop a symbol-table implementation that can handle a huge number of get() operations on a large table, which itself was built with a large number of intermixed get() and put() operations? If you are only doing a few searches, any implementation will do, but you cannot make use of a client like FrequencyCounter for large prob- lems without a good symbol-table implementation. FrequencyCounter is surrogate for a very common situation. Speci cally, it has the following characteristics, which are shared by many other symbol-table clients:
n Search and insert operations are intermixed.
n The number of distinct keys is not small.
n Substantially more searches than inserts are likely.
n Search and insert patterns, though unpredictable, are not random.
Our goal is to develop symbol-table implementations that make it feasible to use such clients to solve typical practical problems.
Next, we consider two elementary implementations and their performance for FrequencyCounter. Then, in the next several sections, you will learn classic imple- mentations that can achieve excellent performance for such clients, even for huge input streams and tables.
www.it-ebooks.info
3.1 n Symbol Tables 373
374 Chapter 3 n Searching
Sequential search in an unordered linked list One straightforward option for the underlying data structure for a symbol table is a linked list of nodes that contain keys and values, as in the code on the facing page. To implement get(), we scan through the list, using equals() to compare the search key with the key in each node in the list. If we  nd the match, we return the associated value; if not, we return null. To imple- ment put(), we also scan through the list, using equals() to compare the client key with the key in each node in the list. If we  nd the match, we update the value associ- ated with that key to be the value given in the second argument; if not, we create a new node with the given key and value and insert it at the beginning of the list. This method is known as sequential search: we search by considering the keys in the table one after another, using equals() to test for a match with our search key.
Algorithm 3.1 (SequentialSearchST) is an implementation of our basic symbol- table API that uses standard list-processing mechanisms, which we have used for el- ementary data structures in Chapter 1. We have left the implementations of size(), keys(), and eager delete() for exercises. You are encouraged to work these exercises to cement your understanding of the linked-list data structure and the basic symbol- table API.
Can this linked-list-based implementation handle applications that need large ta- bles, such as our sample clients? As we have noted, analyzing symbol-table algorithms is more complicated than analyzing sorting algorithms because of the dif culty of
key value
S0 E1 A2 R3 C4 H5 E6 X7 A8 M9 P 10 L 11 E 12
first
red nodes are new
    S
0
7
5
4
3
black nodes are accessed in search
    E
1
S
0
         A
2
E
1
S
0
            R
3
       4
A
2
3
E
1
2
S
0
         C
R
A
E
1
S
0
        2
E
6
circled entries are changed values
gray nodes are untouched
            H
5
       5
C
4
4
R
3
3
A
2
        2
E
1
S
S
0
           H
C
R
A
E
6
0
                        X
H
C
R
A
S
0
                           X
7
H
5
C
4
R
3
A
8
E
6
S
0
                              M
9
X
7
H
5
C
4
R
3
A
8
E
6
S
0
                                P
10
M
9
X
7
H
5
C
4
R
3
A
8
E
6
S
0
                                    L
11
P
10
M
9
X
7
H
5
C
4
R
3
A
8
E
6
S
0
                                       L
11
P
10
M
9
X
7
H
Trace of linked-list ST implementation for standard indexing client
www.it-ebooks.info
5
C
4
R
3
A
8
E
12
S
0

 3.1 n Symbol Tables 375
 aLgorIthM 3.1 Sequential search (in an unordered linked list) public class SequentialSearchST<Key, Value>
 {
private Node first;
private class Node
{  // linked-list node
// first node in the linked list
Key key;
Value val;
Node next;
public Node(Key key, Value val, Node next)
{
   this.key  = key;
   this.val  = val;
   this.next = next;
} }
     public Value get(Key key)
     {  // Search for key, return associated value.
        for (Node x = first; x != null; x = x.next)
           if (key.equals(x.key))
              return x.val;    // search hit
        return null;           // search miss
}
     public void put(Key key, Value val)
     {  // Search for key. Update value if found; grow table if new.
        for (Node x = first; x != null; x = x.next)
           if (key.equals(x.key))
           {  x.val = val; return;  }      // Search hit: update val.
        first = new Node(key, val, first); // Search miss: add new node.
     }
}
This ST implementation uses a private Node inner class to keep the keys and values in an unordered linked list. The get() implementation searches the list sequentially to  nd whether the key is in the table (and returns the associated value if so). The put() implementation also searches the list sequen- tially to check whether the key is in the table. If so, it updates the associated value; if not, it creates a new node with the given key and value and inserts it at the beginning of the list. Implementations of size(), keys(), and eager delete() are left for exercises.
 www.it-ebooks.info
376 Chapter 3 n Searching
characterizing the sequence of operations that might be invoked by a given client. As noted for FrequencyCounter, the most common situation is that, while search and insert patterns are unpredictable, they certainly are not random. For this reason, we pay careful attention to worst-case performance. For economy, we use the term search hit to refer to a successful search and search miss to refer to an unsuccessful search.
 proposition A. Search misses and insertions in an (unordered) linked-list symbol table having N key-value pairs both require N compares, and search hits N com- pares in the worst case.
proof: Whensearchingforakeythatisnotinthelist,wetesteverykeyinthetable against the search key. Because of our policy of disallowing duplicate keys, we need to do such a search before each insertion.
 corollary. InsertingNdistinctkeysintoaninitiallyemptylinked-listsymboltable uses ~N 2/2 compares.
It is true that searches for keys that are in the table need not take linear time. One useful measure is to compute the total cost of searching for all of the keys in the table, divided by N. This quantity is precisely the expected number of compares required for a search under the condition that searches for each key in the table are equally likely. We refer to such a search as a random search hit. Though client search patterns are not likely to be random, they often are well-described by this model. It is easy to show that the average number of compares for a random search hit is ~ N/2: the get() method in Algo- rithm 3.1 uses 1 compare to  nd the  rst key, 2 compares to  nd the second key, and so forth, for an average cost of (1 + 2 + ... + N )/ N = (N  1)/2 ~ N/2.
This analysis strongly indicates that a linked-list implementation with sequential search is too slow for it to be used to solve huge problems such as our reference inputs with clients like FrequencyCounter. The total number of compares is proportional to the product of the number of searches and the number of inserts, which is more than 10 9 for Tale of Two Cities and more than 1014 for the Leipzig Corpora.
As usual, to validate analytic results, we need to run experiments. As an example, we study the operation of FrequencyCounter with command-line argument 8 for tale.txt, which involves 14,350 put() operations (recall that every word in the in- put leads to a put(), to update its frequency, and we ignore the cost of easily avoided calls to contains()). The symbol table grows to 5,737 keys, so about one-third of the
www.it-ebooks.info

 operations increase the size of the table; the rest are searches. To visualize the perfor- mance, we use VisualAccumulator (see page 95) to plot two points corresponding to each put() operation as follows: for the i th put() operation we plot a gray point with x coordinate i and y coordinate the number of key compares it uses and a red point with x coordinate i and y coordinate the cumulative average number of key compares used for the  rst i put() operations. As with any scienti c data, there is a great deal of information in this data for us to investigate (this plot has 14,350 gray points and 14,350 red points). In this context, our primary interest is that the plot validates our hypothesis that about half the list is accessed for the average put() operation. The ac- tual total is slightly lower than half, but this fact (and the precise shape of the curves) is perhaps best explained by characteristics of the application, not our algorithms (see Exercise 3.1.36).
While detailed characterization of performance for particular clients can be com- plicated, speci c hypotheses are easy to formulate and to test for FrequencyCounter with our reference inputs or with randomly ordered inputs, using a client like the DoublingTest client that we introduced in Chapter 1. We will reserve such testing for exercises and for the more sophisticated implementations that follow. If you are not already convinced that we need faster implementations, be sure to work these exercises (or just run FrequencyCounter with SequentialSearchST on leipzig1M.txt!).
5737
0
operations
Costs for java FrequencyCounter 8 < tale.txt using SequentialSearchST
0
14350
www.it-ebooks.info
3.1 n Symbol Tables 377
compares
2246
378 Chapter 3 n Searching
Binary search in an ordered array Next, we consider a full implementation of our ordered symbol-table API. The underlying data structure is a pair of parallel arrays, one for the keys and one for the values. Algorithm 3.2 (BinarySearchST) on the facing page keeps Comparable keys in order in the array, then uses array indexing to enable fast implementation of get() and other operations.
The heart of the implementation is the rank() method, which returns the number of keys smaller than a given key. For get(), the rank tells us precisely where the key is to be found if it is in the table (and, if it is not there, that it is not in the table).
For put(), the rank tells us precisely where to update the value when the key is in the table, and precisely where to put the key when the key is not in the table. We move all larger keys over one position to make room (working from back to front) and insert the given key and value into the proper positions in their respective arrays. Again, studying BinarySearchST in conjunction with a trace of our test client is an instructive intro- duction to this data structure.
This code maintains parallel arrays of keys and values (see Exercise 3.1.12 for an alternative). As with our implementations of generic stacks and queues in Chapter 1, this code carries the inconvenience of having to create a Key array of type Comparable and a Value array of type Object, and to cast them back to Key[] and Value[] in the constructor. As usual, we can use array resizing so that clients do not have to be con- cerned with the size of the array (noting, as you shall see, that this method is too slow to use with large arrays).
   key value
keys[] vals[] 0123456789 N 0123456789
10
21 0 32 10 42130
C 4
H 5
E 6
X7 ACEHRSX
A8 ACEHRSX
M9 ACEHMRSX 8 P10 ACEHMPRSX 9 L11 ACEHLMPRSX10 E12 ACEHLMPRSX10
ACEHLMPRSX
S0S E1ES
A 2 A E R3AERS
entries in red were inserted
entries in black moved to the right
0 circled entries are 0 changed values
84659307 8465910307
8 4 6 5 11 9 10 3 0 7 8 4 12 5 11 9 10 3 0 7 8 4 12 5 11 9 10 3 0 7
 S ACERS
entries in gray 5 24130 did not move 6 24153
 ACEHR ACEHR
S
S
6 24653
7 2465307
7 8465307
     Trace of ordered-array ST implementation for standard indexing client
www.it-ebooks.info

  aLgorIthM 3.2 Binary search (in an ordered array)
  public class BinarySearchST<Key extends Comparable<Key>, Value>
  {
     private Key[] keys;
     private Value[] vals;
     private int N;
     public BinarySearchST(int capacity)
     {   // See Algorithm 1.1 for standard array-resizing code.
         keys = (Key[]) new Comparable[capacity];
         vals = (Value[]) new Object[capacity];
     }
     public int size()
     {  return N;  }
     public Value get(Key key)
     {
        if (isEmpty()) return null;
        int i = rank(key);
        if (i < N && keys[i].compareTo(key) == 0) return vals[i];
        else                                      return null;
     }
     public int rank(Key key)
     // See page 381.
     public void put(Key key, Value val)
     {  // Search for key. Update value if found; grow table if new.
        int i = rank(key);
        if (i < N && keys[i].compareTo(key) == 0)
        {  vals[i] = val; return;  }
        for (int j = N; j > i; j--)
        {  keys[j] = keys[j-1]; vals[j] = vals[j-1];  }
        keys[i] = key; vals[i] = val;
        N++;
     }
     public void delete(Key key)
     // See Exercise 3.1.16 for this method.
}
This ST implementation keeps the keys and values in parallel arrays. The put() implementation moves larger keys one position to the right before growing the table as in the array-based stack imple- mentation in Section 1.3. Array-resizing code is omitted here.
  www.it-ebooks.info
3.1 n Symbol Tables 379
380 Chapter 3 n Searching
Binary search The reason that we keep keys in an ordered array is so that we can use array indexing to dramatically reduce the number of compares required for each search, using the classic and venerable binary search algorithm that we used as an exam-
ple in Chapter 1. We maintain indices into the sorted key array that delimit the subar- ray that might contain the search key. To search, we compare the search key against the key in the middle of the subarray. If the search key is less than the key in the middle, we search in the left half of the subarray; if the search key is greater than the key in the middle, we search in the right half of the subarray; otherwise the key in the middle is equal to the search key. The rank() code on the facing page uses binary search to com-
plete the symbol-table implementation just discussed. This implementation is worthy of careful study. To study it, we start with the equivalent recursive code at left. A call to rank(key, 0, N-1)doesthesamesequenceofcomparesasacalltothenonrecursive implementation in Algorithm 3.2, but this alternate version better exposes the struc- ture of the algorithm, as discussed in Section 1.1. This recursive rank() preserves the following properties:
n If key is in the table, rank() returns its index in the table, which is the same as the number of keys in the table that are smaller than key.
n If key is not in the table, rank() also returns the number of keys in the table that are smaller than key.
Taking the time to convince yourself that the nonrecursive rank() in Algorithm 3.2 operates as expected (either by proving that it is equivalent to the recursive version or by proving directly that the loop always terminates with the value of lo precisely equal to the number of keys in the table that are smaller than key) is a worthwhile exercise for any programmer. (Hint : Note that lo starts at 0 and never decreases.)
Other operations Since the keys are kept in an ordered array, most of the order-based operations are compact and straightforward, as you can see from the codepoange382.For example, a call to select(k) just returns keys[k].We have left delete() and floor() as exercises. You are encouraged to study the implementation of ceiling() and the two-argument keys() and to work these exercises to cement your understanding of the ordered symbol-table API and this implementation.
   public int rank(Key key, int lo, int hi)
  {
     if (hi < lo) return lo;
     int mid = lo + (hi - lo) / 2;
     int cmp = key.compareTo(keys[mid]);
     if      (cmp < 0)
          return rank(key, lo, mid-1);
     else if (cmp > 0)
          return rank(key, mid+1, hi);
     else return mid;
}
recursive binary search
 www.it-ebooks.info

 3.1 n Symbol Tables 381 aLgorIthM 3.2 (continued) Binary search in an ordered array (iterative)
  public int rank(Key key)
  {
     int lo = 0, hi = N-1;
     while (lo <= hi)
     {
        int mid = lo + (hi - lo) / 2;
        int cmp = key.compareTo(keys[mid]);
        if      (cmp < 0) hi = mid - 1;
        else if (cmp > 0) lo = mid + 1;
        else return mid;
}
return lo; }
This method uses the classic method described in the text to compute the number of keys in the table that are smaller than key. Compare key with the key in the middle: if it is equal, return its index; if it is less, look in the left half; if it is greater, look in the right half.
   keys[]
successful search for P 0 1 2 3 4 5 6 7 8 9
lo hi mid
094 ACEHLMPRSX 597 ACEHLMPRSX 565 ACEHLMPRSX 666 ACEHLMPRSX
entries in black are a[lo..hi]
   entry in red is a[mid] unsuccessful search for Q loop exits with keys[mid] = P: return 6
 lo hi mid
094 ACEHLMPRSX 597 ACEHLMPRSX 565 ACEHLMPRSX 766 ACEHLMPRSX loop exits with lo > hi: return 7
Trace of binary search for rank in an ordered array
  www.it-ebooks.info
 382 Chapter 3 n Searching
 aLgorIthM 3.2 (continued) ordered symbol-table operations for binary search public Key min()
  {  return keys[0];  }
  public Key max()
  {  return keys[N-1];  }
  public Key select(int k)
  {  return keys[k];  }
  public Key ceiling(Key key)
  {
     int i = rank(key);
     return keys[i];
  }
  public Key floor(Key key)
  // See Exercise 3.1.17.
  public Key delete(Key key)
  // See Exercise 3.1.16.
  public Iterable<Key> keys(Key lo, Key hi)
  {
     Queue<Key> q = new Queue<Key>();
     for (int i = rank(lo); i < rank(hi); i++)
        q.enqueue(keys[i]);
     if (contains(hi))
        q.enqueue(keys[rank(hi)]);
     return q;
}
These methods, along with the methods of Exercise 3.1.16 and Exercise 3.1.17, complete the imple- mentation of our (ordered) symbol-table API using binary search in an ordered array. The min(), max(), and select() methods are trivial, just amounting to returning the appropriate key from its known position in the array. The rank() method, which is the basis of binary search, plays a central role in the others. The floor() and delete() implementations, left for exercises, are more compli- cated, but still straightforward.
  www.it-ebooks.info
 Analysis of binary search The recursive implementation of rank() also leads to an immediate argument that binary search guarantees fast search, because it cor- responds to a recurrence relation that describes an upper bound on the number of compares.
The implementation just given for ceiling() is based on a single call to rank(), and the default two-argument size() implementation calls rank() twice, so this proof also establishes that these operations (and floor()) are supported in guaranteed logarith- mic time (min(), max(), and select() are constant-time operations).
www.it-ebooks.info
3.1 n Symbol Tables 383
 proposition b. Binary search in an ordered array with N keys uses no more than lg N  1 compares for a search (successful or unsuccessful).
proof: This analysis is similar to (but simpler than) the analysis of mergesort (Proposition F in Chapter 2). Let C(N) be the number of compares to search for a key in a symbol table of size N. We have C(0)=0, C(1)=1, and for N > 0 we can write a recurrence relationship that directly mirrors the recursive method:
C(N )  C(⎣N/2⎦)  1.
Whether the search goes to the left or to the right, the size of the subarray is no more than ⎣N/2⎦, and we use one compare to check for equality and to choose whether to go left or right. When N is one less than a power of 2 (say N = 2n1), this recurrence is not dif cult to solve. First, since ⎣N/2⎦ = 2n11, we have
C(2n 1)  C(2n11)  1.
Applying the same equation to the  rst term on the right, we have
C(2n 1)  C(2n21)  1  1. Repeating the previous step n  2 additional times gives
C(2n 1)  C(20)  n which leaves us with the solution
C(N) = C(2n1)n 1< lgN1.
Exact solutions for general N are more complicated, but it is not dif cult to extend this argument to establish the stated property for all values of N (see Exercise 3.1.20). With binary search, we achieve a logarithmic-time search guarantee.

 384
method
put()
   get()
 delete()
contains()
  size()
   min()
   max()
  floor()
 ceiling()
  rank()
 select()
deleteMin()
deleteMax()
Chapter 3 n Searching order of growth
BinarySearchST costs
of running time
N
log N N log N 1
1
1 log N log N log N 1 N
1
Despite its guaranteed logarithmic search, BinarySearchST still does not enable us to use clients like FrequencyCounter to solve huge problems, because the put() method is too slow. Bi- nary search reduces the number of compares, but not the running time, because its use does not change the fact that the number of array accesses required to build a symbol table in an ordered ar- ray is quadratic in the size of the array when keys are randomly ordered (and in typical practical situations where the keys, while not random, are well-described by this model).
proposition b (continued). Inserting a new key into an or- dered array of size N uses ~ 2N array accesses in the worst case, so inserting N keys into an initially empty table uses ~ N 2 array accesses in the worst case.
proof: Same as for Proposition A.
For Tale of Two Cities, with over 10 4 distinct keys, the cost to build the table is nearly 10 8 array accesses, and for the Leipzig project, with over 106 distinct keys, the cost to build the table is over 10 11
array accesses. While not quite prohibitive on modern computers, these costs are ex- tremely (and unnecessarily) high.
Returning to the cost of the put() operations for FrequencyCounter for words of length 8 or more, we see a reduction in the average cost from 2,246 compares (plus array accesses) per operation for SequentialSearchST to 484 for BinarySearchST. As before, this cost is even better than would be predicted by analysis, and the extra improvement is likely again explained by properties of the application (see Exercise 3.1.36). This improvement is impressive, but we can do much better, as you shall see.
5737
cost
0
operations
Costs for java FrequencyCounter 8 < tale.txt using BinarySearchST
0
14350
www.it-ebooks.info
484
Preview Binary search is typically far better than sequential search and is the meth- od of choice in numerous practical applications. For a static table (with no insert op- erations allowed), it is worthwhile to initialize and sort the table, as in the version of binary search that we considered in Chapter 1 (see page 99). Even when the bulk of the key-value pairs is known before the bulk of the searches (a common situation in applications), it is worthwhile to add to BinarySearchST a constructor that initial- izes and sorts the table (see Exercise 3.1.12). Still, binary search is infeasible for use in many other applications. For example, it fails for our Leipzig Corpora application because searches and inserts are intermixed and the table size is too large. As we have emphasized, typical modern search clients require symbol tables that can support fast implementations of both search and insert. That is, we need to be able to build huge tables where we can insert (and perhaps remove) key-value pairs in unpredictable pat- terns, intermixed with searches.
The table below summarizes performance characteristics for the elementary sym- bol-table implementations considered in this section. The table entries give the leading term of the cost (number of array accesses for binary search, number of compares for the others), which implies the order of growth of the running time.
algorithm (data structure)
worst-case cost (after n inserts)
search insert
average-case cost (after n random inserts)
search hit insert
efficiently support ordered operations?
3.1 n Symbol Tables 385
    sequential search (unordered linked list)
binary search (ordered array)
The central question is whether we can devise algorithms and data structures that achieve logarithmic performance for both search and insert. The answer is a resound- ing yes! Providing that answer is the main thrust of this chapter. Along with the fast sort capability discussed in Chapter 2, fast symbol-table search/insert is one of the most important contributions of algorithmics and one of the most important steps toward the development of the rich computational infrastructure that we now enjoy.
How can we achieve this goal? To support ef cient insertion, it seems that we need a linked structure. But a singly linked list forecloses the use of binary search, because the ef ciency of binary search depends on our ability to get to the middle of any subarray
N N N/2 N no lgN 2N lgN N yes
Cost summary for basic symbol-table implementations
www.it-ebooks.info

386 Chapter 3 n Searching
quickly via indexing (and the only way to get to the middle of a singly linked list is to follow links). To combine the ef ciency of binary search with the  exibility of linked structures, we need more complicated data structures. That combination is provided both by binary search trees, the subject of the next two sections, and by hash tables, the subject of Section 3.4.
We consider six symbol-table implementations in this chapter, so a brief preview is in order. The table below is a list of the data structures, along with the primary reasons in favor of and against using each for an application. They appear in the order in which we consider them.
We will get into more detail on properties of the algorithms and implementations as we discuss them, but the brief characterizations in this table will help you keep them in a broader context as you learn them. The bottom line is that we have several fast symbol-table implementations that can be and are used to great effect in countless applications.
 underlying
data structure implementation pros cons
 linked list (sequential search)
ordered array (binary search)
binary search tree
balanced BST
hash table
  SequentialSearchST
    BinarySearchST
BST
RedBlackBST
SeparateChainingHashST
 LinearProbingHashST
best for tiny STs
optimal search and space, order-based ops
easy to implement, order-based ops
optimal search and insert, order-based ops
fast search/insert for common types of data
slow for large STs
slow insert
no guarantees space for links
space for links
need hash for each type no order-based ops space for links/empty
pros and cons of symbol-table implementations
www.it-ebooks.info

Q. Why not use an Item type that implements Comparable for symbol tables, in the same way as we did for priority queues in Section 2.4, instead of having separate keys and values ?
A. Thatisalsoareasonableoption.Thesetwoapproachesillustratetwodifferentways to associate information with keys—we can do so implicitly by building a data type that includes the key or explicitly by separating keys from values. For symbol tables, we have chosen to highlight the associative array abstraction. Note also that a client speci es just a key in search, not a key-value aggregation.
Q. Why bother with equals() ? Why not just use compareTo() throughout?
A. Notalldatatypesleadtokeyvaluesthatareeasytocompare,eventhoughhavinga symbol table still might make sense. To take an extreme example, you may wish to use pictures or songs as keys. There is no natural way to compare them, but we can certainly test equality (with some work).
Q. Why not allow keys to take the value null?
A. We assume that Key is an Object because we use it to invoke compareTo() or equals(). But a call like a.compareTo(b) would cause a null pointer exception if a is null. By ruling out this possibility, we allow for simpler client code.
Q. Why not use a method like the less() method that we used for sorting?
A. Equality plays a special role in symbol tables, so we also would need a method for testing equality. To avoid proliferation of methods that have essentially the same func- tion, we adopt the built-in Java methods equals() and compareTo().
Q. Whynotdeclarekey[]asObject[](insteadofComparable[])inBinarySearchST before casting, in the same way that val[] is declared as Object?
A. Goodquestion.Ifyoudoso,youwillgetaClassCastExceptionbecausekeysneed to be Comparable (to ensure that entries in key[] have a compareTo() method). Thus, declaring key[] as Comparable[] is required. Delving into the details of program- ming-language design to explain the reasons would take us somewhat off topic. We use precisely this idiom (and nothing more complicated) in any code that uses Comparable generics and arrays throughout this book.
www.it-ebooks.info
3.1 n Symbol Tables 387
 Q&A

388 Chapter 3 n Searching Q&A (continued)
Q. Whatifweneedtoassociatemultiplevalueswiththesamekey?Forexample,ifwe use Date as a key in an application, wouldn’t we have to process equal keys?
A. Maybe, maybe not. For example, you can’t have two trains arrive at the station on the same track at the same time (but they could arrive on different tracks at the same time). There are two ways to handle the situation: use some other information to dis- ambiguate or make the value a Queue of values having the same key. We consider ap- plications in detail in Section 3.5.
Q. Presorting the table as discussed on page 385 seems like a good idea. Why relegate that to an exercise (see Exercise 3.1.12)?
A. Indeed, this may be the method of choice in some applications. But adding a slow insert method to a data structure designed for fast search “for convenience” is a per- formance trap, because an unsuspecting client might intermix searches and inserts in a huge table and experience quadratic performance. Such traps are all too common, so that “buyer beware” is certainly appropriate when using software developed by oth- ers, particularly when interfaces are too wide. This problem becomes acute when a large number of methods are included “for convenience” leaving performance traps throughout, while a client might expect ef cient implementations of all methods. Java’s ArrayList class is an example (see Exercise 3.5.27).
 www.it-ebooks.info

3.1 n Symbol Tables 389
 ExErcisEs
 3.1.1 Write a client that creates a symbol table mapping letter grades to numerical scores, as in the table below, then reads from standard input a list of letter grades and computes and prints the GPA (the average of the numbers corresponding to the grades).
A+ A A- B+ B B- C+ C C- D F
4.33 4.00 3.67 3.33 3.00 2.67 2.33 2.00 1.67 1.00 0.00
3.1.2 Developasymbol-tableimplementationArraySTthatusesan(unordered)array as the underlying data structure to implement our basic symbol-table API.
3.1.3 Develop a symbol-table implementation OrderedSequentialSearchST that uses an ordered linked list as the underlying data structure to implement our ordered symbol-table API.
3.1.4 Develop Time and Event ADTs that allow processing of data as in the example illustrated on page 367.
3.1.5 Implement size(), delete(), and keys() for SequentialSearchST.
3.1.6 Givethenumberofcallstoput()andget()issuedbyFrequencyCounter,asa
function of the number W of words and the number D of distinct words in the input.
3.1.7 What is the average number of distinct keys that FrequencyCounter will  nd among N random nonnegative integers less than 1,000, for N=10, 102, 103, 104, 105, and 106?
3.1.8 WhatisthemostfrequentlyusedwordoftenlettersormoreinTaleofTwoCities?
3.1.9 AddcodetoFrequencyCountertokeeptrackofthelastcalltoput().Printthe last word inserted and the number of words that were processed in the input stream prior to this insertion. Run your program for tale.txt with length cutoffs 1, 8, and 10.
3.1.10 GiveatraceoftheprocessofinsertingthekeysE A S Y Q U E S T I O N intoan initially empty table using SequentialSearchST. How many compares are involved?
3.1.11 GiveatraceoftheprocessofinsertingthekeysE A S Y Q U E S T I O N into an initially empty table using BinarySearchST. How many compares are involved?
3.1.12 Modify BinarySearchST to maintain one array of Item objects that contain keys and values, rather than two parallel arrays. Add a constructor that takes an array of
           www.it-ebooks.info

390 Chapter 3 n Searching ExErcisEs (continued)
Item values as argument and uses mergesort to sort the array.
3.1.13 Which of the symbol-table implementations in this section would you use for an application that does 103 put() operations and 106 get() operations, randomly intermixed? Justify your answer.
3.1.14 Which of the symbol-table implementations in this section would you use for an application that does 106 put() operations and 103 get() operations, randomly intermixed? Justify your answer.
3.1.15 Assume that searches are 1,000 times more frequent than insertions for a BinarySearchST client. Estimate the percentage of the total time that is devoted to insertions, when the number of searches is 103, 10 6, and 10 9.
3.1.16 Implement the delete() method for BinarySearchST.
3.1.17 Implement the floor() method for BinarySearchST.
3.1.18 Prove that the rank() method in BinarySearchST is correct.
3.1.19 Modify FrequencyCounter to print all of the values having the highest fre-
quency of occurrence, not just one of them. Hint : Use a Queue.
3.1.20 Complete the proof of Proposition B (show that it holds for all values of N). Hint : Start by showing that C(N) is monotonic: C(N)  C(N+1) for all N > 0.
 www.it-ebooks.info

3.1.21 Memory usage. Compare the memory usage of BinarySearchST with that of SequentialSearchST for N key-value pairs, under the assumptions described in Sec- tion 1.4. Do not count the memory for the keys and values themselves, but do count references to them. For BinarySearchST, assume that array resizing is used, so that the array is between 25 percent and 100 percent full.
3.1.22 Self-organizing search. A self-organizing search algorithm is one that rearrang- es items to make those that are accessed frequently likely to be found early in the search. Modify your search implementation for Exercise 3.1.2 to perform the following action on every search hit: move the key-value pair found to the beginning of the list, moving all pairs between the beginning of the list and the vacated position to the right one posi- tion. This procedure is called the move-to-front heuristic.
3.1.23 Analysis of binary search. Prove that the maximum number of compares used for a binary search in a table of size N is precisely the number of bits in the binary rep- resentation of N, because the operation of shifting 1 bit to the right converts the binary representation of N into the binary representation of ⎣N/2⎦.
3.1.24 Interpolation search. Suppose that arithmetic operations are allowed on keys (for example, they may be Double or Integer values). Write a version of binary search that mimics the process of looking near the beginning of a dictionary when the word begins with a letter near the beginning of the alphabet. Speci cally, if kx is the key value sought, klo is the key value of the  rst key in the table, and khi is the key value of the last key in the table, look  rst ⎣(kx  klo)/(khi  klo)⎦-way through the table, not half-way. Test your implementation against BinarySearchST for FrequencyCounter.
3.1.25 Software caching. Since the default implementation of contains() calls get(), the inner loop of FrequencyCounter
    if (!st.contains(word)) st.put(word, 1);
    else                    st.put(word, st.get(word) + 1);
leads to two or three searches for the same key. To enable clear client code like this without sacri cing ef ciency, we can use a technique known as software caching, where we save the location of the most recently accessed key in an instance variable. Modify SequentialSearchST and BinarySearchST to take advantage of this idea.
www.it-ebooks.info
3.1 n Symbol Tables 391
 crEAtivE problEms

392 Chapter 3 n Searching
crEAtivE problEms (continued)
3.1.26 Frequency count from a dictionary. Modify FrequencyCounter to take the name of a dictionary  le as its argument, count frequencies of the words from standard input that are also in that  le, and print two tables of the words with their frequencies, one sorted by frequency, the other sorted in the order found in the dictionary  le.
3.1.27 Small tables. Suppose that a BinarySearchST client has S search operations and N distinct keys. Give the order of growth of S such that the cost of building the table is the same as the cost of all the searches.
3.1.28 Ordered insertions. Modify BinarySearchST so that inserting a key that is larg- er than all keys in the table takes constant time (so that building a table by calling put() for keys that are in order takes linear time).
3.1.29 Test client. Write a test client for BinarySearchST that tests the implemen- tations of min(), max(), floor(), ceiling(), select(), rank(), deleteMin(), deleteMax(), and keys() that are given in the text. Start with the standard index- ing client given on page 370. Add code to take additional command-line arguments, as appropriate.
3.1.30 Certi cation. Add assert statements to BinarySearchST to check algorithm invariants and data structure integrity after every insertion and deletion. For example, every index i should always be equal to rank(select(i)) and the array should always be in order.
 www.it-ebooks.info

3.1.31 Performance driver. Write a performance driver program that uses put() to  ll a symbol table, then uses get() such that each key in the table is hit an average of ten times and there is about the same number of misses, doing so multiple times on random sequences of string keys of various lengths ranging from 2 to 50 characters; measures the time taken for each run; and prints out or plots the average running times.
3.1.32 Exercise driver. Write an exercise driver program that uses the methods in our ordered symbol-table API on dif cult or pathological cases that might turn up in prac- tical applications. Simple examples include key sequences that are already in order, key sequences in reverse order, key sequences where all keys are the same, and keys consist- ing of only two distinct values.
3.1.33 Driver for self-organizing search. Write a driver program for self-organizing search implementations (see Exercise 3.1.22) that uses put() to  ll a symbol table with N keys, then does 10 N successful searches according to a prede ned probability distribution. Use this driver to compare the running time of your implementation from Exercise 3.1.22 with BinarySearchST for N = 103, 104, 105, and 106 using the prob- ability distribution where search hits the i th smallest key with probability 1/2 i .
3.1.34 Zipf’s law. Do the previous exercise for the probability distribution where search hits the i th smallest key with probability 1/(i HN) where HN is a Harmonic num- ber (seepage 185). This distribution is called Zipf ’s law. Compare the move-to-front heu- ristic with the optimal arrangement for the distributions in the previous exercise, which is to keep the keys in increasing order (decreasing order of their expected frequency).
3.1.35 Performance validation I. Run doubling tests that use the  rst N words of Tale of Two Cities for various values of N to test the hypothesis that the running time of FrequencyCounter is quadratic when it uses SequentialSearchST for its symbol table.
3.1.36 Performance validation II. Explain why the performance of BinarySearchST and SequentialSearchST for FrequencyCounter is even better than predicted by analysis.
3.1.37 Put/get ratio. Determine empirically the ratio of the amount of time that BinarySearchST spends on put() operations to the time that it spends on get() op- erations when FrequencyCounter is used to  nd the frequency of occurrence of values
www.it-ebooks.info
3.1 n Symbol Tables 393
 ExpErimENts

394 Chapter 3 n Searching ExpErimENts (continued)
in 1 million random M-bit int values, for M = 10, 20, and 30. Answer the same question for tale.txt and compare the results.
3.1.38 Amortized cost plots. Develop instrumentation for FrequencyCounter, SequentialSearchST, and BinarySearchST so that you can produce plots like the ones in this section showing the cost of each put() operation during the computation.
3.1.39 Actual timings. Instrument FrequencyCounter to use Stopwatch and StdDraw to make a plot where the x-axis is the number of calls on get() or put() and the y-axis is the total running time, with a point plotted of the cumulative time after each call. Run your program for Tale of Two Cities using SequentialSearchST and again using BinarySearchST and discuss the results. Note : Sharp jumps in the curve may be ex- plained by caching, which is beyond the scope of this question.
3.1.40 Crossover to binary search. Find the values of N for which binary search in a symbol table of size N becomes 10, 100, and 1,000 times faster than sequential search. Predict the values with analysis and verify them experimentally.
3.1.41 Crossover to interpolation search. Find the values of N for which interpolation search in a symbol table of size N becomes 1, 2, and 10 times faster than binary search, assuming the keys to be random 32-bit integers (see Exercise 3.1.24). Predict the values with analysis, and verify them experimentally.
 www.it-ebooks.info

This page intentionally left blank
www.it-ebooks.info

       a subtree
root a left link
right child of root
null links
data structure, which quali es as one of the most fundamental al- gorithms in computer science.
To begin, we de ne basic terminology. We are working with data structures made up of nodes that contain links that are either null or references to other nodes. In a binary tree, we have the restric- tion that every node is pointed to by just one other node, which is called its parent (except for one node, the root, which has no nodes pointing to it), and that each node has exactly two links, which are called its left and right links, that point to nodes called its left child and right child, respectively. Although links point to nodes, we can
In this section, we will examine a symbol-table implementation that combines the  exibility of insertion in a linked list with the ef ciency of search in an ordered array. Speci cally, using two links per node (instead of the one link per node found in linked lists) leads to an ef cient symbol-table implementation based on the binary search tree
          Anatomy of a binary tree
view each link as pointing to a binary tree, the tree whose root is the referenced node. Thus, we can de ne a binary tree as either a null link or a node with a left link and a right link, each references to (disjoint) subtrees that are themselves binary trees. In a binary search tree, each node also has a key and a value, with an ordering restriction to support ef cient search.
We draw BSTs with keys in the nodes and use terminology such as “A is the left child of E” that associates nodes with keys. Lines connecting the nodes represent links, and we give the value associated with a key in black, beside the nodes (sup- pressing the value as dictated by context). Each node’s links connect it to nodes below it on the page, except for null links, which are short segments at the bottom. As usual, our exam- ples use the single-letter keys that are generated by our index- ing test client.
 Definition. A binary search tree (BST) is a binary tree where each node has a Comparable key (and an associated value) and satis es the restriction that the key in any node is larger than the keys in all nodes in that node’s left subtree and small- er than the keys in all nodes in that node’s right subtree.
parent of A and R
S
key ofE E X
  left link
        A R9 value
   CH
associated with R
  keys smaller than E keys larger than E Anatomy of a binary search tree
396
www.it-ebooks.info
 3.2 BinAry SeArCh treeS

 Basic implementation Algorithm 3.3 de nes the BST data structure that we use throughout this section to implement the ordered symbol-table API. We begin by considering this classic data structure de nition and the characteristic associated im- plementations of the get() (search) and put() (insert) methods.
Representation We de ne a private nested class to de ne nodes in BSTs, just as we did for linked lists. Each node contains a key, a value, a left link, a right link, and a node count (when relevant, we include node counts in red above the node
in our drawings). The left link points to a BST for items with smaller
  keys, and the right link points to a BST for items with larger keys. The instance variable N gives the node count in the subtree rooted at the node. This  eld facilitates the implementation of various ordered symbol-table operations, as you will see. The private size() method in Algorithm 3.3 is implemented to assign the value 0 to null links, so that we can maintain this  eld by making sure that the invariant
    size(x) = size(x.left) + size(x.right) + 1
holds for every node x in the tree.
A BST represents a set of keys (and associated values), and there
are many different BSTs that represent the same set. If we project the keys in a BST such that all keys in each node’s left subtree appear to the left of the key in the node and all keys in each node’s right subtree appear to the right of the key in the node, then we always get the keys in sorted order. We take advantage of the  exibility inherent in having many BSTs represent this sorted order to develop ef cient algorithms for building and using BSTs.
8 6S1 2E3X
3.2 n Binary Search Trees
397
node count N
        A12R CH1
M ACEHMRSX
8 2E5
1C2R2 AH11X
MS ACEHMRSX
Two BSTs that represent the same set of keys
                         Search As usual, when we search for a key in a symbol table, we have one of two possible outcomes. If a node containing the key is in the table, we have a search hit, so we return the associated value. Otherwise, we have a search miss (and return null). A recursive algorithm to search for a key in a BST follows immediately from the recursive structure: if the tree is empty, we have a search miss; if the search key is equal to the key at the root, we have a search hit. Otherwise, we search (recursively) in the appropriate subtree, moving left if the search key is smaller, right if it is larger. The recursive get() method onpage 399 implements this algorithm directly. It takes a node (root of a subtree) as  rst argument and a key as second argument, starting with the root of the tree and the search key. The code maintains the invariant that no parts of the tree other than the subtree rooted at the current node can have a node whose key is equal to the search key. Just as the size of the interval in binary search shrinks by about half on each iteration,
www.it-ebooks.info

 398 Chapter 3 n Searching
 aLgorIthM 3.3 Binary search tree symbol table
public class BST<Key extends Comparable<Key>, Value>
 {
private Node root;
private class Node
{
   private Key key;
   private Value val;
   private Node left, right;
   private int N;
// root of BST
// key
// associated value
// links to subtrees
// # nodes in subtree rooted here
   public Node(Key key, Value val, int N)
   {  this.key = key; this.val = val; this.N = N; }
}
public int size()
{  return size(root);  }
private int size(Node x)
{
   if (x == null) return 0;
   else           return x.N;
}
public Value get(Key key)
// See page 399.
public void put(Key key, Value val)
// See page 399.
// See page 407 for min(), max(), floor(), and ceiling().
// See page 409 for select() and rank().
// See page 411 for delete(), deleteMin(), and deleteMax().
// See page 413 for keys().
}
This implementation of the ordered symbol-table API uses a binary search tree built from Node ob- jects that each contain a key, associated value, two links, and a node count N. Each Node is the root of a subtree containing N nodes, with its left link pointing to a Node that is the root of a subtree with smaller keys and its right link pointing to a Node that is the root of a subtree with larger keys. The instance variable root points to the Node at the root of the BST (which has all the keys and associ- ated values in the symbol table). Implementations of other methods appear throughout this section.
 www.it-ebooks.info
  aLgorIthM 3.3 (continued) Search and insert for BSts public Value get(Key key)
  {  return get(root, key);  }
  private Value get(Node x, Key key)
  {  // Return value associated with key in the subtree rooted at x;
     // return null if key not present in subtree rooted at x.
     if (x == null) return null;
     int cmp = key.compareTo(x.key);
     if      (cmp < 0) return get(x.left, key);
     else if (cmp > 0) return get(x.right, key);
     else return x.val;
}
  public void put(Key key, Value val)
  {  // Search for key. Update value if found; grow table if new.
     root = put(root, key, val);
  }
  private Node put(Node x, Key key, Value val)
  {
     // Change key’s value to val if key in subtree rooted at x.
     // Otherwise, add new node to subtree associating key with val.
     if (x == null) return new Node(key, val, 1);
     int cmp = key.compareTo(x.key);
     if      (cmp < 0) x.left  = put(x.left,  key, val);
     else if (cmp > 0) x.right = put(x.right, key, val);
     else x.val = val;
     x.N = size(x.left) + size(x.right) + 1;
     return x;
}
These implementations of get() and put() for the symbol-table API are characteristic recursive BST methods that also serve as models for several other implementations that we consider later in the chapter. Each method can be understood as both working code and a proof by induction of the inductive hypothesis in the opening comment.
  www.it-ebooks.info
3.2 n Binary Search Trees 399
400 Chapter 3 n Searching
successful search for R unsuccessful search for T
SS
EX EX AR AR
                C
black nodes could match the search key
H
R is less than S so look to the left
C H
    M
M
T is greater than S so look to the right
  S EX
S EX
           AR C H
AR CH
       R is greater than E so look to the right
M
gray nodes cannot match the search key
M
T is less than X so look to the left
link is null
so T is not in tree (search miss)
  S EX
     AR CH
M
found R (search hit) so return value
    Search hit (left) and search miss (right) in a BST
the size of the subtree rooted at the current node when searching in a BST shrinks when we go down the tree (by about half, ideally, but at least by one). The procedure stops either when a node containing the search key is found (search hit) or when the current subtree becomes empty (search miss). Starting at the top, the search procedure at each node involves a recursive invocation for one of that node’s children, so the search de-  nes a path through the tree. For a search hit, the path terminates at the node contain- ing the key. For a search miss, the path terminates at a null link.
Insert The search code in Algorithm 3.3 is almost as simple as binary search; that simplicity is an essential feature of BSTs. A more important essential feature of BSTs is that insert is not much more dif cult to implement than search. Indeed, a search for a key not in the tree ends at a null link, and all that we need to do is replace that link with a new node containing the key (see the diagram on the next page). The recursive put() method in Algorithm 3.3 accomplishes this task using logic similar to that we used for the recursive search: if the tree is empty, we return a new node containing the key and value; if the search key is less than the key at the root, we set the left link to the result of inserting the key into the left subtree; otherwise, we set the right link to the result of inserting the key into the right subtree.
www.it-ebooks.info

Recursion It is worthwhile to take the time to
understand the dynamics of these recursive im-
plementations. You can think of the code before
the recursive calls as happening on the way down
the tree: it compares the given key against the
key at each node and moves right or left accord-
ingly. Then, think of the code after the recursive
calls as happening on the way up the tree. For
get() this amounts to a series of return state-
ments, but for put(), it corresponds to resetting
the link of each parent to its child on the search
path and to incrementing the counts on the way
up the path. In simple BSTs, the only new link
is the one at the bottom, but resetting the links
higher up on the path is as easy as the test to
avoid setting them. Also, we just need to incre-
ment the node count on each node on the path,
but we use more general code that sets each to
one plus the sum of the counts in its subtrees.
Later in this section and in the next section, we
shall study more advanced algorithms that are
naturally expressed with this same recursive
scheme but that can change more links on the search paths and need the more general node-count-update code. Elementary BSTs are often implemented with nonrecursive code (see Exercise 3.2.13)—we use recursion in our implementations both to make it easy for you to convince yourself that the code is operating as described and to prepare the groundwork for more sophisticated algorithms.
A careful study of the trace for our standard indexing client that is shown on the next page will give you a feeling for the way in which binary search trees grow. New nodes are attached to null links at the bottom of the tree; the tree structure is not oth- erwise changed. For example, the root has the  rst key inserted, one of the children of the root has the second key inserted, and so forth. Because each node has two links, the tree tends to grow out, rather than just down. Moreover, only the keys on the path from the root to the sought or inserted key are examined, so the number of keys examined becomes a smaller and smaller fraction of the number of keys in the tree as the tree size increases.
inserting L
9 7S
E4X A3R
CH2 M
3.2 n Binary Search Trees 401
         search for L ends at this null link
P
S EX
       AR CH
10
    M
P
   create new node
1 L 8S
      E5X A4R
   CH3
 M LP
Insertion into a BST
reset links and increment counts on the way up
  www.it-ebooks.info

402 Chapter 3 n Searching
key value
key value
S EX
A8R CH
S EX
M
  S0S A8
           E1
S
changed value
   E
S
S
AR
M9
CH
              A2 E
A
R3 E
black nodes are accessed in search
AR
            red nodes
are new S
            S P10
EX AR
     C4ECH
    AR C
gray nodes are untouched
M
P
S EX
                H5
E6
X7
S E
AR CH
L 11
CH
      AR
     changed
value S
 M 6E LP
          AR CH
S
EX AR
CH
changed value
S
X
         E 12
12 E
AR CH
M LP
              BST trace for standard indexing client
www.it-ebooks.info

Analysis The running times of algorithms on binary
search trees depend on the shapes of the trees, which, in turn, CS depend on the order in which keys are inserted. In the best AERX case, a tree with N nodes could be perfectly balanced, with
~ lg N nodes between the root and each null link. In the worst
case there could be N nodes on the search path. The balance in
typical trees turns out to be much closer to the best case than
the worst case.
3.2 n Binary Search Trees 403
best case
H
            typical case
S EX
         For many applications, the following simple model is rea- sonable: We assume that the keys are (uniformly) random, or, equivalently, that they are inserted in random order. Analysis of this model stems from the observation that BSTs are dual to quicksort. The node at the root of the tree corresponds to the  rst partitioning item in quicksort (no keys to the left are larger, and no keys to the right are smaller) and the subtrees are built recursively, corresponding to quicksort’s recursive subar- ray sorts. This observation leads us to the analysis of properties of the trees.
AR CH
 A
BST possibilities
worst case
  C
E
H
R
S
X
               proposition c. Search hits in a BST built from N random keys require ~ 2 ln N (about 1.39 lg N) compares, on the average.
proof: The number of compares used for a search hit ending at a given node is 1 plus the depth. Adding the depths of all nodes, we get a quantity known as the in- ternal path length of the tree. Thus, the desired quantity is 1 plus the average inter- nal path length of the BST, which we can analyze with the same argument that we used for Proposition K in Section 2.3: Let CN be the internal path length of a BST built from inserting N randomly ordered distinct keys, so that the average cost of a searchhitis1CN /N.WehaveC0=C1=0andforN>1wecanwritearecurrence relationship that directly mirrors the recursive BST structure:
CN = N  1  (C0  CN1) / N + (C1  CN2)/N  . . . (CN1  C0 )/N
The N  1 term takes into account that the root contributes 1 to the path length of each of the other N  1 nodes in the tree; the rest of the expression accounts for the subtrees, which are equally likely to be any of the N sizes. After rearranging terms, this recurrence is nearly identical to the one that we solved in Section 2.3 for quicksort, and we can derive the approximation CN ~ 2N ln N.
www.it-ebooks.info

404 Chapter 3 n Searching
 proposition D. Insertions and search misses in a BST built from N random keys require ~ 2 ln N (about 1.39 lg N) compares, on the average.
proof: Insertions and search misses take one more compare, on the average, than search hits. This fact is not dif cult to establish by induction (see Exercise 3.2.16).
Proposition C says that we should expect the BST search cost for random keys to be about 39 percent higher than that for binary search. Proposition D says that the extra cost is well worthwhile, because the cost of inserting a new key is also expected to be logarithmic— exibility not available with binary search in an ordered array, where the number of array accesses required for an insertion is typically linear. As with quicksort, the standard deviation of the number of compares is known to be low, so that these formulas become increasingly accurate as N increases.
Experiments How well does our random-key model match what is found in typical symbol-table clients? As usual, this question has to be studied carefully for particular practical applications, because of the large potential variation in performance. Fortu- nately, for many clients, the model is quite good for BSTs.
For our example study of the cost of the put() operations for FrequencyCounter for words of length 8 or more, we see a reduction in the average cost from 484 array accesses or compares per operation for BinarySearchST to 13 for BST, again providing a quick validation of the logarithmic performance predicted by the theoretical model. More extensive experiments for larger inputs are illustrated in the table on the next page. On the basis of Propositions C and D, it is reasonable to predict that this number should be about twice the natural logarithm of the table size, because the preponder- ance of operations are searches in a nearly full table. This prediction has at least the following inherent inaccuracies:
n Many operations are for smaller tables.
n The keys are not random.
n The table size may be too small for the approximation 2 ln N to be accurate.
Nevertheless, as you can see in the table, this prediction is accurate for our FrequencyCounter test cases to within a few compares. Actually, most of the differ- ence can be explained by re ning the mathematics in the approximation (see Exercise 3.2.35).
www.it-ebooks.info

 20
scale magnified by a factor of 250 compared to previous figures
0
all words 8+ letters 10+ letters
operations
Costs for java FrequencyCounter 8 < tale.txt using BST
14350
0
words
135,635 14,350 4,582
distinct
10,679 5,737 2,260
compares
model actual
18.6 17.5 17.6 13.9 15.4 13.1
words distinct
21,191,455 534,580 4,239,597 299,593 1,610,829 165,555
compares
Typical BST, built from 256 random keys
tale.txt
leipzig1M.txt
average number of compares per put() for FrequencyCounter using BST
www.it-ebooks.info
3.2 n
Binary Search Trees 405
model
actual
23.4 22.1 22.7 21.4 20.5 19.3
13.9
cost
406 Chapter 3 n Searching
Order-based methods and deletion An important reason that BSTs are widely used is that they allow us to keep the keys in order. As such, they can serve as the basis for implementing the numerous methods in our ordered symbol-table API (see page 366) that allow clients to access key-value pairs not just by providing the key, but also by relative key order. Next, we consider implementations of the various methods in our ordered symbol-table API.
Minimum and maximum If the left link of the root is null, the smallest key in a BST is the key at the root; if the left link is not null, the smallest key in the BST is the smallest key in the subtree rooted at the node referenced by the left link. This statement is both a description of the recursive min() method on page 407 and an inductive proof that it  nds the smallest key in the BST. The computation is equivalent to a simple iteration (move left until  nding a null link), but we use recursion for consistency. We might have the recursive method return a Key instead of a Node, but we will later have a need to use this method to access the Node containing
the minimum key. Finding the maximum key is similar, moving to the right instead of to the left.
Floor and ceiling If a given key key is less than the key at the root of a BST, then the  oor of key (the largest key in the BST less than or equal to key) must be in the left subtree. If key is greater than the key at the root, then the  oor of key could be in the right subtree, but only if there is a key smaller than or equal to key in the right subtree; if not (or if key is equal to the key at the root), then the key at the root is the  oor of key. Again, this description serves both as the basis for the recursive floor() method and for an in- ductive proof that it computes the desired result. Interchanging right and left (and less and greater) gives ceiling().
Selection Selection in a BST works in a man- ner analogous to the partition-based method of selection in an array that we studied in Section 2.5. We maintain in BST nodes the variable N that counts the number of keys in the subtree rooted at that node precisely to support this operation.
 nding floor(G)
S
     EX AR
    CH
M floor(G) must be
G is less than S so on the left
  S EX
AR CH
G is greater than E so M floor(G) could be
         on the right
AR CH
M
S EX
result R CH
M
 S EX
         left subtree is null
      A
   www.it-ebooks.info
Computing the  oor function

  aLgorIthM 3.3 (continued) Min, max, floor, and ceiling in BSts
  public Key min()
  {
     return min(root).key;
  }
  private Node min(Node x)
  {
     if (x.left == null) return x;
     return min(x.left);
  }
  public Key floor(Key key)
  {
     Node x = floor(root, key);
     if (x == null) return null;
     return x.key;
}
  private Node floor(Node x, Key key)
  {
     if (x == null) return null;
     int cmp = key.compareTo(x.key);
     if (cmp == 0) return x;
     if (cmp < 0)  return floor(x.left, key);
     Node t = floor(x.right, key);
     if (t != null) return t;
     else           return x;
}
Each client method calls a corresponding private method that takes an additional link (to a Node) as argument and returns null or a Node containing the desired Key via the recursive procedure de- scribed in the text. The max() and ceiling() methods are the same as min() and floor() (respec- tively) with right and left (and < and >) interchanged.
  www.it-ebooks.info
3.2 n Binary Search Trees 407
408
Chapter 3 n Searching
Suppose that we seek the key of rank k (the key such that precisely k other keys in the BST are smaller). If the number of keys t in the left sub- tree is larger than k, we look (recursively) for the key of rank k in the left subtree; if t is equal to k, we return the key at the root; and if t is smaller than k, we look (recursively) for the key of rank k  t  1 in the right subtree. As usual, this de- scription serves both as the basis for the recursive select() method on the facing page and for a proof by induction that it works as expected.
Rank The inverse method rank() that returns the rank of a given key is similar: if the given key is equal to the key at the root, we return the number of keys t in the left subtree; if the given key is less than the key at the root, we return the rank of the key in the left subtree (recursively
 nding select(3) the key of rank 3
count N 6 S
EX AR
CH
         6 keys in left subtree M so search for key of
rank 3 on the left
      2
S EX
  AR CH
M
    2 keys in left subtree so search for key of rank 3-2-1 = 0 on the right
 S EX
    A2 CH
R
2 keys in left subtree so search for key of rank 0 on the left
S
X R
M
    M
    go left until reaching null left link
return that node’s right link E
AR CH
available for M garbage collection
update links and node counts after recursive calls
S
S
X
computed); and if the given key is larger than the key at the root, we re- turn t plus one (to count the key at the root) plus the rank of the key in the right subtree (recursively computed).
E CH
     E AR
X
A
          CH
M
0 keys in left subtree and searching for key of rank 0
so return H
      Selection in a BST
The most dif cult BST op- eration to implement is the delete() method that removes a key-value pair from the symbol table. As a warmup, consider deleteMin() (remove the key-value pair with the smallest key). As with put() we write a recursive method that takes a link to a Node as argument and returns a link to a Node, so that we can re ect changes to the tree by assigning the result to the link used as argument. For deleteMin() we go left until  nding a Node that has a null left link and then replace the link to that node by its right link (simply by returning the right link in the recursive method). The deleted node, with no link now pointing to it, is
      Delete the minimum/maximum
     7 5S
       EX CR
H
Deleting the minimum in a BST
      M
 www.it-ebooks.info

  aLgorIthM 3.3 (continued) Selection and rank in BSts
  public Key select(int k)
  {
     return select(root, k).key;
  }
  private Node select(Node x, int k)
  {   // Return Node containing key of rank k.
      if (x == null) return null;
      int t = size(x.left);
      if      (t > k) return select(x.left,  k);
      else if (t < k) return select(x.right, k-t-1);
      else            return x;
}
  public int rank(Key key)
  {  return rank(key, root);  }
  private int rank(Key key, Node x)
  {  // Return number of keys less than key in the subtree rooted at x.
     if (x == null) return 0;
     int cmp = key.compareTo(x.key);
     if      (cmp < 0) return rank(key, x.left);
     else if (cmp > 0) return 1 + size(x.left) + rank(key, x.right);
     else              return size(x.left);
}
This code uses the same recursive scheme that we have been using throughout this chapter to imple- ment the select() and rank() methods. It depends on using the private size() method given at the beginning of this section that returns the number of nodes in the subtree rooted at a node.
  www.it-ebooks.info
3.2 n Binary Search Trees 409
410 Chapter 3 n Searching
available for garbage collection. Our standard recursive setup accomplishes, after the deletion, the task of setting the appropriate link in the parent and updating the counts in all nodes in the path to the root. The symmetric method works for deleteMax().
Delete We can proceed in a similar manner to de- lete any node that has one child (or no children), but what can we do to delete a node that has two chil- dren? We are left with two links, but have a place in the parent node for only one of them. An answer to this dilemma,  rst proposed by T. Hibbard in 1962, is to delete a node x by replacing it with its successor. Because x has a right child, its successor is the node with the smallest key in its right subtree. The replace- ment preserves order in the tree because there are no keys between x.key and the successor’s key. We can accomplish the task of replacing x by its successor in four (!) easy steps:
n Save a link to the node to be deleted in t.
n Set x to point to its successor min(t.right). n Set the right link of x (which is supposed to
point to the BST containing all the keys larger than x.key) to deleteMin(t.right), the link to the BST containing all the keys that are larger than x.key after the deletion.
n Set the left link of x (which was null) to t.left (all the keys that are less than both the deleted key and its successor).
deleting E
node to delete S
EX AR
         C H
tS
EX AxR
 M
search for key E
          C
go right, then go left until reaching null left link
H
successor
min(t.right)
  M
   S xEX
    t.left H deleteMin(t.right) AR
CM
7 5S
HX AR
C M update links and node counts after
recursive calls
Deletion in a BST
                  Our standard recursive setup accomplishes, after the
recursive calls, the task of setting the appropriate link
in the parent and decrementing the node counts in
the nodes on the path to the root (again, we accom-
plish the task of updating the counts by setting the counts in each node on the search path to be one plus the sum of the counts in its children). While this method does the job, it has a  aw that might cause performance problems in some practical situations. The problem is that the choice of using the successor is arbitrary and not symmetric. Why not use the predecessor? In practice, it is worthwhile to choose at random between the predecessor and the successor. See Exercise 3.2.42 for details.
www.it-ebooks.info

  aLgorIthM 3.3 (continued) Deletion in BSts
  public void deleteMin()
  {
     root = deleteMin(root);
  }
  private Node deleteMin(Node x)
  {
     if (x.left == null) return x.right;
     x.left = deleteMin(x.left);
     x.N = size(x.left) + size(x.right) + 1;
     return x;
}
  public void delete(Key key)
  {  root = delete(root, key);  }
  private Node delete(Node x, Key key)
  {
     if (x == null) return null;
     int cmp = key.compareTo(x.key);
     if      (cmp < 0) x.left  = delete(x.left,  key);
     else if (cmp > 0) x.right = delete(x.right, key);
     else
     {
        if (x.right == null) return x.left;
        if (x.left == null) return x.right;
        Node t = x;
        x = min(t.right);  // See page 407.
        x.right = deleteMin(t.right);
        x.left = t.left;
     }
     x.N = size(x.left) + size(x.right) + 1;
     return x;
}
These methods implement eager Hibbard deletion in BSTs, as described in the text on the facing page. The delete() code is compact, but tricky. Perhaps the best way to understand it is to read the description at left, try to write the code yourself on the basis of the description, then compare your code with this code. This method is typically effective, but performance in large-scale applica- tions can become a bit problematic (see Exercise 3.2.42). The deleteMax() method is the same as deleteMin() with right and left interchanged.
  www.it-ebooks.info
3.2 n Binary Search Trees 411
412 Chapter 3 n Searching
Range queries To implement the keys() method that returns the keys in a given range, we begin with a basic recursive BST traversal method, known as inorder traversal. To illustrate the method, we consider the task of printing all the keys in a BST in order. To do so, print all the keys in the left subtree (which are less than the key at the root by
de nition of BSTs), then print the key at the root, then print all the keys in the right subtree (which are greater than the key at the root by de nition of BSTs), as in the code at left. As usual, the description serves as an argu- ment by induction that this code prints the keys in order. To implement the two-argument keys() method that re- turns to a client all the keys in a speci ed range, we modi- fy this code to add each key that is in the range to a Queue, and to skip the recursive calls for subtrees that cannot contain keys in the range. As with BinarySearchST, the
fact that we gather the keys in a Queue is hidden from the client. The intention is that clients should process all the keys in the range of interest using Java’s foreach construct rather than needing to know what data structure we use to implement Iterable<Key>.
Analysis How ef cient are the order-based operations in BSTs? To study this question, we consider the tree height (the maximum depth of any node in the tree). Given a tree, its height determines the worst-case cost of all BST operations (except for range search which incurs additional cost proportional to the number of keys returned).
   private void print(Node x)
  {
     if (x == null) return;
     print(x.left);
     StdOut.println(x.key);
     print(x.right);
}
printing the keys in a BSt in order
  proposition E. In a BST, all operations take time proportional to the height of the tree, in the worst case.
proof: All of these methods go down one or two paths in the tree. The length of any path is no more than the height, by de nition.
We expect the tree height (the worst-case cost) to be higher than the average internal path length that we de ned onpage 403 (which averages in the short paths as well), but how much higher? This question may seem to you to be similar to the questions an- swered by Proposition C and Proposition D, but it is far more dif cult to answer, certainly beyond the scope of this book. The average height of a BST built from random keys was shown to be logarithmic by J. Robson in 1979, and L. Devroye later showed that the value approaches 2.99 lg N for large N. Thus, if the insertions in our applica- tion are well-described by the random-key model, we are well on the way toward our goal of developing a symbol-table implementation that supports all of these operations
www.it-ebooks.info

 3.2 n Binary Search Trees 413
 aLgorIthM 3.3 (continued) range searching in BSts public Iterable<Key> keys()
  {  return keys(min(), max());  }
  public Iterable<Key> keys(Key lo, Key hi)
  {
      Queue<Key> queue = new Queue<Key>();
      keys(root, queue, lo, hi);
      return queue;
}
  private void keys(Node x, Queue<Key> queue, Key lo, Key hi)
  {
     if (x == null) return;
     int cmplo = lo.compareTo(x.key);
     int cmphi = hi.compareTo(x.key);
     if (cmplo < 0) keys(x.left, queue, lo, hi);
     if (cmplo <= 0 && cmphi >= 0) queue.enqueue(x.key);
     if (cmphi > 0) keys(x.right, queue, lo, hi);
}
To enqueue all the keys from the tree rooted at a given node that fall in a given range onto a queue, we (recursively) enqueue all the keys from the left subtree (if any of them could fall in the range), then enqueue the node at the root (if it falls in the range), then (recursively) enqueue all the keys from the right subtree (if any of them could fall in the range).
searching in the range [F..T] red keys are used in compares
  but are not in the range
S
    EX
AR CH
M
       L
P black keys are in the range
Range search in a BST
www.it-ebooks.info
414 Chapter 3 n Searching
in logarithmic time. We can expect that no path in a tree built from random keys is longer than 3 lg N, but what can we expect if the keys are not random? In the next sec- tion, you will see why this question is moot in practice because of balanced BSTs, which guarantee that the BST height will be logarithmic regardless of the order in which keys are inserted.
In summary, BSTs are not dif cult to implement and can provide fast search and insert for practical applications of all kinds if the key insertions are well-approximated by the random-key model. For our examples (and for many practical applications) BSTs make the difference between being able to accomplish the task at hand and not being able to do so. Moreover, many programmers choose BSTs for symbol-table implementations because they also support fast rank, select, delete, and range query operations. Still, as we have emphasized, the bad worst-case performance of BSTs may not be tolerable in some situations. Good performance of the basic BST implementation is dependent on the keys being suf ciently similar to random keys that the tree is not likely to contain many long paths. With quicksort, we were able to randomize; with a symbol-table API, we do not have that freedom, because the client controls the mix of operations. Indeed, the worst-case behavior is not unlikely in practice—it arises when a client inserts keys in order or in reverse order, a sequence of operations that some client certainly might attempt in the absence of any explicit warnings to avoid doing so. This possibility is a primary reason to seek better algorithms and data structures, which we consider next.
 algorithm (data structure)
worst-case cost (after n inserts)
search insert
average-case cost (after n random inserts)
search hit insert
efficiently support ordered operations?
   sequential search (unordered linked list)
binary search (ordered array)
binary tree search (BST)
N N N/2 N no
lg N N N N
lg N 1.39 lg N
N/2 yes 1.39 lg N yes
Cost summary for basic symbol-table implementations (updated)
www.it-ebooks.info

Q. I’ve seen BSTs before, but not using recursion. What are the tradeoffs?
A. Generally,recursiveimplementationsareabiteasiertoverifyforcorrectness;non- recursive implementations are a bit more ef cient. See Exercise 3.2.13 for an imple- mentation of get(), the one case where you might notice the improved ef ciency. If trees are unbalanced, the depth of the function-call stack could be a problem in a recur- sive implementation. Our primary reason for using recursion is to ease the transition to the balanced BST implementations of the next section, which de nitely are easier to implement and debug with recursion.
Q. Maintaining the node count  eld in Node seems to require a lot of code. Is it really necessary? Why not maintain a single instance variable containing the number of nodes in the tree to implement the size() client method?
A. The rank() and select() methods need to have the size of the subtree rooted at each node. If you are not using these ordered operations, you can streamline the code by eliminating this  eld (see Exercise 3.2.12). Keeping the node count correct for all nodes is admittedly error-prone, but also a good check for debugging. You might also use a recursive method to implement size() for clients, but that would take linear time to count all the nodes and is a dangerous choice because you might experience poor performance in a client program, not realizing that such a simple operation is so expensive.
www.it-ebooks.info
3.2 n Binary Search Trees 415
 Q&A

416 Chapter 3 n Searching
   3.2.1 DrawtheBSTthatresultswhenyouinsertthekeysE A S Y Q U E S T I O N, in that order (associating the value i with the ith key, as per the convention in the text) into an initially empty tree. How many compares are needed to build the tree?
3.2.2 Inserting the keys in the order A X C S E R H into an initially empty BST gives a worst-case tree where every node has one null link, except one at the bottom, which has two null links. Give  ve other orderings of these keys that produce worst-case trees.
3.2.3 Give veorderingsofthekeysA X C S E R Hthat,wheninsertedintoaninitially empty BST, produce the best-case tree.
3.2.4 Suppose that a certain BST has keys that are integers between 1 and 10, and we search for 5. Which sequence below cannot be the sequence of keys examined?
a. 10, 9, 8, 7, 6, 5
b. 4, 10, 8, 6, 5
c. 1, 10, 2, 9, 3, 8, 4, 7, 6, 5 d. 2, 7, 3, 8, 4, 5
e. 1, 2, 10, 4, 8, 5
3.2.5 Suppose that we have an estimate ahead of time of how often search keys are to be accessed in a BST, and the freedom to insert them in any order that we desire. Should the keys be inserted into the tree in increasing order, decreasing order of likely frequency of access, or some other order? Explain your answer.
3.2.6 AddtoBSTamethodheight()thatcomputestheheightofthetree.Developtwo implementations: a recursive method (which takes linear time and space proportional to the height), and a method like size() that adds a  eld to each node in the tree (and takes linear space and constant time per query).
3.2.7 AddtoBSTarecursivemethodavgCompares()thatcomputestheaveragenum- ber of compares required by a random search hit in a given BST (the internal path length of the tree divided by its size, plus one). Develop two implementations: a re- cursive method (which takes linear time and space proportional to the height), and a method like size() that adds a  eld to each node in the tree (and takes linear space and constant time per query).
3.2.8 WriteastaticmethodoptCompares()thattakesanintegerargumentNandcom- putes the number of compares required by a random search hit in an optimal (perfectly
www.it-ebooks.info
 ExErcisEs
  balanced) BST with N nodes, where all the null links are on the same level if the number of links is a power of 2 or on one of two levels otherwise.
3.2.9 DrawallthedifferentBSTshapesthatcanresultwhenNkeysareinsertedintoan initially empty tree, for N = 2, 3, 4, 5, and 6.
3.2.10 Write a test client for BST that tests the implementations of min(), max(), floor(), ceiling(), select(), rank(), delete(), deleteMin(), deleteMax(), and keys() that are given in the text. Start with the standard indexing client given on page 370. Add code to take additional command-line arguments, as appropriate.
3.2.11 How many binary tree shapes of N nodes are there with height N? How many different ways are there to insert N distinct keys into an initially empty BST that result in a tree of height N? (See Exercise 3.2.2.)
3.2.12 Develop a BST implementation that omits rank() and select() and does not use a count  eld in Node.
3.2.13 Give nonrecursive implementations of get() and put() for BST. Partial solution : Here is an implementation of get():
    public Value get(Key key)
    {
       Node x = root;
       while (x != null)
       {
          int cmp = key.compareTo(x.key);
          if (cmp == 0) return x.val;
          else if (cmp < 0) x = x.left;
          else if (cmp > 0) x = x.right;
}
       return null;
    }
The implementation of put() is more complicated because of the need to save a point- er to the parent node to link in the new node at the bottom. Also, you need a separate pass to check whether the key is already in the table because of the need to update the counts. Since there are many more searches than inserts in performance-critical imple- mentations, using this code for get() is justi ed; the corresponding change for put() might not be noticed.
www.it-ebooks.info
3.2 n Binary Search Trees 417

418 Chapter 3 n Searching ExErcisEs (continued)
3.2.14 Give nonrecursive implementations of min(), max(), floor(), ceiling(), rank(), and select().
3.2.15 Give the sequences of nodes examined when the methods in BST are used to compute each of the following quantities for the tree drawn at right.
a. floor("Q")
b. select(5) E
     c. ceiling("Q")
d. rank("J")
e. size("D", "T")
f. keys("D", "T")
DQ AJT
MS
       3.2.16 De netheexternalpathlengthofatreetobethesumofthenumberofnodeson the paths from the root to all null links. Prove that the difference between the external and internal path lengths in any binary tree with N nodes is 2N (see Proposition C).
3.2.17 Draw the sequence of BSTs that results when you delete the keys from the tree of Exercise 3.2.1, one by one, in the order they were inserted.
3.2.18 Draw the sequence of BSTs that results when you delete the keys from the tree of Exercise 3.2.1, one by one, in alphabetical order.
3.2.19 Draw the sequence of BSTs that results when you delete the keys from the tree of Exercise 3.2.1, one by one, by successively deleting the key at the root.
3.2.20 Prove that the running time of the two-argument keys() in a BST is at most proportional to the tree height plus the number of keys in the range.
3.2.21 Add a BST method randomKey() that returns a random key from the symbol table in time proportional to the tree height, in the worst case.
3.2.22 ProvethatifanodeinaBSThastwochildren,itssuccessorhasnoleftchildand its predecessor has no right child.
3.2.23 Is delete() commutative? (Does deleting x, then y give the same result as de- leting y, then x?)
3.2.24 Prove that no compare-based algorithm can build a BST using fewer than lg(N !) ~ N lg N compares.
www.it-ebooks.info

3.2.25 Perfect balance. Write a program that inserts a set of keys into an initially emp- ty BST such that the tree produced is equivalent to binary search, in the sense that the sequence of compares done in the search for any key in the BST is the same as the se- quence of compares used by binary search for the same key.
3.2.26 Exact probabilities. Find the probability that each of the trees in Exercise 3.2.9 is the result of inserting N random distinct elements into an initially empty tree.
3.2.27 Memory usage. Compare the memory usage of BST with the memory usage of BinarySearchST and SequentialSearchST for N key-value pairs, under the assump- tions described in Section 1.4 (see Exercise 3.1.21). Do not count the memory for the keys and values themselves, but do count references to them. Then draw a diagram that depicts the precise memory usage of a BST with String keys and Integer values (such as the ones built by FrequencyCounter), and then estimate the memory usage (in bytes) for the BST built when FrequencyCounter uses BST for Tale of Two Cities.
3.2.28 Sofware caching. Modify BST to keep the most recently accessed Node in an instance variable so that it can be accessed in constant time if the next put() or get() uses the same key (see Exercise 3.1.25).
3.2.29 Tree traversal with constant extra memory. Design an algorithm that performs an inorder tree traversal of a BST using only a constant amount of extra memory. Hint : On the way down the tree, make the child point to the parent and reverse it on the way back up the tree.
3.2.30 BST reconstruction. Given the preorder (or postorder) traversal of a BST (not including null nodes), design an algorithm to reconstruct the BST.
www.it-ebooks.info
3.2 n Binary Search Trees 419
 crEAtivE problEms

420 Chapter 3 n Searching
  3.2.31 Certi cation. Write a method isBST() that takes a Node as argument and re- turns true if the argument node is the root of a binary search tree, false otherwise. Hint : Write a helper method that takes a Node and two Keys as arguments and returns true if the argument node is the root of a binary search tree with all keys strictly be- tween the two argument keys, false otherwise.
Solution :
private boolean isBST()
    {  return isBST(root, null, null)  }
    private boolean isBST(Node x, Key min, Key max)
    {
       if (x == null) return true;
       if (min != null && x.key.compareTo(min) <= 0) return false;
       if (max != null && x.key.compareTo(max) >= 0) return false;
       return isBST(x.left, min, x.key)
           && isBST(x.right, x.key, max);
}
3.2.32 Subtree count check. Write a recursive method that takes a Node as argument and returns true if the subtree count  eld N is consistent in the data structure rooted at that node, false otherwise.
3.2.33 Select/rank check. Write a method that checks, for all i from 0 to size()-1, whether i is equal to rank(select(i)) and, for all keys in the BST, whether key is equal to select(rank(key)).
3.2.34 Threading. Your goal is to support an extended API DoublyThreadedBST that supports the following additional operations in constant time:
Key next(Key key) key that follows key (null if key is the maximum) Key prev(Key key) key that precedes key (null if key is the minimum)
To do so, add  elds pred and succ to Node that contain links to the predecessor and successor nodes, and modify put(), deleteMin(), deleteMax(), and delete() to maintain these  elds.
www.it-ebooks.info
 crEAtivE problEms (continued)
  3.2.35 Re ned analysis. Re ne the mathematical model to better explain the experi- mental results in the table given in the text. Speci cally, show that the average number of compares for a successful search in a tree built from random keys approaches the limit 2 ln N  2 – 3  1.39 lg N – 1.85 as N increases, where   .57721... is Euler’s constant. Hint : Referring to the quicksort analysis in Section 2.3, use the fact that the integral of 1/x approaches ln N  .
3.2.36 Iterator. Is it possible to write a nonrecursive version of keys() that uses space proportional to the tree height (independent of the number of keys in the range)?
3.2.37 Level-order traversal. Write a method printLevel() that takes a Node as argu- ment and prints the keys in the subtree rooted at that node in level order (in order of their distance from the root, with nodes on each level in order from left to right). Hint : Use a Queue.
3.2.38 Tree drawing. Add a method draw() to BST that draws BST  gures in the style of the text. Hint : Use instance variables to hold node coordinates, and use a recursive method to set the values of these variables.
www.it-ebooks.info
3.2 n Binary Search Trees 421

422 Chapter 3 n Searching
   3.2.39 Average case. Run empirical studies to estimate the average and standard de- viation of the number of compares used for search hits and for search misses in a BST built by running 100 trials of the experiment of inserting N random keys into an ini- tially empty tree, for N = 10 4, 10 5, and 10 6. Compare your results against the formula for the average given in Exercise 3.2.35.
3.2.40 Height. Run empirical studies to estimate average BST height by running 100 trials of the experiment of inserting N random keys into an initially empty tree, for N = 104, 105, and 10 6. Compare your results against the 2.99 lg N estimate that is described in the text.
3.2.41 Array representation. Develop a BST implementation that represents the BST with three arrays (preallocated to the maximum size given in the constructor): one with the keys, one with array indices corresponding to left links, and one with array indices corresponding to right links. Compare the performance of your program with that of the standard implementation.
3.2.42 Hibbard deletion degradation. Write a program that takes an integer N from the command line, builds a random BST of size N, then enters into a loop where it deletes a random key (using the code delete(select(StdRandom.uniform(N)))) and then inserts a random key, iterating the loop N 2 times. After the loop, measure and print the average length of a path in the tree (the internal path length divided by N, plus 1). Run your program for N = 102, 103, and 10 4 to test the somewhat counterintuitive hypoth- esis that this process increases the average path length of the tree to be proportional to the square root of N. Run the same experiments for a delete() implementation that makes a random choice whether to use the predecessor or the successor node.
3.2.43 Put/get ratio. Determine empirically the ratio of the amount of time that BST spends on put() operations to the time that it spends on get() operations when FrequencyCounter is used to  nd the frequency of occurrence of values in 1 million randomly-generated integers.
3.2.44 Cost plots. Instrument BST so that you can produce plots like the ones in this section showing the cost of each put() operation during the computation (see Exer- cise 3.1.38).
3.2.45 Actual timings. Instrument FrequencyCounter to use Stopwatch and StdDraw to make a plot where the x axis is the number of calls on get() or put() and the y axis
www.it-ebooks.info
 ExpErimENts
 is the total running time, with a point plotted of the cumulative time after each call. Run your program for Tale of Two Cities using SequentialSearchST and again using BinarySearchST and again using BST and discuss the results. Note: Sharp jumps in the curve may be explained by caching, which is beyond the scope of this question (see Exercise 3.1.39).
3.2.46 Crossover to binary search trees. Find the values of N for which using a binary search tree to build a symbol table of N random double keys becomes 10, 100, and 1,000 times faster than binary search. Predict the values with analysis and verify them experimentally.
3.2.47 Average search time. Run empirical studies to compute the average and stan- dard deviation of the average length of a path to a random node (internal path length divided by tree size, plus 1) in a BST built by insertion of N random keys into an initially empty tree, for N from 100 to 10,000. Do 1,000 trials for each tree size. Plot the results in a Tufte plot, like the one at the bottom of this page,  t with a curve plotting the function 1.39 lg N – 1.85 (see Exercise 3.2.35 and Exercise 3.2.39).
20
0
number of keys N
100
10000
Average path length to a random node in a BST built from random keys
www.it-ebooks.info
1.39 lg N − 1.85
3.2 n Binary Search Trees
423
16
compares
    Definition. A 2-3 search tree is a tree that is either empty or
n A 2-node, with one key (and associated value) and two links,
a left link to a 2-3 search tree with smaller keys, and a right
link to a 2-3 search tree with larger keys
n A 3-node, with two keys (and associated values) and three
links, a left link to a 2-3 search tree with smaller keys, a mid- dle link to a 2-3 search tree with keys between the node’s keys, and a right link to a 2-3 search tree with larger keys
As usual, we refer to a link to an empty tree as a null link.
 3-node
The algorithms in the previous section work well for a wide variety of applications, but they have poor worst-case performance. We introduce in this section a type of binary search tree where costs are guaranteed to be logarithmic, no matter what sequence of keys is used to construct them. Ideally, we would like to keep our binary search trees perfectly balanced. In an N-node tree, we would like the height to be ~lg N so that we can guarantee that all searches can be completed in ~lg N compares, just as for binary search (see Proposition B). Unfortunately, maintaining perfect balance for dynamic insertions is too expensive. In this section, we consider a data structure that slightly re- laxes the perfect balance requirement to provide guaranteed logarithmic performance not just for the insert and search operations in our symbol-table API but also for all of the ordered operations (except range search).
2-3 search trees The primary step to get the  exibility that we need to guarantee balance in search trees is to allow the nodes in our trees to hold more than one key. Spe- ci cally, referring to the nodes in a standard BST as 2-nodes (they hold two links and one key), we now also allow 3-nodes, which hold three links and two keys. Both 2-nodes and 3-nodes have one link for each of the intervals subtended by its keys.
M 2-node
      EJ R
A C H L P SX
null link
Anatomy of a 2-3 search tree
A perfectly balanced 2-3 search tree is one whose null links are all the same distance from the root. To be concise, we use the term 2-3 tree to refer to a perfectly balanced 2-3 search tree (the term denotes a more general structure in other contexts). Later, we shall see ef cient ways to de ne and implement the basic operations on 2-nodes, 3-nodes, and 2-3 trees; for now, let us assume that we can manipulate them conveniently and see how we can use them as search trees.
             424
www.it-ebooks.info
 3.3 BAlAnCeD SeArCh treeS

 successful search for H
H is less than M so
look to the left
M
3.3 n Balanced Search Trees 425 unsuccessful search for B
B is less than M so
look to the left M
EJ R
AC H L P SX
B is less than E
so look to the left M
EJ R
AC H L P SX
          E J R
A C H L P S X
H is between E and J so M look in the middle
E J R
A C H L P S X
                                                           MM
       E J R
A C H L P S X     AC H L P S X
Search The search algorithm for keys in a 2-3 tree directly generalizes the search al- gorithm for BSTs. To determine whether a key is in the tree, we compare it against the keys at the root. If it is equal to any of them, we have a search hit; otherwise, we follow the link from the root to the subtree corresponding to the interval of key values that could contain the search key. If that link is null, we have a search miss; otherwise we recursively search in that subtree.
EJ R
                       found H so return value (search hit)
Search hit (left) and search miss (right) in a 2-3 tree
inserting K
M
EJ R
AC H L P SX
search for K ends here
M
EJ R
AC H KL P SX replace 2-node with
new 3-node containing K Insert into a 2-node
Insert into a 2-node To insert a new key in a 2-3 tree, we might do an unsuccessful search and then hook on a new node with the key at the bottom, as we did with BSTs, but the new tree would not re- main perfectly balanced. The primary reason that 2-3 trees are useful is that we can do insertions and still maintain perfect balance. It is easy to accom- plish this task if the node at which the search ter- minates is a 2-node: we just replace the node with a 3-node containing its key and the new key to be inserted. If the node where the search terminates is a 3-node, we have more work to do.
B is between A and C so look in the middle link is null so B is not in the tree (search miss)
                                     www.it-ebooks.info

426 Chapter 3 n Searching
Insert into a tree consisting of a single 3-node As a  rst warmup before considering the general case, suppose that we want to insert into a tiny 2-3 tree consisting of just a single 3-node. Such a tree has two keys, but no room for a new key in its one node. To be able to perform the insertion, we temporarily put the new key into a 4-node, a natural extension of our node type that has three keys and four links. Creating the 4-node is convenient because it is easy to convert it into a 2-3 tree made up of three 2-nodes, one with the middle key (at the root), one with the smallest of
the three keys (pointed to by the left link of the root), and one with the largest of the three keys (pointed to by the right link of the root). Such a tree is a 3-node BST and also a perfectly balanced 2-3 search tree, with all the null links at the same distance from the root. Before the insertion, the height of the tree is 0; after the insertion, the height of the tree is 1. This case is simple, but it is worth considering be- cause it illustrates height growth in 2-3 trees.
inserting S AE
AE S
E AS
no room for S make a 4-node
split 4-node into this 2-3 tree
               Insert into a 3-node whose parent is a 2-node As a second warmup, suppose that the search ends at a 3-node at the bottom whose parent is a 2-node. In this case, we can still make room for the new key while maintaining perfect balance in the tree, by making a
inserting Z
E J
R containingZ AC H L P SXZ
temporary 4-node as just described, then splitting the 4-node as just described, but then, instead of creat- ing a new node to hold the middle key, moving the middle key to the node’s parent. You can think of the transformation as replacing the link to the old 3-node in the parent by the middle key with links on either side to the new 2-nodes. By our assumption, there is room for doing so in the parent: the parent was a 2-node (with one key and two links) and becomes a 3-node (with two keys and three links). Also, this transformation does not affect the de ning properties of (perfectly balanced) 2-3 trees. The tree remains or- dered because the middle key is moved to the parent, and it remains perfectly balanced: if all null links are the same distance from the root before the insertion, they are all the same distance from the root after the insertion. Be certain that you understand this trans- formation—it is the crux of 2-3 tree dynamics.
Insert into a single 3-node
 M
  search for Z ends at this 3-node
M replace 3-node with temporary 4-node
  R
AC H L P SX
                  E J
              M
EJ       RX
replace 2-node with new 3-node containing middle key
          AC H L P S Z
split 4-node into two 2-nodes pass middle key to parent
Insert into a 3-node whose parent is a 2-node
        www.it-ebooks.info

Insert into a 3-node whose parent is a 3-node Now suppose that the search ends at a node whose parent is a 3-node. Again, we make a temporary 4-node as just described, then split it and insert its middle key into the parent. The parent was a 3-node, so we replace it with a temporary new 4-node containing the middle key from the 4-node split. Then, we perform precisely the same transformation on that node. That is, we split the new 4-node and insert its middle key into its par- ent. Extending to the general case is clear: we con- tinue up the tree, splitting 4-nodes and inserting their middle keys in their parents until reaching a 2-node, which we replace with a 3-node that does not need to be further split, or until reaching a 3-node at the root.
Splitting the root If we have 3-nodes along the whole path from the insertion point to the root, we end up with a tempo-
3.3 n Balanced Search Trees inserting D
427
SX
SX
SX
R
SX
   search for D ends at this 3-node
M
LP
M
R
L P M
  E J AC H
R
             add new key D to 3-node to make temporary 4-node
EJ ACD H
add middle key C to 3-node to make temporary 4-node
                      CE J
A D H L P
split 4-node into two 2-nodes pass middle key to parent
add middle key E to 2-node to make new 3-node
R
                 inserting D
search for D ends
at this 3-node
rary 4-node at the root. EM
   E J
AC H L
A D H L P
In this case we can pro-
ceed in precisely the
same way as for inser-
tion into a tree consist-
ing of a single 3-node.
We split the tempo-
rary 4-node into three
2-nodes, increasing the height of the tree by 1. Note that this last transformation preserves perfect balance be- cause it is performed at the root.
  CJ
                   add new key D to 3-node to make temporary 4-node
EJ ACD H L
add middle key C to 3-node to make temporary 4-node
CE J ADHL
split 4-node into two 2-nodes pass middle key to parent
split 4-node into two 2-nodes pass middle key to parent
Insert into a 3-node whose parent is a 3-node
                    split 4-node into three 2-nodes increasing tree height by 1
E
Local transformations Splitting a temporary 4-node in a 2-3 tree involves one of six transformations, sum- marized at the bottom of the next page. The 4-node may be the root; it may be the left child or the right child of a 2-node; or it may be the left child, middle child, or right child of a 3-node. The basis of the 2-3 tree insertion al- gorithm is that all of these transformations are purely lo- cal: no part of the tree needs to be examined or modi ed other than the speci ed nodes and links. The number of
     C
J
   ADHL
Splitting the root
www.it-ebooks.info

428 Chapter 3 n Searching
links changed for each trans- formation is bounded by a small constant. In particular, the transformations are effec- tive when we  nd the speci ed patterns anywhere in the tree, not just at the bottom. Each of the transformations passes up one of the keys from a 4-node to that node’s parent in the tree and then restructures links ac- cordingly, without touching any other part of the tree.
ae bc d
              less than a
between
between
between
between
greater
than e ...       ...       ...       ...       ...       ...
a and b
b and c
ac e
bd
d and e
c and d
                   less than a
between
between
between
between
greater
than e ...       ...       ...       ...       ...       ...
a and b
Splitting a 4-node is a local transformation
that preserves order and perfect balance
b and c
c and d
d and e
   Global properties Moreover,
these local transformations
preserve the global properties that the tree is ordered and perfectly balanced: the num- ber of links on the path from the root to any null link is the same. For reference, a com- plete diagram illustrating this point for the case that the 4-node is the middle child of a 3-node is shown above. If the length of every path from a root to a null link is h before the transformation, then it is h after the transformation. Each transformation preserves this property, even while splitting the 4-node into two 2-nodes and while changing the parent from a 2-node to a 3-node or from a 3-node into a temporary 4-node. When the root splits into three 2-nodes, the length of every path from the root to a null link increases by 1. If you are not fully convinced, work Exercise 3.3.7, which asks you to
root
parent is a 2-node
d ab c
parent is a 3-node
  a bc
b
left
middle
right
     d e
bd e
a c e
a b d
               ab c
           left
b d
a c
a e bc d
a b
                             right a
                    bc d
cd e
                Splitting a temporary 4-node in a 2-3 tree (summary)
www.it-ebooks.info
 ac
ac
bd
bd
ce
ac
extend the diagrams at the top of the previous page for the other  ve cases to illustrate the same point. Understanding that every local transformation preserves order and perfect balance in the whole tree is the key to understanding the algorithm.
Unlike standard BSTs, which grow down from the top, 2-3 trees grow up from the bottom. If you take the time to carefully study the  gure on the next page, which gives the sequence of 2-3 trees that is produced by our standard indexing test client and the sequence of 2-3 trees that is produced when the same keys are inserted in increasing or- der, you will have a good understanding of the way that 2-3 trees are built. Recall that in a BST, the increasing-order sequence for 10 keys results in a worst-case tree of height 9. In the 2-3 trees, the height is 2.
The preceding description is suf cient to de ne a symbol-table implementation with 2-3 trees as the underlying data structure. Analyzing 2-3 trees is different from analyzing BSTs because our primary interest is in worst-case performance, as opposed to average-case performance (where we analyze expected performance under the ran- dom-key model). In symbol-table implementations, we normally have no control over the order in which clients insert keys into the table and worst-case analysis is one way to provide performance guarantees.
Thus, we can guarantee good worst-case performance with 2-3 trees. The amount of time required at each node by each of the operations is bounded by a constant, and both operations examine nodes on just one path, so the total cost of any search or insert is guaranteed to be logarithmic. As you can see from comparing the 2-3 tree depicted at the bottom ofpage 431 with the BST formed from the same keys on page 405, a perfectly balanced 2-3 tree strikes a remarkably  at posture. For example, the height of a 2-3 tree that contains 1 billion keys is between 19 and 30. It is quite remarkable that we can guarantee to perform arbitrary search and insertion operations among 1 billion keys by examining at most 30 nodes.
However, we are only part of the way to an implementation. Although it is possible to write code that performs transformations on distinct data types representing 2- and 3-nodes, most of the tasks that we have described are inconvenient to implement in
www.it-ebooks.info
3.3 n Balanced Search Trees 429
 proposition F. Search and insert operations in a 2-3 tree with N keys are guaran- teed to visit at most lg N nodes.
proof: The height of an N-node 2-3 tree is between ⎣log3 N⎦ = ⎣(lg N)/(lg 3)⎦ (if the tree is all 3-nodes) and ⎣lg N⎦ (if the tree is all 2-nodes) (see Exercise 3.3.4).

430 Chapter 3 n Searching
  S insert A A AC
insert S
EESC
AEE
AS REH
ARS CEL
AC     R S
H ER M
AC H S
X ER P
A C H SX
M ER R
A C HM S X PMS
ER
AC H P SX
C AE
C AEH
CH
AEL CH
AELM H
CM AELP
H CM
AELPR H
C MR AELPS
                                                                                                                                                                                                 LMXH ERC
                 A C HL P S X standard indexing client
MR AELPSX
same keys in increasing order
                      2-3 construction traces
www.it-ebooks.info

this direct representation because there are numerous different cases to be handled. We would need to maintain two different types of nodes, compare search keys against each of the keys in the nodes, copy links and other information from one type of node to another, convert nodes from one type to another, and so forth. Not only is there a substantial amount of code involved, but the overhead incurred could make the algo- rithms slower than standard BST search and insert. The primary purpose of balancing is to provide insurance against a bad worst case, but we would prefer the overhead cost for that insurance to be low. Fortunately, as you will see, we can do the transformations in a uniform way using little overhead.
3.3 n Balanced Search Trees 431
           Typical 2-3 tree built from random keys
www.it-ebooks.info

432 Chapter 3 n Searching
Red-black BSTs The insertion algorithm for 2-3 trees just described is not dif cult to understand; now, we will see that it is also not dif cult to implement. We will con- sider a simple representation known as a red-black BST that leads to a natural imple- mentation. In the end, not much code is required, but understanding how and why the code gets the job done requires a careful look.
3-node
ab
between a and b ...
b a
between
 Encoding 3-nodes The basic idea behind red-black
BSTs is to encode 2-3 trees by starting with standard
BSTs (which are made up of 2-nodes) and adding extra
information to encode 3-nodes. We think of the links
as being of two different types: red links, which bind
together two 2-nodes to represent 3-nodes, and black
links, which bind together the 2-3 tree. Speci cally,
we represent 3-nodes as two 2-nodes connected by a
single red link that leans left (one of the 2-nodes is the
left child of the other). One advantage of using such a
representation is that it allows us to use our get() code
for standard BST search without modi cation. Given
any 2-3 tree, we can immediately derive a corresponding BST, just by converting each node as speci ed. We refer to BSTs that represent 2-3 trees in this way as red-black BSTs.
An equivalent de nition Another way to proceed is to de ne red-black BSTs as BSTs having red and black links and satisfying the following three restrictions:
n Red links lean left.
n No node has two red links connected to it.
n The tree has perfect black balance : every path from the root to a null link has the
same number of black links—we refer to this number as the tree’s black height. There is a 1-1 correspondence between red-black BSTs de ned in this way and 2-3 trees.
A 1-1 correspondence If we draw the red links horizontally in a red-black BST, all of the null links are the same distance from the root, and if we then collapse together the nodes connected by red links, the result is a 2-3 tree. Conversely, if we draw 3-nodes in
A red-black tree with horizontal red links is a 2-3 tree
      less than a ...
less than a
greater than b ...
                 a and b ...       ...
greater than b ...
   Encoding a 3-node with two 2-nodes connected by a left-leaning red link
                                                                    www.it-ebooks.info

red-black BST
A
horizontal red links
a 2-3 tree as two 2-nodes connected by a red link that leans left, then no node has two red links connected to it, and the tree has perfect black balance, since the black links correspond to the 2-3 tree links, which are perfectly balanced by de nition. Whichever way we choose to de ne them, red-black BSTs are both BSTs and 2-3 trees. Thus, if we can im- plement the 2-3 tree insertion algorithm by maintaining the 1-1 correspondence, then we get the best of both worlds: the simple and ef cient search method from standard BSTs and the ef cient inser- tion-balancing method from 2-3 trees.
M JR
ELPX CHS
3.3 n Balanced Search Trees 433
                            M EJR
                          2-3 tree
ACHLPSX
M
EJ R
AC H L P SX
                 1-1 correspondence between red-black BSTs and 2-3 trees
Color representation For convenience, since each node is pointed to by precisely one link (from its parent), we encode the color of links innodes,byaddingabooleaninstancevariable color to our Node data type, which is true if the link from the parent is red and false if it is black. By convention, null links are black. For clarity in our code, we de ne constants RED and BLACK for use in setting and testing this variable. We use a private method isRed() to test the color of a node’s link to its parent. When we refer to the color of a node, we are referring to the color of the link pointing to it, and vice versa.
Rotations The implementation that we will consider might allow right-leaning red links or two red links in a row during an operation, but it always corrects these conditions before com- pletion, through judicious use of an operation called rotation that switches the orientation of
h.left.color h
h.right.color is BLACK
  is RED
E CJ
ADG
             www.it-ebooks.info
private static final boolean RED
private static final boolean BLACK = false;
private class Node
{
{
} }
private boolean isRed(Node x)
{
   if (x == null) return false;
   return x.color == RED;
}
Node representation for red-black BSTs
this.key
this.val
this.N
this.color = color;
= key;
= val;
= N;
// key
Key key;
Value val;
Node left, right; // subtrees
int N;            // # nodes in this subtree
boolean color;    // color of link from
                  // associated data
                  //   parent to this node
Node(Key key, Value val, int N, boolean color)
= true;

434
Chapter 3 n Searching
could be right or left, red or black
S
red links. First, suppose that we have a right-leaning red link that needs to be rotated to lean to the left (see the diagram at left). This operation is called a left rotation. We organize the computation as a method that takes a link to a red-black BST as argument and, as- suming that link to be to a Node h whose right link is red, makes the necessary adjustments and returns a link to a node that is the root of a red-black BST for the same set of keys whose left link is red. If you check each of the lines of code against the before/after drawings in the diagram, you will  nd this operation is easy to understand: we are switching from having the smaller of the two keys at the root to having the larger of the two keys at the root. Implementing a right rotation that converts a left-leaning red link to a right-leaning one amounts to the same code, with left and right interchanged (see the diagram at right below).
  h
Ex
       less than E
between E and S
greater than S
Node rotateLeft(Node h)
{
   Node x = h.right;
   h.right = x.left;
   x.left = h;
   x.color = h.color;
   h.color = RED;
   x.N = h.N;
   h.N = 1 + size(h.left)
           + size(h.right);
   return x;
}
h
less than E
x
greater than S
Resetting the link in the parent after a rotation
   E
S
Whether left or right, every rotation leaves us with a link. We always use the link returned by rotateRight() or rotateLeft() to reset the appro-
    between E and S
priate link in the parent (or the root of the tree). That may be a right or a left link, but we can always use it to reset the link in the parent. This link may be red or black—both rotateLeft() and
S E
between E and S
h
greater than S
     Left rotate (right link of h)
rotateRight() preserve its color by setting x.color to
x
less than E
   h.color. This might allow two red links in a row to occur within the tree, but our algorithms will also use rotations to correct this condition when it arises. For example, the code
    h = rotateLeft(h);
Node rotateRight(Node h)
{
   Node x = h.left;
   h.left = x.right;
   x.right = h;
   x.color = h.color;
   h.color = RED;
   x.N = h.N;
   h.N = 1 + size(h.left)
           + size(h.right);
   return x;
x
Eh
S
less than E
Right rotate (left link of h)
rotates left a right-leaning red link that is to the right of node h, setting h to point to the root of the resulting sub- tree (which contains all the same nodes as the subtree pointed to by h before the rotation, but a different root). The ease of writing this type of code is the primary reason we use recursive implementations of BST methods, as it makes doing rotations an easy supplement to normal in- sertion, as you will see.
}
        www.it-ebooks.info
between E and S
greater than S

We can use rotations to help maintain the 1-1 correspondence between 2-3 trees and red-black BSTs as new keys are inserted because they pre- serve the two de ning properties of red-black BSTs: order and perfect black balance. That is, we can use rotations on a red-black BST without having to worry about losing its order or its perfect black balance. Next, we see how to use rotations to preserve the other two de ning properties of red- black BSTs (no consecutive red links on any path and no right-leaning red links). We warm up with some easy cases.
Insert into a single 2-node A red-black BST with 1 key is just a single 2-node. Inserting the second key immediately shows the need for having a rotation operation. If the new key is smaller than the key in the tree, we just make a new (red) node with the new key and we are done: we have a red-black BST that is equivalent to a single 3-node. But if the new key is larger than the key in the tree, then attaching a new (red) node gives a right-leaning red link, and the code root = rotateLeft(root); com- pletes the insertion by rotating the red link to the left and updating the tree root link. The result in both cases is the red-black representation of a single 3-node, with two keys, one left-leaning red link, and black height 0.
Insert into a 2-node at the bottom We insert keys into a red-black BST as usual into a BST, adding a new node at the bottom (respecting the or- der), but always connected to its parent with a red link. If the parent is a 2-node, then the same two cases just discussed are effective. If the new node is attached to the left link, the parent simply becomes a 3-node; if it is at- tached to a right link, we have a 3-node leaning the wrong way, but a left rotation  nishes the job.
red links connected to it; our goal is to correct this condition.
n The simplest of the three cases is when the new key is larger than
the two in the tree and is therefore attached on the rightmost link of the 3-node, making a balanced tree with the middle key at the root, connected with red links to nodes containing a smaller and a larger key. If we  ip the colors of those two links from red to black, then we have a balanced tree of (black) height 1 with three nodes, exactly what we need to maintain our 1-1 correspondence to 2-3 trees. The other two cases eventually reduce to this case.
left
a
root
search ends at this null link
root
red link to new node containing a converts 2-node
to 3-node
root
search ends at this null link
attached new node
3.3 n Balanced Search Trees 435
  b
    b
    right
a
a
a
       b b
with red link
root
rotated left
to make a legal 3-node
              Insert into a tree with two keys (in a 3-node)
Insert into a single 2-node (two cases)
insert C
E
AS
R
right link red so rotate left
E AS CR
E
C S
AR
Insert into a 2-node at the bottom
This case reduces to three subcases: the new key is either less than both keys in the tree, between them, or greater than both of them. Each of the cases introduces a node with two
add new node here
           www.it-ebooks.info

436
Chapter 3 n Searching n If the new key is
larger
a
a
a
smaller
between
   smaller than the two keys in the tree and goes on the left link, then we have two red links in a row, both leaning to the left, which we can reduce to the previ- ous case (middle key at the root, con- nected to the others by two red links) by rotating the top link to the right.
n If the new key goes between the two keys in the tree, we
b
b
b
search ends at this null link
c a colors flipped a
c b
search ends at this null link
c
attached new node with red link
rotated right
c
colors flipped to black
c
a
a
a
a
c
search ends at this null link
c
attached new node with red link
c
rotated left
rotated right
                    attached new node with red link
b
b
b
b b
b
                               c
to black
a
c
         colors flipped to black
   b ac
         h
could be left or right link
again have two red links in a row, a right-leaning one below a left-leaning one, which we can reduce to the previous case (two red links in a row, to the left) by rotating left the bot- tom link.
In summary, we achieve the desired result by doing zero, one, or two rotations followed by  ipping the colors of the two children of the root. As with 2-3 trees, be certain that you understand these transformations, as they are the key to red-black tree dynamics.
Flipping colors To  ip the colors of the two red children of a node, we use a method flipColors(), shown at left. In addition to  ipping the colors of the children from red to black, we also  ip the color of the parent from black to red. A critically important characteristic of this operation is that, like rotations, it is a local transformation that preserves per- fect black balance in the tree. Moreover, this convention im- mediately leads us to a full implementation, as we describe next.
Insert into a single 3-node (three cases)
   E AS
        less than A
between A and E
between E and S
greater than S
void flipColors(Node h)
{  h.color = RED;
   h.left.color = BLACK;
}
A
red link attaches middle node to parent
E
black links split S
h.right.color = BLACK;
        to 2-nodes
less between between greater
than A A and E E and S than S Flipping colors to split a 4-node
    www.it-ebooks.info

Keeping the root black In the case just considered (insert into a single 3-node), the color  ip will color the root red. This can also happen in larger trees. Strictly speaking, a red root implies that the root is part of a 3-node, but that is not the case, so we color the root black after each insertion. Note that the black
height of the tree increases by 1 whenever the root is involved in a color  ip, where its childrens’ colors are both  ipped from red to black.
inserting H E
AC     RS
E CS
AR
add new node here
E CS
AR
H
both children red so flip colors
E CR
AHS
right link red so rotate left
3.3 n Balanced Search Trees 437
             Insert into a 3-node at the bottom
Now suppose that we add a new node at the bottom that is connected to a 3-node. The same three cases just discussed arise. Either the new link is connected to the right link of the 3-node (in which case we just  ip colors) or to the left link of the 3-node (in which case we need to rotate the top link right and  ip colors) or to the middle link of the 3-node (in which case we rotate left the bottom link, then rotate right the top link, then  ip colors). Flipping the colors makes the link to the middle node red, which amounts to passing it up to its parent, putting us back in the same situation with respect to the parent, which we can  x by
two lefts in a row so rotate right
        E
AC     HRS
                     moving up the tree.
Passing a red link up the tree The 2-3 tree insertion
algorithm calls for us to split the 3-node, passing the
middle key up to be inserted into its parent, continuing
until encountering a 2-node or the root. In every case
we have considered, we precisely accomplish this objec-
tive: after doing any necessary rotations, we  ip colors,
which turns the middle node to red. From the point of CH view of the parent of that node, that link becoming red A
              ER AC H S
E CR
AHS
R ES
                      can be handled in precisely the same manner as if the
red link came from attaching a new node: we pass up
a red link to the middle node. The three cases sum-
marized in the diagram on the next page precisely capture the operations necessary in a red-black tree to implement the key operation in 2-3 tree insertion: to insert into a 3-node, create a temporary 4-node, split it, and pass a red link to the middle key up to its parent. Continuing the same process, we pass a red link up the tree until reaching a 2-node or the root.
www.it-ebooks.info
Insert into a 3-node at the bottom

438 Chapter 3 n Searching
In summary, we can maintain our 1-1 correspondence between 2-3 trees and red-black BSTs during insertion by judi-
cious use of three simple operations: left
rotate, right rotate, and color  ip. We can accomplish the insertion by performing h the following operations, one after the
h
rotate
left rotate
h
flip colors
                          other, on each node as we pass up the tree right
 from the point of insertion:
n If the right child is red and the left
child is black, rotate left.
n If both the left child and its left
child are red, rotate right.
n If both children are red,  ip colors.
Passing a red link up a red-black BST
        It certainly is worth your while to check that this sequence handles each of the cases just described. Note that the  rst operation handles both the rotation necessary to lean the 3-node to the left when the parent is a 2-node and the rotation necessary to lean the bottom link to the left when the new red link is the middle link in a 3-node.
Implementation Since the balancing operations are to be performed on the way up the tree from the point of insertion, implementing them is easy in our standard recursive implementation: we just do them after the recursive calls, as shown in Algo- rithm 3.4. The three operations listed in the previous paragraph each can be accom- plished with a single if statement that tests the colors of two nodes in the tree. Even though it involves a small amount of code, this implementation would be quite dif cult to understand without the two layers of abstraction that we have developed (2-3 trees and red-black BSTs) to implement it. At a cost of testing three to  ve node colors (and perhaps doing a rotation or two or  ipping colors when a test succeeds), we get BSTs that have nearly perfect balance.
The traces for our standard indexing client and for the same keys inserted in increas- ing order are given on page 440. Considering these examples simply in terms of our three operations on red-black trees, as we have been doing, is an instructive exercise. Another instructive exercise is to check the correspondence with 2-3 trees that the algo- rithm maintains (using the  gure for the same keys given on page 430). In both cases, you can test your understanding of the algorithm by considering the transformations (two color  ips and two rotations) that are needed when P is inserted into the red-black BST (see Exercise 3.3.12).
www.it-ebooks.info

  aLgorIthM 3.4 insert for red-black BSts
public class RedBlackBST<Key extends Comparable<Key>, Value>
  {
     private Node root;
     private class Node // BST node with color bit (see page 433)
     private boolean isRed(Node h)    // See page 433.
     private Node rotateLeft(Node h)  // See page 434.
     private Node rotateRight(Node h) // See page 434.
     private void flipColors(Node h)  // See page 436.
     private int size()               // See page 398.
     public void put(Key key, Value val)
     {  // Search for key. Update value if found; grow table if new.
        root = put(root, key, val);
        root.color = BLACK;
}
     private Node put(Node h, Key key, Value val)
     {
        if (h == null)  // Do standard insert, with red link to parent.
           return new Node(key, val, 1, RED);
        int cmp = key.compareTo(h.key);
        if      (cmp < 0) h.left  = put(h.left,  key, val);
        else if (cmp > 0) h.right = put(h.right, key, val);
        else h.val = val;
        if (isRed(h.right) && !isRed(h.left))    h = rotateLeft(h);
        if (isRed(h.left) && isRed(h.left.left)) h = rotateRight(h);
        if (isRed(h.left) && isRed(h.right))     flipColors(h);
        h.N = size(h.left) + size(h.right) + 1;
return h; }
}
The code for the recursive put() for red-black BSTs is identical to put() in elementary BSTs except for the three if statements after the recursive calls, which provide near-perfect balance in the tree by maintaining a 1-1 correspondence with 2-3 trees, on the way up the search path. The  rst rotates left any right-leaning 3-node (or a right-leaning red link at the bottom of a temporary 4-node); the second rotates right the top link in a temporary 4-node with two left-leaning red links; and the third  ips colors to pass a red link up the tree (see text).
  www.it-ebooks.info
3.3 n Balanced Search Trees 439
440 Chapter 3 n Searching
  insert S
S insert A A ESCC
         EA AE EC
          AS AE
EC RASHAH
RE
EH CCSLCL
ARA RH
HES MCM CH AEL
A
RH XEXPCM
CHS AELP A
RH MEXRCM
CMS AELR
                            E
                                                                               AH
M
P H
            CR CHPX AEMS
  PER S ASLP
MH LERXCR
CLPXAEMX AHSLPS
standard indexing client same keys in increasing order
Red-black BST construction traces
                                                   www.it-ebooks.info

Deletion Since put() in Algorithm 3.4 is already one of the most intricate methods that we consider in this book, and the implementations of deleteMin(), deleteMax(), and delete() for red-black BSTs are a bit more complicated, we defer their full implementations to exercises. Still, the basic approach is worthy of study. To describe it, we begin by returning to 2-3 trees. As with insertion, we can de ne a se- quence of local transformations that allow us to delete a node while still maintaining perfect balance. The process is somewhat more complicated than for insertion, because we do the transformations both on the way down the search path,
when we introduce temporary 4-nodes (to allow for a node to be deleted), and also on the way up the search path, where we split any leftover 4-nodes (in the same manner as for insertion).
at the root
on the way down
3.3 n Balanced Search Trees 441
       Top-down 2-3-4 trees As a  rst warmup for deletion, we con-
sider a simpler algorithm that does transformations both on the
way down the path and on the way up the path: an insertion algo-
rithm for 2-3-4 trees, where the temporary 4-nodes that we saw in
2-3 trees can persist in the tree. The insertion algorithm is based on
doing transformations on the way down the path to maintain the
invariant that the current node is not a 4-node (so we are assured
that there will be room to insert the new key at the bottom) and
transformations on the way up the path to balance any 4-nodes
that may have been created. The transformations on the way down
are precisely the same transformations that we used for splitting
4-nodes in 2-3 trees. If the root is a 4-node, we split it into three
2-nodes, increasing the height of the tree by 1. On the way down
the tree, if we encounter a 4-node with a 2-node as parent, we split
the 4-node into two 2-nodes and pass the middle key to the par-
ent, making it a 3-node; if we encounter a 4-node with a 3-node as
parent, we split the 4-node into two 2-nodes and pass the middle
key to the parent, making it a 4-node. We do not need to worry
about encountering a 4-node with a 4-node as parent by virtue of
the invariant. At the bottom, we have, again by virtue of the invariant, a 2-node or a 3-node, so we have room to insert the new key. To implement this algorithm with red- black BSTs, we
n Represent 4-nodes as a balanced subtree of three 2-nodes, with both the left and right child connected to the parent with a red link
n Split 4-nodes on the way down the tree with color  ips
n Balance 4-nodes on the way up the tree with rotations, as for insertion
                                                                                        at the bottom
Transformations for insert in top-down 2-3-4 trees
         www.it-ebooks.info

442 Chapter 3 n Searching
Remarkably, you can implement top-down 2-3-4 trees by moving one line of code in put() in Algorithm 3.4: move the colorFlip() call (and accompanying test) to be- fore the recursive calls (between the test for null and the comparison). This algorithm has some advantages over 2-3 trees in applications where multiple processes have access to the same tree, because it always is operating within a link or two of the current node. The deletion algorithms that we describe next are based on a similar scheme and are effective for these trees as well as for 2-3 trees.
at the root
Delete the minimum As a second warmup
for deletion, we consider the operation of
deleting the minimum from a 2-3 tree. The
basic idea is based on the observation that we
can easily delete a key from a 3-node at the
bottom of the tree, but not from a 2-node.
Deleting the key from a 2-node leaves a node
with no keys; the natural thing to do would
be to replace the node with a null link, but
that operation would violate the perfect bal-
ance condition. So, we adopt the following
approach: to ensure that we do not end up on
a 2-node, we perform appropriate transfor-
mations on the way down the tree to preserve
the invariant that the current node is not a
2-node (it might be a 3-node or a tempo-
rary 4-node). First, at the root, there are two
possibilities: if the root is a 2-node and both
children are 2-nodes, we can just convert the
three nodes to a 4-node; otherwise we can
borrow from the right sibling if necessary to ensure that the left child of the root is not a 2-node. Then, on the way down the tree, one of the following cases must hold:
n If the left child of the current node is not a 2-node, there is nothing to do.
n If the left child is a 2-node and its immediate sibling is not a 2-node, move a key
from the sibling to the left child.
n If the left child and its immediate sibling are 2-nodes, then combine them with
the smallest key in the parent to make a 4-node, changing the parent from a
3-node to a 2-node or from a 4-node to a 3-node.
Following this process as we traverse left links to the bottom, we wind up on a 3-node or a 4-node with the smallest key, so we can just remove it, converting the 3-node to a
 b
  ab c bc
           cd e         ab
on the way down
bd e
at the bottom
d e
cf g d e
d e
        bf g
cd e         ab
                              ab c
         ab c         b c Transformations for delete the minimum
   www.it-ebooks.info
 a
a
ac
ac
3.3 n Balanced Search Trees 443 2-node or the 4-node to a 3-node. Then, on the way up the tree, we split any unused
temporary 4-nodes.
Delete The same transformations along the search path just described for deleting the minimum are effective to ensure that the current node is not a 2-node during a search for any key. If the search key is at the bottom, we can just remove it. If the key is not at the bottom, then we have to exchange it with its successor as in regular BSTs. Then, since the current node is not a 2-node, we have reduced the problem to deleting the minimum in a subtree whose root is not a 2-node, and we can use the procedure just described for that subtree. After the deletion, as usual, we split any remaining 4-nodes on the search path on the way up the tree.
Several of the exercises at the end of this section are devoted to examples and implementations related to these deletion algorithms. People with an interest in devel- oping or understanding implementations need to master the details covered in these exercises. People with a general interest in the study of algorithms need to recognize that these methods are important because they represent the  rst symbol-table imple- mentation that we have seen where search, insert, and delete are all guaranteed to be ef cient, as we will establish next.
www.it-ebooks.info

444 Chapter 3 n Searching
Properties of red-black BSTs Studying the properties of red-black BSTs is a matter of checking the correspondence with 2-3 trees and then applying the analysis of 2-3 trees. The end result is that all symbol-table operations in red-black BSTs are guaran- teed to be logarithmic in the size of the tree (except for range search, which additionally costs time proportional to the number of keys returned). We repeat and emphasize this point because of its importance.
Analysis First, we establish that red-black BSTs, while not perfectly balanced, are al- ways nearly so, regardless of the order in which the keys are inserted. This fact immedi- ately follows from the 1-1 correspondence with 2-3 trees and the de ning property of 2-3 trees (perfect balance).
 propositionG. Theheightofared-blackBSTwithNnodesisnomorethan2lgN.
proofsketch: Theworstcaseisa2-3treethatisall2-nodesexceptthattheleftmost path is made up of 3-nodes. The path taking left links from the root is twice as long as the paths of length ~ lg N that involve just 2-nodes. It is possible, but not easy, to develop key sequences that cause the construction of red-black BSTs whose average path length is the worst-case 2 lg N. If you are mathematically inclined, you might enjoy exploring this issue by working Exercise 3.3.24.
This upper bound is conservative: experiments involving both random insertions and insertion sequences found in typical applications support the hypothesis that each search in a red-black BST of N nodes uses about 1.0 lg N – 0.5 compares, on the aver- age. Moreover, you are not likely to encounter a substantially higher average number of compares in practice.
                                                                                                                                                                           Typical red-black BST built from random keys (null links omitted)
www.it-ebooks.info

For our example study of the cost of the put() operations for FrequencyCounter for words of length 8 or more, we see a further reduction in the average cost, again pro- viding a quick validation of the logarithmic performance predicted by the theoretical model, though this validation is less surprising than for BSTs because of the guarantee provided by proposition G. The total savings is less than the 40 per cent savings in the search cost because we count rotations and color  ips as well as compares.
3.3 n Balanced Search Trees 445
 tale.txt
leipzig1M.txt
 all words 8+ letters 10+ letters
words
135,635 14,350 4,582
distinct
10,679 5,737 2,260
compares
model actual
13.6 13.5 12.6 12.1 11.4 11.5
words
21,191,455 4,239,597 1,610,829
distinct
534,580 299,593 165,555
compares
model actual
19.4 19.1 18.7 18.4 17.5 17.3
average number of compares per put() for FrequencyCounter using RedBlackBST
 property H. The average length of a path from the root to a node in a red-black BST with N nodes is ~1.00 lg N.
Evidence: Typical trees, such as the one at the bottom of the previous page (and even the one built by inserting keys in increasing order at the bottom of this page) are quite well-balanced, by comparison with typical BSTs (such as the tree depicted on page 405). The table at the top of this page shows that path lengths (search costs) for our FrequencyCounter application are about 40 percent lower than from el- ementary BSTs, as expected. This performance has been observed in countless ap- plications and experiments since the invention of red-black BSTs.
                                                                                                                 Red-black BST built from ascending keys (null links omitted)
www.it-ebooks.info

 446 Chapter 3
n
Searching
20
compares
0
operations
Costs for java FrequencyCounter 8 < tale.txt using RedBlackBST
0
14350
The get() method in red-black BSTs does not examine the node color, so the balanc- ing mechanism adds no overhead; search is faster than in elementary BSTs because the tree is balanced. Each key is inserted just once, but may be involved in many, many search operations, so the end result is that we get search times that are close to optimal (because the trees are nearly balanced and no work for balancing is done during the searches) at relatively little cost (unlike binary search, insertions are guaranteed to be logarithmic). The inner loop of the search is a compare followed by updating a link, which is quite short, like the inner loop of binary search (compare and index arithme- tic). This implementation is the  rst we have seen with logarithmic guarantees for both search and insert, and it has a tight inner loop, so its use is justi ed in a broad variety of applications, including library implementations.
Ordered symbol-table API One of the most appealing features of red-black BSTs is that the complicated code is limited to the put() (and deletion) methods. Our code for the minimum/maximum, select, rank,  oor, ceiling and range queries in standard BSTs can be used without any change, since it operates on BSTs and has no need to refer to the node color. Algorithm 3.4, together with these methods (and the deletion methods), leads to a complete implementation of our ordered symbol-table API. Moreover, all of the methods bene t from the near-perfect balance in the tree because they all require time proportional to the tree height, at most. Thus Proposition G, in combination with Proposition E, suf ces to establish a logarithmic performance guarantee for all of them.
www.it-ebooks.info
12
algorithm (data structure)
worst-case cost (after n inserts)
search insert
average-case cost (after n random inserts)
search hit insert
efficiently support ordere
operations?
3.3 n Balanced Search Trees 447
 proposition i. In a red-black BST, the following operations take logarithmic time in the worst case: search, insertion,  nding the minimum,  nding the maximum,  oor, ceiling, rank, select, delete the minimum, delete the maximum, delete, and range count.
proof: We have just discussed get(), put(), and the deletion operations. For the others, the code from Section 3.2 can be used verbatim (it just ignores the node color). Guaranteed logarithmic performance follows from Propositions E and G, and the fact that each algorithm performs a constant number of operations on each node examined.
On re ection, it is quite remarkable that we are able to achieve such guarantees. In a world awash with information, where people maintain tables with trillions or quadril- lions of entries, the fact is that we can guarantee to complete any one of these opera- tions in such tables with just a few dozen compares.
 d
   sequential search (unordered linked list)
binary search (ordered array)
binary tree search (BST)
2-3 tree search (red-black BST)
N N N/2 N no
lg N
N
N
lg N N/2 yes
1.39 lg N yes 1.00 lg N yes
N
2 lg N
1.39 lg N 1.00 lg N
2 lg N
Cost summary for symbol-table implementations (updated)
www.it-ebooks.info

448 Chapter 3 n Searching
 Q&A
 Q. Why not let the 3-nodes lean either way and also allow 4-nodes in the trees?
A. Thoseare nealternatives,usedbymanyfordecades.Youcanlearnaboutseveralof these alternatives in the exercises. The left-leaning convention reduces the number of cases and therefore requires substantially less code.
Q. Why not use an array of Key values to represent 2-, 3-, and 4-nodes with a single Node type?
A. Goodquestion.ThatispreciselywhatwedoforB-trees(seeChapter6),wherewe allow many more keys per node. For the small nodes in 2-3 trees, the overhead for the array is too high a price to pay.
Q. When we split a 4-node, we sometimes set the color of the right node to RED in rotateRight() and then immediately set it to BLACK in flipColors(). Isn’t that wasteful?
A. Yes, and we also sometimes unnecessarily recolor the middle node. In the grand scheme of things, resetting a few extra bits is not in the same league with the improve- ment from linear to logarithmic that we get for all operations, but in performance-crit- ical applications, you can put the code for rotateRight() and flipColors() inline and eliminate those extra tests. We use those methods for deletion, as well, and  nd them slightly easier to use, understand, and maintain by making sure that they preserve perfect black balance.
www.it-ebooks.info

3.3 n Balanced Search Trees 449
 ExErcisEs
 3.3.1 Drawthe2-3treethatresultswhenyouinsertthekeysE A S Y Q U T I O Nin that order into an initially empty tree.
3.3.2 Drawthe2-3treethatresultswhenyouinsertthekeysY L P M X H C R A E S in that order into an initially empty tree.
3.3.3 FindaninsertionorderforthekeysS E A R C H X M thatleadstoa2-3tree of height 1.
3.3.4 Prove that the height of a 2-3 tree with N keys is between ~log3 N  .63 lg N (for a tree that is all 3-nodes) and ~ lg N (for a tree that is all 2-nodes).
3.3.5 The gureatrightshowsallthestructurallydifferent2-3treeswithN keys, for N from 1 up to 6 (ignore the order of the subtrees). Draw all the structurally different trees for N = 7, 8, 9, and 10.
3.3.6 Findtheprobabilitythateachofthe2-3treesinExercise3.3.5isthe result of the insertion of N random distinct keys into an initially empty tree.
3.3.7 Draw diagrams like the one at the top of page 428 for the other  ve cases in the diagram at the bottom of that page.
3.3.8 Showallpossiblewaysthatonemightrepresenta4-nodewiththree 2-nodes bound together with red links (not necessarily left-leaning).
3.3.9 Which of the following are red-black BSTs?
(i)C (ii) E (iii)E (iv)H
AYDHBYCY H CFGZADHZAT
DA
3.3.10 Draw the red-black BST that results when you insert items with the keys E A S Y Q U T I O N in that order into an initially empty tree.
3.3.11 Draw the red-black BST that results when you insert items with the keys Y L P M X H C R A E S in that order into an initially empty tree.
                                                                 www.it-ebooks.info

450 Chapter 3 n Searching ExErcisEs (continued)
3.3.12 Draw the red-black BST that results after each transformation (color  ip or rotation) during the insertion of P for our standard indexing client.
3.3.13 Trueorfalse:Ifyouinsertkeysinincreasingorderintoared-blackBST,thetree height is monotonically increasing.
3.3.14 Drawthered-blackBSTthatresultswhenyouinsertlettersAthroughKinorder into an initially empty tree, then describe what happens in general when trees are built by insertion of keys in ascending order (see also the  gure in the text).
 3.3.15 Answer the previous two questions for the case when the keys are inserted in de- scending order.
3.3.16 Showtheresultofinsertingnintothe red-black BST drawn at right (only the search path is shown, and you need to include only these nodes in your answer).
3.3.17 Generate two random 16-node red- black BSTs. Draw them (either by hand or with a program). Compare them with the (unbalanced) BSTs built with the same keys.
j
     u t
s r
           q
  p l
ko m
              3.3.18 Drawallthestructurallydifferentred-blackBSTswithNkeys,forNfrom2up to 10 (see Exercise 3.3.5).
3.3.19 With 1 bit per node for color, we can represent 2-, 3-, and 4-nodes. How many bits per node would we need to represent 5-, 6-, 7-, and 8-nodes with a binary tree?
3.3.20 ComputetheinternalpathlengthinaperfectlybalancedBSTofNnodes,when N is a power of 2 minus 1.
3.3.21 CreateatestclientforRedBlackBST,basedonyoursolutiontoExercise3.2.10.
3.3.22 FindasequenceofkeystoinsertintoaBSTandintoared-blackBSTsuchthat the height of the BST is less than the height of the red-black BST, or prove that no such sequence is possible.
www.it-ebooks.info

3.3.23 2-3 trees without balance restriction. Develop an implementation of the basic symbol-table API that uses 2-3 trees that are not necessarily balanced as the underlying data structure. Allow 3-nodes to lean either way. Hook the new node onto the bottom with a black link when inserting into a 3-node at the bottom. Run experiments to de- velop a hypothesis estimating the average path length in a tree built from N random insertions.
3.3.24 Worst case for red-black BSTs. Show how to construct a red-black BST dem- onstrating that, in the worst case, almost all the paths from the root to a null link in a red-black BST of N nodes are of length 2 lg N.
3.3.25 Top-down 2-3-4 trees. Develop an implementation of the basic symbol-table API that uses balanced 2-3-4 trees as the underlying data structure, using the red-black representation and the insertion method described in the text, where 4-nodes are split by  ipping colors on the way down the search path and balancing on the way up.
3.3.26 Single top-down pass. Develop a modi ed version of your solution to Exer- cise 3.3.25 that does not use recursion. Complete all the work splitting and balancing 4-nodes (and balancing 3-nodes) on the way down the tree,  nishing with an insertion at the bottom.
3.3.27 Allow right-leaning red links. Develop a modi ed version of your solution to Exercise 3.3.25 that allows right-leaning red links in the tree.
3.3.28 Bottom-up 2-3-4 trees. Develop an implementation of the basic symbol-table API that uses balanced 2-3-4 trees as the underlying data structure, using the red-black representation and a bottom-up insertion method based on the same recursive approach as Algorithm 3.4. Your insertion method should split only the sequence of 4-nodes (if any) on the bottom of the search path.
3.3.29 Optimal storage. Modify RedBlackBST so that it does not use any extra storage for the color bit, based on the following trick: To color a node red, swap its two links. Then, to test whether a node is red, test whether its left child is larger than its right child. You have to modify the compares to accommodate the possible link swap, and this trick replaces bit compares with key compares that are presumably more expensive, but it shows that the bit in the nodes can be eliminated, if necessary.
3.3.30 Sofware caching. Modify RedBlackBST to keep the most recently accessed Node in an instance variable so that it can be accessed in constant time if the next put() or
www.it-ebooks.info
3.3 n Balanced Search Trees 451
 crEAtivE problEms

452 Chapter 3 n Searching
  get() uses the same key (see Exercise 3.1.25).
3.3.31 Tree drawing. Add a method draw() to RedBlackBST that draws red-black
BST  gures in the style of the text (see Exercise 3.2.38)
3.3.32 AVL trees. An AVL tree is a BST where the height of every node and that of its sibling differ by at most 1. (The oldest balanced tree algorithms are based on using rotations to maintain height balance in AVL trees.) Show that coloring red links that go from nodes of even height to nodes of odd height in an AVL tree gives a (perfectly balanced) 2-3-4 tree, where red links are not necessarily left-leaning. Extra credit : De- velop an implementation of the symbol-table API that uses this as the underlying data structure. One approach is to keep a height  eld in each node, using rotations after the recursive calls to adjust the height as necessary; another is to use the red-black represen- tation and use methods like moveRedLeft() and moveRedRight() in Exercise 3.3.39 and Exercise 3.3.40.
3.3.33 Certi cation. Add to RedBlackBST a method is23() to check that no node is connected to two red links and that there are no right-leaning red links and a method isBalanced() to check that all paths from the root to a null link have the same number of black links. Combine these methods with code from isBST() in Exercise 3.2.31 to create a method isRedBlackBST() that checks that the tree is a red-black BST.
3.3.34 All 2-3 trees. Write code to generate all structurally different 2-3 trees of height 2, 3, and 4. There are 2, 7, and 122 such trees, respectively. (Hint : Use a symbol table.)
3.3.35 2-3 trees. Write a program TwoThreeST.java that uses two node types to im- plement 2-3 search trees directly.
3.3.36 2-3-4-5-6-7-8 trees. Describe algorithms for search and insertion in balanced 2-3-4-5-6-7-8 search trees.
3.3.37 Memoryless. Show that red-black BSTs are not memoryless: for example, if you insert a key that is smaller than all the keys in the tree and then immediately delete the minimum, you may get a different tree.
3.3.38 Fundamental theorem of rotations. Show that any BST can be transformed into any other BST on the same set of keys by a sequence of left and right rotations.
www.it-ebooks.info
 crEAtivE problEms (continued)
3.3.39 Delete the minimum. Implement the deleteMin() operation for red-black BSTs by maintaining the correspondence with the transformations given in the text for moving down the left spine of the tree while maintaining the invariant that the current node is not a 2-node.
Solution:
private Node moveRedLeft(Node h)
{  // Assuming that h is red and both h.left and h.left.left
   // are black, make h.left or one of its children red.
   flipColors(h);
   if (isRed(h.right.left))
   {
      h.right = rotateRight(h.right);
      h = rotateLeft(h);
   }
return h; }
public void deleteMin()
{
   if (!isRed(root.left) && !isRed(root.right))
      root.color = RED;
   root = deleteMin(root);
   if (!isEmpty()) root.color = BLACK;
}
private Node deleteMin(Node h)
{
   if (h.left == null)
      return null;
   if (!isRed(h.left) && !isRed(h.left.left))
      h = moveRedLeft(h);
   h.left = deleteMin(h.left);
   return balance(h);
}
This code assumes a balance() method that consists of the line of code if (isRed(h.right)) h = rotateLeft(h);
www.it-ebooks.info
3.3 n Balanced Search Trees 453

454 Chapter 3 n Searching
  followed by the last  ve lines of the recursive put() in Algorithm 3.4 and a flipColors() implementation that complements the three colors, instead of the method given in the text for insertion. For deletion, we set the parent to BLACK and the two children to RED.
3.3.40 Delete the maximum. Implement the deleteMax() operation for red-black BSTs. Note that the transformations involved differ slightly from those in the previous exercise because red links are left-leaning.
Solution:
}
       public void deleteMax()
       {
          if (!isRed(root.left) && !isRed(root.right))
             root.color = RED;
          root = deleteMax(root);
          if (!isEmpty()) root.color = BLACK;
       }
       private Node deleteMax(Node h)
       {
          if (isRed(h.left))
              h = rotateRight(h);
          if (h.right == null)
             return null;
          if (!isRed(h.right) && !isRed(h.right.left))
             h = moveRedRight(h);
          h.right = deleteMax(h.right);
          return balance(h);
       }
private Node moveRedRight(Node h)
{  // Assuming that h is red and both h.right and h.right.left
   // are black, make h.right or one of its children red.
   flipColors(h)
   if (isRed(h.left.left))
      h = rotateRight(h);
   return h;
www.it-ebooks.info
 crEAtivE problEms (continued)
3.3.41 Delete. Implement the delete() operation for red-black BSTs, combining the methods of the previous two exercises with the delete() operation for BSTs.
Solution :
public void delete(Key key)
{
   if (!isRed(root.left) && !isRed(root.right))
      root.color = RED;
   root = delete(root, key);
   if (!isEmpty()) root.color = BLACK;
}
private Node delete(Node h, Key key)
{
   if (key.compareTo(h.key) < 0)
   {
      if (!isRed(h.left) && !isRed(h.left.left))
         h = moveRedLeft(h);
      h.left =  delete(h.left, key);
   }
else {
      if (isRed(h.left))
         h = rotateRight(h);
      if (key.compareTo(h.key) == 0 && (h.right == null))
         return null;
      if (!isRed(h.right) && !isRed(h.right.left))
         h = moveRedRight(h);
      if (key.compareTo(h.key) == 0)
      {
         Node x = min(h.right);
         h.key = x.key;
         h.val = x.val;
         h.right = deleteMin(h.right);
}
      else h.right = delete(h.right, key);
   }
   return balance(h);
}
www.it-ebooks.info
3.3 n Balanced Search Trees 455

 456
Chapter 3 n Searching ExpErimENts
3.3.42 Count red nodes. Write a program that computes the percentage of red nodes in a given red-black BST. Test your program by running at least 100 trials of the experi- ment of inserting N random keys into an initially empty tree, for N = 10 4, 10 5, and 10 6, and formulate an hypothesis.
3.3.43 Cost plots. Instrument RedBlackBST so that you can produce plots like the ones in this section showing the cost of each put() operation during the computation (see Exercise 3.1.38).
3.3.44 Average search time. Run empirical studies to compute the average and stan- dard deviation of the average length of a path to a random node (internal path length divided by tree size, plus 1) in a red-black BST built by insertion of N random keys into an initially empty tree, for N from 1 to 10,000. Do at least 1,000 trials for each tree size. Plot the results in a Tufte plot, like the one at the bottom of this page,  t with a curve plotting the function lg N – .5.
3.3.45 Count rotations. Instrument your program for Exercise 3.3.43 to plot the number of rotations and node splits that are used to build the trees. Discuss the results.
3.3.46 Height. Instrument your program for Exercise 3.3.43 to plot the height of red-black BSTs. Discuss the results.
20
0
number of keys N
100
10000
Average path length to a random node in a red-black BST built from random keys
www.it-ebooks.info
lg N − .5
13
compares
This page intentionally left blank
www.it-ebooks.info

     b
pqr
  458
If keys are small integers, we can use an array to implement an unordered symbol table, by interpreting the key as an array index so that we can store the value associated with key i in array entry i, ready for immediate access. In this section, we consider hashing, an extension of this simple method that handles more complicated types of keys. We reference key-value pairs using arrays by doing arithmetic operations to transform keys into array indices.
Search algorithms that use hashing consist of two separate parts. The  rst part is to compute a hash function that transforms the search key into an array index. Ide- ally, different keys would map to different indices. This ideal is generally beyond our reach, so we have to face the possibility that two or more different keys may hash to the same array index. Thus, the second part of a hashing search is a collision- resolution process that deals with this situation. After describ- ing ways to compute hash functions, we shall consider two dif- ferent approaches to collision resolution: separate chaining and
key hash value a 2 xyz b 0 pqr c 3 ijk d 2 uvw
collision
M-1
Hashing: the crux of the problem
0 1 2
3
linear probing.
Hashing is a classic example of a time-space tradeoff. If there
were no memory limitation, then we could do any search with only one memory access by simply using the key as an index in a (potentially huge) array. This ideal often cannot be achieved, however, because the amount of memory required is prohibi- tive when the number of possible key values is huge. On the other hand, if there were no time limitation, then we can get by with only a minimum amount of memory by using sequential search in an unordered array. Hashing provides a way to use a reasonable amount of both memory and time to strike a bal-
 a
d
xyz uvw
    c
ijk
  . .
 ance between these two extremes. Indeed, it turns out that we can trade off time and memory in hashing algorithms by adjusting parameters, not by rewriting code. To help choose values of the parameters, we use classical results from probability theory.
Probability theory is a triumph of mathematical analysis that is beyond the scope of this book, but the hashing algorithms we consider that take advantage of the knowl- edge gained from that theory are quite simple, and widely used. With hashing, you can implement search and insert for symbol tables that require constant (amortized) time per operation in typical applications, making it the method of choice for implementing basic symbol tables in many situations.
www.it-ebooks.info
 3.4 hASh tABleS

 Hash functions The  rst problem that we face is the computation of the hash function, which transforms keys into array indices. If we have an array that can hold M key-value pairs, then we need a hash function that can transform any given key into an index into that array: an integer in the range [0, M – 1]. We seek a hash function that both is easy to compute and uniformly distributes the keys: for each key, every integer between 0 and M–1 should be equally likely (independently for every
key). This ideal is somewhat mysterious; to understand hashing, we be- gin by thinking carefully about how to implement such a function.
In principle, any key can be represented as a sequence of bits, so we might design a generic hash function that maps sequences of bits to in- tegers in the desired range. In practice, programmers implement hash functions based on higher-level representations. For example, if the key involves a number, such as a social security number, we could start with that number; if the key involves a string, such as a person’s name, we need to convert the string into a number; and if the key has multiple parts, such as a mailing address, we need to combine the parts somehow. For many common types of keys, we can make use of default implementa- tions provided by Java. We brie y discuss potential implementations for various types of keys so that you can see what is involved because you do need to provide implementations for key types that you create.
key hash (M = 100)
hash (M = 97)
  18
  36
  11
  67
  23
  25
  30
  24
  93
  25
  35
  68
  26
  34
  22
  13
  35
  81
  25
  27
  25
  22
  30
  19
Typical example Suppose that we have an application where the keys
are U.S. social security numbers. A social security number such as 123-45-6789 is a nine-digit number divided into three  elds. The  rst
 eld identi es the geographical area where the number was issued (for
example, social security numbers whose  rst  eld is 035 are from Rhode
Island and numbers whose  rst  eld is 214 are from Maryland) and the
other two  elds identify the individual. There are a billion (109) different
social security numbers, but suppose that our application will need to
process just a few hundred keys, so that we could use a hash table of size
M = 1,000. One possible approach to implementing a hash function is to
use three digits from the key. Using three digits from the third  eld is likely to be pref- erable to using the three digits in the  rst  eld (since customers may not be uniformly dispersed over geographic areas), but a better approach is to use all nine digits to make an int value, then consider hash functions for integers, described next.
Modular hashing
Positive integers The most commonly used method for hashing integers is called modular hashing : we choose the array size M to be prime and, for any positive inte- ger key k, compute the remainder when dividing k by M. This function is very easy to compute (k % M, in Java) and is effective in dispersing the keys evenly between 0 and
www.it-ebooks.info
3.4 n Hash Tables
459
212 12 618 18 302 2 940 40 702 2 704 4 612 12 606 6 772 72 510 10 423 23 650 50 317 17 907 7 507 7 304 4 714 14 857 57 801 1 900 0 413 13 701 1 418 18 601 1

460 Chapter 3 n Searching
M – 1. If M is not prime, it may be the case that not all of the bits of the key play a role, which amounts to missing an opportunity to disperse the values evenly. For example, if the keys are base-10 numbers and M is 10 k, then only the k least signi cant digits are used. As a simple example where such a choice might be problematic, suppose that the keys are telephone area codes and M = 100. For historical reasons, most area codes in the United States have middle digit 0 or 1, so this choice strongly favors the values less than 20, where the use of the prime value 97 better disperses them (a prime value not close to 100 would do even better). Similarly, IP addresses that are used in the internet are binary numbers that are not random for similar historical reasons as for telephone area codes, so we need to use a table size that is a prime (in particular, not a power of 2) if we want to use modular hashing to disperse them.
Floating-point numbers If the keys are real numbers between 0 and 1, we might just multiply by M and round off to the nearest integer to get an index between 0 and M – 1. Although this approach is intuitive, it is defective because it gives more weight to the most signi cant bits of the keys; the least signi cant bits play no role. One way to ad- dress this situation is to use modular hashing on the binary representation of the key (this is what Java does).
Strings Modular hashing works for long keys such as strings, too: we simply treat them as huge integers. For example, the code at left computes a modular hash func- tion for a String s: recall that charAt() returns a char value in Java, which is a 16-bit nonnegative integer. If R is greater than any character value, this computation would
be equivalent to treating the String as an N-digit base-R integer, computing the remainder that results when dividing that number by M. A classic algorithm known as Horner’s method gets the job done with N multiplications, additions, and remain- der operations. If the value of R is suf -
ciently small that no over ow occurs, the result is an integer between 0 and M – 1, as desired. The use of a small prime integer such as 31 ensures that the bits of all the characters play a role. Java’s default implementation for String uses a method like this.
Compound keys If the key type has multiple integer  elds, we can typically mix them together in the way just described for String values. For example, suppose that search keys are of type Date, which has three integer  elds: day (two-digit day), month (two- digit month), and year (four-digit year).We compute the number
    int hash = (((day * R + month) % M ) * R + year) % M;
   int hash = 0;
  for (int i = 0; i < s.length(); i++)
     hash = (R * hash + s.charAt(i)) % M;
hashing a string key
 www.it-ebooks.info

which, if the value of R is suf ciently small that no over ow occurs, is an integer be- tween0andM–1,asdesired.Inthiscase,wecouldsavethecostoftheinner% Mopera- tion by choosing a moderate prime value such as 31 for R. As with strings, this method generalizes to handle any number of  elds.
Java conventions Java helps us address the basic problem that every type of data needs a hash function by ensuring that every data type inherits a method called hashCode() that returns a 32-bit integer. The implementation of hashCode() for a data type must be consistent with equals. That is, if a.equals(b) is true, then a.hashCode() must have the same numerical value as b.hashCode(). Conversely, if the hashCode() values are different, then we know that the objects are not equal. If the hashCode() values are the same, the objects may or may not be equal, and we must use equals() to decide which condition holds. This convention is a basic requirement for clients to be able to use hashCode() for symbol tables. Note that it implies that you must override both hashCode() and equals() if you need to hash with a user-de ned type. The default implementation returns the machine address of the key object, which is seldom what you want. Java provides hashCode() implementations that override the defaults for many common types (including String, Integer, Double, File, and URL).
Converting a hashCode() to an array index Since our goal is an array index, not a 32-bit integer, we combine hashCode() with modular hashing in our implementations to produce integers between 0 and M – 1, as follows:
    private int hash(Key x)
    {  return (x.hashCode() & 0x7fffffff) % M;  }
This code masks off the sign bit (to turn the 32-bit number into a 31-bit nonnegative integer) and then computes the remainder when dividing by M, as in modular hashing. Programmers commonly use a prime number for the hash table size M when using code like this, to attempt to make use of all the
bits of the hash code. Note: To avoid con- fusion, we omit all of these calculations in our hashing examples and use instead the hash values in the table at right.
key SEARCHXMPL hash (M = 5) 2 0 0 4 4 4 2 4 3 3
User-de ned hashCode() Client code expects that hashCode() disperses the keys uniformly among the possible 32-bit result values. That is, for any object x, you can write x.hashCode() and, in principle, expect to get any one of the 232 possible 32-bit values with equal likelihood. Java’s hashCode() implementations for String, Integer, Double, File, and URL aspire to this functionality; for your own type, you have to try to do it on your own. The Date example that we considered on page 460 illustrates
www.it-ebooks.info
hash (M = 16) 6 10 4 14 5 4 15 Hash values for keys in examples
1 14 6
3.4 n Hash Tables 461

462 Chapter 3
n Searching
one way to proceed: make integers from the instance variables and use modular hashing. In Java, the convention that all data types inherit a hashCode() method enables an even simpler approach: use the hashCode() method for the instance vari- ables to convert each to a 32-bit int value and then do the arithmetic, as illustrated at left for Transaction. For primitive- type instance variables, note that a cast to a wrapper type is necessary to access the hashCode() method. Again, the precise values of the multiplier (31 in our exam- ple) is not particularly important.
Software caching If computing the hash
code is expensive, it may be worthwhile to cache the hash for each key. That is, we maintain an instance variable hash in the key type that contains the value of hashCode() for each key object (see Exercise 3.4.25). On the  rst call to hashCode(), we have to compute the full hash code (and set the val- ue of hash), but subsequent calls on hashCode() simply return the value of hash. Java
uses this technique to reduce the cost of computing hashCode() for String objects.
In summary, we have three primary requirements in implementing a good hash function for a given data type:
n It should be consistent—equal keys must produce the same hash value. n It should be ef cient to compute.
n It should uniformly distribute the set of keys.
Satisfying these requirements simultaneously in Java is a job for experts. As with many built-in capabilities, Java programmers who use hashing assume that hashCode() does the job, absent any evidence to the contrary.
Still, you should be vigilant whenever using hashing in situations where good perfor- mance is critical, because a bad hash function is a classic example of a performance bug: everything will work properly, but much more slowly than expected. Perhaps the easiest way to ensure uniformity is to make sure that all the bits of the key play an equal role in computing every hash value; perhaps the most common mistake in implementing hash functions is to ignore signi cant numbers of the key bits. Whatever the implementa- tion, it is wise to test any hash function that you use, when performance is important. Which takes more time: computing a hash function or comparing two keys? Does your
   public class Transaction
  {
     ...
     private final String who;
     private final Date when;
     private final double amount;
     public int hashCode()
     {
         int hash = 17;
         hash = 31 * hash + who.hashCode();
         hash = 31 * hash + when.hashCode();
         hash = 31 * hash
             + ((Double) amount).hashCode();
         return hash;
}
... }
Implementing hashCode() in a user-defined type
 www.it-ebooks.info

110   10679/97
0 key value 96 Hash value frequencies for words in Tale of Two Cities (10,679 keys, M = 97)
hash function spread a typical set of keys uniformly among the values between 0 and M – 1? Doing simple experiments that answer these questions can protect future clients from unfortunate surprises. For example, the histogram above shows that our hash() implementation using the hashCode() from Java’s String data type produces a rea- sonable dispersion of the words for our Tale of Two Cities example.
Underlying this discussion is a fundamental assumption that we make when using hashing; it is an idealized model that we do not actually expect to achieve, but it guides our thinking when implementing hashing algorithms and facilitates their analyses:
3.4 n Hash Tables 463
   Assumption J (uniform hashing assumption). The hash functions that we use uni- formly and independently distribute keys among the integer values between 0 and M–1.
Discussion: Withallofthearbitrarychoiceswehavemade,theJavahashfunctions that we have considered do not satisfy these conditions; nor can any deterministic hash function. The idea of constructing hash functions that uniformly and inde- pendently distribute keys leads to deep issues in theoretical computer science. In 1977, L. Carter and M. Wegman described how to construct a universal family of hash functions. If a hash function is chosen at random from a universal family, the hash function uniformly distributes the keys, but only with partial independence. Although weaker than full independence, the partial independence is suf cient to establish performance guarantees similar to those stated in Propositions K and M.
Assumption J is a useful way to think about hashing for two primary reasons. First, it is a worthy goal when designing hash functions that guides us away from making arbitrary decisions that might lead to an excessive number of collisions. Second, we will use it to develop hypotheses about the performance of hashing algorithms—even when hash functions are not known to satisfy Assumption J, we can perform computational experiments and validate that they achieve the predicted performance.
www.it-ebooks.info
 frequency
464 Chapter 3 n Searching
key hash value S20
E01
A02
R43
C 4 4 0
H 45 1 E 06 23
X 27 4 A08 M49
P 3 10
L 3 11 E 0 12
st
independent
SequentialSearchST
objects
One way to proceed is to ex- pand SequentialSearchST (Al- gorithm 3.1) to implement sep- arate chaining using linked-list primitives (see Exercise 3.4.2). A simpler (though slightly less ef cient) way to proceed is to adopt a more general approach: we build, for each of the M ar- ray indices, a symbol table of the keys that hash to that index, thus reusing code that we have already developed. The implementa- tion SeparateChainingHashST in Algorithm 3.5 maintains an array of SequentialSearchST objects and implements get() and put() by computing a hash function to choose which
Hashing with separate chaining A hash function converts keys into array in- dices. The second component of a hashing algorithm is collision resolution: a strategy for handling the case when two or more keys to be inserted hash to the same index. A straightforward and general approach to collision resolution is to build, for each of the M array indices, a linked list of the key-value pairs whose keys hash to that index. This method is known as separate chaining because items that collide are chained together in separate linked lists. The basic idea is to choose M to be suf ciently large that the lists are suf ciently short to enable ef cient search through a two-step process: hash to  nd the list that could contain the key, then sequentially search through that list for the key.
 first
     A
8
E
12
      first
null
        first
        X
7
S
0
       first
       L
11
Hashing with separate chaining for standard indexing client
P
10
   first
          M
9
H
5
C
4
SequentialSearchST object can contain the key and then using get() and put() (re- spectively) from SequentialSearchST to complete the job.
Since we have M lists and N keys, the average length of the lists is always N  M, no matter how the keys are distributed among the lists. For example, suppose that all the items fall onto the  rst list—the average length of the lists is (N + 0 + 0 + 0 +. . . + 0)/M = N  M. However the keys are distributed on the lists, the sum of the list lengths is N and the average is N  M. Separate chaining is useful in practice because each list is extremely likely to have about N  M key-value pairs. In typical situations, we can verify this con- sequence of Assumption J and count on fast search and insert.
www.it-ebooks.info
R
3

  aLgorIthM 3.5 hashing with separate chaining
  public class SeparateChainingHashST<Key, Value>
  {
     private int M;                                // hash table size
     private SequentialSearchST<Key, Value>[] st;  // array of ST objects
     public SeparateChainingHashST()
     {  this(997);  }
     public SeparateChainingHashST(int M)
     {  // Create M linked lists.
        this.M = M;
        st = (SequentialSearchST<Key, Value>[]) new SequentialSearchST[M];
        for (int i = 0; i < M; i++)
           st[i] = new SequentialSearchST();
     }
     private int hash(Key key)
     {  return (key.hashCode() & 0x7fffffff) % M; }
     public Value get(Key key)
     {  return (Value) st[hash(key)].get(key);  }
     public void put(Key key, Value val)
     {  st[hash(key)].put(key, val);  }
     public Iterable<Key> keys()
     // See Exercise 3.4.19.
}
This basic symbol-table implementation maintains an array of linked lists, using a hash function to choose a list for each key. For simplicity, we use SequentialSearchST methods. We need a cast when creating st[] because Java prohibits arrays with generics. The default constructor speci es 997 lists, so that for large tables, this code is about a factor of 1,000 faster than SequentialSearchST. This quick solution is an easy way to get good performance when you have some idea of the number of key-value pairs to be put() by a client. A more robust solution is to use array resizing to make sure that the lists are short no matter how many key-value pairs are in the table (sepeage 474 and Exercise 3.4.18).
  www.it-ebooks.info
3.4 n Hash Tables 465
466 Chapter 3 n Searching
 propositionk. Inaseparate-chaininghashtablewithMlistsandNkeys,theprob- ability (under Assumption J) that the number of keys in a list is within a small constant factor of N/M is extremely close to 1.
proof sketch: Assumption J makes this an application of classical probability theory. We sketch the proof, for readers who are familiar with basic probabilistic analysis. The probability that a given list will contain exactly k keys is given by the binomial distribution
by the following argument: Choose k out of the N keys. Those k keys hash to the given list with probability 1  M, and the other N – k keys do not hash to the given list with probability 1 – (1  M ). In terms of a  N  M, we can rewrite this expres- sion as
 (10, .12511...)
.125
   0 0 10 20 30
Binomial distribution (N = 104, M = 103,   = 10)
     
k N− k Nk    
   Nk    k  1 −    N − k
 which (for small a) is closely approximated by the classical Poisson distribution
It follows that the probability that a list has more than t a keys on it is bounded by the quantity (a e/t)t e –a. This probability is extremely small for practical ranges of the parameters. For example, if the average length of the lists is 10, the prob- ability that we will hash to some list with more than 20 keys on it is less than (10 e/2)2 e –10  0.0084, and if the average length of the lists is 20, the probability that we will hash to some list with more than 40 keys on it is less than (20 e/2)2e–20  0.0000016. This concentration result does not guarantee that every list will be short. Indeed it is known that, if a is a constant, the average length of the longest list grows with log N / log log N.
 (10, .12572...)
.125
   0 0 10 20 30
Poisson distribution (N = 104, M = 103,   = 10)
      www.it-ebooks.info
 1 M− 1 MM
ke − k!

NN
This classical mathematical analysis is compelling, but it is important to note that it completely depends on Assumption J. If the hash function is not uniform and inde- pendent, the search and insert cost could be proportional to N, no better than with sequential search. Assumption J is much stronger than the corresponding assumption for other probabilistic algorithms that we have seen, and much more dif cult to verify. With hashing, we are assuming that each and every key, no matter how complex, is equally likely to be hashed to one of M indices. We cannot afford to run experiments to test every possible key, so we would have to do more sophisticated experiments in- volving random sampling from the set of possible keys used in an application, followed by statistical analysis. Better still, we can use the algorithm itself as part of the test, to validate both Assumption J and the mathematical results that we derive from it.
Table size In a separate-chaining implementation, our goal is to choose the table size M to be suf ciently small that we do not waste a huge area of contiguous memory with empty chains but suf ciently large that we do not waste time searching through long chains. One of the virtues of separate chaining is that this decision is not critical: if more keys arrive than expected, then searches will take a little longer than if we had chosen a bigger table size ahead of time; if fewer keys are in the table, then we have ex- tra-fast search with some wasted space. When space is not a critical resource, M can be chosen suf ciently large that search time is constant; when space is a critical resource, we still can get a factor of M improvement in performance by choosing M to be as
www.it-ebooks.info
3.4 n Hash Tables 467
 propertyl. Inaseparate-chaininghashtablewithMlistsandNkeys,thenumber of compares (equality tests) for search miss and insert is ~N/M.
Evidence: Countlessprogrammerssincethe1950shaveseenthespeedupsforsep- arate-chaining hash tables predicted by Proposition K, even for hash functions that clearly do not satisfy Assumption J. For example, the diagram on page 468 shows that list length distribution for our FrequencyCounter example (using our hash() implementation based on the hashCode() from Java’s String data type) precisely matches the theoretical model. One exception that has been documented on numerous occasions is poor performance due to hash functions not taking all of the bits of the keys into account. Otherwise, the preponderance of the evidence from the experience of practical programmers puts us on solid ground in stating that hashing with separate chaining using an array of size M speeds up search and insert in a symbol table by a factor of M.

 468 Chapter 3 n Searching 125
  = 10.711...)
 ke −  k!
0
0 10 20 30
list lengths (10,679 keys, M = 997)
List lengths for java FrequencyCounter 8 < tale.txt using SeparateChainingHashST
large as we can afford. For our example FrequencyCounter study, we see in the  gure below a reduction in the average cost from thousands of compares per operation for SequentialSearchST to a small constant for SeparateChainingHashST, as expected. Another option is to use array resizing to keep the lists short (see Exercise 3.4.18).
Deletion To delete a key-value pair, simply hash to  nd the SequentialSearchST containing the key, then invoke the delete() method for that table (see Exercise 3.1.5). Reusing code in this way is preferable to reimplementing this basic operation on linked lists.
Ordered operations The whole point of hashing is to uniformly disperse the keys, so any order in the keys is lost when hashing. If you need to quickly  nd the maximum or minimum key,  nd keys in a given range, or implement any of the other operations in the ordered symbol-table API onpage 366, then hashing is not appropriate, since these operations will all take linear time.
Hashing with separate chaining is easy to implement and probably the fastest (and most widely used) symbol-table implementation for applications where key order is not important. When your keys are built-in Java types or your own type with well- tested implementations of hashCode(), Algorithm 3.5 provides a quick and easy path to fast search and insert. Next, we consider an alternative scheme for collision resolu- tion that is also effective.
10
0
cumulative average
equality tests
frequency
0
operations
14350
Costs for java FrequencyCounter 8 < tale.txt using SeparateChainingHashST (M = 997)
www.it-ebooks.info
3.9
Hashing with linear probing Another approach to implementing hashing is to store N key-value pairs in a hash table of size M > N, relying on empty entries in the table to help with collision resolution. Such methods are called open-addressing hashing methods.
The simplest open-addressing method is called linear probing: when there is a colli- sion (when we hash to a table index that is already occupied with a key different from the search key), then we just check the next entry in the table (by incrementing the index). Linear probing is characterized by identifying three possible outcomes:
n Key equal to search key: search hit
n Empty position (null key at indexed position): search miss n Key not equal to search key: try next entry
We hash the key to a table index, check whether the search key matches the key there, and continue (incrementing the index, wrapping back to the beginning of the table if we reach the end) until  nding either the search key or an empty table entry. It is customary to refer to the operation of determining whether or not a given table entry
key hash value S60
E 10 1 A42 R 14 3 C54 H45 E 10 6 X 15 7 A48 M19 P 14 10 L 6 11 E 10 12
entries in red are new
keys in black are probes
6 7 8 9 10 11 12 13 14 15
S
0
S E 0 1
A 201
0 1 2 3 4 5
3.4 n Hash Tables 469
  entries in gray are untouched
 S E ASER
   2013 ACSER
24013 ACSHER
240513 ACSHER
240563 ACSH E RX
2405 6 37 ACSH E RX
        8405 6 37 M ACSH E RX
9 8405 6 37 PMACSHERX
10 9 8 4 0 5 6 3 7 PMACSHLERX
10 9 8 4 0 5 11 6 3 7
probe sequence wraps to 0
    PM ACSHL E RX   keys[]
   10 9 8 4 0 5 11 12 3 7 Trace of linear-probing ST implementation for standard indexing client
vals[]
 www.it-ebooks.info

 470 Chapter 3 n Searching
 aLgorIthM 3.6 hashing with linear probing
public class LinearProbingHashST<Key, Value>
{
 private int N;
private int M = 16;
private Key[] keys;
private Value[] vals;  // the values
// number of key-value pairs in the table
// size of linear-probing table
// the keys
public LinearProbingHashST()
{
   keys = (Key[])   new Object[M];
   vals = (Value[]) new Object[M];
}
private int hash(Key key)
{  return (key.hashCode() & 0x7fffffff) % M; }
private void resize()        // See page 474.
public void put(Key key, Value val)
{
   if (N >= M/2) resize(2*M);  // double M (see text)
   int i;
   for (i = hash(key); keys[i] != null; i = (i + 1) % M)
      if (keys[i].equals(key)) { vals[i] = val; return; }
   keys[i] = key;
   vals[i] = val;
   N++;
}
     public Value get(Key key)
     {
        for (int i = hash(key); keys[i] != null; i = (i + 1) % M)
           if (keys[i].equals(key))
               return vals[i];
        return null;
} }
This symbol-table implementation keeps keys and values in parallel arrays (as in BinarySearchST) but uses empty spaces (marked by null) to terminate clusters of keys. If a new key hashes to an empty entry, it is stored there; if not, we scan sequentially to  nd an empty position. To search for a key, we scan sequentially starting at its hash index until  nding null (search miss) or the key (search hit). Implementation of keys() is left as Exercise 3.4.19.
 www.it-ebooks.info
 holds an item whose key is equal to the search key as a probe. We use the term inter- changeably with the term compare that we have been using, even though some probes are tests for null.
The essential idea behind hashing with open addressing is this: rather than using mem- ory space for references in linked lists, we use it for the empty entries in the hash table, which mark the ends of probe sequences. As you can see from LinearProbingHashST (Algorithm 3.6), applying this idea to implement the symbol-table API is quite straightforward. We implement the table with parallel arrays, one for the keys and one for the values, and use the hash function as an index to access the data as just discussed.
Deletion How do we delete a key-value pair from a linear-probing table? If you think about the situation for a moment, you will see that setting the key’s table position to null will not work, because that might prematurely terminate the search for a key that was inserted into the table later. As an example, sup-
pose that we try to delete C in this way in our trace example, then search for H. The hash value for H is 4, but it sits at the end of the cluster, in position 7. If we set position 5 to null, then get() will not  nd H. As a consequence, we need to reinsert into the table all of the keys in the cluster to the right of the deleted key. This process is trickier than it might seem, so you are encouraged to trace through the code at right (see Exercise 3.4.17).
As with separate chaining, the performance of
hashing with open addressing depends on the ratio
a  N  M, but we interpret it differently. We re-
fer to a as the load factor of a hash table. For sepa-
rate chaining, a is the average number of keys per
list and is often larger than 1; for linear probing, a
is the percentage of table entries that are occupied;
it cannot be greater than 1. In fact, we cannot let
the load factor reach 1 (completely full table) in
LinearProbingHashST because a search miss would
go into an in nite loop in a full table. Indeed, for the
sake of good performance, we use array resizing to guarantee that the load factor is between one-eighth and one-half. This strategy is validated by mathematical analysis, which we consider before we discuss implementation details.
3.4 n Hash Tables 471
   public void delete(Key key)
  {
     if (!contains(key)) return;
     int i = hash(key);
     while (!key.equals(keys[i]))
        i = (i + 1) % M;
     keys[i] = null;
     vals[i] = null;
     i = (i + 1) % M;
     while (keys[i] != null)
     {
        Key   keyToRedo = keys[i];
        Value valToRedo = vals[i];
        keys[i] = null;
        vals[i] = null;
        N--;
        put(keyToRedo, valToRedo);
        i = (i + 1) % M;
     }
     N--;
     if (N > 0 && N == M/8)
        resize(M/2);
  }
Deletion for linear probing
 www.it-ebooks.info

 472
Chapter 3 n Searching
before
after
Clustering The average cost of linear probing depends on the way in which the entries clump together into contiguous groups of occupied table entries, called clusters, when they are inserted. For example, when the key C is inserted in our example, the result is a cluster ( A C S ) of length 3, which means that four probes are needed to insert H because H hashes to the  rst position in the cluster. Short clusters are certainly a requirement for ef cient perfor- mance. This requirement can be problematic as the table  lls, because long clusters are common. Moreover, since all table positions are equally likely to be the hash value of the next key to be inserted (under the uniform hash- ing assumption), long clusters are more likely to increase in length than short ones, because a new key hashing to any entry in the cluster will cause the cluster to increase in length by 1 (and possibly much more, if there is just one table entry separating the cluster from the next one). Next, we turn to the challenge of quantifying the effect of clustering to predict performance in linear probing, and using that knowledge to set
9/64 chance of new key hitting this cluster
key lands here in that event
and forms a much longer cluster
Clustering in linear probing (M = 64)
design parameters in our implementations.
  = 1/2
  = 1/4
keys[0..127]
linear probing
long clusters are common
random
Table occupancy patterns (2,048 keys, tables laid out in 128-position rows)
www.it-ebooks.info
keys[8064..8192]
Analysis of linear probing Despite the relatively simple form of the results, precise analysis of linear probing is a very challenging task. Knuth’s derivation of the following formulas in 1962 was a landmark in the analysis of algorithms:
3.4 n Hash Tables 473
 proposition m. In a linear-probing hash table of size M and N = a M keys, the average number of probes (under Assumption J) required is
~ 1 + and ~ 1 + 
for search hits and search misses (or inserts), respectively. In particular, when a is about 1/2, the average number of probes for a search hit is about 3/2 and for a search miss is about 5/2. These estimates lose a bit of precision as a approaches 1, but we do not need them for that case, because we will only use linear probing for a less than one-half.
Discussion: Wecomputetheaveragebycomputingthecostofasearchmissstart- ing at each position in the table, then dividing the total by M. All search misses take at least 1 probe, so we count the number of probes after the  rst. Consider the following two extremes in a linear-probing table that is half full (M = 2N): In the best case, table positions with even indices could be empty, and table positions with odd indices could be occupied. In the worst case, the  rst half of the table positions could be empty, and the second half occupied. The average length of the clusters in both cases is N/(2N) = 1/2, but the average number of probes for a search miss is1(allsearchestakeatleast1probe)plus(0+1+0+1+. . .)/(2N)=1/2inthe bestcase,andis1plus(N+(N–1) +...) (2N)~N/4intheworstcase.This argument generalizes to show that the average number of probes for a search miss is proportional to the squares of the lengths of the clusters: If a cluster is of length t, then the expression (t + (t – 1) + . . . + 2 + 1) / M = t(t + 1)/(2M) counts the con- tribution of that cluster to the grand total. The sum of the cluster lengths is N, so, adding this cost for all entries in the table, we  nd that the total average cost for a search miss is 1 + N  (2M) plus the sum of the squares of the lengths of the clusters, divided by 2M. Thus, given a table, we can quickly compute the average cost of a search miss in that table (see Exercise 3.4.21). In general, the clusters are formed by a complicated dynamic process (the linear-probing algorithm) that is dif cult to characterize analytically, and quite beyond the scope of this book.
    www.it-ebooks.info
 1111
2 1 −  2 (1 − )2
474 Chapter 3 n Searching
Proposition M tells us (under our usual Assumption J) that we can expect a search to require a huge number of probes in a nearly full table (as a approaches 1 the values of the formulas describing the number of probes grow very large) but that the expected number of probes is between 1.5 and 2.5 if we can ensure that the load factor a is less than 1/2. Next, we consider the use of array resizing for this purpose.
Array resizing We can use our standard array-resizing technique from Chapter 1 to ensure that the load factor never exceeds one-half. First, we need a new construc- tor for LinearProbingHashST that takes a  xed capacity as argument (add a line to
the constructor in Algorithm 3.6 that sets M to the given value before creating the arrays). Next, we need the resize() method given at left, which creates a new LinearProbingHashST of the giv- en size and puts all the key-value pairs from the old table into the new one by rehashing all the keys. These additions allow us to imple- ment array doubling. The call to resize() in the  rst statement in put() ensures that the table is at
most one-half full. This code builds a hash table twice the size with the same keys, thus halving the value of a. As in other applications of array resizing, we also need to add
     if (N > 0 && N <= M/8) resize(M/2);
as the last statement in delete() to ensure that the table is at least one-eighth full. This ensures that the amount of memory used is always within a constant factor of the number of key-value pairs in the table. With array resizing, we are assured that a  1/2.
Separate chaining The same method works to keep lists short (of average length between 2 and 8) in separate chaining: replace LinearProbingHashST by SeparateChainingHashSTinresize(),callresize(2*M)when(N >= M/2)input(), and call resize(M/2) when (N > 0 && N <= M/8) in delete(). For separate chain- ing, array resizing is optional and not worth your trouble if you have a decent estimate of the client’s N: just pick a table size M based on the knowledge that search times are proportional to 1+ N/M. For linear probing, array resizing is necessary. A client that inserts more key-value pairs than you expect will encounter not just excessively long search times, but an in nite loop when the table  lls.
   private void resize(int cap)
  {
      LinearProbingHashST<Key, Value> t;
      t = new LinearProbingHashST<Key, Value>(cap);
      for (int i = 0; i < M; i++)
         if (keys[i] != null)
             t.put(keys[i], vals[i]);
      keys = t.keys;
      vals = t.vals;
      M    = t.M;
}
resizing a linear-probing hash table
 www.it-ebooks.info

 Amortized analysis From a theoretical standpoint, when we use array resizing, we must settle for an amortized bound, since we know that those insertions that cause the table to double will require a large number of probes.
proposition N. Suppose a hash table is built with array resizing, starting with an empty table. Under Assumption J, any sequence of t search, insert, and delete symbol-table operations is executed in expected time proportional to t and with memory usage always within a constant factor of the number of keys in the table.
proof: Forbothseparatechainingandlinearprobing,thisfactfollowsfromasim- ple restatement of the amortized analysis for array growth that we  rst discussed in Chapter 1, coupled with Proposition K and Proposition M.
10
0
cumulative average
operations
4.2
10
0
cumulative average
0
14350
Costs for java FrequencyCounter 8 < tale.txt using SeparateChainingHashST (with doubling)
0
operations
14350
Costs for java FrequencyCounter 8 < tale.txt using LinearProbingHashST (with doubling)
www.it-ebooks.info
3.4 n Hash Tables 475
3.2
equality tests
equality tests
476 Chapter 3 n Searching
The plots of the cumulative averages for our FrequencyCounter example (shown at the bottom of the previous page) nicely illustrate the dynamic behavior of array resiz- ing in hashing. Each time the array doubles, the cumulative average increases by about 1, because each key in the table needs to be rehashed; then it decreases because about half as many keys hash to each table position, with the rate of decrease slowing as the table  lls again.
Memory As we have indicated, understanding memory usage is an important factor if we want to tune hashing algorithms for optimum performance. While such tuning is for experts, it is a worthwhile exercise to calculate a rough estimate of the amount of memory required, by estimating the number of references used, as follows: Not counting the memory for keys and values, our implementation SeparateChainingHashST uses memory for M references to SequentialSearchST objects plus M SequentialSearchST objects. Each SequentialSearchST object has the usual 16 bytes of object overhead plus one 8-byte reference (first), and there are a total of N Node objects, each with 24 bytes of object overhead plus 3 references (key, value, and next). This compares with an extra reference per node for binary search trees. With array resizing to ensure that the table is between one-eighth and one-half full, linear probing uses between 4N and 16N references. Thus, choosing hashing on the basis of memory usage is not normally justi ed. The calculation is a bit different for primitive types (see Exercise 3.4.24)
method
separate chaining linear probing BSTs
space usage for N items (reference types)
~ 48 N + 32 M between
~32 N and ~128 N ~56N
 www.it-ebooks.info
Space usage in symbol tables

Since the earliest days of computing, researchers have studied (and are study- ing) hashing and have found many ways to improve the basic algorithms that we have discussed. You can  nd a huge literature on the subject. Most of the improvements push down the space-time curve: you can get the same running time for searches using less space or get faster searches using the same amount of space. Other improvements involve better guarantees, on the expected worst-case cost of a search. Others involve improved hash-function designs. Some of these methods are addressed in the exercises.
Detailed comparison of separate chaining and linear probing depends on myriad implementation details and on client space and time requirements. It is not normally justi ed to choose separate chaining over linear probing on the basis of performance (see Exercise 3.5.31). In practice, the primary performance difference between the two methods has to do with the fact that separate chaining uses a small block of memory for each key-value pair, while linear probing uses two large arrays for the whole table. For huge tables, these needs place quite different burdens on the memory management system. In modern systems, this sort of tradeoff is best addressed by experts in extreme performance-critical situations.
With hashing, under generous assumptions, it is not unreasonable to expect to support the search and insert symbol-table operations in constant time, independent of the size of the table. This expectation is the theoretical optimum performance for any symbol-table implementation. Still, hashing is not a panacea, for several reasons, including:
n A good hash function for each type of key is required.
n The performance guarantee depends on the quality of the hash function. n Hash functions can be dif cult and expensive to compute.
n Ordered symbol-table operations are not easily supported.
Beyond these basic considerations, we defer the comparison of hashing with the other symbol-table methods that we have studied to the beginning of Section 3.5.
www.it-ebooks.info
3.4 n Hash Tables 477

478 Chapter 3 n Searching
   Q. How does Java implement hashCode() for Integer, Double, and Long?
A. ForIntegeritjustreturnsthe32-bitvalue.ForDoubleandLongitreturnstheex- clusive or of the  rst 32 bits with the second 32 bits of the standard machine representa-
tion of the number. These choices may not seem to be very random, but they do serve the purpose of spreading out the values.
Q. When using array resizing, the size M of the table is al- ways a power of 2. Isn’t that a potential problem, because it only uses the least signi cant bits of hashCode()?
A. Yes,particularlywiththedefaultimplementations.One way to address this problem is to  rst distribute the key val- ues using a prime larger than M, as in the following example:
    private int hash(Key x)
    {
k  k
51 63 71 85 93
10 3 11 9 12 3 13 1 14 3 15 19 16 15 17 1 18 5 19 1 20 3 21 9 22 3 23 15 24 3 25 39 26 5 27 39 28 57 29 3 30 35 31 1
primes[k]
(2k −  k)
31
61 127 251 509 1021 2039 4093 8191 16381 32749 65521 131071 262139 524287 1048573 2097143 4194301 8388593 16777213 33554393 67108859 134217689 268435399 536870909 1073741789 2147483647
       int t = x.hashCode() & 0x7fffffff;
       if (lgM < 26) t = t % primes[lgM+5];
       return t % M;
}
This code assumes that we maintain an instance variable lgM that is equal to lg M (by initializing to the appropri- ate value, incrementing when doubling, and decrementing when halving) and an array primes[] of the largest prime less than each power of 2 (see the table at right). The con- stant 5 is an arbitrary choice—we expect the  rst % to dis- tribute the values equally among the values less than the prime and the second to map about 25 of those values to each value less than M. Note that the point is moot for large M.
Primes for hash table sizes
Q. I’veforgotten.Whydon’tweimplementhash(x)byreturningx.hashCode() % M? A. We need a result between 0 and M-1, but in Java, the % function may be negative. Q. So, why not implement hash(x) by returning Math.abs(x.hashcode()) % M?
www.it-ebooks.info
 Q&A
  A. Nice try. Unfortunately, Math.abs() returns a negative result for the largest nega- tive number. For many typical calculations, this over ow presents no real problem, but for hashing it would leave you with a program that is likely to crash after a few bil- lion inserts, an unsettling possibility. For example, s.hashCode() is 231 for the Java String value "polygenelubricants". Finding other strings that hash to this value (and to 0) has turned into an amusing algorithm-puzzle pastime.
Q. Do Java library hash functions satisfy Assumption J?
A. No. For example, the hashCode() implementation in the String data type is not
only deterministic but it is speci ed in the API.
Q. WhynotuseBinarySearchSTorRedBlackBSTinsteadofSequentialSearchSTin
Algorithm 3.5?
A. Generally,wesetparameterssoastomakethenumberofkeyshashingtoeachvalue small, and elementary symbol tables are generally better for the small tables. In certain situations, slight performance gains may be achieved with such hybrid methods, but such tuning is best left for experts.
Q. Is hashing faster than searching in red-black BSTs?
A. It depends on the type of the key, which determines the cost of computing hashCode() versusthecostofcompareTo().FortypicalkeytypesandforJavadefault implementations, these costs are similar, so hashing will be signi cantly faster, since it uses only a constant number of operations. But it is important to remember that this question is moot if you need ordered operations, which are not ef ciently supported in hash tables. See Section 3.5 for further discussion.
Q. Why not let the linear probing table get, say, three-quarters full?
A. Noparticularreason.Youcanchooseanyvalueofa,usingPropositionMtoesti- mate search costs. For a = 3/4, the average cost of search hits is 2.5 and search misses is 8.5, but if you let a grow to 7/8, the average cost of a search miss is 32.5, perhaps more than you want to pay. As a gets close to 1, the estimate in Proposition M becomes in- valid, but you don’t want your table to get that close to being full.
www.it-ebooks.info
3.4 n Hash Tables 479

480 Chapter 3 n Searching
   3.4.1 InsertthekeysE A S Y Q U T I O Ninthatorderintoaninitiallyemptytable of M = 5 lists, using separate chaining. Use the hash function 11 k % M to transform the kth letter of the alphabet into a table index.
3.4.2 DevelopanalternateimplementationofSeparateChainingHashSTthatdirectly uses the linked-list code from SequentialSearchST.
3.4.3 Modifyyourimplementationofthepreviousexercisetoincludeaninteger eld for each key-value pair that is set to the number of entries in the table at the time that pair is inserted. Then implement a method that deletes all keys (and associated values) for which the  eld is greater than a given integer k. Note : This extra functionality is use- ful in implementing the symbol table for a compiler.
3.4.4 Write a program to  nd values of a and M, with M as small as possible, such that the hash function (a * k) % M for transforming the kth letter of the alphabet into a tableindexproducesdistinctvalues(nocollisions)forthekeysS E A R C H X M P L. The result is known as a perfect hash function.
3.4.5 Is the following implementation of hashCode() legal? public int hashCode()
{ return 17; }
If so, describe the effect of using it. If not, explain why.
3.4.6 Suppose that keys are t-bit integers. For a modular hash function with prime M, prove that each key bit has the property that there exist two keys differing only in that bit that have different hash values.
3.4.7 Consider the idea of implementing modular hashing for integer keys with the code (a * k) % M , where a is an arbitrary  xed prime. Does this change mix up the bits suf ciently well that you can use nonprime M?
3.4.8 How many empty lists do you expect to see when you insert N keys into a hash table with SeparateChainingHashST, for N=10, 102, 103, 104, 105, and 106? Hint : See Exercise 2.5.31.
3.4.9 Implement an eager delete() method for SeparateChainingHashST.
3.4.10 InsertthekeysE A S Y Q U T I O Ninthatorderintoaninitiallyemptytable
www.it-ebooks.info
 ExErcisEs
  of size M =16 using linear probing. Use the hash function 11 k % M to transform the kth letter of the alphabet into a table index. Redo this exercise for M = 10.
3.4.11 Givethecontentsofalinear-probinghashtablethatresultswhenyouinsertthe keys E A S Y Q U T I O NinthatorderintoaninitiallyemptytableofinitialsizeM =4thatisexpandedwithdoublingwheneverhalffull.Usethehashfunction11 k % M to transform the kth letter of the alphabet into a table index.
3.4.12 SupposethatthekeysAthroughG,withthehashvaluesgivenbelow,areinserted in some order into an initially empty table of size 7 using a linear-probing table (with no resizing for this problem).
key ABCDEFG hash (M = 7) 2 0 0 4 4 4 2
Which of the following could not possibly result from inserting these keys?
a. E F G A C B D b. C E B G F D A c. B D F A C E G d. C G B A D E F e. F G B D A C E f. G E C A D B F
Give the minimum and the maximum number of probes that could be required to build a table of size 7 with these keys, and an insertion order that justi es your answer.
3.4.13 Which of the following scenarios leads to expected linear running time for a random search hit in a linear-probing hash table?
a. All keys hash to the same index.
b. All keys hash to different indices.
c. All keys hash to an even-numbered index.
d. All keys hash to different even-numbered indices.
3.4.14 Answerthepreviousquestionforsearchmiss,assumingthesearchkeyisequally likely to hash to each table position.
3.4.15 How many compares could it take, in the worst case, to insert N keys into an initially empty table, using linear probing with array resizing?
www.it-ebooks.info
3.4 n Hash Tables 481

482 Chapter 3 n Searching ExErcisEs (continued)
3.4.16 Suppose that a linear-probing table of size 106 is half full, with occupied posi- tions chosen at random. Estimate the probability that all positions with indices divisible by 100 are occupied.
3.4.17 Show the result of using the delete() method on page 471 to delete C from the table resulting from using LinearProbingHashST with our standard indexing client (shown on page 469).
3.4.18 AddaconstructortoSeparateChainingHashSTthatgivestheclienttheability to specify the average number of probes to be tolerated for searches. Use array resizing to keep the average list size less than the speci ed value, and use the technique described on page 478 to ensure that the modulus for hash() is prime.
3.4.19 Implementkeys()forSeparateChainingHashSTandLinearProbingHashST. 3.4.20 Add a method to LinearProbingHashST that computes the average cost of a
search hit in the table, assuming that each key in the table is equally likely to be sought.
3.4.21 Add a method to LinearProbingHashST that computes the average cost of a search miss in the table, assuming a random hash function. Note : You do not have to compute any hash functions to solve this problem.
3.4.22 Implement hashCode() for various types: Point2D, Interval, Interval2D, and Date.
3.4.23 Consider modular hashing for string keys with R = 256 and M = 255. Show that this is a bad choice because any permutation of letters within a string hashes to the same value.
3.4.24 Analyze the space usage of separate chaining, linear probing, and BSTs for double keys. Present your results in a table like the one on page 476.
 www.it-ebooks.info

3.4.25 Hash cache. Modify Transaction on page 462 to maintain an instance variable hash, so that hashCode() can save the hash value the  rst time it is called for each object and does not have to recompute it on subsequent calls. Note : This idea works only for immutable types.
3.4.26 Lazy delete for linear probing. Add to LinearProbingHashST a delete() method that deletes a key-value pair by setting the value to null (but not removing the key) and later removing the pair from the table in resize(). Your primary chal- lenge is to decide when to call resize(). Note : You should overwrite the null value if a subsequent put() operation associates a new value with the key. Make sure that your program takes into account the number of such tombstone items, as well as the number of empty positions, in making the decision whether to expand or contract the table.
3.4.27 Double probing. Modify SeparateChainingHashST to use a second hash func- tion and pick the shorter of the two lists. Give a trace of the process of inserting the keys E A S Y Q U T I O NinthatorderintoaninitiallyemptytableofsizeM=3using the function 11 k % M (for the kth letter) as the  rst hash function and the function 17 k % M (for the kth letter) as the second hash function. Give the average number of probes for random search hit and search miss in this table.
3.4.28 Double hashing. Modify LinearProbingHashST to use a second hash function tode netheprobesequence.Speci cally,replace(i + 1) % M (bothoccurrences)by (i + k) % M where k is a nonzero key-dependent integer that is relatively prime to M. Note : You may meet the last condition by assuming that M is prime. Give a trace of the processofinsertingthekeysE A S Y Q U T I O Ninthatorderintoaninitiallyempty table of size M =11, using the hash functions described in the previous exercise. Give the average number of probes for random search hit and search miss in this table.
3.4.29 Deletion. Implement an eager delete() method for the methods described in each of the previous two exercises.
3.4.30 Chi-square statistic. Add a method to SeparateChainingHashST to compute the  2 statistic for the hash table. With N keys and table size M, this number is de ned by the equation
2 = (M/N)((f0 N/M)2 +(f1 N/M)2  ...(fM1N/M)2 )
www.it-ebooks.info
3.4 n Hash Tables 483
 crEAtivE problEms

484 Chapter 3 n Searching
crEAtivE problEms (continued)
where fi is the number of keys with hash value i. This statistic is one way of checking our assumption that the hash function produces random values. If so, this statistic, for N > cM, should be between M  M and M + M with probability 1  1/c.
3.4.31 Cuckoo hashing. Develop a symbol-table implementation that maintains two hash tables and two hash functions. Any given key is in one of the tables, but not both. When inserting a new key, hash to one of the tables; if the table position is occupied, replace that key with the new key and hash the old key into the other table (again kick- ing out a key that might reside there). If this process cycles, restart. Keep the tables less than half full. This method uses a constant number of equality tests in the worst case for search (trivial) and amortized constant time for insert.
3.4.32 Hash attack. Find 2N strings, each of length 2N, that have the same hashCode() value, supposing that the hashCode() implementation for String is the following:
             public int hashCode()
             {
                int hash = 0;
                for (int i = 0; i < length(); i ++)
                   hash = (hash * 31) + charAt(i);
                return hash;
}
Strong hint : Aa and BB have the same value.
3.4.33 Bad hash function. Consider the following hashCode() implementation for String, which was used in early versions of Java:
             public int hashCode()
             {
                int hash = 0;
                int skip = Math.max(1, length()/8);
                for (int i = 0; i < length(); i += skip)
                   hash = (hash * 37) + charAt(i);
                return hash;
}
Explain why you think the designers chose this implementation and then why you think it was abandoned in favor of the one in the previous exercise.
   www.it-ebooks.info

3.4.34 Hash cost. Determine empirically the ratio of the time required for hash() to the time required for compareTo(), for as many commonly-used types of keys for which you can get meaningful results.
3.4.35 Chi-square test. Use your solution from Exercise 3.4.30 to check the assump- tion that the hash functions for commonly-used key types produce random values.
3.4.36 List length range. Write a program that inserts N random int keys into a table of size N / 100 using separate chaining, then  nds the length of the shortest and longest lists, for N = 103, 104, 105, 106.
3.4.37 Hybrid. Run experimental studies to determine the effect of using RedBlackBST instead of SequentialSearchST to handle collisions in SeparateChainingHashST. This solution carries the advantage of guaranteeing logarithmic performance even for a bad hash function and the disadvantage of necessitating maintenance of two different symbol-table implementations. What are the practical effects?
3.4.38 Separate-chaining distribution. Write a program that inserts 10 5 random non- negative integers less than 10 6 into a table of size 10 5 using separate chaining, and that plots the total cost for each 10 3 consecutive insertions. Discuss the extent to which your results validate Proposition K.
3.4.39 Linear-probing distribution. Write a program that inserts N/2 random int keys into a table of size N using linear probing, then computes the average cost of a search miss in the resulting table from the cluster lengths, for N = 10 3, 10 4, 10 5, 10 6. Discuss the extent to which your results validate Proposition M.
3.4.40 Plots. Instrument LinearProbingHashST and SeparateChainingHashST to produce plots like the ones shown in the text.
3.4.41 Double probing. Run experimental studies to evaluate the effectiveness of dou- ble probing (see Exercise 3.4.27).
3.4.42 Double hashing. Run experimental studies to evaluate the effectiveness of dou- ble hashing (see Exercise 3.4.28).
3.4.43 Parking problem. (D. Knuth) Run experimental studies to validate the hypoth- esis that the number of compares needed to insert M random keys into a linear-probing hash table of size M is ~cM 3/2, where c = /2.
3.4 n Hash Tables 485
 ExpErimENts
  www.it-ebooks.info

   486
From the early days of computing, when symbol tables allowed programmers to progress from using numeric addresses in machine language to using symbolic names in assembly language, to modern applications of the new millennium, when symbolic names have meaning across worldwide computer networks, fast search algorithms have played and continue to play an essential role in computation. Modern applications for symbol tables include organization of scienti c data, from searching for markers or patterns in genomic data to mapping the universe; organization of knowledge on the web, from searching in online commerce to putting libraries online; and implement- ing the internet infrastructure, from routing packets among machines on the web to shared  le systems and video streaming. Ef cient search algorithms have enabled these and countless other important applications. We will consider several representative ex- amples in this section:
n A dictionary client and an indexing client that enable fast and  exible access to information in comma-separated-value  les (and similar formats), which are widely used to store data on the web
n An indexing client for building an inverted index of a set of  les
n A sparse-matrix data type that uses a symbol table to address problem sizes far
beyond what is possible with the standard implementation
In Chapter 6, we consider a symbol table that is appropriate for tables such as data- bases and  le systems that contain a vast number of keys, as large as can be reasonably contemplated.
Symbol tables also play a critical role in algorithms that we consider throughout the rest of the book. For example, we use symbol tables to represent graphs (Chapter 4) and to process strings (Chapter 5).
As we have seen throughout this chapter, developing symbol-table implementations that can guarantee fast performance for all operations is certainly a challenging task. On the other hand, the implementations that we have considered are well-studied, widely used, and available in many software environments (including Java libraries). From this point forward, you certainly should consider the symbol-table abstraction to be a key component in your programmer’s toolbox.
www.it-ebooks.info
 3.5 APPliCAtionS

 Which symbol-table implementation should I use? The table at the bottom of this page summarizes the performance characteristics of the algorithms that we have considered in propositions and properties in this chapter (with the exception of the worst-case results for hashing, which are from the research literature and unlikely to be experienced in practice). It is clear from the table that, for typical applications, your decision comes down to a choice between hash tables and binary search trees.
The advantages of hashing over BST implementations are that the code is simpler and search times are optimal (constant), if the keys are of a standard type or are suf-  ciently simple that we can be con dent of developing an ef cient hash function for them that (approximately) satis es the uniform hashing assumption. The advantages of BSTs over hashing are that they are based on a simpler abstract interface (no hash function need be designed); red-black BSTs can provide guaranteed worst-case perfor- mance; and they support a wider range of operations (such as rank, select, sort, and range search). As a rule of thumb, most programmers will use hashing except when one or more of these factors is important, when red-black BSTs are called for. In Chap- ter 5, we will study one exception to this rule of thumb: when keys are long strings, we can build data structures that are even more  exible than red-black BSTs and even faster than hashing.
3.5 n Applications 487
 algorithm (data structure)
sequential search (unordered list)
binary search (ordered array)
binary tree search (BST)
2-3 tree search (red-black BST)
separate chaining† (array of lists)
linear probing† (parallel arrays)
worst-case cost (after n inserts)
search insert
average-case cost key memory (after n random inserts) interface (bytes)
search hit insert
 N N N/2 N equals() 48N
lg N N
2 lg N < lg N c lg N
N
N
2 lg N < lg N c lg N
lg N 1.39 lg N 1.00 lg N N/(2M) < 1.50
N/2 1.39 lg N 1.00 lg N N/M < 2.50
compareTo()
compareTo()
compareTo()
  equals()
 hashCode()
  equals()
 hashCode()
16 N
64 N
64 N
48 N + 32 M between
asymptotic cost summary for symbol-table implementations
32 N and 128 N † under uniform hashing assumption
www.it-ebooks.info

488 Chapter 3 n Searching
Our symbol-table implementations are useful for a wide range of applications, but our algorithms are easily adapted to support several other options that are widely used and worth considering.
Primitive types Suppose that we have a symbol table with integer keys and associ- ated  oating-point numbers. When we use our standard setup, the keys and values are stored as Integer and Double wrapper-type values, so we need two extra memory references to access each key-value pair. These references may be no problem in an ap- plication that involves thousands of searches on thousands of keys but may represent excessive cost in an application that involves billions of searches on millions of keys. Us- ing a primitive type instead of Key would save one reference per key-value pair. When the associated value is also primitive, we can eliminate another reference. The situation is diagrammed at right for separate chaining; the
same tradeoffs hold for other implementations. For performance-critical applications, it is worthwhile and not dif cult to develop versions of our imple- mentations along these lines (see Exercise 3.5.4).
standard implementation
data is stored in Key and Value objects
                       Duplicate keys The possibility of duplicate keys
sometimes needs special consideration in symbol-
table implementations. In many applications, it is
desirable to associate multiple values with the same
key. For example, in a transaction-processing sys-
tem, numerous transactions may have the same
customer key value. Our convention to disallow
duplicate keys amounts to leaving duplicate-key
management to the client. We will consider an ex-
ample of such a client later in this section. In many
of our implementations, we could consider the al-
ternative of leaving key-value pairs with duplicate
keys in the primary search data structure and to return any value with the given key for a search. We might also add methods to return all values with the given key. Our BST and hashing implementations are not dif cult to adapt to keep duplicate keys within the data structure; doing so for red-black BSTs is just slightly more challenging (see Ex- ercise 3.5.9 and Exercise 3.5.10). Such implementations are common in the literature (including earlier editions of this book).
       primitive-type implementation
data is stored in linked-list nodes
Memory usage for separate chaining
                        www.it-ebooks.info

Java libraries Java’s java.util.TreeMap and java.util.HashMap libraries are symbol-table implementations based on red-black BSTs and hashing with separate chaining respectively. TreeMap does not directly support rank(), select(), and other operations in our ordered symbol-table API, but it does support operations that enable ef cient implementation of these. HashMap is roughly equivalent to our SeparateChaingingHashST implementation—it uses array resizing to enforce a load factor of about 75 percent. Java’s java.util.IdentityHashMap library is a symbol-ta- ble implementation that uses reference-equality in place of object-equality; it is roughly equivalent to our LinearProbingHashST with a load factor of 2/3.
To be consistent and specific, we use in this book the symbol-table implementation based on red-black BSTs from Section 3.3 or the one based on linear-probing hashing from Section 3.4. For economy and to emphasize client independence from speci c implementations, we use the name ST as shorthand for RedBlackBST for ordered sym- bol tables in client code and the name HashST as shorthand for LinearProbingHashST when order is not important and hash functions are available. We adopt these conven- tions with full knowledge that speci c applications might have demands that could call for some variation or extension of one of these algorithms and data structures. Which symbol table should you use? Whatever you decide, test your choice to be sure that it is delivering the performance that you expect.
Set APIs Some symbol-table clients do not need the values, just the ability to insert keys into a table and to test whether a key is in the table. Because we disallow duplicate keys, these operations correspond to the following API where we are just interested in the set of keys in the table, not any associated values:
public class SET<Key>
SET()
void add(Key key)
void delete(Key key) boolean contains(Key key) boolean isEmpty()
int size()
String toString()
create an empty set
add key into the set
remove key from the set
is key in the set?
is the set empty?
number of keys in the set string representation of the set
3.5 n Applications 489
 apI for a basic set data type
www.it-ebooks.info

490 Chapter 3 n Searching
You can turn any symbol-table implementation into a SET implementation by ignoring values or by using a simple wrapper class (see Exercises 3.5.1 through 3.5.3).
Extending SET to include union, intersection, complement, and other common math- ematical set operations requires a more sophisticated API (for example, the comple- ment operation requires some mechanism for specifying a universe of all possible keys) and provides a number of interesting algorithmic challenges, as discussed in Exercise 3.5.17.
As with ST, we have unordered and ordered versions of SET. If keys are Comparable, we can include min(), max(), floor(), ceiling(), deleteMin(), deleteMax(), rank(), select(), and the two-argument versions of size() and get() to de ne a full API for ordered keys. To match our ST conventions, we use the name SET in client code for ordered sets and the name HashSET when order is not important.
To illustrate uses of SET, we consider  lter clients that read a sequence of strings from standard input and write some of them to standard output. Such clients have their origin in early systems where main memory was far too small to hold all the data, and they are still relevant today, when we write programs that take their input from the web. As example input, we use tinyTale.txt (see page 371). For readability, we preserve newlines from the input to the output in examples, even though the code does not do so.
 public class DeDup
{
   public static void main(String[] args)
   {
      HashSET<String> set;
      set = new HashSET<String>();
      while (!StdIn.isEmpty())
      {
         String key = StdIn.readString();
         if (!set.contains(key))
         {
            set.add(key);
            StdOut.println(key);
         }
} }
}
Dedup The prototypical  lter example is a SET or HashSET cli- ent that removes duplicates in the input stream. It is custom- ary to refer to this operation as dedup. We maintain a set of the string keys seen so far. If the next key is in the set, ignore it; if it is not in the set, add it to the set and print it. The keys appear on stan- dard output in the order they appear on standard input, with duplicates removed. This process takes space proportional to the number of distinct keys in the input stream (which is typically far smaller than the total number of keys).
Dedup filter
 www.it-ebooks.info
% java DeDup < tinyTale.txt
it was the best of times worst
age wisdom foolishness
epoch belief incredulity
season light darkness
spring hope winter despair

Whitelist and blacklist Another classic  lter uses keys in a separate  le to decide which keys from the input stream are passed to the output stream. This general process has many natural applications. The simplest example is a whitelist, where any key that is in the  le is identi ed as “good.” The client might choose to pass through to standard output any key that is not in the whitelist and to ignore any key that is in the whitelist (as in the example considered in our  rst program in Chapter 1); another client might choose to pass through to standard output any key that is in the whitelist and to ig- nore any key that is not in the whitelist (as
shown in the HashSET client WhiteFilter at right). For example, your email applica- tion might use such a  lter to allow you to specify the addresses of your friends and to direct it to consider emails from any- one else as spam. We build a HashSET of the keys in the speci ed list, then read the keys from standard input. If the next key is in the set, print it; if it is not in the set, ignore it. A blacklist is the opposite, where any key that is in the  le is identi ed as “bad.” Again, there are two natural  lters for clients using a blacklist. In our email example, you might specify the addresses of known spammers and direct the email application to let through all mail not from one of those addresses. We can im- plement a HashSET client BlackFilter that implements this  lter by negating the  lter test in WhiteFilter. Typical practi- cal situations such as a credit card com- pany using a blacklist to  lter out stolen card numbers or an internet router using a whitelist to implement a  rewall are likely to involve huge lists, unbounded input streams, and strict response requirements. The sorts of symbol-table implementa- tions that we have considered enable such challenges to easily be met.
Whitelist filter
3.5 n Applications 491
 public class WhiteFilter
{
   public static void main(String[] args)
   {
      HashSET<String> set;
      set = new HashSET<String>();
      In in = new In(args[0]);
      while (!in.isEmpty())
         set.add(in.readString());
      while (!StdIn.isEmpty())
      {
         String word = StdIn.readString();
         if (set.contains(word))
            StdOut.println(word);
      }
} }
 % more list.txt
was it the of
% java WhiteFilter list.txt < tinyTale.txt
it was the of it was the of
it was the of it was the of
it was the of it was the of
it was the of it was the of
it was the of it was the of
% java BlackFilter list.txt < tinyTale.txt
best times worst times
age wisdom age foolishness
epoch belief epoch incredulity
season light season darkness
spring hope winter despair
www.it-ebooks.info

492 Chapter 3 n Searching
Dictionary clients The most basic kind of symbol-table client builds a symbol table with successive put operations in order to support get requests. Many applications also take advantage of the idea that a symbol table is a dynamic dictionary, where it is easy to look up information and to update the information in the table. The following list of familiar examples illustrates the utility of this approach:
n Phone book. When keys are people’s names and values are their phone num- bers, a symbol table models a phone book. A very signi cant difference from a printed phone book is that we can add new names or change existing phone numbers. We could also use the phone number as the key and the name as the value—if you have never done so, try typing your phone number (with area code) into the search  eld in your browser.
n Dictionary. Associating a word with its de nition is a familiar concept that gives us the name “dictionary.” For centuries people kept printed dictionaries in their homes and of ces in order to check the de nitions and spellings (values) of words (keys). Now, because of good symbol-table implementations, people expect built-in spell checkers and immediate access to word de nitions on their computers.
n Account information. People who own stock now regularly check the current price on the web. Several services on the web associate a ticker symbol (key) with the current price (value), usually along with a great deal of other information. Commercial applications of this sort abound, including  nancial institutions associating account information with a name or account number or educational institutions associating grades with a student name or identi cation number.
n Genomics. Symbols play a central role in modern genomics. The simplest ex- ample is the use of the letters A, C, T, and G to represent the nucleotides found in the DNA of living organisms. The next simplest is the correspondence between codons (nucleotide triplets) and amino acids (TTA corresponds to leucine, TCT to serine, and so forth), then the correspondence between sequences of amino acids and proteins, and so forth. Researchers in genomics routinely use various types of symbol tables to organize this knowledge.
n Experimental data. From astrophysics to zoology, modern scientists are awash in experimental data, and organizing and ef ciently accessing this data are vital to understanding what it means. Symbol tables are a critical starting point, and ad- vanced data structures and algorithms that are based on symbol tables are now an important part of scienti c research.
n Compilers. One of the earliest uses of symbol tables was to organize information for programming. At  rst, programs were simply sequences of numbers, but programmers very quickly found that using symbolic names for operations and
www.it-ebooks.info

memory locations (variable names) was far more convenient. Associating the names with the numbers requires a symbol table. As the size of programs grew, the cost of the symbol-table operations became a bottleneck in program devel- opment time, which led to the development of data structures and algorithms like the ones we consider in this chapter.
n File systems. We use symbol tables regularly to organize data on computer systems. Perhaps the most prominent example is the  le system, where we associate a  le name (key) with the location of its contents (value). Your music player uses the same system to associate song titles (keys) with the location of the music itself (value).
domain
phone book
dictionary account
key
name
word
account number
value
phone number
de nition balance
amino acid
results
memory location
machine IP address
n Internet DNS. The domain name system (DNS)
that is the basis for organizing information on
the internet associates URLs (keys) that humans
understand (such as www.princeton.edu or
www.wikipedia.org) with IP addresses (values)
that computer network routers understand (such
as 208.216.181.15 or 207.142.131.206). This
system is the next-generation “phone book.”
Thus, humans can use names that are easy to re-
member and machines can ef ciently process the
numbers. The number of symbol-table lookups
done each second for this purpose on internet
routers around the world is huge, so perfor-
mance is of obvious importance. Millions of new computers and other devices are put onto the internet each year, so these symbol tables on internet routers need to be dynamic.
Despite its scope, this list is still just a representative sample, intended to give you a  a- vor of the scope of applicability of the symbol-table abstraction. Whenever you specify something by name, there is a symbol table at work. Your computer’s  le system or the web might do the work for you, but there is still a symbol table there somewhere.
As a speci c example, we consider a symbol-table client that you can use to look up information that is kept in a table on a  le or a web page using the comma-separated- value (.csv)  le format. This simple format achieves the (admittedly modest) goal of keeping tabular data in a form that anyone can read (and is likely to be able to read in the future) without needing to use a particular application: the data is in text form, one row per line, with entries separated by commas. You can  nd on the booksite
www.it-ebooks.info
genomics data
compiler
 le share internet
codon data/time
variable name
song name website
3.5 n Applications 493
 typical dictionary applications

494
Chapter 3
n Searching
 % more amino.csv
TTT,Phe,F,Phenylalanine
TTC,Phe,F,Phenylalanine
TTA,Leu,L,Leucine
TTG,Leu,L,Leucine
TCT,Ser,S,Serine
TCC,Ser,S,Serine
...
GAA,Gly,G,Glutamic Acid
GAG,Gly,G,Glutamic Acid
GGT,Gly,G,Glycine
GGC,Gly,G,Glycine
GGA,Gly,G,Glycine
GGG,Gly,G,Glycine
% more DJIA.csv
...
20-Oct-87,1738.74,608099968,1841.01
19-Oct-87,2164.16,604300032,1738.74
16-Oct-87,2355.09,338500000,2246.73
15-Oct-87,2412.70,263200000,2355.09
...
30-Oct-29,230.98,10730000,258.47
29-Oct-29,252.38,16410000,230.07
28-Oct-29,295.18,9210000,260.64
25-Oct-29,299.47,5920000,301.22
...
% more ip.csv
...
www.ebay.com,66.135.192.87
www.princeton.edu,128.112.128.15
www.cs.princeton.edu,128.112.136.35
www.harvard.edu,128.103.60.24
www.yale.edu,130.132.51.8
www.cnn.com,64.236.16.20
www.google.com,216.239.41.99
www.nytimes.com,199.239.136.200
www.apple.com,17.112.152.32
www.slashdot.org,66.35.250.151
www.espn.com,199.181.135.201
www.weather.com,63.111.66.11
www.yahoo.com,216.109.118.65
...
% more UPC.csv
...
0002058102040,,"1 1/4"" STANDARD STORM DOOR"
0002058102057,,"1 1/4"" STANDARD STORM DOOR"
0002058102125,,"DELUXE STORM DOOR UNIT"
0002082012728,"100/ per box","12 gauge shells"
0002083110812,"Classical CD","'Bits and Pieces'"
002083142882,CD,"Garth Brooks - Ropin' The Wind"
0002094000003,LB,"PATE PARISIEN"
0002098000009,LB,"PATE TRUFFLE COGNAC-M&H 8Z RW"
0002100001086,"16 oz","Kraft Parmesan"
0002100002090,"15 pieces","Wrigley's Gum"
0002100002434,"One pint","Trader Joe's milk"
...
typical comma-separated-value (.csv) files
numerous .csv  les that are related to vari- ous applications that we have described, including amino.csv (codon-to-amino- acid encodings), DJIA.csv (opening price, volume, and closing price of the Dow Jones Industrial Average, for every day in its his- tory), ip.csv (a selection of entries from the DNS database), and upc.csv (the Uni- form Product Code bar codes that are wide- ly used to identify consumer products). Spreadsheet and other data-processing applications programs can read and write .csv  les, and our example illustrates that you can also write a Java program to process the data any way that you would like.
LookupCSV (on the facing page) builds a set of key-value pairs from a  le of comma- separated values as speci ed on the com- mand line and then prints out values corre- sponding to keys read from standard input. The command-line arguments are the  le name and two integers, one specifying the  eld to serve as the key and the other speci- fying the  eld to serve as the value.
The purpose of this example is to il- lustrate the utility and  exibility of the symbol-table abstraction. What website has IP address 128.112.136.35? (www. cs.princeton.edu) What amino acid cor- responds to the codon TCC ? (Serine) What was the DJIA on October 29, 1929? (230.07) What product has UPC 0002100001086? (Kraft Parmesan) You can easily look up the answers to questions like these with LookupCSV and the appropriate .csv  les.
Performance is not much of an issue when handling interactive queries (since your computer can look through millions
www.it-ebooks.info

  Dictionary lookup
  public class LookupCSV
  {
     public static void main(String[] args)
     {
        In in = new In(args[0]);
        int keyField = Integer.parseInt(args[1]);
        int valField = Integer.parseInt(args[2]);
        ST<String, String> st = new ST<String, String>();
        while (in.hasNextLine())
        {
           String line = in.readLine();
           String[] tokens = line.split(",");
           String key = tokens[keyField];
           String val = tokens[valField];
           st.put(key, val);
}
        while (!StdIn.isEmpty())
        {
           String query = StdIn.readString();
           if (st.contains(query))
              StdOut.println(st.get(query));
        }
} }
This data-driven symbol-table client reads key-value pairs from a  le, then prints the values corre- sponding to the keys found on standard input. Both keys and values are strings. The  elds to serve as the key and value are taken as command-line arguments.
    % java LookupCSV ip.csv 1 0
128.112.136.35
www.cs.princeton.edu
www.it-ebooks.info
% java LookupCSV amino.csv 0 3
TCC
Serine
3.5 n Applications 495
  % java LookupCSV DJIA.csv 0 3
29-Oct-29
230.07
% java LookupCSV UPC.csv 0 2
0002100001086
Kraft Parmesan
496 Chapter 3 n Searching
of things in the time it takes to type a query), so fast implementations of ST are not no- ticeable when you use LookupCSV. However, when a program is doing the lookups (and a huge number of them), performance matters. For example, an internet router might need to look up millions of IP addresses per second. In this book, we have already seen the need for good performance with FrequencyCounter, and we will see several other examples in this section.
Examples of similar but more sophisticated test clients for .csv  les are described in the exercises. For instance, we could make the dictionary dynamic by also allowing standard-input commands to change the value associated with a key, or we could allow range searching, or we could build multiple dictionaries for the same  le.
Indexing clients Dictionaries are char- acterized by the idea that there is one value associated with each key, so the direct use of our ST data type, which is based on the asso- ciative-array abstraction that assigns one value to each key, is appropriate. Each account num- ber uniquely identi es a customer, each UPC uniquely identi es a product, and so forth. In general, of course, there may be multiple val- ues associated with a given key. For example, in our amino.csv example, each codon identi es one amino acid, but each amino acid is asso- ciated with a list of codons, as in the example aminoI.csv at right, where each line contains an amino acid and the list of codons associated with it. We use the term index to describe sym- bol tables that associate multiple values with each key. Here are some more examples:
aminoI.csv
  Alanine,AAT,AAC,GCT,GCC,GCA,GCG
  Arginine,CGT,CGC,CGA,CGG,AGA,AGG
  Aspartic Acid,GAT,GAC
  Cysteine,TGT,TGC
Glutamic Acid,GAA,GAG
Glutamine,CAA,CAG
Glycine,GGT,GGC,GGA,GGG
Histidine,CAT,CAC
Isoleucine,ATT,ATC,ATA
Leucine,TTA,TTG,CTT,CTC,CTA,CTG
Lysine,AAA,AAG
Methionine,ATG
Phenylalanine,TTT,TTC
Proline,CCT,CCC,CCA,CCG
Serine,TCT,TCA,TCG,AGT,AGC
Stop,TAA,TAG,TGA
Threonine,ACT,ACC,ACA,ACG
Tyrosine,TAT,TAC
Tryptophan,TGG
Valine,GTT,GTC,GTA,GTG
"," separator
      values
A small index  le (20 lines)
n Web search. When you type a keyword and get a list of websites containing that keyword, you are using an index created by your web search engine. There is one value (the set of pages) associated with each key (the query), although the reality is a bit more complicated because we often specify multiple keys.
n Commercial transactions. One way for
a company that maintains customer
accounts to keep track of a day’s transactions is to keep an index of the day’s transactions. The key is the account number; the value is the list of occurrences of that account number in the transaction list.
www.it-ebooks.info
key

n Movies and performers. The  le movies.txt on the booksite (excerpted below) is taken from the Internet Movie Database (IMDB). Each line has a movie name (the key), followed by a list of performers in that movie (the value), separated by slashes.
We can easily build an index by putting the values to be associated with each key into a single data structure (a Queue, say) and then associating that key with that data struc- ture as value. Extending LookupCSV along these lines is straightforward, but we leave that as an exercise (see Exercise 3.5.12)
and consider instead LookupIndex on
page 499, which uses a symbol table to
build an index from  les like aminoI.txt
and movies.txt (where the separator
character need not be a comma, as in a
.csv  le, but can be speci ed on the com-
mand line). After building the index,
LookupIndex then takes key queries and
prints the values associated with each key.
More interesting, LookupIndex also builds
an inverted index associated with each  le, where values and keys switch roles. In the amino acid example, this gives the same functionality as Lookup ( nd the amino acid associated with a given codon); in the movie-performer example it adds the ability to  nd the movies associated with any given performer, which is implicit in the data but would be dif cult to produce without a symbol table. Study this example carefully, as it provides good insight into the essential nature of symbol tables.
domain
key
value
...
Tin Men (1987)/DeBoy, David/Blumenfeld, Alan/...
Tirez sur le pianiste (1960)/Heymann, Claude/...
Titanic (1997)/Mazin, Stan/...DiCaprio, Leonardo/...
Titus (1999)/Weisskopf, Hermann/Rhys, Matthew/...
To Be or Not to Be (1942)/Verebes, Ernö (I)/...
To Be or Not to Be (1983)/.../Brooks, Mel (I)/...
To Catch a Thief (1955)/París, Manuel/...
To Die For (1995)/Smith, Kurtwood/.../Kidman, Nicole/...
...
key values
3.5 n Applications 497
 movies.txt
"/" separator
genomics commercial web search IMDB
amino acid account number search key movie
list of codons list of transactions list of web pages list of performers
typical indexing applications
     Small portion of a large index  le (250,000+ lines)
www.it-ebooks.info

498 Chapter 3 n Searching
Inverted index The term inverted index is normally applied to a situation where values are used to locate keys. We have a large amount of data and want to know where certain keys of interest occur. This application is another prototypical example of a symbol- table client that uses an intermixed sequence of calls to get() and put(). Again, we as- sociate each key with a SET of locations, where the occurrences of the key can be found. The nature and use of the location depend on the application: in a book, a location might be a page number; in a program, a location might be a line number; in genomics, a location might be a position in a genetic sequence; and so forth:
n Internet Movie DataBase (IMDB). In the example just considered, the input is an index that associates each movie with a list of performers. The inverted index associates each performer with a list of movies.
n Book index. Every textbook has an index where you look up a term and get the page numbers containing that term. While creating a good index generally involves work by the book author to eliminate common and irrelevant words, a document preparation
system will certainly use a
symbol table to help auto-
mate the process. An interest-
ing special case is known as a
concordance, which associates
each word in a text with the
set of positions in the text
where that word occurs (see
Exercise 3.5.20).
n Compiler. In a large program
that uses a large number of symbols, it is useful to know where each name is used. Historically, an explicit printed symbol table was one of the most impor- tant tools used by programmers to keep track of where symbols are used in their programs. In modern systems, symbol tables are the basis of software tools that programmers use to manage names.
n File search. Modern operating systems provide you with the ability to type a term and to learn the names of  les containing that term. The key is the term; the value is the set of  les containing that term.
n Genomics. In a typical (if oversimpli ed) scenario in genomics research, a scientist wants to know the positions of a given genetic sequence in an existing genome or set of genomes. Existence or proximity of certain sequences may be of scienti c signi cance. The starting point for such research is an index like a concordance, but modi ed to take into account the fact that genomes are not separated into words (see Exercise 3.5.15).
domain
key
value
 IMDB book compiler  le search genomics
performer term identi er search term subsequence
set of movies
set of pages
set of places used set of  les
set of locations
www.it-ebooks.info
typical inverted indices

  index (and inverted index) lookup
  public class LookupIndex
  {
     public static void main(String[] args)
     {
        In in = new In(args[0]);   // index database
        String sp = args[1];       // separator
        ST<String, Queue<String>> st = new ST<String, Queue<String>>();
        ST<String, Queue<String>> ts = new ST<String, Queue<String>>();
        while (in.hasNextLine())
        {
           String[] a = in.readLine().split(sp);
           String key = a[0];
           for (int i = 1; i < a.length; i++)
           {
              String val = a[i];
              if (!st.contains(key)) st.put(key, new Queue<String>());
              if (!ts.contains(val)) ts.put(val, new Queue<String>());
              st.get(key).enqueue(val);
              ts.get(val).enqueue(key);
} }
        while (!StdIn.isEmpty())
        {
           String query = StdIn.readLine();
           if (st.contains(query))
             for (String s : st.get(query))
                StdOut.println("  " + s);
           if (ts.contains(query))
             for (String s : ts.get(query))
  } }
}
StdOut.println("  " + s);
 This data-driven symbol-table client reads key-value pairs from a  le, then prints the values corresponding to the keys found on standard input. Keys are strings; values are lists of strings. The separating delimiter is taken as a command- line argument.
www.it-ebooks.info
3.5 n Applications 499
% java LookupIndex aminoI.csv ","
Serine
  TCT
  TCA
  TCG
  AGT
  AGC
TCG Serine
% java LookupIndex movies.txt "/"
Bacon, Kevin
  Animal House (1978)
  Apollo 13 (1995)
  Beauty Shop (2005)
  Diner (1982)
  ...
Tin Men (1987)
  DeBoy, David
  Blumenfeld, Alan
  ...
500 Chapter 3 n Searching
FileIndex (on the facing page) takes  le names from the command line and uses a symbol table to build an inverted index associating every word in any of the  les with a SET of  le names where the word can be found, then takes keyword queries from standard input, and produces its associated list of  les. This process is similar to that used by familiar software tools for searching the web or for searching for information on your computer; you type a keyword to get a list of places where that keyword occurs. Developers of such tools typically embellish the process by paying careful attention to
n The form of the query
n The set of  les/pages that are indexed
n The order in which  les are listed in the response
For example, you are certainly used to typing queries that contain multiple keywords to a web search engine (which is based on indexing a large fraction of the pages on the web) that provides answers in order of relevance or importance (to you or to an adver- tiser). The exercises at the end of this section address some of these embellishments. We will consider various algorithmic issues related to web search later, but the symbol table is certainly at the heart of the process.
As with LookupIndex, you are certainly encouraged to download FileIndex from the booksite and use it to index some text  les on your computer or some websites of interest, to gain further appreciation for the utility of symbol tables. If you do so, you will  nd that it can build large indices for huge  les with little delay, because each put operation and get request is taken care of immediately. Providing this immediate re- sponse for huge dynamic tables is one of the classic triumphs of algorithmic technology.
www.it-ebooks.info

  File indexing
  import java.io.File;
  public class FileIndex
  {
     public static void main(String[] args)
     {
        ST<String, SET<File>> st = new ST<String, SET<File>>();
        for (String filename : args)
        {
           File file = new File(filename);
           In in = new In(file);
           while (!in.isEmpty())
           {
              String word = in.readString();
              if (!st.contains(word)) st.put(word, new SET<File>());
              SET<File> set = st.get(word);
              set.add(file);
} }
        while (!StdIn.isEmpty())
        {
           String query = StdIn.readString();
           if (st.contains(query))
 } }
}
for (File file : st.get(query))
  StdOut.println("  " + file.getName());
 This symbol-table client indexes a set of  les. We search for each word in each  le in a symbol table, maintaining a SET of  le names that contain the word. Names for In can also refer to web pages, so this code can also be used to build an inverted index of web pages.
  % more ex1.txt
it was the best of times
% more ex2.txt
it was the worst of times
% more ex3.txt
it was the age of wisdom
% more ex4.txt
it was the age of foolishness
www.it-ebooks.info
3.5 n Applications 501
% java FileIndex ex*.txt
age
ex3.txt
ex4.txt best
ex1.txt was
  ex1.txt
  ex2.txt
  ex3.txt
  ex4.txt
502
Chapter 3 n Searching
Sparse vectors Our next example illustrates the importance of symbol tables in sci- enti c and mathematical calculations. We describe a fundamental and familiar calcula- tion that becomes a bottleneck in typical practical applications, then show how using a symbol table can remove the bottleneck and enable solution of vastly larger problems. Indeed, this particular calculation was at the core of the PageRank algorithm that was developed by S. Brin and L. Page and led to the emergence of Google in the early 2000s
a[][]
                  0   .05
  0   0 .36 .36 .18   .04
  0   0   0 .90   0   .36
.90   0   0   0   0   .37
.47   0 .47   0   0   .19
(and is a well-known mathematical abstraction that is useful in many other contexts).
The basic calculation that we consider is ma- trix-vector multiplication: given a matrix and a vector, compute a result vector whose ith entry
x[]
b[]
      0 .90
0 0
.036
.297
.333 is the dot product of the given vector and the i th
Matrix-vector multiplication
=
.045 .1927
row of the matrix. For simplicity, we consider the case when the matrix is square with N rows and N columns and the vectors are of size N. This operation is elementary to code in Java, requir- ing time proportional to N 2, for the N multipli- cations to compute each of the N entries in the
result vector, which also matches the space proportional to N 2 that is required to store the matrix.
In practice, it is very often the case that N is huge. For example, in the Google appli- cation cited above, N is the number of pages on the web. At the time PageRank was de- veloped, that was in the tens or hundreds of billions and it has skyrocketed since, so the value of N 2 would be far more than 10 20. No one can afford that much time or space, so a better algorithm is needed.
Fortunately, it is also often the case that the matrix is sparse: a huge number of its entries are 0. Indeed, for the Google application, the av- erage number of nonzero entries per row is a small constant: virtual- ly all web pages have links to only a few others (not all the pages on the web). Accordingly, we can represent the matrix as an array of sparse vec- tors, using a SparseVector imple- mentation like the HashST client on the facing page. Instead of using the
   ...
  double[][] a = new double[N][N];
  double[] x = new double[N];
  double[] b = new double[N];
  ...
  // Initialize a[][] and x[].
  ...
  for (int i = 0; i < N; i++)
  {
     sum = 0.0;
     for (int j = 0; j < N; j++)
        sum += a[i][j]*x[j];
     b[i] = sum;
}
Standard implementation of matrix-vector multiplication
 www.it-ebooks.info

  Sparse vector with dot product
  public class SparseVector
  {
     private HashST<Integer, Double> st;
     public SparseVector()
      {  st = new HashST<Integer, Double>();  }
     public int size()
     {  return st.size();  }
     public void put(int i, double x)
      {  st.put(i, x);  }
     public double get(int i)
     {
        if (!st.contains(i)) return 0.0;
        else return st.get(i);
     }
     public double dot(double[] that)
     {
         double sum = 0.0;
         for (int i : st.keys())
             sum += that[i]*this.get(i);
         return sum;
} }
This symbol-table client is a bare-bones sparse vector implementation that illustrates an ef cient dot product for sparse vectors. We multiply each entry by its counterpart in the other operand and add the result to a running sum. The number of multiplications required is equal to the number of nonzero entries in the sparse vector.
  www.it-ebooks.info
3.5 n Applications 503
504 Chapter 3 n Searching
array of double[]objects array of SparseVector objects
01234
01234 aa
00
1 0 1 2 3 4 1 st
2 23.90
3 3 4012344
01234
a[4][2]
Sparse matrix representations
codea[i][j]torefertotheelementinrowiandcolumnj,weusea[i].put(j, val) to set a value in the matrix and a[i].get(j) to retrieve a value. As you can see from the code below, matrix-vector multiplication using this class is even simpler than with the array representation (and it more clearly describes the computation). More important, it only requires time proportional to N plus the number of nonzero elements in the matrix.
For small matrices or matrices that are not sparse, the overhead for maintaining symbol tables can be substantial, but it is worth your while to be sure to understand the rami cations of using symbol tables for huge sparse matrices. To  x ideas, consider a huge application (like the one faced by Brin and
st
   1
 .90
    0.0
  .90
 0.0
 0.0
 0.0
   key value
independent symbol-table objects
   st
   2
 .36
 3
   .36
   4
   .18
  0.0
  0.0
 .36
 .36
 .18
                     0.0
0.0
0.0
.90
0.0
          st
   0
 .90
    .90
  0.0
 0.0
 0.0
 0.0
 st
   0
 .45
 2
  .45
  .45
  0.0
 .45
   0.0
 0.0
  Page) where N is 10 billion or 100 billion, but the average number of nonzero elements per row is less than 10. For such an application, using sym- bol tables speeds up matrix-vector multiplication by a factor of a billion or more. The elementary na- ture of this application should not detract from its importance: programmers who do not take advantage of the potential to save time and space in this way severely limit their potential to solve practical problems, while programmers who do
 ..
SparseVector[] a;
a = new SparseVector[N];
double[] x = new double[N];
double[] b = new double[N];
...
// Initialize a[] and x[].
...
for (int i = 0; i < N; i++)
   b[i] = a[i].dot(x);
www.it-ebooks.info
Sparse matrix-vector multiplication

take factor-of-a-billion speedups when they are available are likely to be able to address problems that could not otherwise be contemplated.
Building the matrix for the Google application is a graph-processing application (and a symbol-table client!), albeit for a huge sparse matrix. Given the matrix, the Page- Rank calculation is nothing more than doing a matrix-vector multiplication, replacing the source vector with the result vector, and iterating the process until it converges (as guaranteed by fundamental theorems in probability theory). Thus, the use of a class like SparseVector can improve the time and space usage for this application by a fac- tor of 10 billion or 100 billion or more.
Similar savings are possible in many scienti c calculations, so sparse vectors and ma- trices are widely used and typically incorporated into specialized systems for scienti c computing. When working with huge vectors and matrices, it is wise to run simple per- formance tests to be sure that the kinds of performance gains that we have illustrated here are not being missed. On the other hand, array processing for primitive types of data is built into most programming languages, so using arrays for vectors that are not sparse, as we did in this example, may offer further speedups. Developing a good understanding of the underlying costs and making the appropriate implementation decisions is certainly worthwhile for such applications.
Symbol tables are a primary contribution of algorithmic technology to the development of our modern computational infrastructure because of their ability to deliver savings on a huge scale in a vast array of practical applications, making the dif- ference between providing solutions to a wide range of problems and not being able to address them at all. Few  elds of science or engineering involve studying the effects of an invention that improves costs by factors of 100 billion—symbol-table applica- tions put us in just that position, as we have just seen in several examples, and these improvements have had profound effects. The data structures and algorithms that we have considered are certainly not the  nal word: they were all developed in just a few decades, and their properties are not fully understood. Because of their importance, symbol-table implementations continue to be studied intensely by researchers around the world, and we can look forward to new developments on many fronts as the scale and scope of the applications they address continue to expand.
www.it-ebooks.info
3.5 n Applications 505

506 Chapter 3 n Searching
 Q&A
 Q. Can a SET contain null?
A. No. As with symbol tables, keys are non-null objects. Q. Can a SET be null?
A. No. A SET can be empty (contain no objects), but not null. As with any Java data type, a variable of type SET can have the value null, but that just indicates that it does not reference any SET. The result of using new to create a SET is always an object that is not null.
Q. If all my data is in memory, there is no real reason to use a  lter, right?
A. Right. Filtering really shines in the case when you have no idea how much data to
expect. Otherwise, it may be a useful way of thinking, but not a cure-all.
Q. I have data in a spreadsheet. Can I develop something like LookupCSV to search through it?
A. Yourspreadsheetapplicationprobablyhasanoptiontoexporttoa.csv le,soyou can use LookupCSV directly.
Q. Why would I need FileIndex? Doesn’t my operating system solve this problem?
A. If you are using an OS that meets your needs, continue to do so, by all means. As with many of our programs, FileIndex is intended to show you the basic underlying mechanisms of such applications and to suggest possibilities to you.
Q. Why not have the dot() method in SparseVector take a SparseVector object as argument and return a SparseVector object?
A. That is a  ne alternate design and a nice programming exercise that requires code that is a bit more intricate than for our design (see Exercise 3.5.16). For general matrix processing, it might be worthwhile to also add a SparseMatrix type.
www.it-ebooks.info

3.5.1 ImplementSETandHashSETas“wrapperclass”clientsofSTandHashST,respec- tively (provide dummy values and ignore them).
3.5.2 DevelopaSETimplementationSequentialSearchSETbystartingwiththecode for SequentialSearchST and eliminating all of the code involving values.
3.5.3 Develop a SET implementation BinarySearchSET by starting with the code for BinarySearchST and eliminating all of the code involving values.
3.5.4 Develop classes HashSTint and HashSTdouble for maintaining sets of keys of primitive int and double types, respectively. (Convert generics to primitive types in the code of LinearProbingHashST.)
3.5.5 Develop classes STint and STdouble for maintaining ordered symbol ta- bles where keys are primitive int and double types, respectively. (Convert generics to primitive types in the code of RedBlackBST.) Test your solution with a version of SparseVector as a client.
3.5.6 DevelopclassesHashSETintandHashSETdoubleformaintainingsetsofkeysof primitive int and double types, respectively. (Eliminate code involving values in your solution to Exercise 3.5.4.)
3.5.7 Develop classes SETint and SETdouble for maintaining ordered sets of keys of primitive int and double types, respectively. (Eliminate code involving values in your solution to Exercise 3.5.5.)
3.5.8 Modify LinearProbingHashST to keep duplicate keys in the table. Return any value associated with the given key for get(), and remove all items in the table that have keys equal to the given key for delete().
3.5.9 Modify BST to keep duplicate keys in the tree. Return any value associated with the given key for get(), and remove all nodes in the tree that have keys equal to the given key for delete().
3.5.10 ModifyRedBlackBSTtokeepduplicatekeysinthetree.Returnanyvalueassoci- ated with the given key for get(), and remove all nodes in the tree that have keys equal to the given key for delete().
www.it-ebooks.info
3.5 n Applications 507
 ExErcisEs

508 Chapter 3 n Searching ExErcisEs (continued)
3.5.11 DevelopaMultiSETclassthatislikeSET,butallowsequalkeysandthusimple- ments a mathematical multiset.
3.5.12 Modify LookupCSV to associate with each key all values that appear in a key- value pair with that key in the input (not just the most recent, as in the associative-array abstraction).
3.5.13 ModifyLookupCSVtomakeaprogramRangeLookupCSVthattakestwokeyval- ues from the standard input and prints all key-value pairs in the .csv  le such that the key falls within the range speci ed.
3.5.14 Develop and test a static method invert() that takes as argument an ST<String, Bag<String>>andproducesasreturnvaluetheinverseofthegivensym- bol table (a symbol table of the same type).
3.5.15 Writeaprogramthattakesastringonstandardinputandanintegerkascom- mand-line argument and puts on standard output a sorted list of the k-grams (sub- strings of length k) found in the string, each followed by its index in the string.
3.5.16 Addamethodsum()toSparseVectorthattakesaSparseVectorasargument and returns a SparseVector that is the term-by-term sum of this vector and the argu- ment vector. Note: You need delete() (and special attention to precision) to handle the case where an entry becomes 0.
 www.it-ebooks.info

3.5.17 Finite mathematical sets. Your goal is to develop an implementation of the fol- lowing API for processing  nite mathematical sets:
public class MathSET<Key> MathSET(Key[] universe)
void add(Key key) MathSET<Key> complement()
void union(MathSET<Key> a)
void intersection(MathSET<Key> a)
void delete(Key key) boolean contains(Key key) boolean isEmpty()
create the empty set (using given universe)
put key into the set
set of keys in the universe that
are not in this set
put any keys from a into the set that are not already there
remove any keys from this set that are not in a
remove key from the set is key in the set?
is the set empty?
number of keys in the set
3.5 n Applications 509
 crEAtivE problEms
    int size()
apI for a basic finite set data type
3.5.18 Multisets. After referring to Exercises 3.5.2 and 3.5.3 and the previous exer- cise, develop APIs MultiHashSET and MultiSET for multisets (sets that can have equal keys) and implementations SeparateChainingMultiSET and BinarySearchMultiSET for multisets and ordered multisets, respectively.
3.5.19 Equal keys in symbol tables. Consider the API MultiST (unordered or ordered) to be the same as our symbol-table APIs de ned on page 363 and page 366, but with equal keys allowed, so that the semantics of get() is to return any value associated with the given key, and we add a new method
    Iterable<Value> getAll(Key key)
www.it-ebooks.info

510 Chapter 3 n Searching
  that returns all values associated with the given key. Using our code for SeparateChainingHashST and BinarySearchST as a starting point, develop imple- mentations BinarySearchMultiST and SeparateChainingMultiST for these APIs.
3.5.20 Concordance. Write an ST client Concordance that puts on standard output a concordance of the strings in the standard input stream (see page 498).
3.5.21 Inverted concordance. Write a program InvertedConcordance that takes a concordance on standard input and puts the original string on standard output stream. Note : This computation is associated with a famous story having to do with the Dead Sea Scrolls. The team that discovered the original tablets enforced a secrecy rule that essentially resulted in their making public only a concordance. After a while, other re- searchers  gured out how to invert the concordance, and the full text was eventually made public.
3.5.22 Fully indexed CSV. Implement an ST client FullLookupCSV that builds an ar- ray of ST objects (one for each  eld), with a test client that allows the user to specify the key and value  elds in each query.
3.5.23 Sparse matrices. Develop an API and an implementation for sparse 2D matri- ces. Support matrix addition and matrix multiplication. Include constructors for row and column vectors.
3.5.24 Non-overlapping interval search. Given a list of non-overlapping intervals of items, write a function that takes an item as argument and determines in which, if any, interval that item lies. For example, if the items are integers and the intervals are 1643-2033, 5532-7643, 8999-10332, 5666653-5669321, then the query point 9122 lies in the third interval and 8122 lies in no interval.
3.5.25 Registrar scheduling. The registrar at a prominent northeastern University re- cently scheduled an instructor to teach two different classes at the same exact time. Help the registrar prevent future mistakes by describing a method to check for such con icts. For simplicity, assume all classes run for 50 minutes starting at 9:00, 10:00, 11:00, 1:00, 2:00, or 3:00.
3.5.26 LRU cache. Create a data structure that supports the following operations: ac- cess and remove. The access operation inserts the item onto the data structure if it’s not already present. The remove operation deletes and returns the item that was least
www.it-ebooks.info
 crEAtivE problEms (continued)
  recently accessed. Hint : Maintain the items in order of access in a doubly linked list, along with pointers to the  rst and last nodes. Use a symbol table with keys = items, values = location in linked list. When you access an element, delete it from the linked list and reinsert it at the beginning. When you remove an element, delete it from the end and remove it from the symbol table.
3.5.27 List. Develop an implementation of the following API: public class List<Item> implements Iterable<Item>
3.5 n Applications 511
  List()
void addFront(Item item) void addBack(Item item) Item deleteFront()
Item deleteBack()
void delete(Item item) void add(int i, Item item) Item delete(int i)
boolean contains(Item item) boolean isEmpty()
int size()
apI for a list data type
Hint : Use two symbol tables, one to  nd the ith item in the list ef ciently, and the other to ef ciently search by item. (Java’s java.util.List interface contains methods like these but does not supply any implementation that ef ciently supports all operations.)
3.5.28 UniQueue. Create a data type that is a queue, except that an element may only be inserted the queue once. Use an existence symbol table to keep track of all elements that have ever been inserted and ignore requests to re-insert such items.
www.it-ebooks.info
create a list
add item to the front
add item to the back
remove from the front
remove from the back
remove item from the list
add item as the ith in the list remove the ith item from the list is item in the list?
is the list empty?
number of items in the list

512 Chapter 3 n Searching
crEAtivE problEms (continued)
3.5.29 Symbol table with random access. Create a data type that supports inserting a key-value pair, searching for a key and returning the associated value, and deleting and returning a random key. Hint : Combine a symbol table and a randomized queue (see Exercise 1.3.35).
 www.it-ebooks.info

3.5.30 Duplicates (revisited). Redo Exercise 2.5.31 using the Dedup  lter given on page 490. Compare the running times of the two approaches. Then use Dedup to run the experiments for N = 10 7, 10 8, and10 9, repeat the experiments for random long values and discuss the results.
3.5.31 Spell checker. With the  le dictionary.txt from the booksite as command- line argument, the BlackFilter client described onpage 491 prints all misspelled words in a text  le taken from standard input. Compare the performance of RedBlackBST, SeparateChainingHashST, and LinearProbingHashST for the  le WarAndPeace.txt (available on the booksite) with this client and discuss the results.
3.5.32 Dictionary. Study the performance of a client like LookupCSV in a scenario where performance matters. Speci cally, design a query-generation scenario instead of taking commands from standard input, and run performance tests for large inputs and large numbers of queries.
3.5.33 Indexing. Study a client like LookupIndex in a scenario where performance matters. Speci cally, design a query-generation scenario instead of taking commands from standard input, and run performance tests for large inputs and large numbers of queries.
3.5.34 Sparse vector. Run experiments to compare the performance of matrix-vector multiplication using SparseVector to the standard implementation using arrays.
3.5.35 Primitive types. Evaluate the utility of using primitive types for Integer and Double values, for LinearProbingHashST and RedBlackBST. How much space and time are saved, for large numbers of searches in large tables?
www.it-ebooks.info
3.5 n Applications 513
 ExpErimENts

This page intentionally left blank
www.it-ebooks.info

Introduction to Programming in Java: An Interdisciplinary Approach
Robert Sedgewick/Kevin Wayne ©2008 • 736 pp • ISBN: 0-321-49805-4
Introduction to Programming in Java takes an inter- disciplinary approach to teaching programming with the Java programming language.
Features
This book thoroughly covers the field and is ideal for introductory programming courses. It can also be used for courses that integrate programming with mathematics, science, or engineering.
Students learn basic computer science concepts in the context of interesting applications in science, engineering, and commercial computing, leveraging familiar science and math while preparing students to use computers effectively in later courses. This serves to demonstrate that computation is not merely a tool, but an integral part of the modern world that pervades scientific inquiry and commercial development.
The book takes an “objects in the middle” approach where students learn basic control structures and functions, then how to use, create, and design classes.
A full programming model includes standard libraries for input, graphics, sound, and image processing that students can immediately put to use.
An integrated Companion Website features extensive Java coding examples, additional exercises, and Web links.
Instructors, contact your Pearson representative to receive an exam copy,
or email PearsonEd.CS@Pearson.com.
 www.it-ebooks.info

                THIS PRODUCT informit.com/register
Register the Addison-Wesley, Exam Cram, Prentice Hall, Que, and Sams products you own to unlock great benefits.
To begin the registration process, simply go to informit.com/register to sign in or create an account.
You will then be prompted to enter the 10- or 13-digit ISBN that appears on the back cover of your product.
Registering your products can unlock the following benefits:
• Access to supplemental content, including bonus chapters, source code, or project files.
• A coupon to be used on your next purchase.
Registration benefits vary by product. Benefits will be listed on your Account page under Registered Products.
  About InformIT — THE TRUSTED TECHNOLOGY LEARNING SOURCE
INFORMIT IS HOME TO THE LEADING TECHNOLOGY PUBLISHING IMPRINTS Addison-Wesley Professional, Cisco Press, Exam Cram, IBM Press, Prentice Hall Professional, Que, and Sams. Here you will gain access to quality and trusted content and resources from the authors, creators, innovators, and leaders of technology. Whether you’re looking for a book on a new technology, a helpful article, timely newsletters, or access to the Safari Books Online digital library, InformIT has a solution for you.
informIT.com
THE TRUSTED TECHNOLOGY LEARNING SOURCE SAFARI BOOKS ONLINE
 www.it-ebooks.info
Addison-Wesley | Cisco Press | Exam Cram IBM Press | Que | Prentice Hall | Sams

 informIT.com THE TRUSTED TECHNOLOGY LEARNING SOURCE
InformIT is a brand of Pearson and the online presence
for the world’s leading technology publishers. It’s your source for reliable and qualified content and knowledge, providing access to the top brands, authors, and contributors from
the tech community.
LearnIT at InformIT
Looking for a book, eBook, or training video on a new technology? Seeking timely and relevant information and tutorials? Looking for expert opinions, advice, and tips? InformIT has the solution.
• Learn about new releases and special promotions by subscribing to a wide variety of newsletters.
Visit informit.com/newsletters.
• Access FREE podcasts from experts at informit.com/podcasts.
• Read the latest author articles and sample chapters at
informit.com/articles.
• Access thousands of books and videos in the Safari Books
Online digital library at safari.informit.com.
• Get tips from expert blogs at informit.com/blogs.
Visit informit.com/learn to discover all the ways you can access the hottest technology content.
Are You Part of the IT Crowd?
Connect with Pearson authors and editors via RSS feeds, Facebook,
Twitter, YouTube, and more! Visit informit.com/socialconnect.
informIT.com THE TRUSTED TECHNOLOGY LEARNING SOURCE
                                                                                                                                                                                                www.it-ebooks.info

                                                                                                                                                                                        Try Safari Books Online FREE
Get online access to 5,000+ Books and Videos
  FREE TRIAL—GET STARTED TODAY!
www.informit.com/safaritrial
                     Find trusted answers, fast
Only Safari lets you search across thousands of best-selling books from the top technology publishers, including Addison-Wesley Professional, Cisco Press, O’Reilly, Prentice Hall, Que, and Sams.
Master the latest tools and techniques
In addition to gaining access to an incredible inventory of technical books, Safari’s extensive collection of video tutorials lets you learn from the leading video training experts.
WAIT, THERE’S MORE!
Keep your competitive edge
With Rough Cuts, get access to the developing manuscript and be among the first to learn the newest technologies.
Stay current with emerging technologies
Short Cuts and Quick Reference Sheets are short, concise, focused content created to get you up-to-speed quickly on new and cutting-edge technologies.
                                                                                                                                                                                                                                                     www.it-ebooks.info
